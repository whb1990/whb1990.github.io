{"pages":[{"title":"Zookeeper知识点","url":"/posts/f9f2d4de.html","text":"简介ZooKeeper是一个典型的分布式数据一致性的解决方案。分布式应用程序可以基于它实现诸如 数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、分布式锁和分布式队列等功能。ZooKeeper可以保证如下分布式一致性特性： 顺序一致性：从同一个客户端发起的事务请求，最终将会严格按照其发起顺序被应用到ZooKeeper中。 原子性：所有事务请求的结果在集群中所有机器上的应用情况是一致的，也就是说要么整个集群都成功应用了某一个事务，要么都没有应用，一定不会出现集群中部分机器应用了该事务，而另外一部分没有应用的情况。 单一视图：无论客户端连接的是哪个ZooKeeper服务器，其看到的服务端数据模型都是一致的。 可靠性：一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会被一直保留下来，除非有另一个事务又对其进行了变更。 实时性：通常人们看到实时性的第一反应是，一旦一个事务被成功应用，那么客户端能够立即从服务端上读取到这个事务变更后的最新数据状态。这里需要注意的是，ZooKeeper仅仅保证在一定的时间段内，客户端最终一定能够从服务端上读取到最新的数据状态。 Zookeeper角色在ZooKeeper中，有三种角色： Leader Follower Observer 一个ZooKeeper集群同一时刻只会有一个Leader，其他都是Follower或Observer。 ZooKeeper配置很简单，每个节点的配置文件(zoo.cfg)都是一样的，只有myid文件不一样。myid的值必须是zoo.cfg中server.{数值}的{数值}部分。 zoo.cfg文件内容示例： 12345678910111213141516171819202122maxClientCnxns=0# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial# synchronization phase can takeinitLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.dataDir=/var/lib/zookeeper/data# the port at which the clients will connectclientPort=2181# the directory where the transaction logs are stored.dataLogDir=/var/lib/zookeeper/logsserver.1=192.168.20.101:2888:3888server.2=192.168.20.102:2888:3888server.3=192.168.20.103:2888:3888server.4=192.168.20.104:2888:3888server.5=192.168.20.105:2888:3888minSessionTimeout=4000maxSessionTimeout=100000 在装有ZooKeeper的机器的终端执行 zookeeper-server status 可以看当前节点的ZooKeeper是什么角色（Leader or Follower）。 12345678[root@node-20-103 ~]# zookeeper-server statusJMX enabled by defaultUsing config: /etc/zookeeper/conf/zoo.cfgMode: follower[root@node-20-104 ~]# zookeeper-server statusJMX enabled by defaultUsing config: /etc/zookeeper/conf/zoo.cfgMode: leader 如上，node-20-104是Leader，node-20-103是follower。 ZooKeeper默认只有Leader和Follower两种角色，没有Observer角色。为了使用Observer模式，在任何想变成Observer的节点的配置文件中加入：peerType=observer 并在所有server的配置文件中，配置成observer模式的server的那行配置追加:observer，例如： 1server.1:localhost:2888:3888:observer ZooKeeper集群的所有机器通过一个Leader选举过程来选定一台被称为『Leader』的机器，Leader服务器为客户端提供读和写服务。Follower和Observer都能提供读服务，不能提供写服务。两者唯一的区别在于，Observer机器不参与Leader选举过程，也不参与写操作的『过半写成功』策略，因此Observer可以在不影响写性能的情况下提升集群的读性能。 会话Session在ZooKeeper中，一个客户端连接是指客户端和ZooKeeper服务器之间的TCP长连接。ZooKeeper对外的服务端口默认是2181，客户端启动时，首先会与服务器建立一个TCP连接，从第一次连接建立开始，客户端会话的生命周期也开始了，通过这个连接，客户端能够通过心跳检测和服务器保持有效的会话，也能够向ZooKeeper服务器发送请求并接受响应，同时还能通过该连接接收来自服务器的Watch事件通知。Session的SessionTimeout值用来设置一个客户端会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在SessionTimeout规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。","tags":"zookeeper"},{"title":"MySQL问题排查SQL","url":"/posts/81d4f14b.html","text":"查看当前应用连接，连接数突增排查1select user,SUBSTRING_INDEX(host,':',1) as ip , count(*) as count,db from information_schema.processlist where host not in ('localhost') and user not in ('replicater') group by ip order by count; 查看表所属及大概行数，一般加字段索引时做参考1select TABLE_SCHEMA,TABLE_NAME,TABLE_ROWS from information_schema.tables where TABLE_NAME='表名'; 查看表碎片，是否需要整理表释放物理空间1select table_name,table_rows,concat(round(DATA_LENGTH/1024/1024, 2), 'MB') as size,DATA_FREE/1024/1024 AS data_free_MB from information_schema.TABLES where table_schema='库名' order by DATA_LENGTH desc; 当前有没有锁1select * from information_schema.innodb_locks; 当前锁堵塞情况1select * from information_schema.innodb_lock_waits; 当前锁等待详细信息1select it.trx_mysql_thread_id, il.lock_id, il.lock_table, il.lock_mode, il.lock_type, it.trx_state, pl.USER||'@'||pl.HOST as user_host, pl.db, pl.command, pl.info, it.trx_started, it.trx_wait_started, now()-trx_wait_started as wait_seconds, il.lock_index, it.trx_weight, it.trx_rows_locked, it.trx_rows_modified from information_schema.INNODB_TRX it,information_schema.innodb_locks il,information_schema.processlist pl where it.trx_id = il.lock_trx_id and it.trx_mysql_thread_id = pl.id\\G 最近一次死锁、未提交事物、CHECKPIONT、BUFFER POOL等1show engine innodb status\\G 过滤无用线程信息可用pager1pager grep -v Sleep;show processlist; 查看当前运行的详细SQL1SELECT * FROM INFORMATION_SCHEMA.PROCESSLIST WHERE info is not null\\G 查看某条sql各阶段执行时间，可开启profiling功能1set global profiling=on; 查看用户信息1select user,host,authentication_string from mysql.user group by user; 查看哪些sql执行最多次1SELECT SCHEMA_NAME,DIGEST_TEXT,COUNT_STAR,SUM_ROWS_SENT,SUM_ROWS_EXAMINED,FIRST_SEEN,LAST_SEEN FROM performance_schema.events_statements_summary_by_digest where SCHEMA_NAME is not null and SCHEMA_NAME !='information_schema' ORDER BY COUNT_STAR desc LIMIT 1; 哪个SQL扫描的行数最多(IO消耗)1SELECT SCHEMA_NAME,DIGEST_TEXT,COUNT_STAR,AVG_TIMER_WAIT,SUM_ROWS_SENT,SUM_ROWS_EXAMINED,FIRST_SEEN,LAST_SEEN FROM performance_schema.events_statements_summary_by_digest where SCHEMA_NAME is not null and SCHEMA_NAME !='information_schema' ORDER BY SUM_ROWS_EXAMINED desc LIMIT 1\\G 哪个SQL使用的临时表最多1SELECT SCHEMA_NAME,DIGEST_TEXT,SUM_CREATED_TMP_DISK_TABLES,SUM_CREATED_TMP_TABLES,FIRST_SEEN,LAST_SEEN FROM performance_schema.events_statements_summary_by_digest where SCHEMA_NAME is not null and SCHEMA_NAME !='information_schema' ORDER BY SUM_CREATED_TMP_DISK_TABLES desc LIMIT 1\\G 哪个SQL返回的结果集最多(net消耗)1SELECT SCHEMA_NAME,DIGEST_TEXT,COUNT_STAR,SUM_ROWS_SENT,SUM_ROWS_SENT,FIRST_SEEN,LAST_SEEN FROM performance_schema.events_statements_summary_by_digest where SCHEMA_NAME is not null and SCHEMA_NAME !='information_schema' ORDER BY SUM_ROWS_SENT desc LIMIT 1\\G 哪个SQL排序数最多(CPU消耗)1SELECT SCHEMA_NAME,DIGEST_TEXT,COUNT_STAR,SUM_ROWS_SENT,SUM_SORT_ROWS,FIRST_SEEN,LAST_SEEN FROM performance_schema.events_statements_summary_by_digest where SCHEMA_NAME is not null and SCHEMA_NAME !='information_schema' ORDER BY SUM_SORT_ROWS desc LIMIT 1\\G","tags":"数据库 mysql"},{"title":"DevOps初识","url":"/posts/230bf701.html","text":"背景DevOps的出现有其必然性。在软件开发生命周期中，遇到了两次瓶颈。 第一次瓶颈是在需求阶段和开发阶段之间，针对不断变化的需求，对软件开发者提出了高要求，后来出现了敏捷方法论，强调适应需求、快速迭代、持续交付。 第二个瓶颈是在开发阶段和构建部署阶段之间，大量完成的开发任务可能阻塞在部署阶段，影响交付，于是有了DevOps。 概念DevOps一词的来自于Development和Operations的组合，突出重视软件开发人员和运维人员的沟通合作，通过自动化流程来使得软件构建、测试、发布更加快捷、频繁和可靠。 DevOps是为了填补开发端和运维端之间的信息鸿沟，改善团队之间的协作关系。不过需要澄清的一点是，从开发到运维，中间还有测试环节。DevOps其实包含了三个部分：开发、测试和运维。 换句话说，DevOps希望做到的是软件产品交付过程中IT工具链的打通，使得各个团队减少时间损耗，更加高效地协同工作。专家们总结出了下面这个DevOps能力图，良好的闭环可以大大增加整体的产出。 持续集成持续集成强调开发人员提交了新代码之后，立刻进行构建、（单元）测试。根据测试结果，可以确定新代码和原有代码能否正确地集成在一起。 持续交付持续交付在持续集成的基础上，将集成后的代码部署到更贴近真实运行环境的「类生产环境」（production-like environments）中。比如，我们完成单元测试后，可以把代码部署到连接数据库的 Staging 环境中更多的测试。如果代码没有问题，可以继续手动部署到生产环境中。 持续部署持续部署则是在持续交付的基础上，把部署到生产环境的过程自动化。 几个关键问题好处是什么？ DevOps的一个巨大好处就是可以高效交付，这也正好是它的初衷。 Puppet和DevOps Research and Assessment (DORA) 主办了2016年DevOps调查报告，根据全球4600位各IT公司的技术工作者的提交数据统计，得出高效公司平均每年可以完成1460次部署。 与低效组织相比，高效组织的部署频繁200倍，产品投入使用速度快2555倍，服务恢复速度快24倍。在工作内容的时间分配上，低效者要多花22%的时间用在为规划好或者重复工作上，而高效者却可以多花29%的时间用在新的工作上。所以这里的高效不仅仅指公司产出的效率提高，还指员工的工作质量得到提升。 另外一个好处就是会改善公司组织文化、提高员工的参与感。 员工们变得更高效，也更有满足和成就感；调查显示高效员工的雇员净推荐值（eNPS:employee Net Promoter Score）更高，即对公司更加认同。 快速部署同时提高IT稳定性，这不矛盾吗？快速的部署其实可以帮助更快地发现问题，产品被更快地交付到用户手中，团队可以更快地得到用户的反馈，从而进行更快地响应。而且，DevOps小步快跑的形式带来的变化是比较小的，出现问题的偏差每次都不会太大，修复起来也会相对容易一些。 三原则基础设施即代码（Infrastructure as Code）DeveOps的基础是将重复的事情使用自动化脚本或软件来实现，例如Docker（容器化）、Jenkins（持续集成）、Puppet（基础架构构建）、Vagrant（虚拟化平台）等。 持续交付（Continuous Delivery）持续交付是在生产环境发布可靠的软件并交付给用户使用。而持续部署则不一定交付给用户使用。 涉及到2个时间，TTR（Time to Repair）修复时间，TTM（Time To Marketing）产品上线时间。要做到高效交付可靠的软件，需要尽可能的减少这2个时间。 部署可以有多种方式，比如蓝绿部署、金丝雀部署等。 协同工作（Culture of Collaboration）开发者和运维人员必须定期进行密切的合作。开发应该把运维角色理解成软件的另一个用户群体。协作有几个的建议： 自动化（减少不必要的协作）； 小范围（每次修改的内容不宜过多，减少发布的风险）； 统一信息集散地（如wiki，让双方能够共享信息）； 标准化协作工具（比如jenkins）。 怎么实现DevOps硬性要求：工具上的准备 代码管理（SCM）：GitHub、GitLab、BitBucket、SubVersion构建工具：Ant、Gradle、maven自动部署：Capistrano、CodeDeploy持续集成（CI）：Bamboo、Hudson、Jenkins配置管理：Ansible、Chef、Puppet、SaltStack、ScriptRock GuardRail容器：Docker、LXC、第三方厂商如AWS编排：Kubernetes、Core、Apache Mesos、DC/OS服务注册与发现：Zookeeper、etcd、Consul脚本语言：python、ruby、shell日志管理：ELK、Logentries系统监控：Datadog、Graphite、Icinga、Nagios、zabbix性能监控：AppDynamics、New Relic、Splunk压力测试：JMeter、Blaze Meter、loader.io预警：PagerDuty、pingdom、厂商自带如AWS SNSHTTP加速器：Varnish消息总线：ActiveMQ、SQS应用服务器：Tomcat、JBossWeb服务器：Apache、Nginx、IIS数据库：MySQL、Oracle、PostgreSQL等关系型数据库；cassandra、mongoDB、redis等NoSQL数据库项目管理（PM）：Jira、Asana、Taiga、Trello、Basecamp、Pivotal Tracker 在工具的选择上，需要结合公司业务需求和技术团队情况而定。 软性需求：文化和人DevOps成功与否，公司组织是否利于协作是关键。开发人员和运维人员可以良好沟通互相学习，从而拥有高生产力。并且协作也存在于业务人员与开发人员之间。 出席了2016年伦敦企业级DevOps峰会的ITV公司在2012年就开始落地DevOps，其通用平台主管Clark在接受了InfoQ的采访，在谈及成功时表示，业务人员非常清楚他们希望在最小化可行产品中实现什么，工程师们就按需交付，不做多余工作。 这样，工程师们使用通用的平台（即打通的工具链）得到更好的一致性和更高的质量。此外，DevOps对工程师个人的要求也提高了，很多专家也认为招募到优秀的人才也是一个挑战。","tags":"devops"},{"title":"分布式学习-分布式事务","url":"/posts/464cb56d.html","text":"事务定义事务提供一种机制将一个活动涉及的所有操作纳入到一个不可分割的执行单元，组成事务的所有操作只有在所有操作均能正常执行的情况下方能提交，只要其中任一操作执行失败，都将导致整个事务的回滚。简单地说，事务提供一种“要么什么都不做，要么做全套（All or Nothing）”机制。 数据库事务特性（ACID）A:原子性(Atomicity)一个事务(transaction)中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 例如：银行转账，从A账户转100元至B账户，分为两个步骤： （1）从A账户取100元（2）存入100元至B账户。这两步要么一起完成，要么一起不完成，如果只完成第一步，第二步失败，钱会莫名其妙少了100元。 C:一致性(Consistency)事务的一致性指的是在一个事务执行之前和执行之后数据库都必须处于一致性状态。如果事务成功地完成，那么系统中所有变化将正确地应用，系统处于有效状态。如果在事务中出现错误，那么系统中的所有变化将自动地回滚，系统返回到原始状态。 例如：现有完整性约束A+B=100，如果一个事务改变了A，那么必须得改变B，使得事务结束后依然满足A+B=100，否则事务失败。 I:隔离性(Isolation)指的是在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。事务查看数据更新时，数据所处的状态要么是另一事务修改它之前的状态，要么是另一事务修改它之后的状态，事务不会查看到中间状态的数据。 例如：现有有个交易是从A账户转100元至B账户，在这个交易事务还未完成的情况下，如果此时B查询自己的账户，是看不到新增加的100元的。 D:持久性(Durability)事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。即使发生系统崩溃，重新启动数据库系统后，数据库还能恢复到事务成功结束时的状态。 打个比方，你买东西的时候需要记录在账本上，即使老板忘记了那也有据可查。 数据库事务实现原理以MySQL的InnoDB为例，事务的ACID是通过InnoDB日志和锁来保证。 事务的隔离性是通过数据库锁的机制实现的，持久性通过redo log（重做日志）来实现，原子性和一致性通过Undo log来实现。 UndoLog的原理很简单，为了满足事务的原子性，在操作任何数据之前，首先将数据备份到一个地方（这个存储数据备份的地方称为UndoLog）。然后进行数据的修改。如果出现了错误或者用户执行了ROLLBACK语句，系统可以利用Undo Log中的备份将数据恢复到事务开始之前的状态。 和Undo Log相反，RedoLog记录的是新数据的备份。在事务提交前，只要将RedoLog持久化即可，不需要将数据持久化。当系统崩溃时，虽然数据没有持久化，但是RedoLog已经持久化。系统可以根据RedoLog的内容，将所有数据恢复到最新的状态。 什么时候使用数据库事务简单而言，就是业务上有一组数据操作，需要如果其中有任何一个操作执行失败，整组操作全部不执行并恢复到未执行状态，要么全部成功，要么全部失败。 在使用数据库事务时需要注意，尽可能短的保持事务，修改多个不同表的数据的冗长事务会严重妨碍系统中的所有其他用户，这很有可能导致一些性能问题。 分布式理论CAP理论 一致性（Consistency）：分布式数据库的数据保持一致。 可用性（Availability）：任何一个节点挂了，其他节点可以继续对外提供服务。 分区容错性（网络分区）Partition tolerance：一个数据库所在的机器坏了，如硬盘坏了，数据丢失了，可以新增一台机器，然后从其他正常的机器把备份的数据同步过来。 在分布式系统中，一致性（Consistency）、可用性（Availability）和分区容忍性（Partition Tolerance）3 个要素最多只能同时满足两个，不可兼得。其中，分区容忍性又是不可或缺的。 CA(放弃P)：将所有的数据放在一个节点。满足一致性、可用性。比如传统的关系型数据库。 AP(放弃C)：放弃强一致性，用最终一致性来保证。比如Zookeeper。 CP(放弃A)：一旦系统遇到故障，受到影响的服务器需要等待一段时间，在恢复期间无法对外提供服务。比如Redis等。 CAP理论举例：有3台机器分别有3个数据库分别有两张表,数据都是一样的Machine1-db1-tbl_person、tbl_orderMachine2-db2-tbl_person、tbl_orderMachine3-db3-tbl_person、tbl_order 1）当向machine1的db1的表tbl_person、tbl_order插入数数据时，同时要把插入的数据同步到machine2、machine3，这就是一致性。2）当其中的一台机器宕机了，可以继续对外提供服务，把宕机的机器重新启动起来可以继续服务，这就是可用性。3）当machine1的机器坏了，数据全部丢失了，不会有任何问题，因为machine2和machine3上还有数据，重新加一台机器machine4，把machine2和machine3其中一台机器的备份数据同步过来就可以了，这就是分区容错性。 为什么三个不能同时满足?虽然 CAP 理论定义是三个要素中只能取两个，但放到分布式环境下来思考，会发现必须选择 P（分区容忍）要素，因为网络本身无法做到 100% 可靠，有可能出故障，所以分区是一个必然的现象。 如果选择了 CA（一致性 + 可用性） 而放弃了 P（分区容忍性），那么当发生分区现象时，为了保证 C（一致性），系统需要禁止写入，当有写入请求时，系统返回 error（例如，当前系统不允许写入），这又和 A(可用性) 冲突了，因为 A（可用性）要求返回 no error 和 no timeout。 因此，分布式系统理论上不可能选择 CA （一致性 + 可用性）架构，只能选择 CP（一致性 + 分区容忍性） 或者 AP （可用性 + 分区容忍性）架构，在一致性和可用性做折中选择。 主要解释一下为什么在满足分区容错性的条件下，可用性与一致性不能同时满足。一致性要求所有节点数据都一致时再响应客户端请求，那么一旦发生节点宕机或者网络隔离，就需要等待节点恢复或者网络恢复或者集群重新调整节点数目等等，才能满足一致性；在这段时间，服务是不可用的。相反如果想要在这种状态下，服务继续可用，便需要牺牲一致性。 顺便一提，CAP理论中是忽略网络延迟，也就是当事务提交时，从节点A复制到节点B，但是在现实中这个是明显不可能的，所以总会有一定的时间是不一致。同时CAP中选择两个，比如你选择了CP，并不是叫你放弃A。因为P出现的概率实在是太小了，大部分的时间你仍然需要保证CA。就算分区出现了你也要为后来的A做准备，比如通过一些日志的手段，是其他机器回复至可用。 CAP理论告诉我们分布式系统只能选择AP或者CP，但实际上并不是说整个系统只能选择AP或者CP，在 CAP 理论落地实践时，我们需要将系统内的数据按照不同的应用场景和要求进行分类，每类数据选择不同的策略（CP 还是 AP），而不是直接限定整个系统所有数据都是同一策略。 另外，只能选择CP或者AP是指系统发生分区现象时无法同时保证C（一致性）和A（可用性），但不是意味着什么都不做，当分区故障解决后，系统还是要保持保证CA。 BASE理论BASE 是 Basically Available(基本可用)、Soft state(软状态)和 Eventually consistent (最终一致性)三个短语的缩写。是对CAP中AP的一个扩展 基本可用:分布式系统在出现故障时，允许损失部分可用功能，保证核心功能可用。比如服务降级、页面降级。 软状态:允许系统中存在中间状态，这个状态不影响系统可用性。 这里的中间状态是指不同的data replication之间的数据更新可以出现延时的最终一致性。 如CAP理论里面的示例，当向machine1的db1的表tbl_person、tbl_order插入数数据时，同时要把插入的数据同步到machine2、machine3，当machine3的网络有问题时，同步失败，但是过一会网络恢复了就同步成功了，这个同步失败的状态就称为软状态，因为最终还是同步成功了。 最终一致:最终一致是指经过一段时间后，所有节点数据都将会达到一致。 BASE解决了CAP中理论没有网络延迟，在BASE中用软状态和最终一致，保证了延迟后的一致性。BASE和 ACID 是相反的，它完全不同于ACID的强一致性模型，而是通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。 数据一致性模型数据的一致性模型可以分成以下 3 类： 强一致性：数据更新成功后，任意时刻所有副本中的数据都是一致的，一般采用同步的方式实现。 弱一致性：数据更新成功后，系统不承诺立即可以读到最新写入的值，也不承诺具体多久之后可以读到。 最终一致性：弱一致性的一种形式，数据更新成功后，系统不承诺立即可以返回最新写入的值，但是保证最终会返回上一次更新操作的值。 分布式事务什么是分布式事务分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了保证不同数据库的数据一致性。 举个互联网常用的交易业务为例： 上图中包含了库存和订单两个独立的微服务，每个微服务维护了自己的数据库。在交易系统的业务逻辑中，一个商品在下单之前需要先调用库存服务，进行扣除库存，再调用订单服务，创建订单记录。 可以看到，如果多个数据库之间的数据更新没有保证事务，将会导致出现子系统数据不一致，业务出现问题。 分布式事务解决方案2PC2PC = Two Phase commit 二阶段提交（RDBMS（关系型数据库管理系统）经常就是这种机制，保证强一致性）。 在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有节点（称作参与者）的操作结果并最终指示这些节点是否要把操作结果进行真正的提交。 算法思路参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。 核心思想对每一个事务都采用先尝试后提交的处理方式，处理后所有的读操作都要能获得最新的数据，因此也可以将二阶段提交看作是一个强一致性算法。 处理流程 阶段1：提交事务请求（投票阶段）询问是否可以提交事务 进一步将准备阶段分为以下三个步骤： 1）协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应。2）参与者节点执行询问发起为止的所有事务操作，并将Undo信息和Redo信息写入日志。（注意：若成功这里其实每个参与者已经执行了事务操作）3）各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个”同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个”中止”消息。 阶段2：执行事务提交（commit、rollback） 真正的提交事务 如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源)。 当协调者节点从所有参与者节点获得的响应消息都为”同意”时:1）协调者节点向所有参与者节点发出”正式提交(commit)”的请求。2）参与者节点正式完成操作，并释放在整个事务期间内占用的资源。3）参与者节点向协调者节点反馈ack(应答)”完成”消息。4）协调者节点收到所有参与者节点反馈的ack应答”完成”消息后，完成事务。 如果任一参与者节点在第一阶段返回的响应消息为”中止”，或者 协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时：1）协调者节点向所有参与者节点发出”回滚操作(rollback)”的请求。2）参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源。3）参与者节点向协调者节点发送”回滚完成”消息。4）协调者节点收到所有参与者节点反馈的”回滚完成”消息后，取消事务。 不管最后结果如何，第二阶段都会结束当前事务。 存在的问题 1、同步阻塞问题。执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。 2、单点故障。由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题） 3、数据不一致。在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这会导致只有一部分参与者接受到了commit请求。而在这部分参与者接到commit请求之后就会执行commit操作。但是其他未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据不一致性的现象。 4、二阶段无法解决的问题：协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。 需要注意的是：在全局事务决定回滚时，直接逐个发送rollback请求即可，不必分阶段。 2PC机制需要RM提供底层支持（一般是兼容XA）。如果使用Java，那么可以使用开源软件 atomikos 或者JOTM来快速实现，两者都支持spring事务整合。 3PC3PC = Three Phase commit 三阶段提交 由于二阶段提交存在着诸如同步阻塞、单点问题、脑裂等缺陷，所以，在二阶段提交的基础上做了改进，提出了三阶段提交。 与两阶段提交不同的是，三阶段提交有两个改动点： 1、引入超时机制。同时在协调者和参与者中都引入超时机制。 2、将二阶段的准备阶段拆分为2个阶段，插入了一个preCommit阶段，使得原先在二阶段提交中，参与者在准备之后，由于协调者发生崩溃或错误，而导致参与者处于无法知晓是否提交或者中止的“不确定状态”所产生的可能相当长的延时的问题得以解决。保证了在最后提交阶段之前各参与节点的状态是一致的。 处理流程 阶段1：CanCommit阶段，是否提交-询问是否可以做事务提交 事务询问：协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。 响应反馈：参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态。否则反馈No。 阶段2：PreCommit阶段，预先提交-预先提交事务 假如协调者从所有的参与者获得的反馈都是Yes响应，那么就会执行事务的预执行。 发送预提交请求：协调者向参与者发送PreCommit请求，并进入Prepared阶段。 事务预提交：参与者接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。 响应反馈：如果参与者成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。 假如有任何一个参与者向协调者发送了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。 1.发送中断请求：协调者向所有参与者发送abort请求。2.中断事务：参与者收到来自协调者的abort请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。 阶段3：doCommit阶段，执行事务提交（commit、rollback）真正的提交事务执行提交 发送提交请求：协调者接收到参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送doCommit请求。 事务提交：参与者接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。 响应反馈：事务提交完之后，向协调者发送Ack响应。 完成事务：协调者接收到所有参与者的ack响应之后，完成事务。 中断事务 协调者没有接收到参与者发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。 发送中断请求：协调者向所有参与者发送abort请求。 事务回滚：参与者接收到abort请求之后，利用其在阶段二记录的undo信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。 反馈结果：参与者完成事务回滚之后，向协调者发送ACK消息。 中断事务：协调者接收到参与者反馈的ACK消息之后，执行事务的中断。 在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。（其实这个应该是基于概率来决定的，当进入第三阶段时，说明参与者在第二阶段已经收到了PreCommit请求，那么协调者产生PreCommit请求的前提条件是他在第二阶段开始之前，收到所有参与者的CanCommit响应都是Yes。（一旦参与者收到了PreCommit，意味他知道大家其实都同意修改了）所以，一句话概括就是，当进入第三阶段时，由于网络超时等原因，虽然参与者没有收到commit或者abort响应，但是他有理由相信：成功提交的几率很大。） 2PC与3PC的区别 相对于2PC，3PC主要解决的单点故障问题，并减少阻塞，因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行commit。而不会一直持有事务资源并处于阻塞状态。但是这种机制也会导致数据一致性问题，因为，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。 目前两阶段提交、三阶段提交存在如下的局限性，并不适合在微服务架构体系下使用： 所有的操作必须是事务性资源（比如数据库、消息队列、EJB组件等），存在使用局限性（微服务架构下多数使用HTTP协议），比较适合传统的单体应用； 由于是强一致性，资源需要在事务内部等待，性能影响较大，吞吐率不高，不适合高并发与高性能的业务场景； TCC事务TCC事务机制相对于传统事务机制（X/Open XA），其特征在于它不依赖资源管理器(RM)对XA的支持，而是通过对（由业务系统提供的）业务逻辑的调度来实现分布式事务。 解决了XA的几个缺点: 解决了协调者单点，由主业务方发起并完成这个业务活动。业务活动管理器也变成多点，引入集群。 同步阻塞:引入超时，超时后进行补偿，并且不会锁定整个资源，将资源转换为业务逻辑形式，粒度变小。 数据一致性，有了补偿机制之后，由业务活动管理器控制一致性 。 一个完整的TCC业务由一个主业务服务和若干个从业务服务组成，主业务服务发起并完成整个业务活动，TCC模式要求从服务提供三个接口：Try、Confirm、Cancel。 Try：完成所有业务检查，预留必须业务资源。 Confirm：真正执行业务，不作任何业务检查；只使用Try阶段预留的业务资源；Confirm操作满足幂等性。 Cancel：释放Try阶段预留的业务资源；Cancel操作满足幂等性。 整个TCC业务分成两个阶段完成： 第一阶段：主业务服务分别调用所有从业务的try操作，并在活动管理器中登记所有从业务服务。当所有从业务服务的try操作都调用成功或者某个从业务服务的try操作失败，进入第二阶段。 第二阶段：活动管理器根据第一阶段的执行结果来执行confirm或cancel操作。如果第一阶段所有try操作都成功，则活动管理器调用所有从业务活动的confirm操作。否则调用所有从业务服务的cancel操作。 与2PC比较： 位于业务服务层而非资源层。 没有单独的准备（prepare）阶段，Try操作兼备资源操作与准备能力。 Try操作可以灵活选择业务资源的锁定粒度。 开发成本较高。 缺点： Canfirm和Cancel的幂等性很难保证。 这种方式缺点比较多，通常在复杂场景下是不推荐使用的，除非是非常简单的场景，非常容易提供回滚Cancel，而且依赖的服务也非常少的情况。 这种实现方式会造成代码量庞大，耦合性高。而且非常有局限性，因为有很多的业务是无法很简单的实现回滚的，如果串行的服务很多，回滚的成本实在太高。 本地消息表（异步确保最终一致性）本地消息表的方案最初是由ebay提出，核心思路是将分布式事务拆分成本地事务进行处理。通过在事务主动发起方额外新建事务消息表，事务发起方处理业务和记录事务消息在本地事务中完成，轮询事务消息表的数据发送事务消息，事务被动方基于消息中间件消费事务消息表中的事务。 简单来说就是：本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性，并且使用了消息队列来保证最终一致性。 处理流程把分布式事务最先开始处理的事务方成为事务主动方，在事务主动方之后处理的业务内的其他事务成为事务被动方。流程如下图： 事务主动方处理本地事务。 事务主动发在本地事务中处理业务更新操作和写消息表操作。（如上图中操作1、2） 事务主动方通过消息中间件，通知事务被动方处理事务通知事务待消息。 消息中间件可以基于Kafka、RocketMQ消息队列，事务主动方法主动写消息到消息队列，事务消费方消费并处理消息队列中的消息。（如上图中操作3、4、5） 事务被动方通过消息中间件，通知事务主动方事务已处理的消息。（如上图中6、7、8） 为了数据的一致性，当处理错误需要重试，事务发送方和事务接收方相关业务处理需要支持幂等。具体保存一致性的容错处理如下： 1、当步骤1处理出错，事务回滚，相当于什么都没发生。2、当步骤2、步骤3处理出错，由于未处理的事务消息还是保存在事务发送方，事务发送方可以定时轮询为超时消息数据，再次发送的消息中间件进行处理。事务被动方消费事务消息重试处理。3、如果是业务上的失败，事务被动方可以发消息给事务主动方进行回滚。4、如果多个事务被动方已经消费消息，事务主动方需要回滚事务时需要通知事务被动方回滚。 优点 从应用设计开发的角度实现了消息数据的可靠性，消息数据的可靠性不依赖于消息中间件，弱化了对MQ中间件特性的依赖。 方案轻量，容易实现。 缺点 与具体的业务场景绑定，耦合性强，不可公用。 消息数据与业务数据同库，占用业务系统资源。 业务系统在使用关系型数据库的情况下，消息服务性能会受到关系型数据库并发性能的局限。 结合MQ实现的可靠消息最终一致性基于MQ的分布式事务方案其实是对本地消息表的封装，将本地消息表基于MQ 内部，其他方面的协议基本与本地消息表一致。 处理流程以阿里的 RocketMQ 中间件为例，在本地消息表方案中，保证事务主动方发写业务表数据和写消息表数据的一致性是基于数据库事务，RocketMQ的事务消息相对于普通MQ，相对于提供了2PC的提交接口，方案如下： 正常情况——事务主动方发消息 这种情况下，事务主动方服务正常，没有发生故障，发消息流程如下： 1、发送方向 MQ服务端(MQ Server)发送half消息。2、MQ Server 将消息持久化成功之后，向发送方 ACK 确认消息已经发送成功。3、发送方开始执行本地事务逻辑。4、发送方根据本地事务执行结果向 MQ Server 提交二次确认（commit 或是 rollback）。5、MQ Server 收到 commit 状态则将半消息标记为可投递，订阅方最终将收到该消息；MQ Server 收到 rollback 状态则删除半消息，订阅方将不会接受该消息。 异常情况——事务主动方消息恢复 在断网或者应用重启等异常情况下，发送方提交的二次确认超时未到达 MQ Server，此时处理逻辑如下： 5、MQ Server 对该消息发起消息回查。6、发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果。7、发送方根据检查得到的本地事务的最终状态再次提交二次确认。8、MQ Server基于commit / rollback 对消息进行投递或者删除。 MQ分布式事务 事务主动方基于MQ通信通知事务被动方处理事务，事务被动方基于MQ返回处理结果。如果事务被动方消费消息异常，需要不断重试，业务处理逻辑需要保证幂等。如果是事务被动方业务上的处理失败，可以通过MQ通知事务主动方进行补偿或者事务回滚。 优点 消息数据独立存储 ，降低业务系统与消息系统之间的耦合。 吞吐量由于使用本地消息表方案。 缺点 一次消息发送需要两次网络请求(half消息、commit/rollback消息)。 业务处理服务需要实现消息状态回查接口。 尽最大努力通知这种方案主要用在与第三方系统通讯时，比如：调用微信或支付宝支付后的支付结果通知。这种方案也是结合MQ进行实现，例如：通过MQ发送http请求，设置最大通知次数。达到通知次数后即不再通知。 处理流程 业务活动的主动方，在完成业务处理之后，向业务活动的被动方发送消息，允许消息丢失。 主动方可以设置时间阶梯型通知规则，在通知失败后按规则重复通知，直到通知N次后不再通知。 主动方提供校对查询接口给被动方按需校对查询，用于恢复丢失的业务消息。 业务活动的被动方如果正常接收了数据，就正常返回响应，并结束事务。 如果被动方没有正常接收，根据定时策略，向业务活动主动方查询，恢复丢失的业务消息 方案特点 用到的服务模式：可查询操作、幂等操作。 被动方的处理结果不影响主动方的处理结果； 适用于对业务最终一致性的时间敏感度低的系统； 适合跨企业的系统间的操作，或者企业内部比较独立的系统间的操作，比如银行通知、商户通知等； Saga事务——最终一致性简介Saga事务源于1987年普林斯顿大学的Hecto和Kenneth发表的如何处理long lived transaction（长活事务）论文，Saga事务核心思想是将长事务拆分为多个本地短事务，由Saga事务协调器协调，如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。 Saga事务基本协议 每个Saga事务由一系列幂等的有序子事务(sub-transaction) Ti 组成。 每个Ti 都有对应的幂等补偿动作Ci，补偿动作用于撤销Ti造成的结果。 可以看到，和TCC相比，Saga没有“预留”动作，它的Ti就是直接提交到库。 Saga事务执行顺序下面以下单流程为例，整个操作包括：创建订单、扣减库存、支付、增加积分Saga的执行顺序有两种： 事务正常执行完成 T1, T2, T3, ..., Tn，例如：扣减库存(T1)，创建订单(T2)，支付(T3)，依次有序完成整个事务。 事务回滚 T1, T2, ..., Tj, Cj,..., C2, C1，其中0 < j < n，例如：扣减库存(T1)，创建订单(T2)，支付(T3，支付失败)，支付回滚(C3)，订单回滚(C2)，恢复库存(C1)。 Saga恢复策略： 向前恢复(forward recovery) 对应于上面第一种执行顺序，适用于必须要成功的场景，发生失败进行重试，执行顺序是类似于这样的：T1, T2, …, Tj(失败), Tj(重试),…, Tn，其中j是发生错误的子事务(sub-transaction)。该情况下不需要Ci。 向后恢复(backward recovery) 对应于上面提到的第二种执行顺序，其中j是发生错误的子事务(sub-transaction)，这种做法的效果是撤销掉之前所有成功的子事务，使得整个Saga的执行结果撤销。 Saga事务实现方式 1、命令协调(Order Orchestrator)：中央协调器负责集中处理事件的决策和业务逻辑排序。 中央协调器（Orchestrator，简称OSO）以命令/回复的方式与每项服务进行通信，全权负责告诉每个参与者该做什么以及什么时候该做什么。 以电商订单的例子为例： 1、事务发起方的主业务逻辑请求OSO服务开启订单事务。2、OSO向库存服务请求扣减库存，库存服务回复处理结果。3、OSO向订单服务请求创建订单，订单服务回复创建结果。4、OSO向支付服务请求支付，支付服务回复处理结果。5、主业务逻辑接收并处理OSO事务处理结果回复。 中央协调器必须事先知道执行整个订单事务所需的流程(例如通过读取配置)。如果有任何失败，它还负责通过向每个参与者发送命令来撤销之前的操作来协调分布式的回滚。基于中央协调器协调一切时，回滚要容易得多，因为协调器默认是执行正向流程，回滚时只要执行反向流程即可。 2、事件编排 (Event Choreography0：没有中央协调器（没有单点风险）时，每个服务产生并观察其他服务的事件，并决定是否应采取行动。 在事件编排方法中，第一个服务执行一个事务，然后发布一个事件。该事件被一个或多个服务进行监听，这些服务再执行本地事务并发布（或不发布）新的事件。 当最后一个服务执行本地事务并且不发布任何事件时，意味着分布式事务结束，或者它发布的事件没有被任何Saga参与者听到都意味着事务结束。 以电商订单的例子为例： 1、事务发起方的主业务逻辑发布开始订单事件。2、库存服务监听开始订单事件，扣减库存，并发布库存已扣减事件。3、订单服务监听库存已扣减事件，创建订单，并发布订单已创建事件。4、支付服务监听订单已创建事件，进行支付，并发布订单已支付事件。5、主业务逻辑监听订单已支付事件并处理。 事件/编排是实现Saga模式的自然方式，它很简单，容易理解，不需要太多的代码来构建。如果事务涉及2至4个步骤，则可能是非常合适的。 命令协调设计的优点 1、服务之间关系简单，避免服务之间的循环依赖关系，因为Saga协调器会调用Saga参与者，但参与者不会调用协调器2、程序开发简单，只需要执行命令/回复(其实回复消息也是一种事件消息)，降低参与者的复杂性。3、易维护扩展，在添加新步骤时，事务复杂性保持线性，回滚更容易管理，更容易实施和测试 命令协调设计的缺点 1、中央协调器容易处理逻辑容易过于复杂，导致难以维护。2、存在协调器单点故障风险。 事件/编排设计的优点 1、避免中央协调器单点故障风险。2、当涉及的步骤较少服务开发简单，容易实现。 事件/编排设计的缺点 1、服务之间存在循环依赖的风险。2、当涉及的步骤较多，服务间关系混乱，难以追踪调测。 值得补充的是，由于Saga模型中没有Prepare阶段，因此事务间不能保证隔离性，当多个Saga事务操作同一资源时，就会产生更新丢失、脏数据读取等问题，这时需要在业务层控制并发，例如：在应用层面加锁，或者应用层面预先冻结资源。 分布式事务解决方案比较 2PC/3PC 依赖于数据库，能够很好的提供强一致性和强事务性，但相对来说延迟比较高，比较适合传统的单体应用，在同一个方法中存在跨库操作的情况，不适合高并发和高性能要求的场景。 TCC 适用于执行时间确定且较短，实时性要求高，对数据一致性要求高，比如互联网金融企业最核心的三个服务：交易、支付、账务。 本地消息表/MQ事务 都适用于事务中参与方支持操作幂等，对一致性要求不高，业务上能容忍数据不一致到一个人工检查周期，事务涉及的参与方、参与环节较少，业务上有对账/校验系统兜底。 Saga事务 由于Saga事务不能保证隔离性，需要在业务层控制并发，适合于业务场景事务并发操作同一资源较少的情况。 Saga相比缺少预提交动作，导致补偿动作的实现比较麻烦，例如业务是发送短信，补偿动作则得再发送一次短信说明撤销，用户体验比较差。Saga事务较适用于补偿动作容易处理的场景。","tags":"分布式"},{"title":"分布式学习-限流算法","url":"/posts/6e0ef647.html","text":"限流的作用由于API接口无法控制调用方的行为，因此当遇到瞬时请求量激增时，会导致接口占用过多服务器资源，使得其他请求响应速度降低或是超时，更有甚者可能导致服务器宕机。 限流(Rate limiting)指对应用服务的请求进行限制，例如某一接口的请求限制为100个每秒,对超过限制的请求则进行快速失败或丢弃。 限流可以应对： 热点业务带来的突发请求； 调用方bug导致的突发请求； 恶意攻击请求。 因此，对于公开的接口最好采取限流措施。 为什么要分布式限流 但线上业务出于各种原因考虑，多是分布式系统，单节点的限流仅能保护自身节点，但无法保护应用依赖的各种服务，并且在进行节点扩容、缩容时也无法准确控制整个服务的请求限制。 而如果实现了分布式限流，那么就可以方便地控制整个服务集群的请求限制，且由于整个集群的请求数量得到了限制，因此服务依赖的各种资源也得到了限流的保护。 限流算法分类 1、计数器算法（固定时间窗口）；2、滑动时间窗口；3、令牌桶算法；4、漏桶算法； 计数器算法算法解读计数器算法是限流算法里最简单也是最容易实现的一种算法。计数器就是统计记录单位时间内进入系统或者某一接口的请求次数，在限定的次数内的请求则正常接收处理，超过次数的请求则拒绝掉，或者改为异步处理。 比如规定，对于A接口1分钟的访问次数不能超过100个。那么可以这么做：在一开始的时候，设置一个计数器counter，每当一个请求过来的时候，counter就加1，如果counter的值大于100并且该请求与第一个请求的间隔时间还在1分钟之内，那么说明请求数过多；如果该请求与第一个请求的间隔时间大于1分钟，且counter的值还在限流范围内，那么就重置 counter，具体算法的示意图如下： 算法示例使用 AomicInteger 来进行统计当前正在并发执行的次数，如果超过域值就直接拒绝请求，提示系统繁忙… 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package com.springboot.whb.study.currentLimiting;import com.google.common.base.Joiner;import org.apache.commons.lang3.concurrent.BasicThreadFactory;import java.time.LocalDateTime;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger;/** * @author: whb * @description: 计数器限流算法 * 使用 AomicInteger 来进行统计当前正在并发执行的次数，如果超过域值就直接拒绝请求，提示系统繁忙 */public class CounterLimiter &#123; /** * 计数器限流算法（比较暴力/超出直接拒绝） * Atomic，限制总数 */ private static final AtomicInteger atomic = new AtomicInteger(0); /** * 线程池 */ public static final ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(10, 100, 60, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(1000), new BasicThreadFactory.Builder().namingPattern(Joiner.on(\"-\").join(\"client-thread-pool-\", \"%s\")).build()); /** * 限流 */ private void atomicLimiter() &#123; // 最大支持 3 個 if (atomic.get() &gt;= 3) &#123; System.out.println(LocalDateTime.now() + \" - \" + Thread.currentThread().getName() + \" - \" + \"拒絕...\"); &#125; else &#123; try &#123; atomic.incrementAndGet(); //处理核心逻辑 System.out.println(LocalDateTime.now() + \" - \" + Thread.currentThread().getName() + \" - \" + \"通过...\"); TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; atomic.decrementAndGet(); &#125; &#125; &#125; /** * 测试限流 * * @throws InterruptedException */ public void testAtomicLimiter() throws InterruptedException &#123; for (int i = 0; i &lt; 5; i++) &#123; threadPoolExecutor.execute(this::atomicLimiter); &#125; TimeUnit.SECONDS.sleep(5); &#125; /** * main方法调用 */ public static void main(String[] args) throws InterruptedException &#123; CounterLimiter counterLimiter = new CounterLimiter(); counterLimiter.testAtomicLimiter(); &#125;&#125; 运行结果 计数器算法虽然简单，但比较粗放，存在一个十分致命的问题，那就是临界问题，如下图： 如上图所示，假设有一个恶意用户，他在0:59时，瞬间发送了100个请求，并且1:00又瞬间发送了100个请求，那么其实这个用户在 1秒里面，瞬间发送了200个请求。我们刚才规定的是1分钟最多100个请求，也就是每秒钟最多1.7个请求，用户通过在时间窗口的重置节点处突发请求，可以瞬间超过我们的速率限制。用户有可能通过算法的这个漏洞，瞬间压垮我们的应用。 其实这个问题的本质就是统计的精度太低，那如何降低临界问题的影响？看下面的滑动时间窗口算法。 滑动时间窗口算法解读滑动窗口，又称rolling window，跟TCP中的滑动窗口名称一致，但要区分开来。先用一张图解释下滑动时间窗口算法： 如上图，整个红色的矩形框表示一个时间窗口，在计数器算法中，我们规定一个时间窗口就是一分钟。在滑动时间窗口算法中我们将滑动窗口 划成了6格，所以每格代表的是10秒钟。每过10秒钟，时间窗口就会往右滑动一格。每一个格子都有自己独立的计数器counter，比如当一个请求 在0:35秒的时候到达，那么0:30~0:39对应的counter就会加1。 那么滑动窗口怎么解决刚才的临界问题的呢？看上图，0:59到达的100个请求会落在灰色的格子中，而1:00到达的请求会落在红色的格子中。当时间到达1:00时，窗口会往右移动一格，那么此时时间窗口内的总请求数量一共是200个，超过了限定的100个，所以此时能够检测出来触发了限流。 再回顾一下刚才的计数器算法，可以发现，计数器算法其实就是滑动窗口算法。只是它没有对时间窗口做进一步地划分，所以只有1格。 由此可见，当滑动窗口的格子划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。 算法示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141package com.springboot.whb.study.currentLimiting;/** * @author: whb * @description: 滑动时间窗口限流算法 */import java.util.Iterator;import java.util.Random;import java.util.concurrent.ConcurrentLinkedQueue;import java.util.stream.IntStream;public class TimeWindowLimited &#123; /** * 缓存请求的队列 */ private ConcurrentLinkedQueue&lt;Long&gt; queue = new ConcurrentLinkedQueue&lt;&gt;(); /** * 滑动时间窗口大小 */ private int seconds; /** * 最大可接受请求 */ private int max; public TimeWindowLimited(int max, int timeWindowOfSeconds) &#123; this.seconds = timeWindowOfSeconds; this.max = max; new Thread(() -&gt; &#123; for (; ; ) &#123; clean(); try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; Thread.currentThread().interrupt(); &#125; &#125; &#125;).start(); &#125; /** * 获取令牌，并且添加时间 */ public void take() &#123; long start = System.currentTimeMillis(); try &#123; int size = sizeOfValid(); if (size &gt; max - 1) &#123; System.err.println(\" 队列已满，队列容量:\" + queue.size() + \",max:\" + max + \",queue:\" + printQueue()); throw new IllegalStateException(\"full\"); &#125; synchronized (queue) &#123; if (sizeOfValid() &gt; max - 1) &#123; System.err.println(\" 队列已满: in synchronized,size:\" + queue.size() + \",max:\" + max + \",queue:\" + printQueue()); throw new IllegalStateException(\"full\"); &#125; this.queue.offer(System.currentTimeMillis()); &#125; System.out.println(\" queue: d,size:\" + queue.size() + \",max:\" + max + \",queue:\" + printQueue()); &#125; finally &#123; System.out.println(\"耗时:\" + (System.currentTimeMillis() - start) + \" ms\"); &#125; &#125; /** * 打印队列内容 * * @return */ private String printQueue() &#123; Iterator&lt;Long&gt; it = queue.iterator(); StringBuilder sb = new StringBuilder(); while (it.hasNext()) &#123; Long t = it.next(); sb.append(\" \").append(t); &#125; return sb.toString(); &#125; /** * 有效请求 * * @return */ public int sizeOfValid() &#123; Iterator&lt;Long&gt; it = queue.iterator(); Long ms = System.currentTimeMillis() - seconds * 1000; int count = 0; while (it.hasNext()) &#123; long t = it.next(); if (t &gt; ms) &#123; count++; &#125; &#125; return count; &#125; /** * 清理 */ public void clean() &#123; Long c = System.currentTimeMillis() - seconds * 1000; Long tl = null; System.out.println(\"peek: \" + queue.peek() + \"c:\" + c); while ((tl = queue.peek()) != null &amp;&amp; tl &lt; c) &#123; System.out.println(\"peek: t:\" + tl); queue.poll(); &#125; &#125; public static void main(String[] args) &#123; final TimeWindowLimited timeWindow = new TimeWindowLimited(200, 2); IntStream.range(0, 100).forEach((i) -&gt; &#123; new Thread(() -&gt; &#123; for (; ; ) &#123; System.out.println(\"before take i:\" + i); try &#123; Thread.sleep(new Random().nextInt(20) * 100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; try &#123; timeWindow.take(); System.out.println(\"some option, i:\" + i); &#125; catch (Exception e) &#123; System.err.println(\" take i:\" + i + \", encounter error:\" + e.getMessage()); try &#123; Thread.sleep(10L); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; continue; &#125; System.out.println(\"after take i:\" + i); &#125; &#125;).start(); &#125;); &#125;&#125; 运行结果 漏桶算法算法解读漏桶算法（Leaky Bucket）：主要目的是控制数据注入到网络的速率，平滑网络上的突发流量，数据可以以任意速度流入到漏桶中。漏桶算法提供了一种机制，通过它，突发流量可以被整形以便为网络提供一个稳定的流量。 漏桶可以看作是一个带有常量服务时间的单服务器队列，如果漏桶为空，则不需要流出水滴，如果漏桶（包缓存）溢出，那么水滴会被溢出丢弃。 用一个简单的例子描述就是注水漏水过程，往桶中以一定速率流出水，以任意速率流入水，当水超过桶流量则丢弃，因为桶容量是不变的，保证了整体的速率。 算法示例漏桶算法可以通过 信号量（Semaphore） 的方式实现，很好的达到削峰的目的，如下示例代码，队列中任务存活个数就如同是水桶最多能盛装的水量，当超出这个阀值就会丢弃任务…. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package com.springboot.whb.study.currentLimiting;import com.google.common.base.Joiner;import org.apache.commons.lang3.concurrent.BasicThreadFactory;import java.time.LocalDateTime;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.Semaphore;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;/** * @author: whb * @description: 漏桶限流算法 */public class LeakyBucket &#123; /** * 信号量，用来达到削峰的目的，平滑流量 */ private static final Semaphore semaphore = new Semaphore(3); /** * 线程池 */ public static final ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(10, 100, 60, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(1000), new BasicThreadFactory.Builder().namingPattern(Joiner.on(\"-\").join(\"client-thread-pool-\", \"%s\")).build()); /** * 限流算法 */ private void semaphoreLimiter() &#123; // 队列中允许存活的任务个数不能超过 5 个 if (semaphore.getQueueLength() &gt; 5) &#123; System.out.println(LocalDateTime.now() + \" - \" + Thread.currentThread().getName() + \" - 拒絕...\"); &#125; else &#123; try &#123; semaphore.acquire(); System.out.println(LocalDateTime.now() + \" - \" + Thread.currentThread().getName() + \" - 通过...\"); //处理核心逻辑 TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; semaphore.release(); &#125; &#125; &#125; /** * 测试限流算法 * * @throws InterruptedException */ public void testSemaphore() throws InterruptedException &#123; for (int i = 0; i &lt; 10; i++) &#123; threadPoolExecutor.execute(this::semaphoreLimiter); &#125; TimeUnit.SECONDS.sleep(5); &#125; /** * main方法中执行测试方法 * * @param args * @throws InterruptedException */ public static void main(String[] args) throws InterruptedException &#123; LeakyBucket leakyBucket = new LeakyBucket(); leakyBucket.testSemaphore(); &#125;&#125; 运行结果 一共 10 个线程同时请求，初始信号量为3，表示最多可以同时处理 3 个任务，超出进入缓冲区排队等待，当缓冲区满了后则拒绝接收新的请求… 令牌桶算法算法解读令牌桶算法是比较常见的限流算法之一，大概描述如下： 所有的请求在处理之前都需要拿到一个可用的令牌才会被处理； 根据限流大小，设置按照一定的速率往桶里添加令牌； 桶设置最大的放置令牌限制，当桶满时、新添加的令牌就被丢弃或者拒绝； 请求达到后首先要获取令牌桶中的令牌，拿着令牌才可以进行其他的业务逻辑，处理完业务逻辑之后，将令牌直接删除； 令牌桶有最低限额，当桶中的令牌达到最低限额的时候，请求处理完之后将不会删除令牌，以此保证足够的限流； 算法示例在Google Guava中提供了一个RateLimiter 工具类，就是基于令牌桶算法实现平滑突发的限流策略. 令牌桶的好处是可以方便的改变速度，一旦需要提高速率，则按需提高放入桶中的令牌的速率。一般会定时(比如1000毫秒)往桶中增加一定数量的令牌, 有些变种算法则可以实时的计算应该增加的令牌的数量。 在示例代码中为每秒中产生 2 个令牌，意味着每500毫秒会产生一个令牌。 limiter.acquire(num) 表示消费多少个令牌。当桶中有足够的令牌时，则直接返回0，否则阻塞，直到有可用的令牌数才返回，返回的值为阻塞的时间。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.springboot.whb.study.currentLimiting;import com.google.common.base.Joiner;import com.google.common.util.concurrent.RateLimiter;import org.apache.commons.lang3.concurrent.BasicThreadFactory;import java.time.LocalDateTime;import java.util.concurrent.*;/** * @author: whb * @description: 谷歌令牌桶算法测试 */public class TokenBucket &#123; /** * 每秒生成2个令牌 */ private static final RateLimiter limiter = RateLimiter.create(2); /** * 线程池 */ public static final ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(10, 100, 60, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(1000), new BasicThreadFactory.Builder().namingPattern(Joiner.on(\"-\").join(\"client-thread-pool-\", \"%s\")).build()); /** * 限流 */ private void rateLimiter() &#123; // 默认就是 1 final double acquire = limiter.acquire(1); System.out.println(\"当前时间 - \" + LocalDateTime.now() + \" - \" + Thread.currentThread().getName() + \" - 阻塞 - \" + acquire + \" 通过...\"); &#125; /** * 限流算法测试接口 * * @throws InterruptedException */ public void testRateLimiter() throws InterruptedException &#123; for (int i = 0; i &lt; 5; i++) &#123; threadPoolExecutor.execute(this::rateLimiter); &#125; TimeUnit.SECONDS.sleep(5); &#125; /** * main方法中调用 * * @param args * @throws InterruptedException */ public static void main(String[] args) throws InterruptedException &#123; TokenBucket rateLimiterTest = new TokenBucket(); rateLimiterTest.testRateLimiter(); &#125;&#125; 运行结果 通过控制台的输出可以很直观的看出每个令牌产生时间间隔大约在 500 毫秒左右。","tags":"分布式"},{"title":"分布式学习-分布式全局唯一ID","url":"/posts/a8c8e58f.html","text":"什么是分布式系统唯一ID在复杂分布式系统中，往往需要对大量的数据和消息进行唯一标识。 如在金融、电商、支付、等产品的系统中，数据日渐增长，对数据分库分表后需要有一个唯一ID来标识一条数据或消息，数据库的自增ID显然不能满足需求，此时一个能够生成全局唯一ID的系统是非常必要的。 分布式系统唯一ID的特点 全局唯一性：不能出现重复的ID号，既然是唯一标识，这是最基本的要求。 趋势递增：在MySQL InnoDB引擎中使用的是聚集索引，由于多数RDBMS使用B-tree的数据结构来存储索引数据，在主键的选择上面我们应该尽量使用有序的主键保证写入性能。 单调递增：保证下一个ID一定大于上一个ID，例如事务版本号、IM增量消息、排序等特殊需求。 信息安全：如果ID是连续的，恶意用户的扒取工作就非常容易做了，直接按照顺序下载指定URL即可；如果是订单号就更危险了。所以在一些应用场景下，会需要ID无规则、不规则。 同时除了对ID号码自身的要求，业务还对ID号生成系统的可用性要求极高，想象一下，如果ID生成系统瘫痪，这就会带来一场灾难。由此总结下一个ID生成系统应该做到如下几点： 平均延迟和TP999延迟都要尽可能低； 可用性5个9； 高QPS。 分布式系统唯一ID实现方案UUIDUUID是指在一台机器在同一时间中生成的数字在所有机器中都是唯一的。按照开放软件基金会(OSF)制定的标准计算，用到了以太网卡地址、纳秒级时间、芯片ID码和许多可能的数字UUID由以下几部分的组合： （1）当前日期和时间。 （2）时钟序列。 （3）全局唯一的IEEE机器识别号，如果有网卡，从网卡MAC地址获得，没有网卡以其他方式获得。标准的UUID格式为：xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx (8-4-4-4-12)，以连字号分为五段形式的36个字符，示例：550e8400-e29b-41d4-a716-446655440000Java标准类库中已经提供了UUID的API。 1UUID.randomUUID(); 优点 性能非常高：本地生成，没有网络消耗。 缺点 不易存储：UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用。信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。ID作为主键时在特定的环境会存在一些问题，比如做DB主键的场景下，UUID就非常不适用。 Twitter的snowflakesnowflake 是 Twitter 开源的分布式ID生成算法，是一种划分命名空间来生成ID的一种算法，结果是一个long型的ID。其核心思想是：把64-bit分别划分成多段。如下图所示： 1位标识符：始终是0，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0。 41位时间戳：41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截 )得到的值，这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的。 10位机器标识码：可以部署在1024个节点，如果机器分机房（IDC）部署，这10位可以由 5位机房ID + 5位机器ID 组成。 12位序列：毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号 优点 毫秒数在高位，自增序列在低位，整个ID都是趋势递增的。 不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的。 可以根据自身业务特性分配bit位，非常灵活。 缺点 强依赖机器的时钟，如果服务器时钟回拨，会导致重复ID生成。 在分布式环境上，每个服务器的时钟不可能完全同步，有时会出现不是全局递增的情况。 snowflake Java实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146/** * Twitter_Snowflake&lt;br&gt; * SnowFlake的结构如下(每部分用-分开):&lt;br&gt; * 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 &lt;br&gt; * 1位标识，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0&lt;br&gt; * 41位时间截(毫秒级)，注意，41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截) * 得到的值），这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的（如下下面程序IdWorker类的startTime属性）。 * 41位的时间截，可以使用69年，年T = (1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69&lt;br&gt; * 10位的数据机器位，可以部署在1024个节点，包括5位datacenterId和5位workerId&lt;br&gt; * 12位序列，毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号&lt;br&gt; * 加起来刚好64位，为一个Long型。&lt;br&gt; * SnowFlake的优点是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分)，并且效率较高， * 经测试，SnowFlake每秒能够产生26万ID左右。 */public class SnowflakeIdWorker &#123; // ==============================Fields=========================================== /** 开始时间截 (2015-01-01) */ private final long twepoch = 1420041600000L; /** 机器id所占的位数 */ private final long workerIdBits = 5L; /** 数据标识id所占的位数 */ private final long datacenterIdBits = 5L; /** 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数) */ private final long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits); /** 支持的最大数据标识id，结果是31 */ private final long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits); /** 序列在id中占的位数 */ private final long sequenceBits = 12L; /** 机器ID向左移12位 */ private final long workerIdShift = sequenceBits; /** 数据标识id向左移17位(12+5) */ private final long datacenterIdShift = sequenceBits + workerIdBits; /** 时间截向左移22位(5+5+12) */ private final long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; /** 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095) */ private final long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits); /** 工作机器ID(0~31) */ private long workerId; /** 数据中心ID(0~31) */ private long datacenterId; /** 毫秒内序列(0~4095) */ private long sequence = 0L; /** 上次生成ID的时间截 */ private long lastTimestamp = -1L; //==============================Constructors===================================== /** * 构造函数 * @param workerId 工作ID (0~31) * @param datacenterId 数据中心ID (0~31) */ public SnowflakeIdWorker(long workerId, long datacenterId) &#123; if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123; throw new IllegalArgumentException(String.format(\"worker Id can't be greater than %d or less than 0\", maxWorkerId)); &#125; if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) &#123; throw new IllegalArgumentException(String.format(\"datacenter Id can't be greater than %d or less than 0\", maxDatacenterId)); &#125; this.workerId = workerId; this.datacenterId = datacenterId; &#125; // ==============================Methods========================================== /** * 获得下一个ID (该方法是线程安全的) * @return SnowflakeId */ public synchronized long nextId() &#123; long timestamp = timeGen(); //如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常 if (timestamp &lt; lastTimestamp) &#123; throw new RuntimeException( String.format(\"Clock moved backwards. Refusing to generate id for %d milliseconds\", lastTimestamp - timestamp)); &#125; //如果是同一时间生成的，则进行毫秒内序列 if (lastTimestamp == timestamp) &#123; sequence = (sequence + 1) &amp; sequenceMask; //毫秒内序列溢出 if (sequence == 0) &#123; //阻塞到下一个毫秒,获得新的时间戳 timestamp = tilNextMillis(lastTimestamp); &#125; &#125; //时间戳改变，毫秒内序列重置 else &#123; sequence = 0L; &#125; //上次生成ID的时间截 lastTimestamp = timestamp; //移位并通过或运算拼到一起组成64位的ID return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) // | (datacenterId &lt;&lt; datacenterIdShift) // | (workerId &lt;&lt; workerIdShift) // | sequence; &#125; /** * 阻塞到下一个毫秒，直到获得新的时间戳 * @param lastTimestamp 上次生成ID的时间截 * @return 当前时间戳 */ protected long tilNextMillis(long lastTimestamp) &#123; long timestamp = timeGen(); while (timestamp &lt;= lastTimestamp) &#123; timestamp = timeGen(); &#125; return timestamp; &#125; /** * 返回以毫秒为单位的当前时间 * @return 当前时间(毫秒) */ protected long timeGen() &#123; return System.currentTimeMillis(); &#125; //==============================Test============================================= /** 测试 */ public static void main(String[] args) &#123; SnowflakeIdWorker idWorker = new SnowflakeIdWorker(0, 0); for (int i = 0; i &lt; 1000; i++) &#123; long id = idWorker.nextId(); System.out.println(Long.toBinaryString(id)); System.out.println(id); &#125; &#125;&#125; 数据库自增ID（Flicker）主要思路是采用数据库自增ID + replace_into实现唯一ID的获取。 123456create table t_global_id( id bigint(20) unsigned not null auto_increment, stub char(1) not null default '', primary key (id), unique key stub (stub)) engine=MyISAM; 123# 每次业务可以使用以下SQL读写MySQL得到ID号replace into t_golbal_id(stub) values('a');select last_insert_id(); replace into跟insert功能类似，不同点在于：replace into首先尝试插入数据列表中，如果发现表中已经有此行数据（根据主键或唯一索引判断）则先删除，再插入。否则直接插入新数据。当然为了避免数据库的单点故障，最少需要两个数据库实例，通过区分auto_increment的起始值和步长来生成奇偶数的ID。 比如有两台机器。设置步长step为2，Server1的初始值为1（1，3，5，7，9，11…）、Server2的初始值为2（2，4，6，8，10…）如下所示，为了实现上述方案分别设置两台机器对应的参数，Server1从1开始发号，Server2从2开始发号，两台机器每次发号之后都递增2。如下： 1234567Server1：auto-increment-increment = 2auto-increment-offset = 1Server2：auto-increment-increment = 2auto-increment-offset = 2 优点 简单。充分借助数据库的自增ID机制，可靠性高，生成有序的ID。 缺点 ID生成依赖数据库单机的读写性能。 依赖数据库，当数据库异常时整个系统不可用。 对于MySQL的性能问题，可以用如下方案解决： 在分布式环境中，我们可以部署N台数据库实例，每台设置成不同的初始值，自增步长为机器的台数。每台的初始值分别为1,2,3…N，步长为N。 这种方案虽然解决了性能问题，但是也存在很大的局限性： 系统水平扩容困难：系统定义好步长之后，增加机器之后调整步长困难。如果要添加机器怎么办？假设现在只有一台机器发号是1,2,3,4,5（步长是1），这个时候需要扩容机器一台。可以这样做：把第二台机器的初始值设置得比第一台超过很多，比如14（假设在扩容时间之内第一台不可能发到14），同时设置步长为2，那么这台机器下发的号码都是14以后的偶数。然后摘掉第一台，把ID值保留为奇数，比如7，然后修改第一台的步长为2。让它符合我们定义的号段标准，对于这个例子来说就是让第一台以后只能产生奇数。扩容方案看起来复杂吗？貌似还好，现在想象一下如果我们线上有100台机器，这个时候要扩容该怎么做？简直是噩梦。 数据库压力大：每次获取一个ID都必须读写一次数据库。当然对于这种问题，也有相应的解决方案，就是每次获取ID时都批量获取一个区间的号段到内存中，用完之后再来获取。数据库的性能提高了几个量级。 美团的Leaf-segmentLeaf-segment 在使用数据库的方案上做了优化，利用proxy server批量获取，每次获取一段IDs(step决定大小)，然后把这段IDs作为id池缓存起来使用。用完之后再去数据库获取新的号段，从而大大的减轻数据库的压力。解决了原方案每次获取ID都得读写一次数据库，造成数据库压力大的问题。Leaf-segment的总体架构如下： 优点 Leaf服务可以很方便的线性扩展，性能完全能够支撑大多数业务场景。 ID号码是趋势递增的8byte的64位数字，满足上述数据库存储的主键要求。 容灾性高：Leaf服务内部有号段缓存，即使DB宕机，短时间内Leaf仍能正常对外提供服务。 可以自定义max_id的大小，非常方便业务从原有的ID方式上迁移过来。 缺点 ID号码不够随机，能够泄露发号数量的信息，不太安全。 TP999数据波动大，当号段使用完之后还是会hang在更新数据库的I/O上，tg999数据会出现偶尔的尖刺。 DB宕机会造成整个系统不可用。 Leaf-segment 后2点缺点，Leaf-segment做了双buffer优化，以及“一主两从”的高可用容灾。 美团的Leaf-snowflake Leaf-snowflake 方案完全沿用snowflake方案的bit位设计，即是1+41+10+12的方式组装ID号。相比 snowflake，Leaf-snowflake做了以下2点优化： 使用Zookeeper持久顺序节点的特性自动对snowflake节点配置wokerID，一定程度的提高系统的伸缩性和容错性。 解决时钟回拨会可能导致生成重复的ID号的问题。 Leaf-snowflake是按照下面几个步骤启动的： 启动Leaf-snowflake服务，连接Zookeeper，在leaf_forever父节点下检查自己是否已经注册过（是否有该顺序子节点）。 如果有注册过直接取回自己的workerID（zk顺序节点生成的int类型ID号），启动服务。 如果没有注册过，就在该父节点下面创建一个持久顺序节点，创建成功后取回顺序号当做自己的workerID号，启动服务。 微信的序列号生成器seqsvrseqsvr 是微信的一个高可用、高可靠的序列号生成器，利用生成的序列号，实现终端与后台的数据增量同步机制。这套同步机制仍然在消息收发、朋友圈通知、好友数据更新等需要数据同步的地方发挥着核心的作用。seqsvr的架构可以分为两层，即StoreSvr和AllocSvr（存储层和缓存中间层）。架构如下图： 从垂直方向看，AllocSvr负责直接为客户端分配sequence，而StoreSvr则负责当前最大sequence num的可靠存储（通过NRW实现）。这个角度看来，和美团点评的Leaf-segment是非常相似的。主要区别在于两点，第一是seqsvr产生的sequence是在UID（用户ID）之下的id，换言之——UID + sequence = 全局ID；第二点是seqsvr使用了NRW实现了数据存储的强一致性。 从水平方向看，seqsvr使用UID进行了水平切分，实现了负载均衡。对单一的一个set分析可知，AllocSvr可以完全以运行在内存中，而不用实现持久化。因为最恶劣的情况就是，AllocSvr中一部分id还没有被消费的情况下宕机了，重启之后又重新申请了一段id，所以有一部分id被跳过了。然而，微信的sequence num有64位，而且是位于UID之下的，所以跳过一段id完全可以接受。 所以，seqsvr的主要压力还是在StoreSvr，即使进行了Set切分，NRW存储模式依然还是要在吞吐量上付出代价。大概是经过了进一步的实验，seqsvr进行了进一步的优化——分段号共享存储。如下图所示，max_seq就是当前的最大序列号。一组用户共享一个max_seq，分组的方式依然是使用UID进行切分。这样一来，seqsvr中StoreSvr的压力变得更小了。举例来说，如果大家的操作频率是均等的，那么StoreSvr的写入压力降为切分之前的1 / N（N为分组内部用户的数目）。而且StoreSvr对数据的载入压力也降低为1 / N。 Redis生成唯一IDRedis实现了一个原子操作INCR和INCRBY实现递增的操作。当使用数据库性能不够时，可以采用Redis来代替，同时使用Redis集群来提高吞吐量。 可以初始化每台Redis的初始值为1,2,3,4,5，然后步长为5。各个Redis生成的ID为： 12345A：1，6，11，16，21B：2，7，12，17，22C：3，8，13，18，23D：4，9，14，19，24E：5，10，15，20，25 优点 不依赖于数据库，灵活方便，且性能优于数据库。 数字ID天然排序，对分页或者需要排序的结果很有帮助。 缺点 如果系统中没有Redis，还需要引入新的组件，增加系统复杂度。 需要编码和配置的工作量比较大。这个都不是最大的问题。 Zookeeper生成唯一IDzookeeper主要通过其znode数据版本来生成序列号，可以生成32位和64位的数据版本号，客户端可以使用这个版本号来作为唯一的序列号。 很少会使用zookeeper来生成唯一ID。主要是由于需要依赖zookeeper，并且是多步调用API，如果在竞争较大的情况下，需要考虑使用分布式锁。因此，性能在高并发的分布式环境下，也不甚理想。","tags":"分布式"},{"title":"本地代码上传到GitHub","url":"/posts/ceff156c.html","text":"首先你需要一个github账号，所有还没有的话先去注册吧！ https://github.com/ 我们使用git需要先安装git工具，这里给出下载地址，下载后一路直接安装即可： https://git-for-windows.github.io/ 进入Github首页，点击New repository新建一个项目 填写相应信息后点击create即可 Repository name: 仓库名称 Description(可选): 仓库描述介绍 Public, Private : 仓库权限（公开共享，私有或指定合作者） Initialize this repository with a README: 添加一个README.md gitignore: 不需要进行版本管理的仓库类型，对应生成文件.gitignore license: 证书类型，对应生成文件LICENSE 点击Clone or dowload会出现一个地址，copy这个地址备用。 接下来就到本地操作了，首先鼠标右键，如果你之前安装git成功的话，右键会出现两个新选项，分别为Git Gui Here,Git Bash Here,这里我们选择Git Bash Here，进入如下界面： 接下来输入如下代码（关键步骤），把github上面的仓库克隆到本地 1git clone https://github.com/whb1990/blogSourceCode.git 地址换成你自己的。 这个步骤以后你的本地项目文件夹下面就会多出个文件夹，该文件夹名即为你github上面的项目名，如图我多出了个blogSourceCode文件夹，我们把本地需要上传的文件都复制到该文件夹下： 接着继续输入命令 cd blogSourceCode，进入 blogSourceCode 文件夹 接下来依次输入以下代码即可完成其他剩余操作： git add . （注：别忘记后面的.，此操作是把blogSourceCode文件夹下面的文件都添加进来） 执行完该命令可以看到有如下提示信息： 这个提示的大致意思就是： 1234567您已经在当前存储库中添加了另一个Git存储库。外部存储库的克隆将不包含嵌入存储库的内容，也不知道如何获取它。如果要添加子模块，请使用： git submodule add &lt;url&gt; themes/next如果错误地添加了此路径，则可以使用 git rm --cached themes/next 因为这个项目是我用Hexo搭建的个人博客，用到了Next主题(另一个Git存储库)，上面的提示也告诉了我们该怎么做，其实除了上面两种方式，还有一种方式就是直接删除你要包含的子库目录下的.git文件夹即可。 git commit -m &quot;提交信息&quot; （注：“提交信息”里面换成你需要，如“first commit”） git push -u origin master （注：此操作目的是把本地仓库push到github上面，此步骤需要你输入帐号和密码） 去GitHub上看下上传后的代码 问题解决： 在上传代码到GitHub的时候，提示如下错误： 原因是推送的文件太大。我这次推送的内容超过的1G，所以报错了。 方法一：修改提交缓存大小为5000M，或者更大的数字 1git config --global http.postBuffer 5242880000 –global配置对当前用户生效，如果需要对所有用户生效，则用–system 或者在克隆/创建版本库生成的 .git目录下面修改生成的config文件增加如下： 12[http] postBuffer = 524288000 方法二： 配置git的最低速度和最低速度时间： 12git config --global http.lowSpeedLimit 0git config --global http.lowSpeedTime 999999 单位 秒 –global配置对当前用户生效，如果需要对所有用户生效，则用–system 我是选择的方法一，解决效果如下：","tags":"git github"},{"title":"Hexo live2d插件效果预览","url":"/posts/fcf4ee5f.html","text":"Epsilon2.1 Gantzert_Felixander haru miku ni-j nico nietzche nipsilon nito shizuku tsumiki wanko z16 hibiki koharu haruto Unitychan tororo hijiki","tags":"hexo"},{"title":"分布式学习-Session丢失及解决","url":"/posts/223e2ff2.html","text":"什么是Session丢失Session是为了将同一个用户的多次访问在系统中被识别为“同一个用户”而产生的概念。除此之外，还可以基于它来减少重复往DB或者远程服务处获取与该用户相关的信息，以起到提升性能的作用。 在做了负载均衡的场景中，如果选择的负载策略是hash策略，那么会使得Session产生一个副作用：用户一旦由于某种原因从原先访问服务器A变成访问服务器B，就会出现“登陆状态丢失”、“缓存穿透”等问题。 为什么hash策略会出现这个问题呢？首先有必要先了解一下hash是如何进行的。hash策略就是下图这样的一个散列函数。在函数不变的情况下，A永远对应01，B对应04，C对应08。 以nginx中的ip_hash策略来举个例子。正常情况下用户的ip不会在短时间内发生变化，所以当使用ip_hash策略进行负载均衡时，意味着期望同一个用户能够一直访问到同一台服务器上，就像下图这样。 如此一来，我们只需要在这一台服务器上将这个用户相关的信息缓存在进程内，这时，客户端与服务端之间的相当于建立了一个信任，相互认识。这个信任就是「Session」。但是，当我们加了一台服务器之后，事情就发生变化了。 这个时候原先的预期就被破坏了。因为用户与序号0节点的链接变成了与序号3的链接，所以产生了Session丢失问题。与此同时，在序号0节点上做的进程内缓存都无效了，而在序号3节点上又没有用户相关的任何缓存，导致大量数据需要从下游的DB或者远程服务处获取。要知道，一旦涉及到网络通信，性能必然明显下降，I/O、序列化都是耗时的工作。更重要的是，一旦同时有大量用户产生这个情况，由于后端的DB和远程服务瞬时无法承载激增的高密度请求，可能会导致它挂起。这还没完，如果当前程序没有一些故障隔离或者降级策略，还会进一步产生蝴蝶效应，导致整个大系统响应缓慢。 nginx是如何解决的通过在nginx中引入nginx-sticky-module模块可以来解决这个问题。解决的整个过程如下。可以看到，当client第一次进入到nginx匹配节点的时候，在给它分配一个节点的同时，会将这个节点的唯一标识进行md5后写入到cookie中一并返回，如果下次再发起请求的时候发现带有这个cookie值，就直接转发到该值所对应的节点上去。这个机制被专业的称之为「Session保持」。 虽然可以利用cookie来解决这个问题，但是cookie也有一个潜在的问题，如果客户端未开启cookie功能，这个机制就失效了。不过好在目前主流浏览器都是默认打开cookie的。 其他解决方案Session复制这是最简单粗暴的方式。根据上面的案例来看，导致问题的原因是节点3没有用户的Session。那么很容易想到，在节点3运行之前把Session相关的Cache数据复制过去，并且在多个节点之间持续保证数据的同步，也就是说，每一台节点上都存在每个用户的Session数据。 实现的方案有很多，特别是不同的宿主程序都或多或少提供了一些切入点，甚至是拿来即用的方案，如Tomcat的Delta Manager和Backup Manager、Tomcat和IIS的Filter机制等等。此类方案的特点是 优点：天然高可用，一部分节点宕机没事。因为每一个节点上存放着所有已连接用户的会话信息。 缺点：因为每台计算机的内存是有上限的，仅适用于会话相关的数据大小较小的场景。并且，由于多个节点之间需要同步数据，需要额外解决数据一致性问题。与此同时，随着节点越多，损耗越大（延迟、带宽等），有广播风暴风险。 Session共享通过将session信息存放到全局共享的存储介质中来达到一样的效果，如数据库、远程缓存等，这是一种中心化思想的解决方案。 此类方案的特点是： 优点：不管节点怎么增加和减少，100%不会产生会话丢失。 缺点：每次读写请求都需要增加额外共享储存调用，增加了网络I/O、序列化等操作，性能明显下降。另外，用作共享的存储介质除了增加了额外的维护成本外，还需要解决单点问题，以免产生系统性风险。 三种方案对比 分别用一句话概括一下这3个方案： Session 保持：原来在哪还是去哪。Session 复制：不管在哪都有一样的数据。Session 共享：所有节点共用一份数据。","tags":"分布式"},{"title":"分布式学习-负载均衡","url":"/posts/95c2b1da.html","text":"概述分布式系统的关键是做冗余，让这些冗余能发挥高可用作用的就是负载均衡。负载均衡的作用是一个“连接者”，让上下游之间以期望的方式“连接”起来。所以，有必要先了解一下这些上下游的全貌，并且从中找到做负载均衡的地方。 分布式系统有各式各样的架构方式，不过本质上都是上图这样的一个分层架构。图中红点标记出的地方就是需要做负载均衡的地方，可以看到，就是每两层之间的连接处。这些连接处在实际做负载均衡的时候，需要结合所处的网络层次。因为在不同的网络层次有不同的做法。如下图。 一般主流的四层负载均衡和七层负载均衡，前者指的就是传输层，主要涉及的协议是TCP、UDP等，后者指的应用层，主要涉及的协议是Http、Https和FTP等。用来实现负载均衡的解决方案有很多，分为基于硬件或者基于软件的，比较成熟的诸如：F5（支持四层、七层）、LVS（支持四层）、Nginx（支持七层）等等。 常用负载均衡策略轮询这是最常用也最简单策略，平均分配，人人都有、一人一次。大致的代码如下。 1234567891011int globalIndex = 0; try&#123; return servers[globalIndex];&#125;finally&#123; globalIndex++; if (globalIndex == 3) globalIndex = 0;&#125; 加权轮询 在轮询的基础上，增加了一个权重的概念。权重是一个泛化后的概念，可以用任意方式来体现，本质上是一个能者多劳思想。比如，可以根据宿主的性能差异配置不同的权重。大致的代码如下。 1234567891011121314151617int matchedIndex = -1;int total = 0;for (int i = 0; i &lt; servers.Length; i++)&#123; //每次循环的时候做自增（步长=权重值） servers[i].cur_weight += servers[i].weight; //将每个节点的权重值累加到汇总值中 total += servers[i].weight; //如果 当前节点的自增数 &gt; 当前待返回节点的自增数，则覆盖。 if (matchedIndex == -1 || servers[matchedIndex].cur_weight &lt; servers[i].cur_weight) &#123; matchedIndex = i; &#125;&#125;servers[matchedIndex].cur_weight -= total;//④被选取的节点减去②的汇总值，以降低下一次被选举时的初始权重值。return servers[matchedIndex]; 这段代码的过程如下图的表格。”()”中的数字就是自增数，代码中的cur_weight。 值得注意的是，加权轮询本身还有不同的实现方式，虽说最终的比例都是2：1：2。但是在请求送达的先后顺序上可以所有不同。比如「5-4，3，2-1」和上面的案例相比，最终比例是一样的，但是效果不同。「5-4，3，2-1」更容易产生并发问题，导致服务端拥塞，且这个问题随着权重数字越大越严重。例子：10：5：3的结果是「18-17-16-15-14-13-12-11-10-9，8-7-6-5-4，3-2-1」 最少连接数 这是一种根据实时的负载情况，进行动态负载均衡的方式。维护好活动中的连接数量，然后取最小的返回即可。大致的代码如下。 1234var matchedServer = servers.orderBy(e =&gt; e.active_conns).first();matchedServer.active_conns += 1;return matchedServer;//在连接关闭时还需对active_conns做减1的动作。 最快响应这也是一种动态负载均衡策略，它的本质是根据每个节点对过去一段时间内的响应情况来分配，响应越快分配的越多。具体的运作方式也有很多，上图的这种可以理解为，将最近一段时间的请求耗时的平均值记录下来，结合前面的「加权轮询」来处理，所以等价于2：1：3的加权轮询。 Hash法hash法的负载均衡与之前的几种不同在于，它的结果是由客户端决定的。通过客户端带来的某个标识经过一个标准化的散列函数进行打散分摊。 常用负载均衡策略优缺点和适用场景 健康探测保障高可用不管是什么样的策略，难免会遇到机器故障或者程序故障的情况。所以要确保负载均衡能更好的起到效果，还需要结合一些「健康探测」机制。定时的去探测服务端是不是还能连上，响应是不是超出预期的慢。如果节点属于“不可用”的状态的话，需要将这个节点临时从待选取列表中移除，以提高可用性。一般常用的「健康探测」方式有3种。 HTTP探测使用Get/Post的方式请求服务端的某个固定的URL，判断返回的内容是否符合预期。一般使用Http状态码、response中的内容来判断。 TCP探测基于Tcp的三次握手机制来探测指定的IP + 端口。最佳实践可以借鉴阿里云的SLB机制，如下图。 UDP探测可能有部分应用使用的UDP协议。在此协议下可以通过报文来进行探测指定的IP + 端口。最佳实践同样可以借鉴阿里云的SLB机制，如下图。 结果的判定方式是：在服务端没有返回任何信息的情况下，默认正常状态。否则会返回一个ICMP的报错信息。 实施负载均衡硬件负载均衡硬件这块名气最大的还属F5。此类硬件负载均衡器的特点是“壕”，毕竟是纯商业化的东西，投入的资源和精力自然是众多开源软件负载均衡所无法比拟的，所以功能非常强大。包含访问加速、压缩、安全等等负载均衡之外的许多附加功能。 如果用F5组网的话，有两种结构，串行结构和并行结构，也称为直连模式和旁路模式。前者的优势在对硬件产生压力较小、且天然安全性高，而后者对原网络架构的改动较小、且扩展性较好。大家在实际的使用中结合自身情况来部署。 软件负载均衡（L7） 针对Web应用的L7负载均衡，比较主流的产品是2个Nginx、HAProxy。在L7做负载均衡，最大的特点就是灵活，请求的URL、Header都是可以去掌控的，所以可以利用其中的任何信息为负载均衡策略所用。实际操作中主要做2步： 在公网的域名解析中，配置解析到「反向代理」。记录类型是「A」，记录值是「反向代理」的IP。 配置真实提供服务的Web应用IP和端口，和负载均衡均衡策略。上图中的配置是Nginx中的示例，负载均衡策略的缺省值是轮询。 软件负载均衡（L4） 当Web应用所依赖的TCP协议的服务需要横向扩展，或者需要做数据库、分布式缓存的多主、主从集群时，那么就需要一个支持L4的负载均衡软件。这里最知名的就属LVS了，它是内核态的程序，所以相比用Nginx、HAProxy来做L4的负载均衡，在性能、资源的消耗上会更优一些。实际运用中的操作步骤主要也是2步： 在LVS中添加一个IP虚拟服务（IPVS），并指定它的IP、端口和负载均衡策略。 将IP虚拟服务关联到真实的服务上，并指定模式和权重的信息。（做L4的负载均衡可以使用NAT或者FULLNAT模式） LVS的模式一共有四种，除了NAT和FULLNAT（NAT的增强版）模式外，它的TUN模式可以在L3做负载均衡，DR模式可以在L2做负载均衡，到这个层面其实就和做硬件同处于一个层次了。并且，随着层次的深入，虽然对功能性上有所弱化，但是如果不考虑端口的话，单从IP层面的负载均衡来说，用DR模式做，则对数据包的加工介入度会降到最低，因此也是通过软件做负载均衡能够达到的性能极致。另外，LVS中运用的虚拟IP概念，本质上和Nginx中的“server”概念一样，定义了一个统一入口，作用上并没有差别。将Nginx中的upstream关联到server，就如LVS操作步骤第2点中的关联一般。 优缺点不同的解决方案有不同的侧重点。因此在单个解决方案已经无法满足的情况下，可以组合使用，各尽所长。 推荐方案负载均衡这个领域还是以高可用和性能为2个最重要因素，下面是推荐的一种组合方式，也是在系统量级达到每小时上亿PV之后最被广泛使用的一种。理论上，利用第一步DNS的域名解析所带的负载均衡效果，只要复制多套LVS主备出来，绑上多个不同的虚IP，可以做到无限横向扩展，以支撑不断增长的流量。用到的3个软件目前都是开源产品，LVS+Keepalived负责做Nginx的负载均衡，而Nginx负责分发到实际的请求到Http和Tcp协议的应用上。关于LVS的模式选择，如果在同网段内的话优先使用DR模式进行L2转发，性能最好。否则使用TUN模式进行L3分发。与此同时，在L4、L7的分发上使用Nginx来做，可以发挥其灵活易扩展的特点以及其它的一些额外特性如缓存等。","tags":"分布式 高可用 负载均衡"},{"title":"手写RPC-升级版","url":"/posts/a6a74f01.html","text":"概述手写RPC-简易版 ，实现了一个很简单的RPC调用示例，其中还存在很多问题及可优化的点，这次做个升级，完全重写之前的代码，使得代码逻辑更加规范，同时引入Zookeeper辅助完成服务治理。在代码展示前，先介绍下Zookeeper、服务治理等概念。 ZookeeperZooKeeper（简称zk）是一个分布式、开源的应用协调服务，利用和Paxos类似的ZAB选举算法实现分布式一致性服务。有类似于Unix文件目录的节点信息，同时可以针对节点的变更添加watcher监听以能够及时感知到节点信息变更。可提供的功能例如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、分布式锁和分布式队列等功能。如下图就是DUBBO存储在ZooKeeper的节点数据情况： 在本地启动服务后通过zk客户端连接后也可通过命令查看节点信息，如下图所示。 ZooKeeper包含了4种不同含义的功能节点，在每次创建节点之前都需要明确声明节点类型: 类型 定义 描述 PERSISTENT 持久化目录节点 客户端与zookeeper断开连接后，该节点依旧存在 PERSISTENT_SEQUENTIAL 持久化顺序编号目录节点 客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号 EPHEMERAL 临时目录节点 客户端与zookeeper断开连接后，该节点被删除 EPHEMERAL_SEQUENTIAL 临时顺序编号目录节点 客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号 ZooKeeper使用之前需要先进行安装，后开启服务端的服务， 我们的服务作为客户端连接ZooKeeper以便于后续的操作。具体可参考官网文档Zookeeper3.5.5 官方文档，在实际的java项目开发中也是可以通过maven引入ZkClient或者Curator开源的客户端，在本文学习笔记中是使用的Curator，因为其已经封装了原始的节点注册、数据获取、添加watcher等功能。具体maven引入的版本如下： 12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;4.2.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;4.2.0&lt;/version&gt;&lt;/dependency&gt; 服务治理服务治理也就是针对服务进行管理的措施，例如 服务发现、 服务暴露、 负载均衡、 快速上下线等都是服务治理的具体体现。 服务发现：从服务管理中心获取到需要的服务相关信息，例如可以从zk中获取相关服务的机器信息，然后就可以和具体机器直连完成相关功能。 服务暴露：服务提供方可以提供什么样子的功能，经过服务暴露暴露出去，其他使用方就可以通过服务发现发现具体的服务提供方信息。 负载均衡：一般针对的是服务提供方，避免大量请求同时打到一台机器上，采用随机、轮询等措施让请求均分到各个机器上，提供服务效率， 限流， 灰度等也都是类似的操作，通过动态路由、软负载的形式处理分发请求。 快速上线下：以往需要上下线可能需要杀掉机器上的进程，现在只需要让该服务停止暴露即可，实现服务的灵活上下线。 数据处理流程服务端：服务的提供方，接受网络传输的请求数据、通过网络把应答数据发送给客户端; 客户端：服务的调用方，使用本地代理，通过网络把请求数据发送出去，接受服务端返回的应答数据. 所有的数据传输都是按照上面图片说的流程来的，如果需要添加自定义的序列化工具，则需要在把数据提交到socket的输出流缓冲区之前按照序列化工具完成序列化操作，反序列化则进行反向操作即可。 RPC V2版本文件夹目录如下图所示： balance文件夹：负载均衡有关； config文件夹：网络套接字传输的数据模型以及服务暴露、服务发现的数据模型； core文件夹：核心文件夹，包含了服务端和客户端的请求处理、代理生成等； demo文件夹：测试使用； domain文件夹：模型、枚举常量； io.protocol文件夹：目前是只有具体的请求对象和网络io的封装； register文件夹：服务注册使用，实现了使用zk进行服务注册和服务发现的操作； serialize文件夹：序列化、反序列化，实现了Java和Hessian两种。 服务注册&amp;服务发现ServiceRegister：123456789101112131415161718192021222324252627282930package com.springboot.whb.study.rpc.rpc_v2.register;import com.springboot.whb.study.rpc.rpc_v2.config.BasicConfig;import com.springboot.whb.study.rpc.rpc_v2.core.RpcRequest;import com.springboot.whb.study.rpc.rpc_v2.domain.ServiceType;import java.net.InetSocketAddress;/** * @author: whb * @description: 服务注册 */public interface ServiceRegister &#123; /** * 服务注册 * * @param config */ void register(BasicConfig config); /** * 服务发现，从注册中心获取可用的服务提供方信息 * * @param request * @param nodeType * @return */ InetSocketAddress discovery(RpcRequest request, ServiceType nodeType);&#125; ZkServiceRegister默认使用了CuratorFramework客户端完成zk数据的操作. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149package com.springboot.whb.study.rpc.rpc_v2.register;import com.springboot.whb.study.rpc.rpc_v2.balance.DefaultLoadBalance;import com.springboot.whb.study.rpc.rpc_v2.balance.LoadBalance;import com.springboot.whb.study.rpc.rpc_v2.config.BasicConfig;import com.springboot.whb.study.rpc.rpc_v2.core.RpcRequest;import com.springboot.whb.study.rpc.rpc_v2.domain.ServiceType;import lombok.extern.slf4j.Slf4j;import org.apache.curator.RetryPolicy;import org.apache.curator.framework.CuratorFramework;import org.apache.curator.framework.CuratorFrameworkFactory;import org.apache.curator.retry.ExponentialBackoffRetry;import org.apache.zookeeper.CreateMode;import java.net.InetSocketAddress;import java.util.List;/** * @author: whb * @description: Zookeeper服务注册实现类 */@Slf4jpublic class ZkServiceRegister implements ServiceRegister &#123; private CuratorFramework client; private static final String ROOT_PATH = \"whb/demo-rpc\"; private LoadBalance loadBalance = new DefaultLoadBalance(); public ZkServiceRegister() &#123; //重试策略 RetryPolicy policy = new ExponentialBackoffRetry(1000, 3); this.client = CuratorFrameworkFactory .builder() .connectString(\"127.0.0.1:2181\") .sessionTimeoutMs(50000) .retryPolicy(policy) .namespace(ROOT_PATH) .build(); // 业务的根路径是 /whb/demo-rpc ,其他的都会默认挂载在这里 this.client.start(); System.out.println(\"zk启动正常\"); &#125; /** * 服务注册 * * @param config */ @Override public void register(BasicConfig config) &#123; String interfacePath = \"/\" + config.getInterfaceName(); try &#123; if (this.client.checkExists().forPath(interfacePath) == null) &#123; // 创建 服务的永久节点 this.client.create() .creatingParentsIfNeeded() .withMode(CreateMode.PERSISTENT) .forPath(interfacePath); &#125; config.getMethods().forEach(method -&gt; &#123; String methodPath = null; try &#123; ServiceType serviceType = config.getType(); if (serviceType == ServiceType.PROVIDER) &#123; // 服务提供方，需要暴露自身的ip、port信息，而消费端则不需要 String address = getServiceAddress(config); methodPath = String.format(\"%s/%s/%s/%s\", interfacePath, serviceType.getType(), method.getMethodName(), address); &#125; else &#123; methodPath = String.format(\"%s/%s/%s\", interfacePath, serviceType.getType(), method.getMethodName()); &#125; log.info(\"zk path: [\" + ROOT_PATH + methodPath + \"]\"); // 创建临时节点，节点包含了服务提供段的信息 this.client.create() .creatingParentsIfNeeded() .withMode(CreateMode.EPHEMERAL) .forPath(methodPath, \"0\".getBytes()); &#125; catch (Exception e) &#123; log.error(\"创建临时节点[\" + methodPath + \"]失败，error:&#123;&#125;\", e); &#125; &#125;); &#125; catch (Exception e) &#123; log.error(\"创建服务节点失败，error:&#123;&#125;\", e); &#125; &#125; /** * 服务发现 * * @param request * @param nodeType * @return */ @Override public InetSocketAddress discovery(RpcRequest request, ServiceType nodeType) &#123; String path = String.format(\"/%s/%s/%s\", request.getClassName(), nodeType.getType(), request.getMethodName()); try &#123; List&lt;String&gt; addressList = this.client.getChildren().forPath(path); // 采用负载均衡的方式获取服务提供方信息,不过并没有添加watcher监听模式 String address = loadBalance.balance(addressList); if (address == null) &#123; return null; &#125; return parseAddress(address); &#125; catch (Exception e) &#123; log.error(\"服务发现接口异常，error:&#123;&#125;\", e); &#125; return null; &#125; /** * 获取服务地址 * * @param config * @return */ private String getServiceAddress(BasicConfig config) &#123; String hostInfo = new StringBuilder() .append(config.getHost()) .append(\":\") .append(config.getPort()) .toString(); return hostInfo; &#125; /** * 封装端口 * * @param address * @return */ private InetSocketAddress parseAddress(String address) &#123; String[] result = address.split(\":\"); return new InetSocketAddress(result[0], Integer.valueOf(result[1])); &#125; /** * 设置负载均衡策略 * * @param loadBalance */ public void setLoadBalance(LoadBalance loadBalance) &#123; this.loadBalance = loadBalance; &#125;&#125; 负载均衡LoadBalance123456789101112131415161718package com.springboot.whb.study.rpc.rpc_v2.balance;import java.util.List;/** * @author: whb * @description: 负载均衡接口定义 */public interface LoadBalance &#123; /** * 负载均衡 * * @param addressList * @return */ String balance(List&lt;String&gt; addressList);&#125; AbstractLoadBalance1234567891011121314151617181920212223242526272829package com.springboot.whb.study.rpc.rpc_v2.balance;import java.util.List;/** * @author: whb * @description: 抽象负载均衡 */public abstract class AbstractLoadBalance implements LoadBalance &#123; @Override public String balance(List&lt;String&gt; addressList) &#123; if (addressList == null || addressList.isEmpty()) &#123; return null; &#125; if (addressList.size() == 1) &#123; return addressList.get(0); &#125; return doLoad(addressList); &#125; /** * 抽象接口，让子类去实现 * * @param addressList * @return */ abstract String doLoad(List&lt;String&gt; addressList);&#125; DefaultLoadBalance123456789101112131415161718package com.springboot.whb.study.rpc.rpc_v2.balance;import java.util.List;import java.util.Random;/** * @author: whb * @description: 默认负载均衡--随机负载均衡 */public class DefaultLoadBalance extends AbstractLoadBalance &#123; @Override String doLoad(List&lt;String&gt; addressList) &#123; //随机 Random random = new Random(); return addressList.get(random.nextInt(addressList.size())); &#125;&#125; 消息协议MessageProtocol12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.springboot.whb.study.rpc.rpc_v2.io.protocol;import com.springboot.whb.study.rpc.rpc_v2.core.RpcRequest;import com.springboot.whb.study.rpc.rpc_v2.core.RpcResponse;import java.io.InputStream;import java.io.OutputStream;/** * @author: whb * @description: 请求、应答 解析和反解析，包含了序列化以及反序列化操作 */public interface MessageProtocol &#123; /** * 服务端解析从网络传输的数据，转变成request对象 * * @param inputStream * @return */ RpcRequest serviceToRequest(InputStream inputStream); /** * 服务端把计算的结果包装好，通过输出流返回给客户端 * * @param response * @param outputStream * @param &lt;T&gt; */ &lt;T&gt; void serviceGetResponse(RpcResponse&lt;T&gt; response, OutputStream outputStream); /** * 客户端把请求拼接好，通过输出流发送到服务端 * * @param request * @param outputStream */ void clientToRequest(RpcRequest request, OutputStream outputStream); /** * 客户端接收到服务端响应的结果，转变成response对象 * * @param inputStream */ &lt;T&gt; RpcResponse&lt;T&gt; clientGetResponse(InputStream inputStream);&#125; DefaultMessageProtocol123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188package com.springboot.whb.study.rpc.rpc_v2.io.protocol;import com.springboot.whb.study.rpc.rpc_v2.core.RpcRequest;import com.springboot.whb.study.rpc.rpc_v2.core.RpcResponse;import com.springboot.whb.study.rpc.rpc_v2.serialize.HessianSerialize;import com.springboot.whb.study.rpc.rpc_v2.serialize.SerializeProtocol;import lombok.extern.slf4j.Slf4j;import java.io.ByteArrayOutputStream;import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.util.Arrays;/** * @author: whb * @description: 套接字的io流和服务端、客户端的数据传输 */@Slf4jpublic class DefaultMessageProtocol implements MessageProtocol &#123; /** * 序列化协议 */ private SerializeProtocol serializeProtocol; public DefaultMessageProtocol() &#123; this.serializeProtocol = new HessianSerialize(); //this.serializeProtocol = new JavaInnerSerialize(); &#125; public void setSerializeProtocol(SerializeProtocol serializeProtocol) &#123; // 可替换序列化协议 this.serializeProtocol = serializeProtocol; &#125; /** * 服务端解析从网络传输的数据，转变成request对象 * * @param inputStream * @return */ @Override public RpcRequest serviceToRequest(InputStream inputStream) &#123; try &#123; // 2、bytes -&gt; request 反序列化 byte[] bytes = readBytes(inputStream); System.out.println(\"[2]服务端反序列化出obj:[\" + new String(bytes) + \"], length:\" + bytes.length); //System.out.println(\"[2]服务端反序列化出obj length:\" + bytes.length); RpcRequest request = serializeProtocol.deserialize(RpcRequest.class, bytes); return request; &#125; catch (Exception e) &#123; log.error(\"[2]服务端反序列化从网络传输的数据转变成request对象失败，error:&#123;&#125;\", e); &#125; return null; &#125; /** * 服务端把计算的结果包装好，通过输出流返回给客户端 * * @param response * @param outputStream * @param &lt;T&gt; */ @Override public &lt;T&gt; void serviceGetResponse(RpcResponse&lt;T&gt; response, OutputStream outputStream) &#123; try &#123; // 3、把response 序列化成bytes 传给客户端 byte[] bytes = serializeProtocol.serialize(RpcResponse.class, response); System.out.println(\"[3]服务端序列化出bytes:[\" + new String(bytes) + \"], length:\" + bytes.length); //System.out.println(\"[3]服务端序列化出bytes length:\" + bytes.length); outputStream.write(bytes); &#125; catch (Exception e) &#123; log.error(\"[3]服务端序列化计算的结果出输给客户端失败，error:&#123;&#125;\", e); &#125; &#125; /** * 客户端把请求拼接好，通过输出流发送到服务端 * * @param request * @param outputStream */ @Override public void clientToRequest(RpcRequest request, OutputStream outputStream) &#123; try &#123; // 1、先把这个request -&gt; bytes 序列化掉 byte[] bytes = serializeProtocol.serialize(RpcRequest.class, request); System.out.println(\"[1]客户端序列化出bytes:[\" + new String(bytes) + \"], length:\" + bytes.length); //System.out.println(\"[1]客户端序列化出bytes length:\" + bytes.length); outputStream.write(bytes); &#125; catch (IOException e) &#123; log.error(\"[1]客户端序列化请求参数失败，error:&#123;&#125;\", e); &#125; &#125; /** * 客户端接收到服务端响应的结果，转变成response对象 * * @param inputStream */ @Override public &lt;T&gt; RpcResponse&lt;T&gt; clientGetResponse(InputStream inputStream) &#123; try &#123; // 4、bytes 反序列化成response byte[] bytes = readBytes(inputStream); System.out.println(\"[4]客户端反序列化出bytes:[\" + new String(bytes) + \"], length:\" + bytes.length); //System.out.println(\"[4]客户端反序列化出bytes length:\" + bytes.length); RpcResponse response = serializeProtocol.deserialize(RpcResponse.class, bytes); return response; &#125; catch (Exception e) &#123; log.error(\"[4]客户端反序列化计算结果失败，error:&#123;&#125;\", e); &#125; return null; &#125; /** * 流转二进制数组 * * @param inputStream * @return * @throws IOException */ private byte[] readBytes(InputStream inputStream) throws IOException &#123; if (inputStream == null) &#123; throw new RuntimeException(\"输入流为空\"); &#125; return inputStreamToByteArr2(inputStream); &#125; /** * 流转二进制数组方法1 * * @param inputStream * @return * @throws IOException */ private byte[] inputStreamToByteArr1(InputStream inputStream) throws IOException &#123; // 有个前提是数据最大是1024，并没有迭代读取数据 byte[] bytes = new byte[1024]; int count = inputStream.read(bytes, 0, 1024); return Arrays.copyOf(bytes, count); &#125; /** * 流转二进制数组方法2 * * @param inputStream * @return * @throws IOException */ private byte[] inputStreamToByteArr2(InputStream inputStream) throws IOException &#123; ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); int bufesize = 1024; while (true) &#123; byte[] data = new byte[bufesize]; int count = inputStream.read(data, 0, bufesize); byteArrayOutputStream.write(data, 0, count); if (count &lt; bufesize) &#123; break; &#125; &#125; return byteArrayOutputStream.toByteArray(); &#125; /** * 流转二进制数组方法3，调用该方法之后会阻塞在read，可通过jstack查看相关信息 * * @param inputStream * @return * @throws IOException */ private byte[] inputStreamToByteArr3(InputStream inputStream) throws IOException &#123; ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); int bufesize = 1024; byte[] buff = new byte[bufesize]; int rc = 0; while ((rc = inputStream.read(buff, 0, bufesize)) &gt; 0) &#123; byteArrayOutputStream.write(buff, 0, rc); buff = new byte[bufesize]; &#125; byte[] bytes = byteArrayOutputStream.toByteArray(); return bytes; &#125;&#125; 数据传输模型ArgumentConfig12345678910111213141516171819202122232425package com.springboot.whb.study.rpc.rpc_v2.config;import lombok.Data;import java.io.Serializable;/** * @author: whb * @description: 参数配置 */@Datapublic class ArgumentConfig implements Serializable &#123; private static final long serialVersionUID = 1L; /** * 第几个参数 */ private int index; /** * 参数类型 */ private String type;&#125; BasicConfig123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.springboot.whb.study.rpc.rpc_v2.config;import com.springboot.whb.study.rpc.rpc_v2.domain.ServiceType;import lombok.Data;import java.util.List;/** * @author: whb * @description: 基础配置 */@Datapublic class BasicConfig &#123; /** * 地址 */ private String host; /** * 端口号 */ private int port; /** * 服务提供方还是服务消费方 */ private ServiceType type; /** * 接口名 */ private String interfaceName; /** * 接口类 */ private Class&lt;?&gt; interfaceClass; /** * 方法集合 */ private List&lt;MethodConfig&gt; methods; /** * 分组 */ private String group; /** * 默认版本号是default */ private String version = \"default\";&#125; ClientConfig1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.springboot.whb.study.rpc.rpc_v2.config;import com.springboot.whb.study.rpc.rpc_v2.core.ProxyInstance;import com.springboot.whb.study.rpc.rpc_v2.domain.ServiceType;import lombok.Data;import java.io.Serializable;import java.lang.reflect.Proxy;/** * @author: whb * @description: 客户端配置 */@Datapublic class ClientConfig&lt;T&gt; extends BasicConfig implements Serializable &#123; private static final long serialVersionUID = 1L; private T proxy; /** * 反射包装成客户端参数配置对象 * * @param interfaceClass * @param invocationHandler * @param &lt;T&gt; * @return */ public static &lt;T&gt; ClientConfig&lt;T&gt; convert(Class&lt;T&gt; interfaceClass, ProxyInstance invocationHandler) &#123; ClientConfig&lt;T&gt; config = new ClientConfig&lt;&gt;(); config.setVersion(\"default\"); config.setInterfaceClass(interfaceClass); config.setInterfaceName(interfaceClass.getName()); config.setMethods(MethodConfig.convert(interfaceClass.getMethods())); config.setType(ServiceType.CONSUMER); Object proxy = Proxy.newProxyInstance(ClientConfig.class.getClassLoader(), new Class&lt;?&gt;[]&#123;interfaceClass&#125;, invocationHandler); config.setProxy((T) proxy); return config; &#125;&#125; MethodConfig123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687package com.springboot.whb.study.rpc.rpc_v2.config;import lombok.Data;import java.io.Serializable;import java.lang.reflect.Method;import java.lang.reflect.Parameter;import java.util.ArrayList;import java.util.List;/** * @author: whb * @description: 方法配置 */@Datapublic class MethodConfig implements Serializable &#123; private static final long serialVersionUID = 1L; /** * 方法名 */ private String methodName; /** * 参数 */ private List&lt;ArgumentConfig&gt; argumentConfigs; /** * 是否需要返回 */ private Boolean isReturn; /** * 返回值类型 */ private Class&lt;?&gt; returnType; /** * 方法数组转方法配置集合 * * @param methods * @return */ public static List&lt;MethodConfig&gt; convert(Method[] methods) &#123; List&lt;MethodConfig&gt; methodConfigList = new ArrayList&lt;&gt;(methods.length); MethodConfig methodConfig = null; for (Method method : methods) &#123; methodConfig = new MethodConfig(); methodConfig.setMethodName(method.getName()); Class&lt;?&gt; returnType = method.getReturnType(); String returnName = returnType.getName(); if (\"void\".equals(returnName)) &#123; methodConfig.setIsReturn(false); &#125; else &#123; methodConfig.setIsReturn(true); &#125; methodConfig.setReturnType(returnType); methodConfig.setArgumentConfigs(convert(method.getParameters())); methodConfigList.add(methodConfig); &#125; return methodConfigList; &#125; /** * 参数数组转参数配置集合 * * @param parameters * @return */ private static List&lt;ArgumentConfig&gt; convert(Parameter[] parameters) &#123; List&lt;ArgumentConfig&gt; argumentConfigs = new ArrayList&lt;&gt;(parameters.length); int start = 0; ArgumentConfig argumentConfig = null; for (Parameter parameter : parameters) &#123; argumentConfig = new ArgumentConfig(); argumentConfig.setIndex(start); argumentConfig.setType(parameter.getType().getName()); argumentConfigs.add(argumentConfig); start += 1; &#125; return argumentConfigs; &#125;&#125; ServiceConfig1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.springboot.whb.study.rpc.rpc_v2.config;import com.alibaba.fastjson.JSON;import com.springboot.whb.study.rpc.rpc_v2.core.RpcService;import com.springboot.whb.study.rpc.rpc_v2.domain.ServiceType;import lombok.Data;import lombok.extern.slf4j.Slf4j;import java.io.Serializable;import java.net.InetAddress;import java.net.UnknownHostException;/** * @author: whb * @description: 服务方配置 */@Data@Slf4jpublic class ServiceConfig&lt;T&gt; extends BasicConfig implements Serializable &#123; private static final long serialVersionUID = 1L; private T ref; /** * 统计调用次数使用 */ private int count; @Override public String toString() &#123; return JSON.toJSONString(this); &#125; public static &lt;T&gt; ServiceConfig&lt;T&gt; convert(String interfaceName, Class&lt;T&gt; interfaceClass, T ref, RpcService rpcService) &#123; ServiceConfig&lt;T&gt; serviceConfig = new ServiceConfig&lt;&gt;(); serviceConfig.setRef(ref); serviceConfig.setInterfaceName(interfaceName); serviceConfig.setInterfaceClass(interfaceClass); serviceConfig.setCount(0); serviceConfig.setMethods(MethodConfig.convert(interfaceClass.getMethods())); serviceConfig.setPort(rpcService.getPort()); serviceConfig.setType(ServiceType.PROVIDER); try &#123; InetAddress addr = InetAddress.getLocalHost(); serviceConfig.setHost(addr.getHostAddress()); &#125; catch (UnknownHostException e) &#123; log.error(\"服务方获取本机地址失败，error:&#123;&#125;\", e); &#125; return serviceConfig; &#125;&#125; 枚举常量ServiceType123456789101112131415161718192021222324252627package com.springboot.whb.study.rpc.rpc_v2.domain;/** * @author: whb * @description: 服务类型枚举常量 */public enum ServiceType &#123; /** * 服务提供者 */ PROVIDER(\"provider\"), /** * 服务消费者 */ CONSUMER(\"consumer\"); private String type; ServiceType(String type) &#123; this.type = type; &#125; public String getType() &#123; return type; &#125;&#125; 序列化、反序列化SerializeProtocol123456789101112131415161718package com.springboot.whb.study.rpc.rpc_v2.serialize;/** * @author: whb * @description: 序列化协议接口 */public interface SerializeProtocol &#123; /** * 序列化 */ &lt;T&gt; byte[] serialize(Class&lt;T&gt; clazz, T t); /** * 反序列化 */ &lt;T&gt; T deserialize(Class&lt;T&gt; clazz, byte[] bytes);&#125; JavaInnerSerialize1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889package com.springboot.whb.study.rpc.rpc_v2.serialize;import lombok.extern.slf4j.Slf4j;import java.io.*;/** * @author: whb * @description: Java序列化 */@Slf4jpublic class JavaInnerSerialize implements SerializeProtocol &#123; /** * 序列化 * * @param clazz * @param t * @param &lt;T&gt; * @return */ @Override public &lt;T&gt; byte[] serialize(Class&lt;T&gt; clazz, T t) &#123; ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); ObjectOutputStream objectOutputStream = null; try &#123; objectOutputStream = new ObjectOutputStream(outputStream); objectOutputStream.writeObject(t); objectOutputStream.flush(); byte[] bytes = outputStream.toByteArray(); return bytes; &#125; catch (Exception e) &#123; log.error(\"Java 序列化失败，error:&#123;&#125;\", e); &#125; finally &#123; if (outputStream != null) &#123; try &#123; outputStream.close(); &#125; catch (IOException e) &#123; log.error(\"Java 序列化关闭二进制输出流失败,error:&#123;&#125;\", e); &#125; &#125; if (objectOutputStream != null) &#123; try &#123; objectOutputStream.close(); &#125; catch (IOException e) &#123; log.error(\"Java 序列化关闭对象流失败，error:&#123;&#125;\", e); &#125; &#125; &#125; return null; &#125; /** * 反序列化 * * @param clazz * @param bytes * @param &lt;T&gt; * @return */ @Override public &lt;T&gt; T deserialize(Class&lt;T&gt; clazz, byte[] bytes) &#123; ByteArrayInputStream inputStream = new ByteArrayInputStream(bytes); ObjectInputStream objectInputStream = null; try &#123; objectInputStream = new ObjectInputStream(inputStream); T obj = (T) objectInputStream.readObject(); return obj; &#125; catch (Exception e) &#123; log.error(\"Java 反序列化失败，error:&#123;&#125;\", e); &#125; finally &#123; if (inputStream != null) &#123; try &#123; inputStream.close(); &#125; catch (IOException e) &#123; log.error(\"Java 反序列化关闭二进制输入流失败，error:&#123;&#125;\", e); &#125; &#125; if (objectInputStream != null) &#123; try &#123; objectInputStream.close(); &#125; catch (IOException e) &#123; log.error(\"Java 反序列化关闭对象输入流失败，error:&#123;&#125;\", e); &#125; &#125; &#125; return null; &#125;&#125; HessianSerialize123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687package com.springboot.whb.study.rpc.rpc_v2.serialize;import com.alibaba.com.caucho.hessian.io.Hessian2Input;import com.alibaba.com.caucho.hessian.io.Hessian2Output;import lombok.extern.slf4j.Slf4j;import java.io.ByteArrayInputStream;import java.io.ByteArrayOutputStream;import java.io.IOException;/** * @author: whb * @description: Hessian二进制序列化 */@Slf4jpublic class HessianSerialize implements SerializeProtocol &#123; /** * 序列化 * * @param clazz * @param t * @param &lt;T&gt; * @return */ @Override public &lt;T&gt; byte[] serialize(Class&lt;T&gt; clazz, T t) &#123; ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); Hessian2Output hessian2Output = new Hessian2Output(outputStream); try &#123; //验证过，一定需要在flush之前关闭掉hessian2Output，否则获取的bytes字段信息为空 hessian2Output.writeObject(t); &#125; catch (IOException e) &#123; throw new RuntimeException(e.getMessage()); &#125; finally &#123; try &#123; hessian2Output.close(); &#125; catch (IOException e) &#123; log.error(\"Hessian 二进制序列化，关闭流失败，error:&#123;&#125;\", e); &#125; &#125; try &#123; outputStream.flush(); byte[] bytes = outputStream.toByteArray(); return bytes; &#125; catch (IOException e) &#123; throw new RuntimeException(e.getMessage()); &#125; finally &#123; try &#123; outputStream.close(); &#125; catch (IOException e) &#123; log.error(\"Hessian 二进制序列化，关闭输出流失败，error:&#123;&#125;\", e); &#125; &#125; &#125; /** * 反序列化 * * @param clazz * @param bytes * @param &lt;T&gt; * @return */ @Override public &lt;T&gt; T deserialize(Class&lt;T&gt; clazz, byte[] bytes) &#123; ByteArrayInputStream inputStream = new ByteArrayInputStream(bytes); Hessian2Input hessian2Input = new Hessian2Input(inputStream); try &#123; T t = (T) hessian2Input.readObject(); return t; &#125; catch (IOException e) &#123; throw new RuntimeException(e.getMessage()); &#125; finally &#123; try &#123; hessian2Input.close(); &#125; catch (IOException e) &#123; log.error(\"Hessian 反序列化，流关闭失败，error:&#123;&#125;\", e); &#125; try &#123; inputStream.close(); &#125; catch (IOException e) &#123; log.error(\"Hessian 反序列化，输入流关闭失败，error:&#123;&#125;\", e); &#125; &#125; &#125;&#125; 请求、响应对象RpcRequest1234567891011121314151617181920212223242526272829303132333435363738394041package com.springboot.whb.study.rpc.rpc_v2.core;import com.alibaba.fastjson.JSON;import lombok.Data;import java.io.Serializable;/** * @author: whb * @description: RPC请求对象 */@Datapublic class RpcRequest implements Serializable &#123; private static final long serialVersionUID = 1L; /** * 类名 */ private String className; /** * 方法名 */ private String methodName; /** * 参数 */ private Object[] arguments; /** * 参数类型 */ private Class&lt;?&gt;[] parameterTypes; @Override public String toString() &#123; return JSON.toJSONString(this); &#125;&#125; RpcResponse123456789101112131415161718192021222324252627282930313233343536package com.springboot.whb.study.rpc.rpc_v2.core;import com.alibaba.fastjson.JSON;import lombok.Data;import java.io.Serializable;/** * @author: whb * @description: RPC响应对象 */@Datapublic class RpcResponse&lt;T&gt; implements Serializable &#123; private static final long serialVersionUID = 1L; /** * 响应结果 */ private T result; /** * 是否出错 */ private Boolean isError; /** * 错误信息 */ private String errorMsg; @Override public String toString() &#123; return JSON.toJSONString(this); &#125;&#125; 服务端处理ServiceConnection123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package com.springboot.whb.study.rpc.rpc_v2.core;import lombok.Data;import lombok.extern.slf4j.Slf4j;import java.io.IOException;import java.net.ServerSocket;import java.net.Socket;/** * @author: whb * @description: 服务连接 */@Slf4j@Datapublic class ServiceConnection implements Runnable &#123; /** * 端口号 */ private int port; /** * 服务关闭标记位 */ private volatile boolean flag = true; /** * 服务端套接字 */ private ServerSocket serverSocket; /** * 服务处理器 */ private ServiceHandler serviceHandler; /** * 初始化 * * @param port * @param serviceHandler */ public void init(int port, ServiceHandler serviceHandler) &#123; try &#123; this.port = port; this.serverSocket = new ServerSocket(this.port); &#125; catch (IOException e) &#123; throw new RuntimeException(\"启动失败：\" + e.getMessage()); &#125; this.serviceHandler = serviceHandler; log.info(\"服务启动了...\"); &#125; @Override public void run() &#123; while (flag) &#123; try &#123; Socket socket = serverSocket.accept(); serviceHandler.handler(socket); &#125; catch (IOException e) &#123; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e1) &#123; log.error(\"服务处理异常，error:&#123;&#125;\", e); &#125; &#125; &#125; &#125; /** * 关闭连接 */ public void destory() &#123; log.info(\"服务端套接字关闭...\"); this.flag = false; &#125;&#125; ServiceHandler123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114package com.springboot.whb.study.rpc.rpc_v2.core;import com.google.common.util.concurrent.ThreadFactoryBuilder;import com.springboot.whb.study.rpc.rpc_v2.io.protocol.MessageProtocol;import lombok.Data;import lombok.extern.slf4j.Slf4j;import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.net.Socket;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ThreadFactory;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;/** * @author: whb * @description: 服务端处理器 */@Slf4j@Datapublic class ServiceHandler &#123; /** * 线程池 */ private ThreadPoolExecutor executor = null; /** * 服务接口 */ private RpcService rpcService; /** * 消息协议 */ private MessageProtocol messageProtocol; public ServiceHandler(RpcService rpcService) &#123; this.rpcService = rpcService; //创建线程的线程工厂 ThreadFactory commonThreadName = new ThreadFactoryBuilder() .setNameFormat(\"Parse-Task-%d\") .build(); //构造线程池 this.executor = new ThreadPoolExecutor( 10, 10, 2, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(200), commonThreadName, (Runnable r, ThreadPoolExecutor executor) -&gt; &#123; SocketTask socketTask = (SocketTask) r; Socket socket = socketTask.getSocket(); if (socket != null) &#123; try &#123; //无法及时处理和响应就快速拒绝掉 socket.close(); log.info(\"reject socket:\" + socketTask + \", and closed.\"); &#125; catch (IOException e) &#123; log.error(\"socket关闭失败，error:&#123;&#125;\", e); &#125; &#125; &#125; ); &#125; /** * 服务处理：接收到新的套接字，包装成为一个runnable提交给线程去执行 * * @param socket */ public void handler(Socket socket) &#123; this.executor.execute(new SocketTask(socket)); &#125; class SocketTask implements Runnable &#123; private Socket socket; public SocketTask(Socket socket) &#123; this.socket = socket; &#125; public Socket getSocket() &#123; return socket; &#125; @Override public void run() &#123; try &#123; InputStream inputStream = socket.getInputStream(); OutputStream outputStream = socket.getOutputStream(); // 获取客户端请求数据，统一包装成RpcRequest RpcRequest request = messageProtocol.serviceToRequest(inputStream); RpcResponse response = rpcService.invoke(request); log.info(\"request:[\" + request + \"],response:[\" + response + \"]\"); // 反射调用，得到具体的返回值 messageProtocol.serviceGetResponse(response, outputStream); &#125; catch (Exception e) &#123; log.error(\"服务端处理出现异常，error:&#123;&#125;\", e); &#125; finally &#123; if (socket != null) &#123; try &#123; socket.close(); &#125; catch (IOException e) &#123; log.error(\"socket关闭失败，error:&#123;&#125;\", e); &#125; &#125; &#125; &#125; &#125;&#125; RpcService123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158package com.springboot.whb.study.rpc.rpc_v2.core;import com.google.common.base.Joiner;import com.springboot.whb.study.rpc.rpc_v2.config.ServiceConfig;import com.springboot.whb.study.rpc.rpc_v2.io.protocol.DefaultMessageProtocol;import com.springboot.whb.study.rpc.rpc_v2.io.protocol.MessageProtocol;import com.springboot.whb.study.rpc.rpc_v2.register.ServiceRegister;import com.springboot.whb.study.rpc.rpc_v2.register.ZkServiceRegister;import lombok.Data;import lombok.extern.slf4j.Slf4j;import org.apache.commons.lang3.concurrent.BasicThreadFactory;import java.lang.reflect.Method;import java.util.HashMap;import java.util.Map;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;/** * @author: whb * @description: RPC服务 */@Slf4j@Datapublic class RpcService &#123; /** * k 是接口全名称 * v 是对应的对象包含的详细信息 */ private Map&lt;String, ServiceConfig&gt; serviceConfigMap = new HashMap&lt;&gt;(); /** * 端口号 */ private int port; /** * 服务注册 */ private ServiceRegister serviceRegister; /** * 连接器还未抽象处理，使用的还是BIO模型 */ private ServiceConnection serviceConnection; /** * 服务处理器 */ private ServiceHandler serviceHandler; /** * 线程池 */ ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(10, 100, 60, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(1000), new BasicThreadFactory.Builder().namingPattern(Joiner.on(\"-\").join(\"service-thread-pool-\", \"%s\")).build()); public RpcService(int port) &#123; this.port = port; this.serviceHandler = new ServiceHandler(this); this.serviceHandler.setMessageProtocol(new DefaultMessageProtocol()); this.serviceRegister = new ZkServiceRegister(); &#125; /** * 设置消息协议 * * @param messageProtocol */ public void setMessageProtocol(MessageProtocol messageProtocol) &#123; if (this.serviceHandler == null) &#123; throw new RuntimeException(\"套接字处理器无效\"); &#125; this.serviceHandler.setMessageProtocol(messageProtocol); &#125; /** * 添加服务接口 * * @param interfaceClass * @param ref * @param &lt;T&gt; */ public &lt;T&gt; void addService(Class&lt;T&gt; interfaceClass, T ref) &#123; String interfaceName = interfaceClass.getName(); ServiceConfig&lt;T&gt; serviceConfig = ServiceConfig.convert(interfaceName, interfaceClass, ref, this); serviceConfigMap.put(interfaceName, serviceConfig); &#125; /** * 注册服务 */ private void register() &#123; //服务注册，在网络监听启动之前就需要完成 serviceConfigMap.values().forEach(serviceRegister::register); &#125; /** * 服务启动 */ public void start() &#123; this.register(); log.info(\"服务注册完成\"); this.serviceConnection = new ServiceConnection(); this.serviceConnection.init(port, serviceHandler); threadPoolExecutor.execute(serviceConnection); //优雅关闭 Runtime.getRuntime().addShutdownHook(new Thread(() -&gt; &#123; RpcService.this.destroy(); &#125;)); &#125; /** * 通过反射执行，执行结果封装RpcResponse * * @param request * @param &lt;K&gt; * @param &lt;V&gt; * @return */ public &lt;K, V&gt; RpcResponse invoke(RpcRequest request) &#123; if (request == null) &#123; RpcResponse&lt;V&gt; response = new RpcResponse&lt;&gt;(); response.setResult(null); response.setIsError(true); response.setErrorMsg(\"未知异常\"); return response; &#125; String className = request.getClassName(); //暂时不考虑没有对应的serviceConfig的情况 ServiceConfig&lt;K&gt; serviceConfig = serviceConfigMap.get(className); K ref = serviceConfig.getRef(); try &#123; Method method = ref.getClass().getMethod(request.getMethodName(), request.getParameterTypes()); V result = (V) method.invoke(ref, request.getArguments()); RpcResponse&lt;V&gt; response = new RpcResponse&lt;&gt;(); response.setResult(result); response.setIsError(false); response.setErrorMsg(\"\"); return response; &#125; catch (Exception e) &#123; &#125; return null; &#125; /** * 关闭服务 */ public void destroy() &#123; this.serviceConnection.destory(); log.info(\"服务端关闭了\"); &#125;&#125; 客户端处理代理对象ProxyInstance1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.springboot.whb.study.rpc.rpc_v2.core;import lombok.extern.slf4j.Slf4j;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.net.InetSocketAddress;/** * @author: whb * @description: 客户端代理对象 */@Slf4jpublic class ProxyInstance implements InvocationHandler &#123; /** * RPC调用方 */ private RpcClient rpcClient; private Class clazz; public ProxyInstance(RpcClient client, Class clazz) &#123; this.rpcClient = client; this.clazz = clazz; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; RpcRequest request = new RpcRequest(); request.setClassName(clazz.getName()); request.setMethodName(method.getName()); request.setArguments(args); request.setParameterTypes(method.getParameterTypes()); //获取服务提供方信息 InetSocketAddress address = rpcClient.discovery(request); log.info(\"[\" + Thread.currentThread().getName() + \"] discovery service: \" + address); //发起网络请求，得到请求数据 RpcResponse response = rpcClient.invoke(request, address); return response.getResult(); &#125;&#125; ClientHandler1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677package com.springboot.whb.study.rpc.rpc_v2.core;import com.springboot.whb.study.rpc.rpc_v2.io.protocol.MessageProtocol;import lombok.extern.slf4j.Slf4j;import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.net.InetSocketAddress;import java.net.Socket;/** * @author: whb * @description: 客户端处理器 */@Slf4jpublic class ClientHandler &#123; private RpcClient rpcClient; private MessageProtocol messageProtocol; public ClientHandler(RpcClient rpcClient) &#123; this.rpcClient = rpcClient; &#125; public void setMessageProtocol(MessageProtocol messageProtocol) &#123; this.messageProtocol = messageProtocol; &#125; public &lt;T&gt; RpcResponse&lt;T&gt; invoke(RpcRequest request, InetSocketAddress address) &#123; RpcResponse&lt;T&gt; response = new RpcResponse&lt;&gt;(); Socket socket = getSocketInstance(address); if (socket == null) &#123; // 套接字链接失败 response.setIsError(true); response.setErrorMsg(\"套接字链接失败\"); return response; &#125; try &#123; InputStream inputStream = socket.getInputStream(); OutputStream outputStream = socket.getOutputStream(); messageProtocol.clientToRequest(request, outputStream); response = messageProtocol.clientGetResponse(inputStream); &#125; catch (IOException e) &#123; log.error(\"客户端处理异常，error:&#123;&#125;\", e); &#125; finally &#123; if (socket != null) &#123; try &#123; socket.close(); &#125; catch (IOException e) &#123; log.error(\"客户端关闭套接字失败，error:&#123;&#125;\", e); &#125; &#125; &#125; return response; &#125; /** * 获取对象实例 * * @param address * @return */ private Socket getSocketInstance(InetSocketAddress address) &#123; try &#123; return new Socket(address.getHostString(), address.getPort()); &#125; catch (IOException e) &#123; log.error(\"客户端获取套接字失败，error:&#123;&#125;\", e); &#125; return null; &#125;&#125; RpcClient123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101package com.springboot.whb.study.rpc.rpc_v2.core;import com.springboot.whb.study.rpc.rpc_v2.config.ClientConfig;import com.springboot.whb.study.rpc.rpc_v2.domain.ServiceType;import com.springboot.whb.study.rpc.rpc_v2.io.protocol.DefaultMessageProtocol;import com.springboot.whb.study.rpc.rpc_v2.register.ServiceRegister;import com.springboot.whb.study.rpc.rpc_v2.register.ZkServiceRegister;import java.net.InetSocketAddress;import java.util.HashMap;import java.util.Map;/** * @author: whb * @description: RPC客户端 */public class RpcClient &#123; /** * k 是接口的全名称 * v 是对应的对象包含的详细信息 */ private Map&lt;String, ClientConfig&gt; clientConfigMap = new HashMap&lt;&gt;(); /** * 服务注册 */ private ServiceRegister serviceRegister; /** * 客户端处理器 */ private ClientHandler clientHandler; public RpcClient() &#123; this.serviceRegister = new ZkServiceRegister(); this.clientHandler = new ClientHandler(this); // 设置默认的消息处理协议 this.clientHandler.setMessageProtocol(new DefaultMessageProtocol()); &#125; /** * 订阅服务 * * @param clazz * @param &lt;T&gt; */ public &lt;T&gt; void subscribe(Class&lt;T&gt; clazz) &#123; String interfaceName = clazz.getName(); ProxyInstance invocationHandler = new ProxyInstance(this, clazz); ClientConfig&lt;T&gt; clientConfig = ClientConfig.convert(clazz, invocationHandler); clientConfigMap.put(interfaceName, clientConfig); &#125; /** * 服务注册 */ private void register() &#123; // 服务注册，在网络监听启动之前就需要完成 clientConfigMap.values().forEach(serviceRegister::register); &#125; /** * 服务启动 */ public void start() &#123; this.register(); &#125; /** * 服务发现 * * @param request * @return */ public InetSocketAddress discovery(RpcRequest request) &#123; return serviceRegister.discovery(request, ServiceType.PROVIDER); &#125; /** * 反射调用 * * @param request * @param address * @return */ public RpcResponse invoke(RpcRequest request, InetSocketAddress address) &#123; return this.clientHandler.invoke(request, address); &#125; /** * 获取对象实例 * * @param clazz * @param &lt;T&gt; * @return */ public &lt;T&gt; T getInstance(Class&lt;T&gt; clazz) &#123; return (T) (clientConfigMap.get(clazz.getName()).getProxy()); &#125;&#125; 测试测试接口定义Calculate1234567891011121314151617181920212223242526package com.springboot.whb.study.rpc.rpc_v2.demo;/** * @author: whb * @description: 测试接口定义 */public interface Calculate&lt;T&gt; &#123; /** * 求和 * * @param a * @param b * @return */ T add(T a, T b); /** * 求差 * * @param a * @param b * @return */ T sub(T a, T b);&#125; 测试接口实现类SimpleCalculate12345678910111213141516171819202122232425262728package com.springboot.whb.study.rpc.rpc_v2.demo;import java.util.Random;/** * @author: whb * @description: 测试接口实现类 */public class SimpleCalculate implements Calculate&lt;Integer&gt; &#123; @Override public Integer add(Integer a, Integer b) &#123; long start = System.currentTimeMillis(); try &#123; Thread.sleep(new Random().nextInt(1000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; int c = a + b; System.out.println(Thread.currentThread().getName() + \" 耗时:\" + (System.currentTimeMillis() - start)); return c; &#125; @Override public Integer sub(Integer a, Integer b) &#123; return a - b; &#125;&#125; 测试-服务端Service12345678910111213141516package com.springboot.whb.study.rpc.rpc_v2.demo;import com.springboot.whb.study.rpc.rpc_v2.core.RpcService;/** * @author: whb * @description: 测试服务端 */public class Service &#123; public static void main(String[] args) &#123; RpcService rpcService = new RpcService(10001); rpcService.addService(Calculate.class, new SimpleCalculate()); rpcService.start(); &#125;&#125; 测试-客户端Client1234567891011121314151617181920212223242526272829303132333435363738package com.springboot.whb.study.rpc.rpc_v2.demo;import com.google.common.base.Joiner;import com.springboot.whb.study.rpc.rpc_v2.core.RpcClient;import org.apache.commons.lang3.concurrent.BasicThreadFactory;import java.util.Random;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;/** * @author: whb * @description: 测试客户端 */public class Client &#123; public static final ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(10, 100, 60, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(1000), new BasicThreadFactory.Builder().namingPattern(Joiner.on(\"-\").join(\"client-thread-pool-\", \"%s\")).build()); public static void main(String[] args) &#123; RpcClient rpcClient = new RpcClient(); rpcClient.subscribe(Calculate.class); rpcClient.start(); Calculate&lt;Integer&gt; calculateProxy = rpcClient.getInstance(Calculate.class); for (int i = 0; i &lt; 200; i++) &#123; threadPoolExecutor.execute(() -&gt; &#123; long start = System.currentTimeMillis(); int s1 = new Random().nextInt(100); int s2 = new Random().nextInt(100); int s3 = calculateProxy.add(s1, s2); System.out.println(\"[\" + Thread.currentThread().getName() + \"]a: \" + s1 + \", b:\" + s2 + \", c=\" + s3 + \", 耗时:\" + (System.currentTimeMillis() - start)); &#125;); &#125; &#125;&#125; 测试结果zookeeper 服务端 客户端 总结v2版本相比v1版本修改了整个代码结构，使得结构能够更加明确，引入zookeeper作为服务治理功能，大致介绍了zookeeper的特点以及功能，给服务注册、服务发现、序列化协议等均留下了口子，以便实现自定义的协议，v1的io模型是BIO，v2并没有变化，只是由单线程改造成多线程。 整体而言符合一个简单的rpc框架，依旧还是有很多点可以完善、优化的点，如： io模型还是没有替换，后面考虑直接整体接入netty； 不应该每次实时从zk获取节点信息，应该先设置一个本地缓存，再利用zookeeper的watcher功能，开启一个异步线程去监听更新本地缓存，降低和zk交互带来的性能损耗； 没有快速失败、重试的功能，客观情况下存在网络抖动的问题，重试就可以了。 整体的各种协议约定并没有明确规范，比较混乱。","tags":"rpc"},{"title":"Hexo添加音乐播放器","url":"/posts/db828ee7.html","text":"写在前面为博客添加音乐播放器功能，网上有很多种方式，也有很多插件可以用，比如aplayer、dplayer等等。部署方式既可以使用hexo插件，也可以通过提取dist文件的方式。 本人为自己的播放选择的aplayer播放器，一开始是使用hexo插件的方式，但是部署的时候一直报标签解析的错误，查了好久也没查到原因，无奈，放弃使用插件的方式，改为使用提取aplayer的dist文件的方式。 下载aplayer访问aplayer源码：GitHub Aplayer ，将文件下载到本地，解压后将dist文件夹复制到 /themes/next/source 文件夹下。 创建样式新建music.js在/themes/next/source/dist文件夹中新建music.js文件，将下面代码添加进去： 12345678910111213141516171819202122const ap = new APlayer(&#123; container: document.getElementById('aplayer'), autoplay: false, loop: 'all', volume: 0.7, listFolded: true, listMaxHeight: 60, audio: [ &#123; name: 'name1', artist: 'artist1', url: 'url1.mp3', cover: 'cover1.jpg', &#125;, &#123; name: 'name2', artist: 'artist2', url: 'url2.mp3', cover: 'cover2.jpg', &#125; ]&#125;); 参数修改上面代码为你在hexo上生成aplayer播放器的样式，参数修改参考 官方中文文档 。 修改aplayer样式 普通模式： 123456789const ap = new APlayer(&#123; container: document.getElementById('aplayer'), audio: [&#123; name: 'name', artist: 'artist', url: 'url.mp3', cover: 'cover.jpg' &#125;]&#125;); 效果如下： 播放列表模式： 123456789101112131415161718192021222324const ap = new APlayer(&#123; container: document.getElementById('player'), listFolded: false,//列表默认折叠 listMaxHeight: 90,//列表最大高度 lrcType: 3, //此为歌词格式，没有歌词可以直接删掉这一行 audio: [ &#123; name: 'name1', artist: 'artist1', url: 'url1.mp3', cover: 'cover1.jpg', lrc: 'lrc1.lrc', theme: '#ebd0c2' &#125;, &#123; name: 'name2', artist: 'artist2', url: 'url2.mp3', cover: 'cover2.jpg', lrc: 'lrc2.lrc', theme: '#46718b' &#125; ]&#125;); 效果如下： 吸底模式： 12345678910const ap = new APlayer(&#123; container: document.getElementById('player'), fixed: true, audio: [&#123; name: 'name', artist: 'artist', url: 'url.mp3', cover: 'cover.jpg', &#125;]&#125;); 效果如下： 迷你底模式： 12345678910const ap = new APlayer(&#123; container: document.getElementById('player'), mini: true, audio: [&#123; name: 'name', artist: 'artist', url: 'url.mp3', cover: 'cover.jpg', &#125;]&#125;); 附上我的参数： 1234567891011121314151617181920212223242526272829303132const ap = new APlayer(&#123; container: document.getElementById('aplayer'), //播放器容器元素 listFolded: false, //列表默认折叠 listMaxHeight: 90, //列表最大高度 //lrcType: 3, //此为歌词格式，没有歌词可以直接删掉这一行 mini: false, //迷你模式 autoplay: true, //自动播放 theme: '#FADFA3', //主题色 loop: 'all', //音频循环播放, 可选值: 'all'全部循环, 'one'单曲循环, 'none'不循环 order: 'list', //音频循环顺序, 可选值: 'list'列表循环, 'random'随机循环 preload: 'auto', //预加载，可选值: 'none', 'metadata', 'auto' volume: 0.7, //默认音量，请注意播放器会记忆用户设置，用户手动设置音量后默认音量即失效 mutex: false, //互斥，阻止多个播放器同时播放，当前播放器播放时暂停其他播放器 audio: [ //音频信息 &#123; name: '大鱼', //音频名称 artist: '周深、郭沁', //音频艺术家 url: '\"http://lc-tguve1gk.cn-n1.lcfile.com/47b5548df9c80bba84f4/%E5%91%A8%E6%B7%B1%E3%80%81%E9%83%AD%E6%B2%81%20-%20%E5%A4%A7%E9%B1%BC%20%282017%E4%B8%AD%E5%9B%BD%E6%96%B0%E6%AD%8C%E5%A3%B0%E7%AC%AC%E4%BA%8C%E5%AD%A3%E7%AC%AC%E5%8D%81%E6%9C%9F%E7%8E%B0%E5%9C%BA%E4%BC%B4%E5%A5%8F%29.mp3', //音频链接 cover: 'http://lc-tguve1gk.cn-n1.lcfile.com/a9fff99abbddc8757d4b/%E5%A4%A7%E9%B1%BC.jpg', //音频封面 //lrc: 'lrc1.lrc', //歌词 theme: '#ebd0c2' //切换到此音频时的主题色，比上面的 theme 优先级高 &#125;, &#123; name: 'Something just like this', artist: 'Alex Goot _ Madilyn Bailey', url: 'http://lc-tguve1gk.cn-n1.lcfile.com/f3bee3260fa207648d34/Alex%20Goot%20_%20Madilyn%20Bailey%20-%20Something%20Just%20Like%20This.mp3', cover: 'http://lc-tguve1gk.cn-n1.lcfile.com/d21b8e3392433807b1e2/Something%20just%20like%20this.jpg', //lrc: 'lrc2.lrc', theme: '#46718b' &#125; ]&#125;); 部署aplayer的样式设置好之后就可以把aplayer放在自己想要放置的位置上，放置代码如下： 1234&lt;link rel=\"stylesheet\" href=\"/dist/APlayer.min.css\"&gt;&lt;div id=\"aplayer\"&gt;&lt;/div&gt;&lt;script type=\"text/javascript\" src=\"/dist/APlayer.min.js\"&gt;&lt;/script&gt;&lt;script type=\"text/javascript\" src=\"/dist/music.js\"&gt;&lt;/script&gt; 将放置代码放在不同的/themes/next/layout/xxx.swig文件内会有不同的效果。 每个人使用的主题不一样，要根据自己的主题去调试。例如我用的是next-mist主题，且喜欢放置在侧边栏。那么在/themes/next/layout/_marco文件夹下找到sidebar.swig文件。 如果要放置在侧边栏的友链下面,那么在sidebar.swig中找到if theme.links，将放置代码添加到endif之后。如下图： 如要放置到RSS下就在sidebar.swig中搜索if theme.rss，也是添加到endif之后。 我是选择放在了友链下方，如下图： 最终效果如下图： 制作音乐/图片外链正如之前为博客添加评论及统计功能的时候，我们使用了LeanCloud，制作音乐/图片的外链同样也可以使用它。 注册、登陆的步骤在之前的文章里已经描绘过了，这里不再详述，我们直接步入正题。 到你创建的应用里面去，点击存储，如下图。点击_File，点击上传，找到你下载好的音乐文件和音乐图片上传上去就行了。 上传之后刷新页面，将列表向后拉，就可以看到对应的音乐和图片的url连接了。","tags":"hexo"},{"title":"分布式学习-一致性Hash算法","url":"/posts/302399c9.html","text":"示例引入比如现在有 N 个 Redis 服务器，不考虑使用Redis Cluster的情况下，那么如何将一个对象 object 映射到 N 个 Redis 上呢？ 你很可能会采用类似下面的通用方法计算 object 的 hash 值，然后均匀的映射到到 N 个 cache： 求余算法: hash(object) % N 这种通用的计算方法有什么问题呢？ 一个 redis 服务器 x 宕 掉了，这样所有映射到 redis x 的对象都会失效。怎么办？需要把 redis x 从 redis集群中移除，这时候 redis服务器 是 N-1 台，那么对应映射公式变成了 hash(object)%(N-1) ； 还有一种情况是由于访问量增多，需要添加 redis ，这时候 redis 是 N+1 台，映射公式变成了 hash(object)%(N+1) ； 1 和 2 意味着突然之间几乎所有的 redis缓存都失效了。对于服务器而言，这是一场灾难，所有的访问都会直接冲向后端服务器，对后端服务器造成压力，甚至是后端服务器瘫痪。如何解决上面的问题呢？一致性hash算法就派上用场了。 一致性Hash算法一致性Hash用于分布式缓存系统，将Key值映射到具体机器Ip上，并且增加和删除1台机器的数据移动量较小。 一致性Hash算法也是使用取模的方法，只是，刚才描述的取模法是对服务器的数量进行取模，而一致性Hash算法是对2^32取模。简单来说，一致性Hash算法将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形），整个哈希环如下： 整个空间按顺时针方向组织，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32-1，也就是说0点左侧的第一个点代表2^32-1， 0和2^32-1在零点中方向重合，把这个由2^32个点组成的圆环称为Hash环。 以上面的场景为例，假设有4台缓存服务器，node1、node2、node3，node4，那么，在生产环境中，这4台服务器肯定有自己的IP地址或主机名，用它们各自的IP地址或主机名作为关键字进行哈希计算，使用哈希后的结果对2^32取模，可以使用如下公式： hash（node1的IP地址） % 2^32 通过上面公式算出的结果一定能得到一个0到2^32-1之间的整数，就用得出的整数，代表服务器node1，既然这个整数肯定处于0到2^32-1之间，那么，上图中的hash环上必定有一个点与这个整数对应，也就是服务器node1，那么，服务器node1就可以映射到这个环上了，其他服务器依次类推即可得到相应的位置，如下图： 接下来使用如下算法定位数据访问到相应服务器： 将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，遇到的第一台服务器就是该数据应该映射到的服务器。例如我们有Object A、Object B、Object C、Object D四个数据对象，经过哈希计算后，在环空间上的位置如下： 根据一致性哈希算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。 一致性hash算法的容错性和扩展性现在假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。 一般的，在一致性哈希算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。如下图所示： 下面考虑另外一种情况，如果在系统中增加一台服务器Node X，如下图所示： 此时对象Object A、B、D不受影响，只有对象C需要重定位到新的Node X 。 一般的，在一致性哈希算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。 综上所述，一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。 Hash环的数据倾斜问题一致性Hash算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题，例如系统中只有两台服务器，其环分布如下： 此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。为了解决这种数据倾斜问题，一致性Hash算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器IP或主机名的后面增加编号来实现。 例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点： 同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。 一致性Hash算法的Java实现HashUtils工具类1234567891011121314151617181920212223242526272829303132package com.springboot.whb.study.consistentHashing;/** * @author: whb * @description: Hash工具类 */public class HashUtils &#123; /** * 使用FNV1_32_HASH算法计算服务器的Hash值 * * @param str * @return */ public static int getHash(String str) &#123; final int p = 16777619; int hash = (int) 2166136261L; for (int i = 0; i &lt; str.length(); i++) &#123; hash = (hash ^ str.charAt(i)) * p; &#125; hash += hash &lt;&lt; 13; hash ^= hash &gt;&gt; 7; hash += hash &lt;&lt; 3; hash ^= hash &gt;&gt; 17; hash += hash &lt;&lt; 5; // 如果算出来的值为负数则取其绝对值 if (hash &lt; 0) &#123; hash = Math.abs(hash); &#125; return hash; &#125;&#125; 不带虚拟节点具体代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.springboot.whb.study.consistentHashing;import java.util.SortedMap;import java.util.TreeMap;/** * @author: whb * @description: 一致性Hash算法--不带虚拟节点的实现 */public class ConsistentHashingWithoutVirtualNode &#123; /** * 待添加到Hash环的服务器 */ private static String[] servers = &#123;\"127.0.0.1:7000\", \"127.0.0.1:7001\", \"127.0.0.1:7002\", \"127.0.0.1:7003\", \"127.0.0.1:7004\"&#125;; /** * key表示服务器的Hash值，value表示服务器 */ private static SortedMap&lt;Integer, String&gt; sortedMap = new TreeMap&lt;&gt;(); /** * 初始化，将所有服务器放入sortedMap */ static &#123; for (int i = 0; i &lt; servers.length; i++) &#123; int hash = HashUtils.getHash(servers[i]); System.out.println(\"[\" + servers[i] + \"]加入集合中, 其Hash值为：\" + hash); sortedMap.put(hash, servers[i]); &#125; System.out.println(); &#125; /** * 得到应当路由到的结点 * * @param key * @return */ private static String getServer(String key) &#123; //得到该key的hash值 int hash = HashUtils.getHash(key); //得到大于该Hash值的所有Map SortedMap&lt;Integer, String&gt; subMap = sortedMap.tailMap(hash); if (subMap.isEmpty()) &#123; //如果没有比该key的hash值大的，则从第一个node开始 Integer i = sortedMap.firstKey(); //返回对应的服务器 return sortedMap.get(i); &#125; else &#123; //第一个Key就是顺时针过去离node最近的那个结点 Integer i = subMap.firstKey(); //返回对应的服务器 return subMap.get(i); &#125; &#125; public static void main(String[] args) &#123; String[] keys = &#123;\"斗帝\", \"斗圣\", \"斗尊\", \"斗宗\", \"斗皇\", \"斗王\", \"斗灵\", \"大斗师\", \"斗师\", \"斗者\"&#125;; for (String key : keys) &#123; System.out.println(\"[\" + key + \"]的hash值为：\" + HashUtils.getHash(key) + \", 被路由到结点[\" + getServer(key) + \"]\"); &#125; &#125;&#125; 测试结果 带虚拟节点具体代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114package com.springboot.whb.study.consistentHashing;import com.springboot.whb.study.common.util.StringUtils;import java.util.LinkedList;import java.util.List;import java.util.SortedMap;import java.util.TreeMap;/** * @author: whb * @description: 一致性Hash算法--带虚拟节点的实现 */public class ConsistentHashingWithVirtualNode &#123; /** * 待添加到Hash环的服务器 */ private static String[] servers = &#123;\"127.0.0.1:7000\", \"127.0.0.1:7001\", \"127.0.0.1:7002\", \"127.0.0.1:7003\", \"127.0.0.1:7004\"&#125;; /** * 真实节点列表，考虑到服务器的上线、下线，即添加、删除的场景会比较频繁 */ private static List&lt;String&gt; realNodes = new LinkedList&lt;&gt;(); /** * 虚拟节点，Key表示虚拟节点的Hash值，value表示虚拟节点的名称 */ private static SortedMap&lt;Integer, String&gt; virtualNodes = new TreeMap&lt;&gt;(); /** * 虚拟节点的数目 */ private static final int VIRTUAL_NODES = 5; /** * 初始化，加入真实节点及虚拟节点 */ static &#123; //先将原始的服务器添加到真实节点列表 for (int i = 0; i &lt; servers.length; i++) &#123; realNodes.add(servers[i]); &#125; //添加虚拟节点，遍历真实节点列表 for (String str : realNodes) &#123; for (int i = 0; i &lt; VIRTUAL_NODES; i++) &#123; String virtualNodeName = str + \"&amp;&amp;VN\" + String.valueOf(i); setServer(virtualNodeName); &#125; &#125; System.out.println(); &#125; /** * 添加虚拟节点 * * @param virtualNodeName */ private static void setServer(String virtualNodeName) &#123; setServer(virtualNodeName, null); &#125; /** * 添加虚拟节点 * * @param virtualNodeName * @param hash */ private static void setServer(String virtualNodeName, Integer hash) &#123; hash = hash != null ? HashUtils.getHash(hash.toString()) : HashUtils.getHash(virtualNodeName); if (StringUtils.isBlank(virtualNodes.get(hash))) &#123; virtualNodes.put(hash, virtualNodeName); System.out.println(\"虚拟节点[\" + virtualNodeName + \"]被添加, hash值为：\" + hash); &#125; else &#123; //解决Hash碰撞 setServer(virtualNodeName, hash); &#125; &#125; /** * 得到应当路由到的结点 * * @param key * @return */ private static String getServer(String key) &#123; //得到该key的hash值 int hash = HashUtils.getHash(key); // 得到大于该Hash值的所有Map SortedMap&lt;Integer, String&gt; subMap = virtualNodes.tailMap(hash); String virtualNode; if (subMap.isEmpty()) &#123; //如果没有比该key的hash值大的，则从第一个node开始 Integer i = virtualNodes.firstKey(); //返回对应的服务器 virtualNode = virtualNodes.get(i); &#125; else &#123; //第一个Key就是顺时针过去离node最近的那个结点 Integer i = subMap.firstKey(); //返回对应的服务器 virtualNode = subMap.get(i); &#125; return virtualNode; &#125; public static void main(String[] args) &#123; String[] keys = &#123;\"斗帝\", \"斗圣\", \"斗尊\", \"斗宗\", \"斗皇\", \"斗王\", \"斗灵\", \"大斗师\", \"斗师\", \"斗者\"&#125;; for (String key : keys) &#123; String server = getServer(key); String realServer = server.split(\"&amp;&amp;VN\")[0]; System.out.println(\"[\" + key + \"]的hash值为\" + HashUtils.getHash(key) + \", 被路由到虚拟结点[\" + server + \"]，被路由到真实节点[\" + realServer + \"]\"); &#125; &#125;&#125; 测试结果","tags":"分布式"},{"title":"手写RPC-NIO学习","url":"/posts/e4966bd.html","text":"概述NIO是Java1.4推出的一种全新的IO模型，全称是java non-blocking IO，提供ByteBuffer等缓存的容器，达到非阻塞式的高伸缩性网络。 IO模型IO模型是机器进行IO具体操作方法的一种抽象，每种IO模型都有各自的优缺点，需要注意的是要完成各模型的实际开发需要操作系统的支持，在没有poll、epoll出来之前，java进行非阻塞式的读写操作很复杂，而当上述功能出现之后，java才在基于该功能上添加了nio模块，包名是java.nio，现在在类Linux是基于epoll实现的，类Unix（包含Mac）是基于kqueue 实现的。 Buffer是一种缓冲数据的容器，可以存储各种基本类型的数据。线程不安全，数据结构如下图所示：类似于一个数组，其中capacity为缓冲数组的长度，为固定的值；postion表示下一个需要操作的位置；limit为下一个不可操作的位置；各种数据的大小关系是0&lt;=position&lt;=limit&lt;=capacity put 写入数据，每次写入数据的地方都是postion，就会使得postion的值变大，当直到填充的数据长度超过了数组的长度，会抛出BufferOverflowException异常； get 读取数据 每次也会进行postion+1操作,这里需要注意到每次读取数据之前必须进行clear操作要不然会出现数据错误的问题，如下使用例子： 错误示例 正确示例 clear() 清空缓冲区的数据，实际上是假清除，只是将postion置位0，limit置位capacity；源码如下： 123456public final Buffer clear() &#123; position = 0; limit = capacity; mark = -1; return this;&#125; allocate(int n) 申请缓冲区，大小由参数决定; wrap(byte[] byets) 同样是申请缓冲区，传入的参数却是byte[],相当于设置的缓冲区大小是byte数组的长度，然后初始化设置了该缓冲容器的值; flip() 切换到读模式，修改limit为postion，position为0; hasRemaining() 查看是否还有数据可读 return position &lt; limit; 一般的使用套路都是: 12345678ByteBuffer byteBuffer = ByteBuffer.allocate(10);byteBuffer.clear(); // 清空byteBuffer.put(\"hello\".getBytes()); // 写入数据byteBuffer.flip(); // 读数据之前的必备操作while (byteBuffer.hasRemaining())&#123; // 数据是否读取完毕 System.out.print(byteBuffer.get() + \"\\t\" ); // 读取数据&#125;System.out.println(); ChannelChannel通道，和pipeline一个意思，类似于IO的Stream，只是stream是单向，要么是Input要么是Output，而Channel是双向的，也就意味着可以通过一个channel进行读写操作了。不过需要注意可以读写操作和能不能读写操作这是两回事。 Nio的channel具体实现主要为FileChannel、DatagramChannel、SocketChannel、ServerSocketChannel四种，分别对应的是文件、UDP和TCP的客户端和服务端。重点介绍SocketChannle和ServerSocketChannel。 SocketChannelSocketchannel 是客户端，连接一个创建好的TCP网络套接字的通道，可有两种创建方式 新建一个socketchannel，并连接到服务器上; 123SocketChannel socketChannel = SocketChannel.open();// 连接到本地的8081端口的服务器上socketChannel.connect(new InetSocketAddress(8081)); 服务器接收到来自客户端的请求接收到的 12345// 服务端接收到客户端发送的信息，通过accpet即可获取对应的socketChannelSocketChannel socketChannel = serverSocketChannel.accept();// 关闭socketChannel，由于其会抛出异常，最好是放在finally里面，并且做好空判断以及异常捕获socketChannel.close(); 由上图所示，需要从channel读数据，以及向外发送数据都需要使用buffer作为缓冲容器 12345678910111213141516171819// 读数据ByteBuffer byteBuffer = ByteBuffer.allocate(1024);// read 方法会返回读取了多少数据到buffer中，返回-1表示数据以及读取完毕，可以关闭通道了int count = socketChannel.read(byteBuffer);// 写数据String message = \"Hello World!\";// 直接调用write方法写入相关的bytebuffer数组socketChannel.write(message.getBytes());// 写数据方法2String message = \"Hello World!\";ByteBuffer byteBuffer = ByteBuffer.allocate(1024);byteBuffer.clear();byetBuffer.put(message.getBytes());byetBuffer.flip();while(byteBuffer.hasRemaing())&#123; socketChannel.write(byetBuffer);&#125; 由于其为异步模式，在其调用connect()方法的时候是立即返回结果，连接成功返回true，连接不成功返回false，并继续进行连接（服务自主操作），存在还未建立连接就返回了，所以在使用服务端数据的时候再调用finishConnect()确保链接的建立: 12345678SocketChannel socketChannel = SocketChannel.open();socketChannel.configureBlocking (false); // 一定要设置该内容socketChannel.connect(new InetSocketAddress(8081)); while(!socketChannel.finishConnect())&#123; ..... // 日志打印等操作，直到连接成功&#125;// 这是阻塞模式的// 连接成功，可以进行读写操作了 可以通过方法isConnectionPending()的返回值确认是否处于连接中。 ServerSocketChannelServerSocketChannel 是应用在服务端的，和Socketchannel相对应，主要是用来监听新来的TCP请求的一个通道。绑定的本地端口，IP是本机IP。创建方式如下： 123456789101112131415161718192021222324252627282930313233343536373839404142ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();serverSocketChannel.socket().bind(new InetSocketAddress(8081));// 通过对该channel持有的socket进行绑定端口操作// 之前很奇怪一个问题，这个直接调用socket().bind不会有空指针么？肯定不会有这个错误的// 在调用socket()，如果发现其内置的socket为null，就会生成一个socket的适配参数替换nullclass ServerSocketChannelImpl extends ServerSocketChannel implements SelChImpl &#123; private static NativeDispatcher nd; private final FileDescriptor fd; private int fdVal; private volatile long thread = 0L; private final Object lock = new Object(); private final Object stateLock = new Object(); private static final int ST_UNINITIALIZED = -1; private static final int ST_INUSE = 0; private static final int ST_KILLED = 1; private int state = -1; private InetSocketAddress localAddress; private boolean isReuseAddress; ServerSocket socket; // 这个就是调用socket取得的数据 public ServerSocket socket() &#123; Object var1 = this.stateLock; synchronized (this.stateLock) &#123; if (this.socket == null) &#123; this.socket = ServerSocketAdaptor.create(this); &#125; return this.socket; &#125; &#125;&#125;public class ServerSocketAdaptor extends ServerSocket &#123; private final ServerSocketChannelImpl ssc; private volatile int timeout = 0; public static ServerSocket create(ServerSocketChannelImpl var0) &#123; try &#123; return new ServerSocketAdaptor(var0); &#125; catch (IOException var2) &#123; throw new Error(var2); &#125; &#125;&#125; Selectorselector 是nio中能够管理多个channel通道并感知各个通道的读写状态的一个组件，可以使用单线程管理多个channel的从而同时处理多个网络请求。selector和channel是通过selectorkey绑定的 12345678// 创建一个selectorSelector selector = Selector.open();// 创建serversocketChannel并绑定端口ServerSocketChannel serverSocketChannel ..... // 设置为非阻塞模式ServerSocketChannel.configureBlocking(false); // register绑定selector和channel到一个对象SelectionKey中SelectionKey key = channel.register(selector,Selectionkey.OP_READ); 注意register()方法的第二个参数。这是一个“interest集合”，意思是在通过Selector监听Channel时对什么事件感兴趣。可以监听四种不同类型的事件： Selectionkey.Connect 可以连接 （客户端接收到可连接到请求）; Selectionkey.Accept 可以接受 （服务端接到客户端连接的请求）; Selectionkey.Read 可以读取数据; Selectionkey.Write 可以写入数据; SelectionKey绑定channel和selector的对象，还包含有read集合和interest集合(感兴趣，在register设置的值),还可以通过attachment()方法绑定一些其他数据。配套的还有判断其状态的方法 123456public class SelectionKeyImpl extends AbstractSelectionKey &#123; final SelChImpl channel; public final SelectorImpl selector; private int index; private volatile int interestOps; private int readyOps; 选择通道selector从已经注册好的channel中获取已经准备就绪的通道进行操作，以下三种是获取通道的方法: int select() // 阻塞模式，至少有一个准备就绪的通道才返回 int select(long timeout) // 加入超时设置 int selectNow() // 会立即返回，返回当前就绪的通道个数 selectedKeys()获取当前就绪的通道集合 close() 关闭当前的selector，使得绑定的key全部不可用，但是通道本身还是可以正常使用的 12345678910111213141516171819int count = selector.select();Iterator it = selector.selectedKeys().iterator();while (it.hasNext())&#123; SelectionKey selectionKey = (SelectionKey)it.next(); it.remove(); // 处理完成一个key就移除掉，无需再次处理 if(selectionKey.isAcceptable())&#123; ServerSocketChannel serverSocketChannel = (ServerSocketChannel) selectionKey.channel(); SocketChannel socketChannel = serverSocketChannel.accept(); socketChannel.configureBlocking(false); socketChannel.register(selector, SelectionKey.OP_READ); &#125; if(selectionKey.isReadable())&#123; SocketChannel socketChannel = (SocketChannel) selectionKey.channel(); createProcessor(socketChannel); socketChannel.register(selector, SelectionKey.OP_WRITE); selectionKey.cancel(); // 当前key取消掉了，但是通道依旧可用 &#125;&#125; DatagramChannel收发UTP包的通道，适用于UTP协议，发送和读取的是用户数据报 123456DatagramChannel channel = DatagramChannel.open();channel.socket().bind(new InetSocketAddress(10002));// 建立了一个本地10002端口的UTP服务端channel.connect(new InetSocketAddress(10002));// 连接一个IP默认为本机，端口为10002服务// 读写和传统的read、write类似","tags":"rpc nio"},{"title":"Redis知识点学习","url":"/posts/b1cc4593.html","text":"redis 简介Redis本质上是一个Key-Value类型的内存数据库，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。 因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。可用于缓存、事件发布或订阅、高速队列等场景。 该数据库使用ANSI C语言编写，支持网络，提供字符串、哈希、列表、队列、集合结构直接存取，基于内存，可持久化。Redis 内置了 复制（replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（transactions） 和不同级别的 磁盘持久化（persistence）， 并通过 Redis哨兵（Sentinel）和自动分区（Cluster）提供高可用性（high availability）。 redis的应用场景有哪些 1、会话缓存（最常用）2、消息队列，比如支付3、活动排行榜或计数4、发布、订阅消息（消息通知）5、商品列表、评论列表等 为什么要用 redis 而不用 map/guava 做缓存缓存分为本地缓存和分布式缓存。 以java为例，使用自带的map或者guava实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。 使用 redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持 redis 或 memcached服务的高可用，整个程序架构上较为复杂。 redis 和 memcached 的区别 redis支持更丰富的数据类型（支持更复杂的应用场景）：Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。memcached支持简单的数据类型，String。Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而Memecached把数据全部存在内存之中。集群模式：memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是redis目前是原生支持cluster模式的，redis官方就是支持redis cluster集群模式的，比memcached来说要更好。Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的(避免了频繁的上下文切换)多路 IO 复用模型。 redis 删除过期数据 定期删除：redis默认是每隔 100ms 就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载！ 惰性删除：定期删除可能会导致很多过期 key 到了时间并没有被删除掉。所以就有了惰性删除。假如你的过期 key，靠定期删除没有被删除掉，还停留在内存里，除非你的系统去查一下那个 key，才会被redis给删除掉。这就是所谓的惰性删除，也是够懒的哈！ redis 内存淘汰机制Redis 提供 6 种数据淘汰策略： volatile-lru：从已设置过期时间的数据集(server.db[i].expires)中挑选最近最少使用的数据淘汰。volatile-ttl：从已设置过期时间的数据集(server.db[i].expires)中挑选将要过期的数据淘汰。volatile-random：从已设置过期时间的数据集(server.db[i].expires)中任意选择数据淘汰。allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key(这个是最常用的)。allkeys-random：从数据集(server.db[i].dict)中任意选择数据淘汰。no-enviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧! redis淘汰数据时还会同步到aof。 redis 持久化机制Redis 的一种持久化方式叫快照(snapshotting，RDB)，另一种方式是只追加文件(append-only file，AOF)。 快照(snapshotting)持久化(RDB)Redis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。 Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本(Redis 主从结构，主要用来提高 Redis 性能)，还可以将快照留在原地以便重启服务器的时候使用。 Redis会单独创建fork()一个子进程，将当前父进程的数据库数据复制到子进程的内存中，然后由子进程写入到临时文件中，持久化的过程结束了，再用这个临时文件替换上次的快照文件，然后子进程退出，内存释放。 需要注意的是，每次快照持久化都会将主进程的数据库数据复制一遍，导致内存开销加倍，若此时内存不足，则会阻塞服务器运行，直到复制结束释放内存；都会将内存数据完整写入磁盘一次，所以如果数据量大的话，而且写操作频繁，必然会引起大量的磁盘I/O操作，严重影响性能，并且最后一次持久化后的数据可能会丢失； 快照持久化是 Redis 默认采用的持久化方式，在 redis.conf 配置文件中默认有此下配置： 12345save 900 1 #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 save 300 10 #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 save 60 10000 #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。 优点： 只有一个文件dump.rdb，方便持久化。容灾性好，一个文件可以保存到安全的磁盘。性能最大化，fork子进程来完成写操作，让主进程继续处理命令，所以是IO最大化。相对于数据集大时，比AOF的启动效率更高。 缺点： 数据安全性低，通过配置save参数来达到定时的写快照，比如 每900 秒有1个键被修改就进行一次快照，每300秒至少有10个键被修改进行快照，每60秒有至少10000个键被修改进行记录。所以如果当服务器还在等待写快照时出现了宕机，那么将会丢失数据。fork子进程时可能导致服务器停机1秒，数据集太大。 AOF(append-only file)持久化与快照持久化相比，AOF 持久化的实时性更好，因此已成为主流的持久化方案。 以日志的形式记录每个写操作（读操作不记录），只需追加文件但不可以改写文件，redis启动时会根据日志从头到尾全部执行一遍以完成数据的恢复工作。包括flushDB也会执行。 默认情况下 Redis 没有开启 AOF(append only file)方式的持久化，可以通过 appendonly 参数开启： 1appendonly yes 开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入硬盘中的 AOF 文件。 AOF 文件的保存位置和 RDB 文件的位置相同，都是通过 dir 参数设置的，默认的文件名是 appendonly.aof。 在 Redis 的配置文件中存在三种不同的 AOF 持久化方式，它们分别是： 123appendfsync always #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度 appendfsync everysec #每秒钟同步一次，显示地将多个写命令同步到硬盘 appendfsync no #让操作系统决定何时进行同步 为了兼顾数据和写入性能，用户可以考虑 appendfsync everysec 选项 ，让 Redis 每秒同步一次 AOF 文件，Redis 性能几乎没受到任何影响。 而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis 还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。 优点： 数据安全，aof持久化可以配置appendfsync属性，有always，每进行一次命令操作就记录到aof文件中一次；everySec，就是每秒内进行一次文件的写操作；no就是不进行aof文件的写操作。通过append模式写文件，即使中途服务器宕机，可以通过redis-check-aof工具解决数据一致性问题。AOF机制的rewrite模式，用来将过大的aof文件缩小，实现原理是将所有的set 通过一句set 命令总结，所有的SADD命令用总结为一句，这样每种命令都概括为一句来执行，就可以减少aof文件的大小了。（注意，在重写的过程中，是创建子进程来完成重写操作，主进程每个命令都会在AOF缓冲区和AOF重写缓冲区进行保存，这样旧版aof文件可以实现数据最新，当更新完后将重写缓冲区中的数据写入新的aof文件中然后就可以将新的文件替换掉旧版的文件。默认触发是当aof文件大小是上次重写后大小的一倍且文件大于64M时触发。) 缺点： 文件会比RDB形式的文件大。数据集大的时候，比rdb启动效率低。 总结 当两种方式同时开启时，数据恢复redis会优先选择AOF恢复。一般情况下，只要使用默认开启的RDB即可，因为相对于AOF，RDB便于进行数据库备份，并且恢复数据集的速度也要快很多。 开启持久化缓存机制，对性能会有一定的影响，特别是当设置的内存满了的时候，更是下降到几百reqs/s。所以如果只是用来做缓存的话，可以关掉持久化。 Redis 4.0 对于持久化机制的优化Redis 4.0 开始支持 RDB 和 AOF 的混合持久化(默认关闭，可以通过配置项 aof-use-rdb-preamble 开启)。 如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。 这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。 当然缺点也是有的，AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。 Sentinel （哨兵）原理哨兵的功能 监控（Monitoring）：哨兵会不断地检查主节点和从节点是否运作正常。 自动故障转移（Automatic failover）：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。 配置提供者（Configuration provider）：客户端在初始化时，通过连接哨兵来获得当前 Redis 服务的主节点地址。 通知（Notification）：哨兵可以将故障转移的结果发送给客户端。 哨兵系统中的主从节点，与普通的主从节点并没有什么区别，故障发现和转移是由哨兵来控制和完成的。 哨兵节点本质上是 Redis 节点。 每个哨兵节点，只需要配置监控主节点，便可以自动发现其他的哨兵节点和从节点。 在哨兵节点启动和故障转移阶段，各个节点的配置文件会被重写(config rewrite)。 哨兵的原理定时任务每个哨兵节点维护了 3 个定时任务，定时任务的功能分别如下： 通过向主从节点发送 info 命令获取最新的主从结构。通过发布订阅功能获取其他哨兵节点的信息。通过向其他节点发送 ping 命令进行心跳检测，判断是否下线。 主观下线在心跳检测的定时任务中，如果其他节点超过一定时间没有回复，哨兵节点就会将其进行主观下线。顾名思义，主观下线的意思是一个哨兵节点“主观地”判断下线；与主观下线相对应的是客观下线。 客观下线哨兵节点在对主节点进行主观下线后，会通过 sentinelis-master-down-by-addr 命令询问其他哨兵节点该主节点的状态。如果判断主节点下线的哨兵数量达到一定数值，则对该主节点进行客观下线。 需要特别注意的是，客观下线是主节点才有的概念；如果从节点和哨兵节点发生故障，被哨兵主观下线后，不会再有后续的客观下线和故障转移操作。 选举领导者哨兵节点当主节点被判断客观下线以后，各个哨兵节点会进行协商，选举出一个领导者哨兵节点，并由该领导者节点对其进行故障转移操作。 监视该主节点的所有哨兵都有可能被选为领导者，选举使用的算法是 Raft 算法。 Raft 算法的基本思路是先到先得：即在一轮选举中，哨兵 A 向 B 发送成为领导者的申请，如果 B 没有同意过其他哨兵，则会同意 A 成为领导者。 一般来说，谁先完成客观下线，一般就能成为领导者。 故障转移选举出的领导者哨兵，开始进行故障转移操作，该操作大体可以分为 3 个步骤： 在从节点中选择新的主节点：选择的原则是，首先过滤掉不健康的从节点，然后选择优先级最高的从节点(由 slave-priority 指定)。如果优先级无法区分，则选择复制偏移量最大的从节点；如果仍无法区分，则选择 runid 最小的从节点。 更新主从状态:通过 slaveof no one 命令，让选出来的从节点成为主节点；并通过 slaveof 命令让其他节点成为其从节点。 Sentinel 被授权后，它将会获得宕掉的 master 的一份最新配置版本号 (config-epoch)，当 failover 执行结束以后，这个版本号将会被用于最新的配置，通过广播形式通知其它 Sentinel，其它的 Sentinel 则更新对应 master 的配置。 redis的并发竞争key问题问题描述同时有多个子系统去set一个key。这个时候要注意什么呢？ 百度一下基本都是推荐用 Redis 事务机制。但是并不推荐使用 Redis 的事务机制。因为生产环境，基本都是 Redis 集群环境，做了数据分片操作。一个事务中有涉及到多个 Key 操作的时候，这多个 Key 不一定都存储在同一个 redis-server 上。因此，Redis 的事务机制，十分鸡肋。 解决方案如果对这个 Key 操作，不要求顺序这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做set操作即可，比较简单。 如果对这个key操作，要求顺序假设有一个key1,系统A需要将key1设置为valueA,系统B需要将key1设置为valueB,系统C需要将key1设置为valueC. 期望按照key1的value值按照 valueA–&gt;valueB–&gt;valueC的顺序变化。这时在数据写入数据库的时候，需要保存一个时间戳。假设时间戳如下： 12345系统A key 1 &#123;valueA 3:00&#125;系统B key 1 &#123;valueB 3:05&#125;系统C key 1 &#123;valueC 3:10&#125; 那么，假设这会系统B先抢到锁，将key1设置为{valueB 3:05}。接下来系统A抢到锁，发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作了。以此类推。 其他方法，比如利用队列，将set方法变成串行访问也可以。 缓存雪崩简介缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。 通俗来说就是：由于原有缓存失效（或者数据未加载到缓存中），新缓存未到期间（缓存正常从Redis中获取）所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机，造成系统的崩溃。 正常访问如下： 缓存失效的时候如下图： 解决办法 事前：尽量保证整个 Redis 集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略。事中：本地 Ehcache 缓存 + Hystrix 限流&amp;降级，避免 数据库 崩掉。事后：利用 Redis 持久化机制保存的数据尽快恢复缓存。加锁计数（即限制并发的数量，可以用semphore）或者起一定数量的队列来避免缓存失效时大量请求并发到数据库。但这种方式会降低吞吐量。分析用户行为，然后失效时间均匀分布。或者在失效时间的基础上再加1~5分钟的随机数。如果是某台缓存服务器宕机，则考虑做主备。 缓存穿透简介一般是黑客故意去请求缓存中不存在的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。 解决办法 最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中。一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力。也有一个更为简单粗暴的方法，如果一个查询返回的数据为空(不管是数据不存在，还是系统故障)，仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。 缓存并发简介如果网站并发访问高，一个缓存如果失效，可能出现多个进程同时查询DB，同时设置缓存的情况，如果并发确实很大，这也可能造成DB压力过大，还有缓存频繁更新的问题。 解决办法 对缓存查询加锁，如果KEY不存在，就加锁，然后查DB入缓存，然后解锁；其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入DB查询。 缓存预热简介缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！ 解决办法 直接写个缓存刷新页面，上线时手工操作下；数据量不大，可以在项目启动的时候自动进行加载；定时刷新缓存； Redis常见性能问题和解决方案 Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内 尽量避免在压力很大的主库上增加从库 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master &lt;- Slave1 &lt;- Slave2 &lt;- Slave3…这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。 Redis 主从复制原理 从服务器连接主服务器，发送SYNC（同步）命令；主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令；主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令；从服务器收到快照文件后丢弃所有旧数据，载入收到的快照；主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令；从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；（从服务器初始化完成）主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令（从服务器初始化完成后的操作）。 优点 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离；为了分载Master的读操作压力，Slave服务器可以为客户端提供只读操作的服务，写服务仍然必须由Master来完成；Slave同样可以接受其它Slaves的连接和同步请求，这样可以有效的分载Master的同步压力；Master Server是以非阻塞的方式为Slaves提供服务。所以在Master-Slave同步期间，客户端仍然可以提交查询或修改请求；Slave Server同样是以非阻塞的方式完成数据同步。在同步期间，如果有客户端提交查询请求，Redis则返回同步之前的数据。 缺点 Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。 Redis 哨兵模式工作方式 每个Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的Master主服务器，Slave从服务器以及其他Sentinel（哨兵）进程发送一个 PING 命令。如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）如果一个Master主服务器被标记为主观下线（SDOWN），则正在监视这个Master主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认Master主服务器的确进入了主观下线状态当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认Master主服务器进入了主观下线状态（SDOWN）， 则Master主服务器会被标记为客观下线（ODOWN）在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有Master主服务器、Slave从服务器发送 INFO 命令。当Master主服务器被 Sentinel（哨兵）进程标记为客观下线（ODOWN）时，Sentinel（哨兵）进程向下线的 Master主服务器的所有 Slave从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。若没有足够数量的 Sentinel（哨兵）进程同意 Master主服务器下线， Master主服务器的客观下线状态就会被移除。若 Master主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master主服务器的主观下线状态就会被移除。 优点 哨兵模式是基于主从模式的，所有主从的优点，哨兵模式都具有。主从可以自动切换，系统更健壮，可用性更高。 缺点 Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。 Redis Cluster集群模式redis3以后，节点之间提供了完整的sharding（分片）、replication（主备感知能力）、failover（故障转移）的特性。 配置一致性每个节点（Node）内部都保存了集群的配置信息，存储在clusterState中，通过引入自增的epoch变量来使得集群配置在各个节点间保持一致。 sharding数据分片将所有数据划分为16384个分片（slot），每个节点会对应一部分slot，每个key都会根据分布算法映射到16384个slot中的一个，分布算法为slotId=crc16(key)%16384 当一个client访问的key不在对应节点的slots中，redis会返回给client一个moved命令，告知其正确的路由信息从而重新发起请求。client会根据每次请求来缓存本地的路由缓存信息，以便下次请求直接能够路由到正确的节点。 分片迁移分片迁移的触发和过程控制由外部系统完成，redis只提供迁移过程中需要的原语支持。 主要包含两种：一种是节点迁移状态设置，即迁移前标记源、目标节点；另一种是key迁移的原子化命令。 failover故障转移故障发现节点间两两通过TCP保持连接，周期性进行PING、PONG交互，若对方的PONG相应超时未收到，则将其置为PFAIL状态，并传播给其他节点。 故障确认当集群中有一半以上的节点对某一个PFAIL状态进行了确认，则将起改为FAIL状态，确认其故障。 slave选举当有一个master挂掉了，则其slave重新竞选出一个新的master。主要根据各个slave最后一次同步master信息的时间，越新表示slave的数据越新，竞选的优先级越高，就更有可能选中。竞选成功之后将消息传播给其他节点。 集群不可用的情况 集群中任意master挂掉，且当前master没有slave。 集群中超过半数以上master挂掉。 Redis-Cluster采用无中心结构的特点 所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽。 节点的fail是通过集群中超过半数的节点检测失效时才生效。 客户端与redis节点直连,不需要中间代理层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可。 Pipeline有什么好处，为什么要用pipeline可以将多次IO往返的时间缩减为一次，前提是pipeline执行的指令之间没有因果相关性。 使用redis-benchmark进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是pipeline批次指令的数目。 如果有大量的key需要设置同一时间过期需要注意什么如果大量的key过期时间设置的过于集中，到过期的那个时间点，redis可能会出现短暂的卡顿现象。一般需要在时间上加一个随机值，使得过期时间分散一些。 Redis异步队列原理一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。 可不可以不用sleeplist有个指令叫blpop，在没有消息时，它会阻塞住直到消息到来。 能不能生产一次消费多次使用pub/sub主题订阅者模式，可以实现1:N的消息队列。 pub/sub有什么缺点在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如rabbitmq等。 redis如何实现延时队列使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。 假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来使用keys指令可以扫出指定模式的key列表。 如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。","tags":"redis"},{"title":"手写RPC--简易版","url":"/posts/abff3a44.html","text":"之前在网上看很多公司在面试的时候都会问到Dubbo等一些RPC框架，更有甚者直接要求面试者手写PRC，今天就来撩下RPC。 什么是RPCRPC（Remote Procedure Call），远程过程调用，意思是可以在一台机器上调用远程的服务。在非分布式环境下，我们的程序调用服务都是本地调用，但是随着分布式结构的普遍，越来越多的应用需要解耦，将不同的独立功能部署发布成不同的服务供客户端调用，RPC就是为了解决这个问题的。RPC是一种规范，和TCP、UDP都没有关系，RPC可以采用TCP协议完成数据传输，甚至可以使用HTTP应用协议。RPC是C端模式，包含了服务端（服务提供方）、客户端（服务使用方），采用特定的网络传输协议，把数据按照特定的协议包装后进行传输操作等操作。 RPC原理首先，我们心里带着这样的问题：要怎么样去调用远程的服务呢？ ①肯定要知道IP和端口吧（确定唯一一个进程）； ②肯定要知道调用什么服务吧（方法名和参数）； ③调用服务后可能需要结果吧。 这三点又怎么实现呢？RPC的设计由Client，Client stub，Network，Server stub，Server构成。其中Client就是用来调用服务的，Cient stub是用来把调用的方法和参数序列化的（因为要在网络中传输，必须要把对象转变成字节），网络用来传输这些信息到服务器存根，服务器存根用来把这些信息反序列化的，服务器就是服务的提供者，最终调用的就是服务器提供的方法。RPC的结构如下图： 图中1-10序号的含义如下： 客户端像调用本地服务似的调用远程服务; 客户端stub接收到调用后，将类名，方法名，参数列表序列化; 客户端通过插座将消息发送到服务端; Server stub收到消息后进行解码（将消息对象反序列化）; 服务器存根根据解码结果调用本地的服务; 本地服务执行（对于服务端来说是本地执行）并将结果返回给服务器存根; 服务器存根将返回结果打包成消息（将结果消息对象序列化）; 服务端通过插座将消息发送到客户端; 客户端stub接收到结果消息，并进行解码（将结果消息发序列化）; 客户端得到最终结果。 这就是一个完成PRC调用过程，对使用方而言就只暴露了本地代理对象，剩下的数据解析、运输等都被包装了，从服务提供方的角度看还有服务暴露，如下是Dubbo的架构图： 简易RPC实现项目目录 MethodParameter对象12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.springboot.whb.study.rpc.rpc_v1;import com.alibaba.fastjson.JSON;import lombok.Data;import java.io.InputStream;import java.io.ObjectInputStream;/** * @author: whb * @description: 请求对象 */@Datapublic class MethodParameter &#123; /** * 类名 */ private String className; /** * 方法名 */ private String methodName; /** * 参数 */ private Object[] arguments; /** * 参数类型 */ private Class&lt;?&gt;[] parameterTypes; @Override public String toString() &#123; return JSON.toJSONString(this); &#125; /** * 从输入流中读取出类名、方法名、参数等数据组装成一个MethodParameter * * @param inputStream * @return */ public static MethodParameter convert(InputStream inputStream) &#123; try &#123; ObjectInputStream input = new ObjectInputStream(inputStream); String className = input.readUTF(); String methodName = input.readUTF(); Class&lt;?&gt;[] parameterTypes = (Class&lt;?&gt;[]) input.readObject(); Object[] arguments = (Object[]) input.readObject(); MethodParameter methodParameter = new MethodParameter(); methodParameter.setClassName(className); methodParameter.setMethodName(methodName); methodParameter.setArguments(arguments); methodParameter.setParameterTypes(parameterTypes); return methodParameter; &#125; catch (Exception e) &#123; throw new RuntimeException(\"解析请求错误：&#123;&#125;\", e); &#125; &#125;&#125; 服务端-服务暴露1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.springboot.whb.study.rpc.rpc_v1;import com.springboot.whb.study.rpc.rpc_v1.MethodParameter;import java.lang.reflect.Method;import java.util.HashMap;import java.util.Map;/** * @author: whb * @description: 服务端暴露 * 服务暴露存储在objectMap对象中，所有可对提供的服务都必须添加到该容器中，以便于收到网络数据后能找到对应的服务，然后采用反射invoke调用，返回得到的结果。 */public class RpcExploreService &#123; private Map&lt;String, Object&gt; objectMap = new HashMap&lt;&gt;(); /** * 可对外提供的服务 * * @param className * @param object */ public void explore(String className, Object object) &#123; objectMap.put(className, object); &#125; /** * 采用反射进行调用 * * @param methodParameter * @return */ public Object invoke(MethodParameter methodParameter) &#123; Object object = objectMap.get(methodParameter.getClassName()); if (object == null) &#123; throw new RuntimeException(\"无对应的执行类：【\" + methodParameter.getClassName() + \"】\"); &#125; Method method = null; try &#123; method = object.getClass().getMethod(methodParameter.getMethodName(), methodParameter.getParameterTypes()); &#125; catch (NoSuchMethodException e) &#123; throw new RuntimeException(\"执行类：【\" + methodParameter.getClassName() + \"】无对应的执行方法：【\" + methodParameter.getMethodName() + \"】\"); &#125; try &#123; Object result = method.invoke(object, methodParameter.getArguments()); System.out.println(methodParameter); return result; &#125; catch (Exception e) &#123; throw new RuntimeException(\"invoke方法执行失败：\" + e.getMessage()); &#125; &#125;&#125; 服务端-网络数据处理12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394package com.springboot.whb.study.rpc.rpc_v1;import com.google.common.base.Joiner;import org.apache.commons.lang3.concurrent.BasicThreadFactory;import java.io.IOException;import java.io.InputStream;import java.io.ObjectOutputStream;import java.io.OutputStream;import java.net.ServerSocket;import java.net.Socket;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;/** * @author: whb * @description: 服务端-网络数据处理 * 简单的BIO模型，开启了一个ServerSocket后，接收到数据后就将套接字丢给一个新的线程处理，ServerSocketRunnable接收一个socket之后， * 解析出MethodParameter请求对象，然后调用服务暴露的Invoke方法，再写回socket传输给客户端。 */public class IOService implements Runnable &#123; private int port; private ServerSocket serverSocket; private RpcExploreService rpcExploreService; ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(10, 100, 60, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(1000), new BasicThreadFactory.Builder().namingPattern(Joiner.on(\"-\").join(\"thread-pool-\", \"%s\")).build()); private volatile boolean flag; public IOService(RpcExploreService rpcExploreService, int port) throws IOException &#123; this.rpcExploreService = rpcExploreService; this.port = port; this.serverSocket = new ServerSocket(port); this.flag = true; System.out.println(\"******服务端启动了********\"); //优雅关闭 Runtime.getRuntime().addShutdownHook(new Thread(() -&gt; &#123; flag = false; System.out.println(\"+++++服务端关闭了+++++\"); &#125;)); &#125; @Override public void run() &#123; while (true) &#123; Socket socket = null; try &#123; socket = serverSocket.accept(); &#125; catch (IOException e) &#123; &#125; if (socket == null) &#123; continue; &#125; threadPoolExecutor.execute(new ServerSocketRunnable(socket)); &#125; &#125; class ServerSocketRunnable implements Runnable &#123; private Socket socket; public ServerSocketRunnable(Socket socket) &#123; this.socket = socket; &#125; @Override public void run() &#123; try &#123; InputStream inputStream = socket.getInputStream(); OutputStream outputStream = socket.getOutputStream(); MethodParameter methodParameter = MethodParameter.convert(inputStream); Object result = rpcExploreService.invoke(methodParameter); ObjectOutputStream output = new ObjectOutputStream(outputStream); output.writeObject(result); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (socket != null) &#123; try &#123; socket.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125;&#125; 客户端-服务订阅12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package com.springboot.whb.study.rpc.rpc_v1;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.util.HashMap;import java.util.Map;/** * @author: whb * @description: 客户端-服务订阅 * 服务使用方需要使用register进行服务的注册，会生成对应的本地代理对象，后续只需要通过本地代理对象。 */public class RpcUsedService &#123; private Map&lt;String, Object&gt; proxyObejctMap = new HashMap&lt;&gt;(); private Map&lt;String, Class&gt; classMap = new HashMap&lt;&gt;(); private IOClient ioClient; public void setIoClient(IOClient ioClient) &#123; this.ioClient = ioClient; &#125; /** * 服务注册 * * @param clazz */ public void register(Class clazz) &#123; String className = clazz.getName(); classMap.put(className, clazz); if (!clazz.isInterface()) &#123; throw new RuntimeException(\"暂时只支持接口类型的\"); &#125; try &#123; RpcInvocationHandler handler = new RpcInvocationHandler(); handler.setClazz(clazz); Object proxyInstance = Proxy.newProxyInstance(clazz.getClassLoader(), new Class&lt;?&gt;[]&#123;clazz&#125;, handler); proxyObejctMap.put(className, proxyInstance); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public &lt;T&gt; T get(Class&lt;T&gt; clazz) &#123; String className = clazz.getName(); return (T) proxyObejctMap.get(className); &#125; class RpcInvocationHandler implements InvocationHandler &#123; private Class clazz; public void setClazz(Class clazz) &#123; this.clazz = clazz; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; MethodParameter methodParameter = new MethodParameter(); methodParameter.setClassName(clazz.getName()); methodParameter.setMethodName(method.getName()); methodParameter.setArguments(args); methodParameter.setParameterTypes(method.getParameterTypes()); return ioClient.invoke(methodParameter); &#125; &#125;&#125; 客户端-网络处理1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.springboot.whb.study.rpc.rpc_v1;import java.io.*;import java.net.Socket;/** * @author: whb * @description: 客户端-网络处理 * 代理对象被调用后生成一个MethodParameter对象，通过此IOClient把数据传输到服务端，并且返回对应的数据。 */public class IOClient &#123; private String ip; private int port; public IOClient(String ip, int port) &#123; this.ip = ip; this.port = port; &#125; public Object invoke(MethodParameter methodParameter) &#123; Socket socket = null; try &#123; socket = new Socket(ip, port); OutputStream outputStream = socket.getOutputStream(); ObjectOutputStream output = new ObjectOutputStream(outputStream); output.writeUTF(methodParameter.getClassName()); output.writeUTF(methodParameter.getMethodName()); output.writeObject(methodParameter.getParameterTypes()); output.writeObject(methodParameter.getArguments()); InputStream inputStream = socket.getInputStream(); ObjectInputStream input = new ObjectInputStream(inputStream); return input.readObject(); &#125; catch (Exception e) &#123; System.out.println(e.getMessage()); &#125; finally &#123; if (socket != null) &#123; try &#123; socket.close(); &#125; catch (IOException e) &#123; throw new RuntimeException(\"socket关闭失败\"); &#125; &#125; &#125; return null; &#125;&#125; 实践-服务端1234567891011121314151617181920212223package com.springboot.whb.study.rpc.rpc_v1;import com.springboot.whb.study.rpc.rpc_v1.expore.HelloWorldImpl;/** * @author: whb * @description: 服务端 */public class Service &#123; public static void main(String[] args) &#123; RpcExploreService rpcExploreService = new RpcExploreService(); //传入的字符串是接口的全名称 rpcExploreService.explore(\"com.springboot.whb.study.rpc.rpc_v1.expore.HelloWorld\", new HelloWorldImpl()); try &#123; //开启11111端口监听服务 Runnable ioService = new IOService(rpcExploreService, 11111); new Thread(ioService).start(); &#125; catch (Exception e) &#123; &#125; &#125;&#125; 实践-客户端123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.springboot.whb.study.rpc.rpc_v1;import com.google.common.base.Joiner;import com.springboot.whb.study.rpc.rpc_v1.expore.HelloWorld;import org.apache.commons.lang3.concurrent.BasicThreadFactory;import java.util.Random;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;/** * @author: whb * @description: 客户端 */public class Client &#123; public static final ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(10, 100, 60, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(1000), new BasicThreadFactory.Builder().namingPattern(Joiner.on(\"-\").join(\"client-thread-pool-\", \"%s\")).build()); public static void main(String[] args) &#123; RpcUsedService rpcUsedService = new RpcUsedService(); rpcUsedService.register(HelloWorld.class); try &#123; IOClient ioClient = new IOClient(\"127.0.0.1\", 11111); //网络套接字连接 同上是10001端口 rpcUsedService.setIoClient(ioClient); HelloWorld helloWorld = rpcUsedService.get(HelloWorld.class); //生成的本地代理对象 proxy for (int i = 0; i &lt; 100; i++) &#123; threadPoolExecutor.execute(() -&gt; &#123; long start = System.currentTimeMillis(); int a = new Random().nextInt(100); int b = new Random().nextInt(100); int c = helloWorld.add(a, b); // .add 操作就是屏蔽了所有的细节，提供给客户端使用的方法 System.out.println(\"a: \" + a + \", b:\" + b + \", c=\" + c + \", 耗时:\" + (System.currentTimeMillis() - start)); &#125;); &#125; &#125; catch (Exception e) &#123; throw new RuntimeException(\"客户端执行出错:&#123;&#125;\", e); &#125; finally &#123; threadPoolExecutor.shutdown(); &#125; &#125;&#125; 服务接口12345678910package com.springboot.whb.study.rpc.rpc_v1.expore;/** * @author: whb * @description: 接口定义 */public interface HelloWorld &#123; int add(int a, int b);&#125; 服务接口实现123456789101112131415161718192021222324package com.springboot.whb.study.rpc.rpc_v1.expore;import java.util.Random;/** * @author: whb * @description: 接口实现类 */public class HelloWorldImpl implements HelloWorld &#123; @Override public int add(int a, int b) &#123; long start = System.currentTimeMillis(); try &#123; Thread.sleep(new Random().nextInt(10000)); // 故意添加了耗时操作，以便于模拟真实的调用操作 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; int c = a + b; System.out.println(Thread.currentThread().getName() + \" 耗时:\" + (System.currentTimeMillis() - start)); return c; &#125;&#125; 运行效果 总结这只是一个非常简单的RPC实践，包含了服务暴露、服务注册（Proxy生成）、BIO模型进行网络传输，java默认的序列化方法，对RPC有一个初步的认识和了解，知道RPC必须包含的模块。 不过还是有很多需要优化的点以改进： IO模型：使用的是BIO模型，可以改进换成NIO模型，引入netty; 池化：不要随意新建线程，所有的线程都应有线程池统一管理; 服务发现：本地模拟的小demo，并没有服务发现，可以采用zk管理; 序列化：java本身自带的序列化效率很低，可以换成Hessian（DUBBO默认采用其作为序列化工具）、Protobuf（Protobuf是由Google提出的一种支持多语言的跨平台的序列化框架）等; 还有例如服务统计、优雅下线、负载均衡等也都是一个成熟的RPC框架必须要考虑到的点。","tags":"rpc"},{"title":"Hexo搭建博客常见问题","url":"/posts/5b526bb.html","text":"No Layout:index.html问题描述最近对Hexo以及Next主题做了升级，升级之后在执行hexo g编译时出现了No layout:index.html的错误，如下图： 解决思路 查看hexo插件安装情况，因内容较多，只部分截图： 1npm ls --depth 0 hexo的一些插件未安装 12npm ERR! peer dep missing: eslint@&gt;= 4.12.1, required by babel-eslint@10.0.3npm ERR! peer dep missing: eslint@&gt;= 4.12.1, required by babel-eslint@10.0.3 逐一安装缺失的插件 1npm install eslint --save 执行npm install后，执行npm audit fix 访问Hexo博客出现“Cannot GET/xxx”错误问题描述在Hexo博客中，出现Cannot GET/xxx错误便意味着xxx文件未被找到。 Cannot GET/xxx错误本质是hexo server返回的一个404错误。 解决思路 判断public目录下xxx文件是否存在。 如果说xxx.html不存在，那么执行hexo c，hexo g重新生成一次，回到步骤1。 步骤2执行完后xxx.html仍不存在，执行npm audit fix，查看是否少了什么组件，通过npm install hexo-xxx-xxx 安装即可。 步骤3完成之后，执行hexo c，hexo g重新生成静态文件。 仍然有问题，请再参考此文：https://www.cnblogs.com/Sroot/p/6305938.html","tags":"hexo"},{"title":"数据库、缓存不一致问题","url":"/posts/e755a8c.html","text":"概述只要用缓存，就可能会涉及到缓存与数据库双存储双写，只要是双写，就一定会有数据一致性问题，如何保证缓存与数据库的双写一致性？ 读写串行化一般来说，如果允许缓存可以稍微跟数据库偶尔有不一致，也就是说系统不是严格要求缓存+数据库必须保持一致性的话，可以采用读写请求串行化：即读请求和写请求串到一个内存队列里去，从而达到防止并发请求导致数据错乱的问题。值得注意的是，串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低。 代码实现大致如下（网上找的）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * 请求异步处理的service实现 * @author Administrator * */@Service(\"requestAsyncProcessService\") public class RequestAsyncProcessServiceImpl implements RequestAsyncProcessService &#123; @Override public void process(Request request) &#123; try &#123; // 先做读请求的去重 RequestQueue requestQueue = RequestQueue.getInstance(); Map&lt;Integer, Boolean&gt; flagMap = requestQueue.getFlagMap(); if(request instanceof ProductInventoryDBUpdateRequest) &#123; // 如果是一个更新数据库的请求，那么就将那个productId对应的标识设置为true flagMap.put(request.getProductId(), true); &#125; else if(request instanceof ProductInventoryCacheRefreshRequest) &#123; Boolean flag = flagMap.get(request.getProductId()); // 如果flag是null if(flag == null) &#123; flagMap.put(request.getProductId(), false); &#125; // 如果是缓存刷新的请求，那么就判断，如果标识不为空，而且是true，就说明之前有一个这个商品的数据库更新请求 if(flag != null &amp;&amp; flag) &#123; flagMap.put(request.getProductId(), false); &#125; // 如果是缓存刷新的请求，而且发现标识不为空，但是标识是false // 说明前面已经有一个数据库更新请求+一个缓存刷新请求了，大家想一想 if(flag != null &amp;&amp; !flag) &#123; // 对于这种读请求，直接就过滤掉，不要放到后面的内存队列里面去了 return; &#125; &#125; // 做请求的路由，根据每个请求的商品id，路由到对应的内存队列中去 ArrayBlockingQueue&lt;Request&gt; queue = getRoutingQueue(request.getProductId()); // 将请求放入对应的队列中，完成路由操作 queue.put(request); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * 获取路由到的内存队列 * @param productId 商品id * @return 内存队列 */ private ArrayBlockingQueue&lt;Request&gt; getRoutingQueue(Integer productId) &#123; RequestQueue requestQueue = RequestQueue.getInstance(); // 先获取productId的hash值 String key = String.valueOf(productId); int h; int hash = (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); // 对hash值取模，将hash值路由到指定的内存队列中，比如内存队列大小8 // 用内存队列的数量对hash值取模之后，结果一定是在0~7之间 // 所以任何一个商品id都会被固定路由到同样的一个内存队列中去的 int index = (requestQueue.queueSize() - 1) &amp; hash; System.out.println(\"===========日志===========: 路由内存队列，商品id=\" + productId + \", 队列索引=\" + index); return requestQueue.getQueue(index); &#125;&#125; Cache Aside PatternCache Aside Patten：经典的缓存+数据库读写模式。 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。更新的时候，先删除缓存，然后再更新数据库。 为什么是删除缓存，而不是更新缓存？ 之所以更新的时候只是删除缓存，因为对于一些复杂有逻辑的缓存数据，每次数据变更都更新一次缓存会造成额外的负担，只是删除缓存，让该数据下一次被使用的时候再去执行读的操作来重新缓存，这里采用的是懒加载的策略。举个例子，一个缓存涉及的表的字段，在1分钟内就修改了20次，或者是100次，那么缓存更新20次，100次;但是这个缓存在1分钟内就被读取了1次，因此每次更新缓存就会有大量的冷数据，对于缓存符合28黄金法则，20%的数据，占用了80%的访问量。 最初级的缓存不一致问题及解决方案问题：先修改数据库，再删除缓存。如果删除缓存失败了，那么导致数据库中是新数据，缓存中是旧数据，数据就会出现不一致性。 解决思路：先删除缓存，再修改数据库。如果数据库修改失败了，那么数据库中是旧数据，缓存中是空的，那么数据就不会不一致。因为读的时候缓存中没有，则读数据库中的旧数据，然后再更新到缓存中。 比较复杂的数据不一致问题问题：数据发生了变更，先删除了缓存，然后要去修改数据库，但是还没来得及修改，一个请求过来，去读缓存，发现缓存是空的，去查询数据库，查到了修改前的旧数据，放到了缓存中，随后数据变更的程序完成了数据库的修改，这样就会造成数据库和缓存中的数据不一致。 解决思路：更新数据的时候，根据数据的唯一标识，将操作路由到一个JVM的内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发送同一个JVM内部队列中。一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。这样，一个数据变更的操作，先删除缓存，再去更新数据库，但是还没完成更新，此时一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送的队列中，此时会在队列中积压，然后同步等待缓存更新完成。 这样有一个优点：一个队列中多个更新缓存的请求串在一起是没意义的，因此可以做过滤。如果发现队列中已经有一个更新缓存的请求，那么不再放更新缓存的请求操作进去，直接等待前面的更新操作完成即可。 待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。 如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。 高并发场景下，该方案要注意如下的问题： 读请求长时阻塞由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围内返回。 该方案最大的风险点在于，可能数据更新很频繁，导致队列中积压了大量更新操作在里面，然后读请求会发生大量的超时，最后导致大量的请求直接走数据库。 所以务必通过一些模拟真实的测试，看看更新数据的频率是怎样的。 另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要部署多个服务，每个服务分摊一些数据的更新操作。 如果一个内存队列里积压 100 个商品的库存修改操作，每个库存修改操作要耗费 10ms 去完成。那么最后一个商品的读请求，可能等待 10*100=1000ms=1s 后，才能得到数据，这个时候就导致读请求的长时阻塞。 因此，一定要根据实际业务系统的运行情况，去进行一些压力测试和模拟线上环境，看高峰期，内存队列可能会积压多少更新操作，可能会导致最后一个更新操作对应的读请求，会 Hang 多少时间。 如果读请求在 200ms 返回，哪怕是最繁忙的时候，积压 10 个更新操作，最多等待 200ms，那还可以的。 如果一个内存队列中可能积压的更新操作特别多，那就要加机器，让每个机器上部署的服务实例处理更少的数据，那么每个内存队列中积压的更新操作就会越少。 一般来说，数据的写频率是很低的，因此实际上正常来说，在队列中积压的更新操作应该是很少的。像这种针对读高并发、读缓存架构的项目，一般来说写请求是非常少的，每秒的 QPS 能到几百就不错了。 实际粗略测算一下，如果一秒有 500 的写操作，分成 5 个时间片，每 200ms 就 100 个写操作，放到 20 个内存队列中，每个内存队列，可能就积压 5 个写操作。 每个写操作性能测试后，一般是在 20ms 左右就完成，那么针对每个内存队列的数据的读请求，也就最多 Hang 一会儿，200ms 以内肯定能返回了。 经过简单的测算，单机支撑的写 QPS 在几百是没问题的，如果写 QPS 扩大了 10 倍，那么就扩容机器，扩容 10 倍的机器，每个机器 20 个队列。 读请求并发量过高这里还必须做好压力测试，确保恰巧碰上上述情况时，还有一个风险，就是突然间大量读请求会在几十毫秒的延时 Hang 在服务上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰值。 但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。 多服务实例部署的请求路由可能这个服务部署了多个实例，那么必须保证执行数据更新操作，以及执行缓存更新操作的请求，都通过 Nginx 服务器路由到相同的服务实例上。 比如对同一个商品的读写请求，全部路由到同一台机器上。可以自己去做服务间的按照某个请求参数的 Hash 路由，也可以用 Nginx 的 Hash 路由功能等等。","tags":"缓存 redis"},{"title":"数据库常用架构方案","url":"/posts/4c1379b8.html","text":"数据库架构原则 高可用 高性能 一致性 扩展性 常见的架构方案主备架构该方案只有主库提供读写服务，备库冗余作故障转移。数据库链接字符串：jdbc:mysql://vip:3306/xxdb 高可用分析：高可用，主库挂了，keepalive（一种工具）会自动切换到备库。这个过程对业务层是透明的，无需修改代码或配置。 高性能分析：读写都操作主库，很容易产生瓶颈。大部分互联网应用读多写少，读会先成为瓶颈，进而影响写性能。另外，备库只是单纯的备份，资源利用率只有50%。 一致性分析：读写都操作主库，不存在数据一致性问题。 扩展性分析：无法通过加从库来扩展读性能，进而提高整体性能。 可落地分析：两点影响落地：第一，性能一般，这点可以通过建立高效的索引和引入缓存来增加读性能，进而提高性能。这也是通用的方案。第二，扩展性差，这点可以通过分库分表来扩展。 双主架构该方案，两个主库同时提供服务，负载均衡。数据库链接字符串：jdbc:mysql://vip:3306/xxdb 高可用分析：高可用，一个主库挂了，不影响另一台主库提供服务。这个过程对业务层是透明的，无需修改代码或配置。 高性能分析：读写性能相比于方案一都得到提升，提升一倍。 一致性分析：存在数据一致性问题。 扩展性分析：当然可以扩展成三主循环，但不建议（会多一层数据同步，这样同步的时间会更长）。如果非得在数据库架构层面扩展的话，扩展为方案四。 可落地分析：两点影响落地:第一，数据一致性问题，一致性解决方案可解决问题。第二，主键冲突问题，ID统一地由分布式ID生成服务来生成可解决问题。 一主多从该方案采用主从架构，一主多从，读写分离。数据库链接字符串： 12345jdbc:mysql://master-ip:3306/xxdb jdbc:mysql://slave1-ip:3306/xxdb jdbc:mysql://slave2-ip:3306/xxdb 高可用分析：主库单点，从库高可用。一旦主库挂了，写服务也就无法提供。 高性能分析：大部分互联网应用读多写少，读会先成为瓶颈，进而影响整体性能。读的性能提高了，整体性能也提高了。另外，主库可以不用索引，线上从库和线下从库也可以建立不同的索引（线上从库如果有多个还是要建立相同的索引，不然得不偿失；线下从库是平时开发人员排查线上问题时查的库，可以建更多的索引）。 一致性分析：存在数据一致性问题。 扩展性分析：可以通过加从库来扩展读性能，进而提高整体性能。（带来的问题是，从库越多需要从主库拉取binlog日志的端就越多，进而影响主库的性能，并且数据同步完成的时间也会更长） 可落地分析：两点影响落地:第一，数据一致性问题，一致性解决方案可解决问题。第二，主库单点问题，暂时没想到很好的解决方案。 双主+主从数据库链接字符串： 12345jdbc:mysql://vip:3306/xxdbjdbc:mysql://slave1-ip:3306/xxdbjdbc:mysql://slave2-ip:3306/xxdb 高可用分析：高可用。 高性能分析：高性能。 一致性分析：存在数据一致性问题。 扩展性分析：可以通过加从库来扩展读性能，进而提高整体性能。（带来的问题同方案二） 可落地分析：同方案二，但数据同步又多了一层，数据延迟更严重。 数据一致性解决方案主库和从库一致性解决方案 注：图中圈出的是数据同步的地方，数据同步（从库从主库拉取binlog日志，再执行一遍）是需要时间的，这个同步时间内主库和从库的数据会存在不一致的情况。如果同步过程中有读请求，那么读到的就是从库中的老数据。如下图。 既然知道了数据不一致性产生的原因，有下面几个解决方案供参考： 直接忽略，如果业务允许延时存在，那么就不去管它。 强制读主，采用主备架构方案，读写都走主库。用缓存来扩展数据库读性能 。如果缓存挂了，可能会产生雪崩现象，不过一般分布式缓存都是高可用的。 选择读主，写操作时根据库+表+业务特征生成一个key放到Cache里并设置超时时间（大于等于主从数据同步时间）。读请求时，同样的方式生成key先去查Cache，再判断是否命中。若命中，则读主库，否则读从库。代价是多了一次缓存读写，基本可以忽略。 半同步复制，等主从同步完成，写请求才返回。就是大家常说的“半同步复制”semi-sync。这可以利用数据库原生功能，实现比较简单。代价是写请求时延增长，吞吐量降低。 数据库中间件，引入开源（mycat等）或自研的数据库中间层。思路同选择读主。数据库中间件的成本比较高，并且还多引入了一层。 DB和缓存一致性解决方案 先来看一下常用的缓存使用方式： 第一步：淘汰缓存； 第二步：写入数据库； 第三步：读取缓存？返回：读取数据库； 第四步：读取数据库后写入缓存。 注：如果按照这种方式，图一，不会产生DB和缓存不一致问题；图二，会产生DB和缓存不一致问题，即r2.read先于w3.sync执行。如果不做处理，缓存里的数据可能一直是脏数据。解决方式如下： 注：设置缓存时，一定要加上失效时间，以防延时淘汰缓存失败的情况！ MySQL复制MySQL主从复制目的实现数据库读写分离，写操作访问主数据库，读操作访问从数据库，从而使数据库具有更强大的访问负载能力，支撑更多的用户访问。 原理当应用程序客户端发送一条更新命令到数据库的时候，数据库会把这条更新命令同步记录到Binlog中，然后由另外一个线程从Binlog中读取这条日志，然后通过远程通讯的方式将它复制到从服务器上面去，从服务器获得这条更新日志后，将其加入到自己的Relay log中，然后由另外一个SQL执行线程从Relay log中读取这条新的日志，并把它在本地的数据库中重新执行一遍。 这样当客户端应用程序执行一个update命令的时候，这个命令会在主数据库和从数据库上同步执行，从而实现了主数据库向从数据库的复制，让从数据库和主数据库保持一样的数据。 MySQL一主多从复制目的MySQL的主从复制是一种数据同步机制，除了可以将一个主数据库中的数据同步复制到一个从数据库上，还可以将一个主数据库上的数据同步复制到多个从数据库上，也就是所谓的MySQL的一主多从复制。 原理多个从数据库关联到主数据库后，将主数据库上的Binlog日志同步地复制到了多个从数据库上。通过执行日志，让每个从数据库的数据都和主数据库上的数据保持了一致。这里面的数据更新操作表示的是所有数据库的更新操作，除了不包括SELECT之类的查询读操作，其他的INSERT、DELETE、UPDATE这样的DML写操作，以及CREATE TABLE、DROPT ABLE、ALTER TABLE等DDL操作也都可以同步复制到从数据库上去。 优点一主多从复制有四大优点，分别是分摊负载、专机专用、便于冷备和高可用。 分摊负载：将只读操作分布在多个从数据库上，从而将负载分摊到多台服务器上。 专机专用：可以针对不同类型的查询，使用不同的从服务器。 便于冷备：即使数据库进行了一主多从的复制，在一些极端的情况下。也可能会导致整个数据中心的数据都丢失。所以通常需要对数据做冷备，但冷备有一个困难点在于，数据库如果正在进行写操作，冷备的数据就可能不完整，数据文件可能处于损坏状态。使用一主多从的复制就就可以实现零停机的备份。只需要关闭数据库的数据复制进程，文件就处于关闭状态了，然后进行数据文件拷贝，拷贝完成后再重新打开数据复制就可以了。 高可用：如果一台服务器宕机了，只要不发请求给这台服务器就不会出问题。当这台服务器恢复的时候，重新发请求到这台服务器。所以，在一主多从的情况下，某一台从服务器宕机不可用，对整个系统的影响是非常小的。 MySQL主主复制目的一主多从只能够实现从服务器上的这些优点，当主数据库宕机不可用的时候，数据依然是不能够写入的，因为数据不能够写入到从服务器上面去，从服务器是只读的。为了解决主服务器的可用性问题，采用MySQL的主主复制方案。 原理当客户端程序对主服务器A进行数据更新操作的时候，主服务器A会把更新操作写入到Binlog日志中。然后Binlog会将数据日志同步到主服务器B，写入到主服务器的Relay log中，然后执Relay log，获得Relay log中的更新日志，执行SQL操作写入到数据库服务器B的本地数据库中。B服务器上的更新也同样通过Binlog复制到了服务器A的Relay log中，然后通过Relay log将数据更新到服务器A中。 通过这种方式，服务器A或者B任何一台服务器收到了数据的写的操作都会同步更新到另一台服务器，实现了数据库主主复制。主主复制可以提高系统的写可用，实现写操作的高可用。 MySQL主主复制失效恢复正常情况下用户会写入到主服务器A中，然后数据从A复制到主服务器B上。当主服务器A失效的时候，写操作会被发送到主服务器B中去，数据从B服务器复制到A服务器。 主主失效维护过程：最开始的时候，所有的主服务器都可以正常使用，当主服务器A失效的时候，进入故障状态，应用程序检测到主服务器A失效，检测到这个失效可能需要几秒钟或者几分钟的时间，然后应用程序需要进行失效转移，将写操作发送到备份主服务器B上面去，将读操作发送到B服务器对应的从服务器上面去。 一段时间后故障结束，A服务器需要重建失效期间丢失的数据，也就是把自己当作从服务器从B服务器上面去同步数据。同步完成后系统才能恢复正常。这个时候B服务器是用户的主要访问服务器，A服务器当作备份服务器。 MySQL复制注意事项 不要对两个数据库同时进行数据写操作，因为这种情况会导致数据冲突。 复制只是增加了数据的读并发处理能力，并没有增加写并发的能力和系统存储能力。 更新数据表的结构会导致巨大的同步延迟。 需要更新表结构的操作，不要写入到到Binlog中，要关闭更新表结构的Binlog。如果要对表结构进行更新，应该由运维工程师DBA对所有主从数据库分别手工进行数据表结构的更新操作。","tags":"数据库"},{"title":"Hexo搭建GitHub博客(持续更新)","url":"/posts/d5766023.html","text":"入门Hexo由于平时自己喜欢看一些技术类文章整理成Word笔记，总感觉这种方式太low，想自己搭建属于自己的博客，在网上查阅了一下，发现Hexo在GitHub或者是码云上搭建博客非常给力。然后自己也搭建了博客，这篇文章就记录了搭建的过程及一些优化。 什么是HexoHexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown （或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。大家进入 Hexo官网 进行查看。 安装Hexo安装 Hexo 相当简单。然而在安装前，您必须检查电脑中是否已安装下列应用程序： Node.js Git cnpm 如果npm运行出错就安装cnpm国内镜像所有必备的应用程序安装完成后，即可使用 npm或者cnpm 安装 Hexo。打开Git Bash here，输入： 123$ npm install -g hexo-cli 或者 $ cnpm install -g hexo-cli 检查是否安装Hexo完成,查询是否成功，显示hexo-cli 版本就说明成功了 1$ hexo -V 建站安装一切所需的程序后，就可以开始建站了，就是创建我们的博客,大家也可以进入 建站官网 查看。新建一个文件夹，来管理我们的博客项目，执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。 运行命令123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ cnpm install 注：&lt;folder&gt;是表示建站的博客项目名打开Git Bash here，输入： 1$ hexo init githubBlog 进入创建的博客项目下，安装 12$ cd githubBlog$ cnpm install 安装之后，整个博客项目目录如下： 访问URL123$ hexo server 或者$ hexo s 访问URL：http://localhost:4000，效果如下图： 到这里已经通过Hexo初步创建博客了，下面再来了解一下如何将我们的博客托管到GitHub服务器上。 托管到GitHubGitHub创建repositories进入GitHub官网中浏览器输入 https://github.com/ ,如果还没有账号就创建一个账号就好了。登录自己的账号。直接new repositories 或者进入You repositories 在new repositories。 进入到创建 repositories 页面后,一定要注意，将新建的repository的名字为: You account name.github.io。其他默认就好了。 配置GitHub的Repository创建好后，在回到本地的Hexo的githubBlog项目中，找到在项目的根目录下_config.yml找到 deploy标签在该文件下面添加 注：repository: https://github.com/whb1990/whb1990.github.io 是自己刚刚创建You account name.github.io 的repository，在Clone with HTTPS里面，复制粘贴就好了，冒号后面记得空格。branch 后面是master就好了。 1234deploy: #部署 type: git repository: https://github.com/whb1990/whb1990.github.io.git branch: master 在_config.yml找到url进行修改为： 1url: http://whb1990.github.io #博客网址 部署到这里就差不到了，接下来需要执行一些命令，将博客部署到GitHub上去。打开Git Bash Here进入githubBlog 根目录下，首先需要安装一下 hexo-deployer-git 不然可能出现错误无法部署成功。 1$ cnpm install hexo-deployer-git --save 然后在执行以下命令: 123$ hexo clean$ hexo generate$ hexo deploy 或者简写 123$ hexo clean$ hexo g$ hexo d 部署成功如下显示: 测试我们进行访问 https://whb1990.github.io/ 和 http://localhost:4000/ 一样的页面说明是已经成功。 站点文件配置在根githubBlog目录下_config.yml文件，我们暂且称为站点配置文件，以便与后面讲到的主题配置文件(Next主题下的_config.yml文件)进行区分。 网站 参数 描述 title 网站标题 subtitle 网站副标题 description 网站描述 author 您的名字 language 网站使用的语言 timezone 网站时区。Hexo 默认使用您电脑的时区。时区列表。比如说：America/New_York, Japan, 和 UTC 。 目录 参数 描述 source_dir 资源文件夹，这个文件夹用来存放内容。 public_dir 公共文件夹，这个文件夹用于存放生成的站点文件。 tag_dir 标签文件夹 archive_dir 归档文件夹 category_dir 分类文件夹 code_dir Include code 文件夹 i18n_dir 国际化（i18n）文件夹 skip_render 跳过指定文件的渲染，您可使用 glob 来配置路径 文章 参数 描述 默认值 new_post_name 新文章的文件名称 :title.md default_layout 预设布局 post auto_spacing 在中文和英文之间加入空格 false titlecase 把标题转换为 title case false external_link 在新标签中打开链接 true filename_case 把文件名称转换为 (1) 小写或 (2) 大写 0 render_drafts 显示草稿 false post_asset_folder 启动 Asset 文件夹 false relative_link 把链接改为与根目录的相对位址 false future 显示未来的文章 true highlight 代码块的设置 分类&amp;标签 参数 描述 默认值 default_category 默认分类 uncategorized category_map 分类别名 tag_map 标签别名 分页 参数 描述 默认值 per_page 每页显示的文章量 (0 = 关闭分页功能) 10 pagination_dir 分页目录 page 写作创建文章1$ hexo new [layout] &lt;title&gt; 如：创建hello-world 1$ hexo new hello-world 如果不添加title，默认就是标题title: hello-world。这里注意一下，如果创建带有中文的路径名称时，生成静态页面hexo g可能会报错。 12warning: LF will be replaced by CRLF in xxxxThe file will have its original line endings in your working directory. 这是由于原因是路径中存在 / 的符号转义问题 如：创建文章时命名为中文，一般都出现这个小问题。 解决 在命令行中输入: 1$ git config --global core.autocrlf false 然后重新生成文件部署就好了。 编辑文章创建的文章在source/_posts目录下，打开文件进行编辑，完全支持Markdown语法。 Next主题在 Hexo主题官网 中有许多主题，大家喜欢什么就进行部署和编辑就好了，大致的思路都是差不多的。我选择的 Next主题 ，网上很多也是用的这个主题。 安装在githubBlog根目录下，执行以下命令： 1$ git clone https://github.com/theme-next/hexo-theme-next themes/next 上面的命令是clone最新版本的主题，也可以使用下面的命令clone指定版本的主题 1$ git clone --branch v7.1.1 https://github.com/theme-next/hexo-theme-next themes/next 安装完成之后，在themes下就会有next目录 切换主题在项目根目录下打开_config.yml文件将theme设置为next即可：部署之后查看效果如下，有点丑： 主题配置一般配置都在theme/next/-config.yml文件下配置。 修改整体布局 在theme/next/-config.yml找到menu看看自己博客所需的分类 123456789menu: home: / || home #首页 about: /about/ || user #关于 tags: /tags/ || tags #标签 categories: /categories/ || th #目录 archives: /archives/ || archive #归档 #schedule: /schedule/ || calendar #日程 sitemap: /sitemap.xml || sitemap #站点地图 commonweal: /404/ || heartbeat #公益404 在menu_settings如果设置icon: false则无图标，badges: true则标签都会显示数字 123menu_settings: icons: true badges: false 注:这里需要创建about页面，很简单，同理创建标签tags、归档archives页面一样的方式，所需要创建的名称要与menu相对应，举例说明如下。 12$ hexo new page about #看看menu上还有什么标签没创建就行创建$ hexo new page tags #创建标签等 创建完成之后在自己项目查找，如我的是githubBlog/source/目录下查看新创建好的相关标签页面，里面包含各自的index.md文件，大家可以自行编辑了。 Schemes方案设置 12345# Schemes#scheme: Muse #这是 Nex默认版本，黑白主调，大量留白 #scheme: Mist #Muse 的紧凑版本，整洁有序的单栏外观#scheme: Pisces #双栏 Scheme，小家碧玉似的清新scheme: Gemini #双子座，也是双栏形式，和Pisces类似 自己喜欢什么风格自行选择。 social设置 使用方式: Key: permalink || icon Key表示标签显示，permalink表示URI连接，icon表示图标，自己添加所要显示的， 12345678910111213141516171819social: GitHub: https://github.com/whb1990 || github E-Mail: mailto:whbsurpass@163.com || envelope QQ: 270028806 || qq 微信: yan521bo ||weixin #Weibo: https://weibo.com/yourname || weibo #Google: https://plus.google.com/yourname || google #Twitter: https://twitter.com/yourname || twitter #FB Page: https://www.facebook.com/yourname || facebook #VK Group: https://vk.com/yourname || vk #StackOverflow: https://stackoverflow.com/yourname || stack-overflow #YouTube: https://youtube.com/yourname || youtube #Instagram: https://instagram.com/yourname || instagram #Skype: skype:yourname?call|chat || skypesocial_icons: #设置图标是否显示这里 enable: true #表示开启 icons_only: false #只显示图片 transition: false 注：图标库来源 [https://fontawesome.com/icons?from=io] ，在scheme: Pisces该效果不显示。 avatar头像设置 12345678910111213avatar: # In theme directory (source/images): /images/avatar.gif # In site directory (source/uploads): /uploads/avatar.gif # You can also use other linking images. url: /images/avatar.jpg # If true, the avatar would be dispalyed in circle. #圆形框 rounded: true # The value of opacity should be choose from 0 to 1 to set the opacity of the avatar. opacity: 1 # If true, the avatar would be rotated with the cursor. #头像是否旋转 rotated: true toc边栏中的目录设置 12345678910toc: #边栏设置 enable: true #是否启用边栏 # Automatically add list number to toc. number: true #自动将列表编号添加到toc # If true, all words will placed on next lines if header width longer then sidebar width. wrap: false #true时是当标题宽度很长时，自动换到下一行 # If true, all level of TOC in a post will be displayed, rather than the activated part of it. expand_all: false #折叠 # Maximum heading depth of generated toc. You can set it in one post through `toc_max_depth` in Front-matter. max_depth: 6 #最大深度 Creative Commons 4.0国际许可设置 12# Available: by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | zerocreative_commons: by-nc-sa sidebar侧边栏配置这里选择默认吧 1234567891011121314151617181920212223sidebar: # Sidebar Position, available values: left | right (only for Pisces | Gemini). position: left #position: right # Manual define the sidebar width. If commented, will be default for: # Muse | Mist: 320 # Pisces | Gemini: 240 width: 240 # Sidebar Display, available values (only for Muse | Mist): # - post expand on posts automatically. Default. # - always expand for all pages automatically. # - hide expand only when click on the sidebar toggle icon. # - remove totally remove sidebar including sidebar toggle. display: post # Sidebar offset from top menubar in pixels (only for Pisces | Gemini). offset: 12 # Enable sidebar on narrow view (only for Muse | Mist). onmobile: true # Click any blank part of the page to close sidebar (only for Muse | Mist). dimmer: false save_scroll配置 12# Automatically saving scroll position on each post / page in cookies.save_scroll: false #是否在Cookie中自动保存每个帖子/页面上的滚动位置。 excerpt_description 12# Automatically excerpt description in homepage as preamble text.excerpt_description: false #是否自动摘录主页中的描述作为前导文本。 auto_excerpt配置 123auto_excerpt: enable: true #是否自动摘录。不推荐 length: 150 #这里是说文章开头第一个字到第150个字就显示\"阅读全文\" codeblock代码块配置 1234567891011121314codeblock: # Code Highlight theme # Available values: normal | night | night eighties | night blue | night bright # See: https://github.com/chriskempson/tomorrow-theme highlight_theme: normal #代码突出显示主题 # Manual define the border radius in codeblock, leave it blank for the default value: 1 border_radius: 1 # Add copy button on codeblock copy_button: enable: true # Show text copy result. show_result: true # Available values: default | flat | mac style: flat wechat_subscriber微信配置 1234wechat_subscriber: enabled: true #是否启动微信订阅 qcode: /path/to/your/wechatqcode ex. /uploads/wechat-qcode.jpg description: ex. subscribe to my blog by scanning my public wechat account footer 底部设置 12345678910111213141516171819202122232425262728footer: # Specify the date when the site was setup. If not defined, current year will be used. since: 2019 #建站开始时间 # Icon between year and copyright info. icon: # Icon name in Font Awesome. See: https://fontawesome.com/v4.7.0/icons/ # `heart` is recommended with animation in red (#ff0000). name: heart #设置图标，想修改图标从https://fontawesome.com/v4.7.0/icons获取 # If you want to animate the icon, set it to true. animated: true # Change the color of icon, using Hex Code. color: \"#ff0000\" # If not defined, `author` from Hexo `_config.yml` will be used. copyright: ©2019 by 王洪博 #版权 powered: # Hexo link (Powered by Hexo). enable: true ##是否显示Hexo link # Version info of Hexo after Hexo link (vX.X.X). version: true #是否显示Hexo版本 theme: # Theme &amp; scheme info link (Theme - NexT.scheme). enable: true #是否显示NexT主题 # Version info of NexT after scheme info (vX.X.X). version: true #是否显示NexT版本 favicon标签页图标 12345favicon: small: /images/favicon-16x16-next.png #小图标 默认的NexT medium: /images/favicon-32x32-next.png #中图标 默认NexT apple_touch_icon: /images/apple-touch-icon-next.png #苹果触摸图标 safari_pinned_tab: /images/logo.svg #safari固定标签 Math Equations Render Support 数学方程式渲染支持 12345678math: enable: true #默认为false per_page: true engine: mathjax #两种方式 mathjax / katex mathjax: cdn: //cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML #默认 这里大家根据自己需求 katex: cdn: //cdn.jsdelivr.net/npm/katex@0.7.1/dist/katex.min.css #默认 16 .Han Support 支持汉字 设置汉字支持，按照以下步骤： 打开Git Bash Here,进入theme/next目录下 1$ cd themes/next 获取该汉字支持Git module,执行命令以下命令获得 1$ git clone https://github.com/theme-next/theme-next-han source/lib/Han 设置汉字支持 1han: true 更新update 12$ cd themes/next/source/lib/Han$ git pull font字体设置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647font: # Use custom fonts families or not. # Depended options: `external` and `family`. enable: true #默认false 如果要进行字体修改那么设置为true # Uri of fonts host, e.g. //fonts.googleapis.com (Default). host: //fonts.lug.ustc.edu.cn # Font options: # `external: true` will load this font family from `host` above. # `family: Times New Roman`. Without any quotes. # `size: x.x`. Use `em` as unit. Default: 1 (16px) # Global font settings used for all elements inside &lt;body&gt;. global: external: true family: Lato size: # Font settings for site title (.site-title). title: external: true family: size: # Font settings for headlines (&lt;h1&gt; to &lt;h6&gt;). headings: external: true family: Roboto Slab size: # Font settings for posts (.post-body). posts: external: true family: # Font settings for &lt;code&gt; and code blocks. codes: external: true family: Roboto Mono # Font settings for Logo. # Fallback to `global` font settings. logo: external: true family: size: 添加图标链接到GitHub一般在右上角或者左上角，如配置右上角Fork_me_on_GitHub,按以下步骤进行 打开 Fork_me_on_GitHub 链接，里面有许多样式，选择自己喜欢的样式，将其复制下来。 打开自己博客项目中的themes/next/layout/_layout.swig文件，搜索&lt;div class=&quot;headband&quot;&gt;&lt;/div&gt; 将复制的内容粘贴到&lt;div class=&quot;headband&quot;&gt;&lt;/div&gt;下面，如下： 配置右上角的Fork_me_on_GitHub: 修改文章底部标签在博客项目中找到/themes/next/layout/_macro/post.swig，搜索 rel=&quot;tag&quot;，将 #号 换成&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt; 原先#号的样式 修改为图标的样式 设置背景动画样式NexT里面有几种动画背景样式canvas_nest、three_waves、canvas_lines、canvas_sphere等 canvas_nest如下图所示: 按照以下步骤完成 打开Git Bash Here进入自己文件夹下/themes/next文件夹下 1$ cd /themes/next 下载安装 canvas_nest module 执行 1$ git clone https://github.com/theme-next/theme-next-canvas-nest source/lib/canvas-nest 在 /themes/next/source/lib查看会看到canvas_nest文件夹 在/themes/next/_config.yml设置 1canvas_nest: true three_waves如图所示 three_waves 设置步骤，和 canvas_nest 步骤是一样的。下载完成后，在/themes/next/_config.yml设置 12345three_waves: true#ORcanvas_lines: true#ORcanvas_sphere: true canvas_ribbon canvas_ribbon只适合 scheme Pisces 这里不测试了，大家可以进入 canvas_ribbon 安装。 在网站底部添加访问量 进入 \\themes\\next\\layout\\_partials\\footer.swig 文件顶部第一行添加 1&lt;script async src=\"https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js\"&gt;&lt;/script&gt; 搜索 1&#123;% if theme.footer.powered.enable %&#125; 在这个位置上添加以下代码: 12345&lt;div class=\"powered-by\"&gt;&lt;i class=\"fa fa-user-md\"&gt;&lt;/i&gt;&lt;span id=\"busuanzi_container_site_uv\"&gt; 本站访客数:&lt;span id=\"busuanzi_value_site_uv\"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt; 注：这里的id值可以选择两种 12busuanzi_value_site_uv #表示用户连续点击n篇文章，只记录1次访客数busuanzi_value_site_pv #表示用户连续点击n篇文章，记录+n次访问量 这里对应的是2上的id值 给每篇文章添加类别和标签在创建的文章都在source/_post目录下找到，每篇文章添加tags、categories 添加进度条添加进度条的话在手机浏览的时候一般情况都有自带的进度条了，例如微信浏览、浏览器浏览等等，这样就出现重复的进度条了，这里看个人是否添加。但是在电脑浏览器浏览却是不错的。本例设置的如下pace-theme-center-circle显示 按照以下步骤进行或者进入这里 Progress配置 查看如何配置 打开Git Bash Here进入自己文件夹下/themes/next文件夹下 1$ cd /themes/next 下载安装 Progress module 执行 1$ git clone https://github.com/theme-next/theme-next-pace source/lib/pace 在 /themes/next/source/lib查看会看到pace文件夹 在/themes/next/_config.yml设置 123456pace: enable: true # Themes list: # big-counter | bounce | barber-shop | center-atom | center-circle | center-radar | center-simple # corner-indicator | fill-left | flat-top | flash | loading-bar | mac-osx | material | minimal theme: minimal #任选一种 添加站内搜索由于可能需要快速查找相关文章，那么就需要添加站内搜索。 按以下步骤进行或者进入 NexT配置站内搜索 文档查看如何配置 安装站内搜索插件 123$ npm install hexo-generator-searchdb --save或者$ cnpm install hexo-generator-searchdb --save 在根目录下的_config.yml添加 123456#表示站内搜索search: path: search.xml field: post format: html limit: 10000 在themes/next/_config.yml文件中搜索local_search,进行设置 12345local_search: enable: true #设置为true trigger: auto # auto / manual，auto 自动搜索、manual：按回车[enter ]键手动搜索 top_n_per_article: 1 unescape: true 添加打赏NexT主要提供三种打赏方式分别是微信、支付宝、比特币在themes/next搜索Reward： 123456reward_settings: # If true, reward would be displayed in every article by default. # You can show or hide reward in a specific article throuth `reward: true | false` in Front-matter. enable: true #启用打赏 animation: true #启用动画效果 comment: 捐赠作者请点击下方的“打赏”按钮 #内容 友情链接12345678# Blog rolls #友情链接links_icon: linklinks_title: 友情链接links_layout: block#links_layout: inlinelinks: Eirunye: http://eirunye.github.io/ #所需添加的友情链接 Title是表示友情链接的博客名称或者随意你取，后面是链接，冒号后面记得空格 程晓明: https://www.infoq.cn/profile/1278512 添加阅读统计给每篇文章进行添加阅读统计，效果如下图: 进入 leancloud 创建应用 进入设置页面获取应用Key 将App ID、App Key 配置到next/_config.yml中leancloud_visitors 1234567leancloud_visitors: enable: true 设置为true 默认为false app_id: #你的App ID，注意冒号后面空格 app_key: #你的App Key，注意冒号后面空格 Dependencies: https://github.com/theme-next/hexo-leancloud-counter-security #设置依赖 security: true #如果您不关心lc计数器中的安全性并且只想直接使用它（没有hexo-leancloud-counter-security插件），请将`security`设置为`false`。 betterPerformance: true#更好的性能 在leancloud存储的位置创建Class,必须命名为Counter 查看后台统计数据 添加评论我的博客选择的是Valine。 在next/_config.yml搜索Valine,进入 Valine 官网，也是 leancloud 官网，进入leancloud 控制台,没有账号密码就进行设置。 创建应用参考上面 添加阅读统计 的创建应用。 进入设置页面获取应用key参考上面 添加阅读统计 的进入设置页面获取应用key。 在next/_config.yml进行配置。 1234567891011valine: enable: true # 设置为true，默认为false appid: # 将应用key的App ID设置在这里 appkey: # 将应用key的App Key设置在这里 notify: true# 邮箱通知 , https://github.com/xCss/Valine/wiki，默认为false verify: true# 验证码 默认为false placeholder: Just go go ^_^ # 初始化评论显示，根据自己修改，这里默认， avatar: wavatar # 头像风格，默认为mm，可进入网址：https://valine.js.org/visitor.html查看头像设置，这里有许多头像风格，进行设置 guest_info: nick,mail,link # 自定义评论标题 pageSize: 10 # 分页大小，10页就自动分页 visitor: true # 是否允许游客评论 ，进入官网查看设置：https://valine.js.org/visitor.html 显示结果 这样就完成了valine评论的配置了，接下来就可以进行评论了，我们还可以在后台查看评论信息。 在后台查看评论数据 在valine后台，存储位置中的数据里面创建Class，名称必须为命名为Comment参考上面 添加阅读统计 的创建Class。 注：选择valine评论系统是因为支持国内网络，不需要连接外网（翻墙）就可以进行显示评论系统，而且很好管理，页面简单。 添加RSS效果如下图： 实现方法： 切换到你的blog根目录下，然后安装 Hexo 插件：(这个插件会放在node_modules这个文件夹里) 1$ cnpm install --save hexo-generator-feed 然后在根目录的站点配置文件_config.yml下进行配置 12## Plugins: http://hexo.io/plugins/plugins: hexo-generate-feed # RSS订阅 然后打开next主题文件夹里面的_config.yml,在里面配置为如下： 1234# Set rss to false to disable feed link.# Leave rss as empty to use site's feed link.# Set rss to specific value if you have burned your feed already.rss: /atom.xml 点击出现桃心效果效果如下图： 实现方法 打开浏览器，输入： http://7u2ss1.com1.z0.glb.clouddn.com/love.js 然后将里面的代码copy一下，新建love.js文件并且将代码复制进去，然后保存。 将love.js文件放到路径/themes/next/source/js/src里面，然后打开\\themes\\next\\layout\\_layout.swig文件,在末尾（在前面引用会出现找不到的bug）添加以下代码： 12&lt;!-- 页面点击小红心 --&gt;&lt;script type=\"text/javascript\" src=\"/js/src/love.js\"&gt;&lt;/script&gt; 修改文章内链接文本样式效果如下图： 实现方法 修改文件 themes\\next\\source\\css\\_common\\components\\post\\post.styl，在末尾添加如下css样式： 1234567891011// 文章内链接文本样式.post-body p a&#123; color: #0593d3; border-bottom: none; border-bottom: 1px solid #0593d3; &amp;:hover &#123; color: #fc6423; border-bottom: none; border-bottom: 1px solid #fc6423; &#125;&#125; 其中选择.post-body 是为了不影响标题，选择 p 是为了不影响首页“阅读全文”的显示样式,颜色可以自己定义。 在每篇文章末尾统一添加“本文结束”标记效果如下图： 实现方法 在路径 \\themes\\next\\layout\\_macro 中新建 passage-end-tag.swig 文件,并添加以下内容： 12345&lt;div&gt; &#123;% if not is_index %&#125; &lt;div style=\"text-align:center;color: #ccc;font-size:14px;\"&gt;-------------本文结束&lt;i class=\"fa fa-paw\"&gt;&lt;/i&gt;感谢您的阅读-------------&lt;/div&gt; &#123;% endif %&#125;&lt;/div&gt; 接着打开\\themes\\next\\layout\\_macro\\post.swig文件，在post-body 之后， post-footer 之前添加如下画红色部分代码（post-footer之前两个DIV）： 12345&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include 'passage-end-tag.swig' %&#125; &#123;% endif %&#125;&lt;/div&gt; 然后打开主题配置文件（_config.yml),在末尾添加： 123# 文章末尾添加“本文结束”标记passage_end_tag: enabled: true 修改``代码块自定义样式效果如下： 实现方法打开\\themes\\next\\source\\css\\_custom\\custom.styl,向里面加入：(颜色可以自己定义) 123456789101112131415// Custom styles.code &#123; color: #ff7600; background: #fbf7f8; margin: 2px;&#125;// 大代码块的自定义样式.highlight, pre &#123; margin: 5px 0; padding: 5px; border-radius: 3px;&#125;.highlight, code, pre &#123; border: 1px solid #d6d6d6;&#125; 主页文章添加阴影效果效果如下图： 实现方法 打开\\themes\\next\\source\\css\\_custom\\custom.styl,向里面加入： 12345678// 主页文章添加阴影效果 .post &#123; margin-top: 60px; margin-bottom: 60px; padding: 25px; -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5); -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5); &#125; 添加热度效果如下图： 实现方法 next主题集成leanCloud，打开/themes/next/layout/_macro/post.swig,在画红线的区域添加℃： 然后打开，/themes/next/languages/zh-Hans.yml,将画红框的改为热度就可以了: 网站底部字数统计效果如下图： 实现方法 切换到根目录下，然后运行如下代码 1$ cnpm install hexo-wordcount --save 然后在/themes/next/layout/_partials/footer.swig文件尾部加上： 1234&lt;div class=\"theme-info\"&gt; &lt;div class=\"powered-by\"&gt;&lt;/div&gt; &lt;span class=\"post-count\"&gt;站点总字数&#123;&#123; totalcount(site) &#125;&#125;字&lt;/span&gt;&lt;/div&gt; 添加 README.md 文件每个项目下一般都有一个 README.md 文件，但是使用 hexo 部署到仓库后，项目下是没有 README.md 文件的。 在 Hexo 目录下的 source 根目录下添加一个 README.md 文件，修改站点配置文件 _config.yml，将 skip_render 参数的值设置为 1skip_render: README.md 保存退出即可。再次使用 hexo d 命令部署博客的时候就不会在渲染 README.md 这个文件了。 实现统计功能效果如下图： 实现方法 在根目录下安装 hexo-wordcount,运行： 1$ cnpm install hexo-wordcount --save 然后在主题的配置文件中，配置如下： 12345678# Post wordcount display settings# Dependencies: https://github.com/willin/hexo-wordcountpost_wordcount: item_text: true wordcount: true #字数统计 min2read: true #阅读时长预计 totalcount: true #总字数统计 separated_meta: true 添加顶部加载条效果如下图： 实现方法 打开/themes/next/layout/_partials/head.swig文件，添加红框上的代码 12&lt;script src=\"//cdn.bootcss.com/pace/1.0.2/pace.min.js\"&gt;&lt;/script&gt;&lt;link href=\"//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css\" rel=\"stylesheet\"&gt; 但是，默认的是粉色的，要改变颜色可以在/themes/next/layout/_partials/head.swig文件中添加如下代码（接在刚才link的后面） 12345678910111213&lt;style&gt; .pace .pace-progress &#123; background: #1E92FB; /*进度条颜色*/ height: 3px; &#125; .pace .pace-progress-inner &#123; box-shadow: 0 0 10px #1E92FB, 0 0 5px #1E92FB; /*阴影颜色*/ &#125; .pace .pace-activity &#123; border-top-color: #1E92FB; /*上边框颜色*/ border-left-color: #1E92FB; /*左边框颜色*/ &#125;&lt;/style&gt; 在文章底部增加版权信息效果如下图： 实现方法 在目录 next/layout/_macro/下添加 my-copyright.swig： 1234567891011121314151617181920212223242526272829303132&#123;% if page.copyright %&#125;&lt;div class=\"my_post_copyright\"&gt; &lt;script src=\"//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js\"&gt;&lt;/script&gt; &lt;!-- JS库 sweetalert 可修改路径 --&gt; &lt;script src=\"https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js\"&gt;&lt;/script&gt; &lt;script src=\"https://unpkg.com/sweetalert/dist/sweetalert.min.js\"&gt;&lt;/script&gt; &lt;p&gt;&lt;span&gt;本文标题:&lt;/span&gt;&lt;a href=\"&#123;&#123; url_for(page.path) &#125;&#125;\"&gt;&#123;&#123; page.title &#125;&#125;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;文章作者:&lt;/span&gt;&lt;a href=\"/\" title=\"访问 &#123;&#123; theme.author &#125;&#125; 的个人博客\"&gt;&#123;&#123; theme.author &#125;&#125;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;发布时间:&lt;/span&gt;&#123;&#123; page.date.format(\"YYYY年MM月DD日 - HH:MM\") &#125;&#125;&lt;/p&gt; &lt;p&gt;&lt;span&gt;最后更新:&lt;/span&gt;&#123;&#123; page.updated.format(\"YYYY年MM月DD日 - HH:MM\") &#125;&#125;&lt;/p&gt; &lt;p&gt;&lt;span&gt;原始链接:&lt;/span&gt;&lt;a href=\"&#123;&#123; url_for(page.path) &#125;&#125;\" title=\"&#123;&#123; page.title &#125;&#125;\"&gt;&#123;&#123; page.permalink &#125;&#125;&lt;/a&gt; &lt;span class=\"copy-path\" title=\"点击复制文章链接\"&gt;&lt;i class=\"fa fa-clipboard\" data-clipboard-text=\"&#123;&#123; page.permalink &#125;&#125;\" aria-label=\"复制成功！\"&gt;&lt;/i&gt;&lt;/span&gt; &lt;/p&gt; &lt;!-- &lt;p&gt;&lt;span&gt;许可协议:&lt;/span&gt;&lt;i class=\"fa fa-creative-commons\"&gt;&lt;/i&gt; &lt;a rel=\"license\" href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/\" target=\"_blank\" title=\"Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)\"&gt;署名-非商业性使用-禁止演绎 4.0 国际&lt;/a&gt; 转载请保留原文链接及作者。&lt;/p&gt; --&gt; &lt;/div&gt;&lt;script&gt; var clipboard = new Clipboard('.fa-clipboard'); $(\".fa-clipboard\").click(function()&#123; clipboard.on('success', function()&#123; swal(&#123; title: \"\", text: '复制成功', icon: \"success\", showConfirmButton: true &#125;); &#125;); &#125;); &lt;/script&gt;&#123;% endif %&#125; 在目录next/source/css/_common/components/post/下添加my-post-copyright.styl： 123456789101112131415161718192021222324252627282930313233343536373839404142434445.my_post_copyright &#123; width: 85%; max-width: 45em; margin: 2.8em auto 0; padding: 0.5em 1.0em; border: 1px solid #d3d3d3; font-size: 0.93rem; line-height: 1.6em; word-break: break-all; background: rgba(255,255,255,0.4);&#125;.my_post_copyright p&#123;margin:0;&#125;.my_post_copyright span &#123; display: inline-block; width: 5.2em; color: #b5b5b5; font-weight: bold;&#125;.my_post_copyright .raw &#123; margin-left: 1em; width: 5em;&#125;.my_post_copyright a &#123; color: #808080; border-bottom:0;&#125;.my_post_copyright a:hover &#123; color: #a3d2a3; text-decoration: underline;&#125;.my_post_copyright:hover .fa-clipboard &#123; color: #000;&#125;.my_post_copyright .post-url:hover &#123; font-weight: normal;&#125;.my_post_copyright .copy-path &#123; margin-left: 1em; width: 1em; +mobile()&#123;display:none;&#125;&#125;.my_post_copyright .copy-path:hover &#123; color: #808080; cursor: pointer;&#125; 修改next/layout/_macro/post.swig，在代码 12345&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include 'wechat-subscriber.swig' %&#125; &#123;% endif %&#125;&lt;/div&gt; 之前添加增加如下代码： 12345&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include 'my-copyright.swig' %&#125; &#123;% endif %&#125;&lt;/div&gt; 如下图： 修改next/source/css/_common/components/post/post.styl文件，在最后一行增加代码： 1@import \"my-post-copyright\" 保存重新生成即可。如果要在该博文下面增加版权信息的显示，需要在 Markdown 中增加copyright: true的设置，类似： 123456789101112---title: Java并发-ReentrantLockcopyright: truedate: 2019-08-26 14:59:12updated:tags: - Java - J.U.Ccategories: - Java - J.U.C--- 如果你觉得每次都要输入copyright: true很麻烦的话,那么在/scaffolds/post.md文件中添加： 1copyright: true 这样每次hexo new &quot;你的内容&quot;之后，生成的md文件会自动把copyright:true加到里面去。 隐藏网页底部powered By Hexo / 强力驱动打开themes/next/layout/_partials/footer.swig,隐藏或删除如下代码，如下图： 修改打赏字体不闪动修改文件next/source/css/_common/components/post/post-reward.styl，然后注释其中的函数wechat:hover和alipay:hover，如下： 123456789101112/* 注释文字闪动函数 #wechat:hover p&#123; animation: roll 0.1s infinite linear; -webkit-animation: roll 0.1s infinite linear; -moz-animation: roll 0.1s infinite linear;&#125; #alipay:hover p&#123; animation: roll 0.1s infinite linear; -webkit-animation: roll 0.1s infinite linear; -moz-animation: roll 0.1s infinite linear;&#125;*/ 文章加密访问效果如下图： 实现方法 打开themes/next/layout/_partials/head/head.swig文件,在以下位置插入这样一段代码： 12345678910&lt;script&gt; (function()&#123; if('&#123;&#123; page.password &#125;&#125;')&#123; if (prompt('请输入文章密码') !== '&#123;&#123; page.password &#125;&#125;')&#123; alert('密码错误！'); history.back(); &#125; &#125; &#125;)();&lt;/script&gt; 然后在文章上写成类似这样： 添加鼠标点击显示字体效果效果如下图： 实现方法 在 /themes/next/source/js 下新建文件 click_show_text.js，在 click_show_text.js 文件中添加以下代码： 123456789101112131415161718192021222324252627282930313233var a_idx = 0;jQuery(document).ready(function($) &#123; $(\"body\").click(function(e) &#123; var a = new Array (\"富强\", \"民主\", \"文明\", \"和谐\", \"自由\", \"平等\", \"公正\", \"法治\", \"爱国\", \"敬业\", \"诚信\", \"友善\"); var $i = $(\"&lt;span/&gt;\").text(a[a_idx]); a_idx = (a_idx + 1) % a.length; var x = e.pageX, y = e.pageY; $i.css(&#123; \"z-index\": 5, \"top\": y - 20, \"left\": x, \"position\": \"absolute\", \"font-weight\": \"bold\", \"color\": \"#FF0000\" &#125;); $(\"body\").append($i); $i.animate(&#123; \"top\": y - 180, \"opacity\": 0 &#125;, 3000, function() &#123; $i.remove(); &#125;); &#125;); setTimeout('delay()', 2000);&#125;);function delay() &#123; $(\".buryit\").removeAttr(\"onclick\");&#125; 其中的社会主义核心价值观可以根据你自己的创意替换为其他文字，然后在 \\themes\\next\\layout\\_layout.swing 文件末尾添加以下代码： 12&lt;!--单击显示文字--&gt;&lt;script type=\"text/javascript\" src=\"/js/click_show_text.js\"&gt;&lt;/script&gt; 添加鼠标点击烟花爆炸效果效果如下图： 实现方法 在 \\themes\\next\\source\\js 目录下新建一个 fireworks.js 的文件，里面写入以下代码： 1\"use strict\";function updateCoords(e)&#123;pointerX=(e.clientX||e.touches[0].clientX)-canvasEl.getBoundingClientRect().left,pointerY=e.clientY||e.touches[0].clientY-canvasEl.getBoundingClientRect().top&#125;function setParticuleDirection(e)&#123;var t=anime.random(0,360)*Math.PI/180,a=anime.random(50,180),n=[-1,1][anime.random(0,1)]*a;return&#123;x:e.x+n*Math.cos(t),y:e.y+n*Math.sin(t)&#125;&#125;function createParticule(e,t)&#123;var a=&#123;&#125;;return a.x=e,a.y=t,a.color=colors[anime.random(0,colors.length-1)],a.radius=anime.random(16,32),a.endPos=setParticuleDirection(a),a.draw=function()&#123;ctx.beginPath(),ctx.arc(a.x,a.y,a.radius,0,2*Math.PI,!0),ctx.fillStyle=a.color,ctx.fill()&#125;,a&#125;function createCircle(e,t)&#123;var a=&#123;&#125;;return a.x=e,a.y=t,a.color=\"#F00\",a.radius=0.1,a.alpha=0.5,a.lineWidth=6,a.draw=function()&#123;ctx.globalAlpha=a.alpha,ctx.beginPath(),ctx.arc(a.x,a.y,a.radius,0,2*Math.PI,!0),ctx.lineWidth=a.lineWidth,ctx.strokeStyle=a.color,ctx.stroke(),ctx.globalAlpha=1&#125;,a&#125;function renderParticule(e)&#123;for(var t=0;t&lt;e.animatables.length;t++)&#123;e.animatables[t].target.draw()&#125;&#125;function animateParticules(e,t)&#123;for(var a=createCircle(e,t),n=[],i=0;i&lt;numberOfParticules;i++)&#123;n.push(createParticule(e,t))&#125;anime.timeline().add(&#123;targets:n,x:function(e)&#123;return e.endPos.x&#125;,y:function(e)&#123;return e.endPos.y&#125;,radius:0.1,duration:anime.random(1200,1800),easing:\"easeOutExpo\",update:renderParticule&#125;).add(&#123;targets:a,radius:anime.random(80,160),lineWidth:0,alpha:&#123;value:0,easing:\"linear\",duration:anime.random(600,800)&#125;,duration:anime.random(1200,1800),easing:\"easeOutExpo\",update:renderParticule,offset:0&#125;)&#125;function debounce(e,t)&#123;var a;return function()&#123;var n=this,i=arguments;clearTimeout(a),a=setTimeout(function()&#123;e.apply(n,i)&#125;,t)&#125;&#125;var canvasEl=document.querySelector(\".fireworks\");if(canvasEl)&#123;var ctx=canvasEl.getContext(\"2d\"),numberOfParticules=30,pointerX=0,pointerY=0,tap=\"mousedown\",colors=[\"#FF1461\",\"#18FF92\",\"#5A87FF\",\"#FBF38C\"],setCanvasSize=debounce(function()&#123;canvasEl.width=2*window.innerWidth,canvasEl.height=2*window.innerHeight,canvasEl.style.width=window.innerWidth+\"px\",canvasEl.style.height=window.innerHeight+\"px\",canvasEl.getContext(\"2d\").scale(2,2)&#125;,500),render=anime(&#123;duration:1/0,update:function()&#123;ctx.clearRect(0,0,canvasEl.width,canvasEl.height)&#125;&#125;);document.addEventListener(tap,function(e)&#123;\"sidebar\"!==e.target.id&amp;&amp;\"toggle-sidebar\"!==e.target.id&amp;&amp;\"A\"!==e.target.nodeName&amp;&amp;\"IMG\"!==e.target.nodeName&amp;&amp;(render.play(),updateCoords(e),animateParticules(pointerX,pointerY))&#125;,!1),setCanvasSize(),window.addEventListener(\"resize\",setCanvasSize,!1)&#125;\"use strict\";function updateCoords(e)&#123;pointerX=(e.clientX||e.touches[0].clientX)-canvasEl.getBoundingClientRect().left,pointerY=e.clientY||e.touches[0].clientY-canvasEl.getBoundingClientRect().top&#125;function setParticuleDirection(e)&#123;var t=anime.random(0,360)*Math.PI/180,a=anime.random(50,180),n=[-1,1][anime.random(0,1)]*a;return&#123;x:e.x+n*Math.cos(t),y:e.y+n*Math.sin(t)&#125;&#125;function createParticule(e,t)&#123;var a=&#123;&#125;;return a.x=e,a.y=t,a.color=colors[anime.random(0,colors.length-1)],a.radius=anime.random(16,32),a.endPos=setParticuleDirection(a),a.draw=function()&#123;ctx.beginPath(),ctx.arc(a.x,a.y,a.radius,0,2*Math.PI,!0),ctx.fillStyle=a.color,ctx.fill()&#125;,a&#125;function createCircle(e,t)&#123;var a=&#123;&#125;;return a.x=e,a.y=t,a.color=\"#F00\",a.radius=0.1,a.alpha=0.5,a.lineWidth=6,a.draw=function()&#123;ctx.globalAlpha=a.alpha,ctx.beginPath(),ctx.arc(a.x,a.y,a.radius,0,2*Math.PI,!0),ctx.lineWidth=a.lineWidth,ctx.strokeStyle=a.color,ctx.stroke(),ctx.globalAlpha=1&#125;,a&#125;function renderParticule(e)&#123;for(var t=0;t&lt;e.animatables.length;t++)&#123;e.animatables[t].target.draw()&#125;&#125;function animateParticules(e,t)&#123;for(var a=createCircle(e,t),n=[],i=0;i&lt;numberOfParticules;i++)&#123;n.push(createParticule(e,t))&#125;anime.timeline().add(&#123;targets:n,x:function(e)&#123;return e.endPos.x&#125;,y:function(e)&#123;return e.endPos.y&#125;,radius:0.1,duration:anime.random(1200,1800),easing:\"easeOutExpo\",update:renderParticule&#125;).add(&#123;targets:a,radius:anime.random(80,160),lineWidth:0,alpha:&#123;value:0,easing:\"linear\",duration:anime.random(600,800)&#125;,duration:anime.random(1200,1800),easing:\"easeOutExpo\",update:renderParticule,offset:0&#125;)&#125;function debounce(e,t)&#123;var a;return function()&#123;var n=this,i=arguments;clearTimeout(a),a=setTimeout(function()&#123;e.apply(n,i)&#125;,t)&#125;&#125;var canvasEl=document.querySelector(\".fireworks\");if(canvasEl)&#123;var ctx=canvasEl.getContext(\"2d\"),numberOfParticules=30,pointerX=0,pointerY=0,tap=\"mousedown\",colors=[\"#FF1461\",\"#18FF92\",\"#5A87FF\",\"#FBF38C\"],setCanvasSize=debounce(function()&#123;canvasEl.width=2*window.innerWidth,canvasEl.height=2*window.innerHeight,canvasEl.style.width=window.innerWidth+\"px\",canvasEl.style.height=window.innerHeight+\"px\",canvasEl.getContext(\"2d\").scale(2,2)&#125;,500),render=anime(&#123;duration:1/0,update:function()&#123;ctx.clearRect(0,0,canvasEl.width,canvasEl.height)&#125;&#125;);document.addEventListener(tap,function(e)&#123;\"sidebar\"!==e.target.id&amp;&amp;\"toggle-sidebar\"!==e.target.id&amp;&amp;\"A\"!==e.target.nodeName&amp;&amp;\"IMG\"!==e.target.nodeName&amp;&amp;(render.play(),updateCoords(e),animateParticules(pointerX,pointerY))&#125;,!1),setCanvasSize(),window.addEventListener(\"resize\",setCanvasSize,!1)&#125;; 然后在 \\themes\\next\\layout\\layout.swing 文件中写入以下代码： 123&lt;canvas class=\"fireworks\" style=\"position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;\" &gt;&lt;/canvas&gt; &lt;script type=\"text/javascript\" src=\"//cdn.bootcss.com/animejs/2.2.0/anime.min.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\" src=\"/js/fireworks.js\"&gt;&lt;/script&gt; 自定义鼠标指针样式在 \\themes\\next\\source\\css\\_custom\\custom.styl 文件 body 样式里写入如下代码： 12345/*自定义鼠标样式*/body &#123; cursor: url(\"/images/mouse.cur\"),auto; background-color: @theme_background;&#125; 鼠标指针可以用 Axialis CursorWorkshop 这个软件自己制作，不同主题具体放的文件有所不同，确保在博客主体 body 的 CSS 文件中即可，其中的鼠标指针链接可替换成自己的，首先尝试加载mouse.cur ，如果该文件不存在或由于其他原因无效，那么 auto 会被使用，也就是自动默认效果，图片格式为.ico、.ani、.cur，建议使用.cur，如果使用.ani或者其他格式无效，原因是浏览器兼容问题。 添加彩色滚动变换字体在你想要添加彩色滚动变换字体的地方写入以下代码即可，其中文字可自行更改： 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;div id=\"binft\"&gt;&lt;/div&gt; &lt;script&gt; var binft = function (r) &#123; function t() &#123; return b[Math.floor(Math.random() * b.length)] &#125; function e() &#123; return String.fromCharCode(94 * Math.random() + 33) &#125; function n(r) &#123; for (var n = document.createDocumentFragment(), i = 0; r &gt; i; i++) &#123; var l = document.createElement(\"span\"); l.textContent = e(), l.style.color = t(), n.appendChild(l) &#125; return n &#125; function i() &#123; var t = o[c.skillI]; c.step ? c.step-- : (c.step = g, c.prefixP &lt; l.length ? (c.prefixP &gt;= 0 &amp;&amp; (c.text += l[c.prefixP]), c.prefixP++) : \"forward\" === c.direction ? c.skillP &lt; t.length ? (c.text += t[c.skillP], c.skillP++) : c.delay ? c.delay-- : (c.direction = \"backward\", c.delay = a) : c.skillP &gt; 0 ? (c.text = c.text.slice(0, -1), c.skillP--) : (c.skillI = (c.skillI + 1) % o.length, c.direction = \"forward\")), r.textContent = c.text, r.appendChild(n(c.prefixP &lt; l.length ? Math.min(s, s + c.prefixP) : Math.min(s, t.length - c.skillP))), setTimeout(i, d) &#125; var l = \"\", o = [\"青青陵上柏，磊磊涧中石。\", \"人生天地间，忽如远行客。\",\"斗酒相娱乐，聊厚不为薄。\", \"驱车策驽马，游戏宛与洛。\",\"洛中何郁郁，冠带自相索。\",\"长衢罗夹巷，王侯多第宅。\",\"两宫遥相望，双阙百余尺。\",\"极宴娱心意，戚戚何所迫？\"].map(function (r) &#123; return r + \"\" &#125;), a = 2, g = 1, s = 5, d = 75, b = [\"rgb(110,64,170)\", \"rgb(150,61,179)\", \"rgb(191,60,175)\", \"rgb(228,65,157)\", \"rgb(254,75,131)\", \"rgb(255,94,99)\", \"rgb(255,120,71)\", \"rgb(251,150,51)\", \"rgb(226,183,47)\", \"rgb(198,214,60)\", \"rgb(175,240,91)\", \"rgb(127,246,88)\", \"rgb(82,246,103)\", \"rgb(48,239,130)\", \"rgb(29,223,163)\", \"rgb(26,199,194)\", \"rgb(35,171,216)\", \"rgb(54,140,225)\", \"rgb(76,110,219)\", \"rgb(96,84,200)\"], c = &#123; text: \"\", prefixP: -s, skillI: 0, skillP: 0, direction: \"forward\", delay: a, step: g &#125;; i() &#125;; binft(document.getElementById('binft')); &lt;/script&gt; 我是放在了侧边栏头像的下边，描述的位置\\themes\\next\\layout\\_macro\\sidebar.swing： 浏览器网页标题恶搞效果如下图： 实现方法 在目录 \\themes\\next\\source\\js 下新建一个 FunnyTitle.js 文件，在里面填写如下代码： 1234567891011121314151617&lt;!--浏览器搞笑标题--&gt; var OriginTitle = document.title; var titleTime; document.addEventListener('visibilitychange', function () &#123; if (document.hidden) &#123; $('[rel=\"icon\"]').attr('href', \"/img/trhx2.png\"); document.title = 'ヽ(●-`Д´-)ノ你丑你就走！'; clearTimeout(titleTime); &#125; else &#123; $('[rel=\"icon\"]').attr('href', \"/img/trhx2.png\"); document.title = 'ヾ(Ő∀Ő3)ノ你帅就回来！' + OriginTitle; titleTime = setTimeout(function () &#123; document.title = OriginTitle; &#125;, 2000); &#125; &#125;); 然后在 \\themes\\next\\layout\\layout.swing 文件中写入以下代码： 12&lt;!--浏览器搞笑标题--&gt;&lt;script type=\"text/javascript\" src=\"\\js\\FunnyTitle.js\"&gt;&lt;/script&gt; 再次部署博客后就可以看见标题搞笑的效果了。 添加网站雪花飘落效果效果如下图： 实现方法 在 \\themes\\next\\source\\js 目录下新建一个 snow.js 文件，粘贴以下代码： 123456789101112131415161718192021222324252627282930313233343536373839404142/*样式一*/(function($)&#123; $.fn.snow = function(options)&#123; var $flake = $('&lt;div id=\"snowbox\" /&gt;').css(&#123;'position': 'absolute','z-index':'9999', 'top': '-50px'&#125;).html('&amp;#10052;'), documentHeight = $(document).height(), documentWidth = $(document).width(), defaults = &#123; minSize : 10, maxSize : 20, newOn : 1000, flakeColor : \"#AFDAEF\" /* 此处可以定义雪花颜色，若要白色可以改为#FFFFFF */ &#125;, options = $.extend(&#123;&#125;, defaults, options); var interval= setInterval( function()&#123; var startPositionLeft = Math.random() * documentWidth - 100, startOpacity = 0.5 + Math.random(), sizeFlake = options.minSize + Math.random() * options.maxSize, endPositionTop = documentHeight - 200, endPositionLeft = startPositionLeft - 500 + Math.random() * 500, durationFall = documentHeight * 10 + Math.random() * 5000; $flake.clone().appendTo('body').css(&#123; left: startPositionLeft, opacity: startOpacity, 'font-size': sizeFlake, color: options.flakeColor &#125;).animate(&#123; top: endPositionTop, left: endPositionLeft, opacity: 0.2 &#125;,durationFall,'linear',function()&#123; $(this).remove() &#125;); &#125;, options.newOn); &#125;;&#125;)(jQuery);$(function()&#123; $.fn.snow(&#123; minSize: 5, /* 定义雪花最小尺寸 */ maxSize: 50,/* 定义雪花最大尺寸 */ newOn: 300 /* 定义密集程度，数字越小越密集 */ &#125;);&#125;); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128/*样式二*//* 控制下雪 */function snowFall(snow) &#123; /* 可配置属性 */ snow = snow || &#123;&#125;; this.maxFlake = snow.maxFlake || 200; /* 最多片数 */ this.flakeSize = snow.flakeSize || 10; /* 雪花形状 */ this.fallSpeed = snow.fallSpeed || 1; /* 坠落速度 */&#125;/* 兼容写法 */requestAnimationFrame = window.requestAnimationFrame || window.mozRequestAnimationFrame || window.webkitRequestAnimationFrame || window.msRequestAnimationFrame || window.oRequestAnimationFrame || function(callback) &#123; setTimeout(callback, 1000 / 60); &#125;;cancelAnimationFrame = window.cancelAnimationFrame || window.mozCancelAnimationFrame || window.webkitCancelAnimationFrame || window.msCancelAnimationFrame || window.oCancelAnimationFrame;/* 开始下雪 */snowFall.prototype.start = function()&#123; /* 创建画布 */ snowCanvas.apply(this); /* 创建雪花形状 */ createFlakes.apply(this); /* 画雪 */ drawSnow.apply(this)&#125;/* 创建画布 */function snowCanvas() &#123; /* 添加Dom结点 */ var snowcanvas = document.createElement(\"canvas\"); snowcanvas.id = \"snowfall\"; snowcanvas.width = window.innerWidth; snowcanvas.height = document.body.clientHeight; snowcanvas.setAttribute(\"style\", \"position:absolute; top: 0; left: 0; z-index: 1; pointer-events: none;\"); document.getElementsByTagName(\"body\")[0].appendChild(snowcanvas); this.canvas = snowcanvas; this.ctx = snowcanvas.getContext(\"2d\"); /* 窗口大小改变的处理 */ window.onresize = function() &#123; snowcanvas.width = window.innerWidth; /* snowcanvas.height = window.innerHeight */ &#125;&#125;/* 雪运动对象 */function flakeMove(canvasWidth, canvasHeight, flakeSize, fallSpeed) &#123; this.x = Math.floor(Math.random() * canvasWidth); /* x坐标 */ this.y = Math.floor(Math.random() * canvasHeight); /* y坐标 */ this.size = Math.random() * flakeSize + 2; /* 形状 */ this.maxSize = flakeSize; /* 最大形状 */ this.speed = Math.random() * 1 + fallSpeed; /* 坠落速度 */ this.fallSpeed = fallSpeed; /* 坠落速度 */ this.velY = this.speed; /* Y方向速度 */ this.velX = 0; /* X方向速度 */ this.stepSize = Math.random() / 30; /* 步长 */ this.step = 0 /* 步数 */&#125;flakeMove.prototype.update = function() &#123; var x = this.x, y = this.y; /* 左右摆动(余弦) */ this.velX *= 0.98; if (this.velY &lt;= this.speed) &#123; this.velY = this.speed &#125; this.velX += Math.cos(this.step += .05) * this.stepSize; this.y += this.velY; this.x += this.velX; /* 飞出边界的处理 */ if (this.x &gt;= canvas.width || this.x &lt;= 0 || this.y &gt;= canvas.height || this.y &lt;= 0) &#123; this.reset(canvas.width, canvas.height) &#125;&#125;;/* 飞出边界-放置最顶端继续坠落 */flakeMove.prototype.reset = function(width, height) &#123; this.x = Math.floor(Math.random() * width); this.y = 0; this.size = Math.random() * this.maxSize + 2; this.speed = Math.random() * 1 + this.fallSpeed; this.velY = this.speed; this.velX = 0;&#125;;// 渲染雪花-随机形状（此处可修改雪花颜色！！！）flakeMove.prototype.render = function(ctx) &#123; var snowFlake = ctx.createRadialGradient(this.x, this.y, 0, this.x, this.y, this.size); snowFlake.addColorStop(0, \"rgba(255, 255, 255, 0.9)\"); /* 此处是雪花颜色，默认是白色 */ snowFlake.addColorStop(.5, \"rgba(255, 255, 255, 0.5)\"); /* 若要改为其他颜色，请自行查 */ snowFlake.addColorStop(1, \"rgba(255, 255, 255, 0)\"); /* 找16进制的RGB 颜色代码。 */ ctx.save(); ctx.fillStyle = snowFlake; ctx.beginPath(); ctx.arc(this.x, this.y, this.size, 0, Math.PI * 2); ctx.fill(); ctx.restore();&#125;;/* 创建雪花-定义形状 */function createFlakes() &#123; var maxFlake = this.maxFlake, flakes = this.flakes = [], canvas = this.canvas; for (var i = 0; i &lt; maxFlake; i++) &#123; flakes.push(new flakeMove(canvas.width, canvas.height, this.flakeSize, this.fallSpeed)) &#125;&#125;/* 画雪 */function drawSnow() &#123; var maxFlake = this.maxFlake, flakes = this.flakes; ctx = this.ctx, canvas = this.canvas, that = this; /* 清空雪花 */ ctx.clearRect(0, 0, canvas.width, canvas.height); for (var e = 0; e &lt; maxFlake; e++) &#123; flakes[e].update(); flakes[e].render(ctx); &#125; /* 一帧一帧的画 */ this.loop = requestAnimationFrame(function() &#123; drawSnow.apply(that); &#125;);&#125;/* 调用及控制方法 */var snow = new snowFall(&#123;maxFlake:60&#125;);snow.start(); 然后在 \\themes\\next\\layout\\layout.swing 文件中写入以下代码： 12&lt;!-- 雪花特效 --&gt;&lt;script type=\"text/javascript\" src=\"\\js\\snow.js\"&gt;&lt;/script&gt; 如果没效果，请确认网页是否已载入JQurey，如果没有请在下雪代码之前引入JQ即可： 12&lt;script type=\"text/javascript\" src=\"http://libs.baidu.com/jquery/1.8.3/jquery.js\"&gt;&lt;/script&gt;&lt;script type=\"text/javascript\" src=\"http://libs.baidu.com/jquery/1.8.3/jquery.min.js\"&gt;&lt;/script&gt; 添加背景动态彩带效果效果如下图： 实现方法 在 \\themes\\next\\layout\\layout.swing 文件中写入以下代码： 12345&lt;!-- 样式一（鼠标点击更换样式） --&gt;&lt;script src=\"https://g.joyinshare.com/hc/ribbon.min.js\" type=\"text/javascript\"&gt;&lt;/script&gt;&lt;!-- 样式二（飘动的彩带） --&gt;&lt;script src=\"https://g.joyinshare.com/hc/piao.js\" type=\"text/javascript\"&gt;&lt;/script&gt; 添加背景代码雨特效效果如下图： 实现方法 在 \\themes\\next\\source\\js 目录下新建一个 DigitalRain.js 文件，粘贴以下代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657window.onload = function()&#123; //获取画布对象 var canvas = document.getElementById(\"canvas\"); //获取画布的上下文 var context =canvas.getContext(\"2d\"); var s = window.screen; var W = canvas.width = s.width; var H = canvas.height; //获取浏览器屏幕的宽度和高度 //var W = window.innerWidth; //var H = window.innerHeight; //设置canvas的宽度和高度 canvas.width = W; canvas.height = H; //每个文字的字体大小 var fontSize = 12; //计算列 var colunms = Math.floor(W /fontSize); //记录每列文字的y轴坐标 var drops = []; //给每一个文字初始化一个起始点的位置 for(var i=0;i&lt;colunms;i++)&#123; drops.push(0); &#125; //运动的文字 var str =\"WELCOME TO WWW.ITRHX.COM\"; //4:fillText(str,x,y);原理就是去更改y的坐标位置 //绘画的函数 function draw()&#123; context.fillStyle = \"rgba(238,238,238,.08)\";//遮盖层 context.fillRect(0,0,W,H); //给字体设置样式 context.font = \"600 \"+fontSize+\"px Georgia\"; //给字体添加颜色 context.fillStyle = [\"#33B5E5\", \"#0099CC\", \"#AA66CC\", \"#9933CC\", \"#99CC00\", \"#669900\", \"#FFBB33\", \"#FF8800\", \"#FF4444\", \"#CC0000\"][parseInt(Math.random() * 10)];//randColor();可以rgb,hsl, 标准色，十六进制颜色 //写入画布中 for(var i=0;i&lt;colunms;i++)&#123; var index = Math.floor(Math.random() * str.length); var x = i*fontSize; var y = drops[i] *fontSize; context.fillText(str[index],x,y); //如果要改变时间，肯定就是改变每次他的起点 if(y &gt;= canvas.height &amp;&amp; Math.random() &gt; 0.99)&#123; drops[i] = 0; &#125; drops[i]++; &#125; &#125;; function randColor()&#123;//随机颜色 var r = Math.floor(Math.random() * 256); var g = Math.floor(Math.random() * 256); var b = Math.floor(Math.random() * 256); return \"rgb(\"+r+\",\"+g+\",\"+b+\")\"; &#125; draw(); setInterval(draw,35);&#125;; 然后在 \\themes\\next\\source\\css\\_custom\\custom.styl 中写入样式： 12345678910canvas &#123; position: fixed; right: 0px; bottom: 0px; min-width: 100%; min-height: 100%; height: auto; width: auto; z-index: -1;&#125; 在 \\themes\\next\\layout\\layout.swing 文件中写入以下代码： 123&lt;!-- 代码雨 --&gt; &lt;canvas id=\"canvas\" width=\"1440\" height=\"900\" &gt;&lt;/canvas&gt; &lt;script type=\"text/javascript\" src=\"/js/DigitalRain.js\"&gt;&lt;/script&gt; 代码块复制功能效果如下图： 实现方法 下载 clipboard.js clipboard.js clipboard.min.js 推荐 保存文件clipboard.js / clipboard.min.js 到路径\\themes\\next\\source\\js\\src下。 使用clipboard.js 也是在 \\themes\\next\\source\\js\\src 目录下，创建clipboard-use.js，文件内容如下： 12345678910111213141516/*页面载入完成后，创建复制按钮*/!function (e, t, a) &#123; /* code */ var initCopyCode = function()&#123; var copyHtml = ''; copyHtml += '&lt;button class=\"btn-copy\" data-clipboard-snippet=\"\"&gt;'; copyHtml += ' &lt;i class=\"fa fa-globe\"&gt;&lt;/i&gt;&lt;span&gt;copy&lt;/span&gt;'; copyHtml += '&lt;/button&gt;'; $(\".highlight .code pre\").before(copyHtml); new ClipboardJS('.btn-copy', &#123; target: function(trigger) &#123; return trigger.nextElementSibling; &#125; &#125;); &#125; initCopyCode(); 在\\themes\\next\\source\\css\\_custom\\custom.styl样式文件中添加下面代码： 123456789101112131415161718192021222324252627282930313233343536//代码块复制按钮.highlight&#123; //方便copy代码按钮（btn-copy）的定位 position: relative;&#125;.btn-copy &#123; display: inline-block; cursor: pointer; background-color: #eee; background-image: linear-gradient(#fcfcfc,#eee); border: 1px solid #d5d5d5; border-radius: 3px; -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; -webkit-appearance: none; font-size: 13px; font-weight: 700; line-height: 20px; color: #333; -webkit-transition: opacity .3s ease-in-out; -o-transition: opacity .3s ease-in-out; transition: opacity .3s ease-in-out; padding: 2px 6px; position: absolute; right: 5px; top: 5px; opacity: 0;&#125;.btn-copy span &#123; margin-left: 5px;&#125;.highlight:hover .btn-copy&#123; opacity: 1;&#125; 引用 在\\themes\\next\\layout\\_layout.swig文件中，添加引用（注：在 swig 末尾或 body 结束标签（&lt;/body&gt;）之前添加）： 123&lt;!-- 代码块复制功能 --&gt; &lt;script type=\"text/javascript\" src=\"/js/src/clipboard.min.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\" src=\"/js/src/clipboard-use.js\"&gt;&lt;/script&gt; Hexo文章中图片点击实现全屏查看使用图片浏览放大功能fancybox插件。 切换到lib目录 1$ cd next/source/lib 下载插件 1$ git clone https://github.com/theme-next/theme-next-fancybox3 fancybox 更改主题配置文件 1fancybox: true 3D动态标签云 安装标签云hexo-tag-cloud插件 1$ cnpm install hexo-tag-cloud@^2.* --save 配置sidebar.swig文件 打开next/layout/_macro/sidebar.swig，输入： 1234567891011&#123;% if site.tags.length &gt; 1 %&#125;&lt;script type=\"text/javascript\" charset=\"utf-8\" src=\"/js/tagcloud.js\"&gt;&lt;/script&gt;&lt;script type=\"text/javascript\" charset=\"utf-8\" src=\"/js/tagcanvas.js\"&gt;&lt;/script&gt;&lt;div class=\"widget-wrap\"&gt; &lt;div id=\"myCanvasContainer\" class=\"widget tagcloud\"&gt; &lt;canvas width=\"250\" height=\"250\" id=\"resCanvas\" style=\"width=100%\"&gt; &#123;&#123; list_tags() &#125;&#125; &lt;/canvas&gt; &lt;/div&gt;&lt;/div&gt;&#123;% endif %&#125; 根据自己的需要放在合适的位置。重新hexo s一下，就可以出现刚刚那个3d标签云了! 添加卡通人物效果如下图： 实现方法 下载 live2d 1$ cnpm install --save hexo-helper-live2d 下载模型 1$ cnpm install live2d-widget-model-z16 更多模型选择请 点击此处， 各个模型的预览请 点击此处 修改站点配置文件 12345678910111213141516171819202122232425262728293031323334#添加萌宠，以下任选一个#live2d-widget-model-chitose#live2d-widget-model-epsilon2_1#live2d-widget-model-gf#live2d-widget-model-haru/01 (use npm install --save live2d-widget-model-haru)#live2d-widget-model-haru/02 (use npm install --save live2d-widget-model-haru)#live2d-widget-model-haruto#live2d-widget-model-hibiki#live2d-widget-model-hijiki#live2d-widget-model-izumi#live2d-widget-model-koharu#live2d-widget-model-miku#live2d-widget-model-ni-j#live2d-widget-model-nico#live2d-widget-model-nietzsche#live2d-widget-model-nipsilon#live2d-widget-model-nito#live2d-widget-model-shizuku#live2d-widget-model-tororo#live2d-widget-model-tsumiki#live2d-widget-model-unitychan#live2d-widget-model-wanko#live2d-widget-model-z16live2d: enable: true scriptFrom: local model: use: live2d-widget-model-z16 display: position: right #模型位置 width: 140 #模型宽度 height: 260 #模型高度 mobile: show: false #是否在手机端显示 卡通人物升级版效果如下图： 能说话、能换装、能玩游戏、能拍照、还能自定义。 实现方法 下载 张书樵 大神的项目，解压到本地博客目录的themes/next/source下，修改autoload.js文件，如下：将 1234const live2d_path = \"https://cdn.jsdelivr.net/gh/stevenjoezhang/live2d-widget/\";改为const live2d_path = \"/live2d-widget/\"; 在/themes/next/layout/_layout.swing中,新增如下内容： 1&lt;script src=\"/live2d-widget/autoload.js\"&gt;&lt;/script&gt; 在主题配置文件 中,新增如下内容： 12live2d: enable: true 想修改看板娘大小、位置、格式、文本内容等，可查看并修改 waifu-tips.js 、 waifu-tips.json 和 waifu.css。 扩展看板娘模型由于官方的看板娘模型比较少，可手动添加模型。 把 github模型 下载到本地，解压后将assets目录拷贝到博客根目录中的live2d_models（自己新建，文件名不可改）里，再修改_config.yml 里的 live2d中model.use即可（改为live2d_models中的模型名字就行）。 去掉顶部黑线打开themes\\next\\source\\css\\_custom\\custom.styl添加以下代码： 1.headband &#123;display:none;&#125; 修改主题页面布局为圆角方法一在/themes/next/source/css/_variables/custom.styl文件种添加如下代码（以Gemini风格为例）： 123456789101112131415// 修改主题页面布局为圆角// Variables of Gemini scheme// =================================================@import \"Pisces.styl\";// Settings for some of the most global styles.// --------------------------------------------------$body-bg-color = #eee// Borders.// --------------------------------------------------$box-shadow-inner = 0 2px 2px 0 rgba(0,0,0,.12), 0 3px 1px -2px rgba(0,0,0,.06), 0 1px 5px 0 rgba(0,0,0,.12)$box-shadow = 0 2px 2px 0 rgba(0,0,0,.12), 0 3px 1px -2px rgba(0,0,0,.06), 0 1px 5px 0 rgba(0,0,0,.12), 0 -1px .5px 0 rgba(0,0,0,.09)$border-radius-inner = initial$border-radius = initial$border-radius-inner = 15px 15px 15px 15px;$border-radius = 15px; 方法二在\\themes\\next\\source\\css\\_variables\\Gemini.styl文件中直接添加： 123// 修改主题页面布局为圆角$border-radius-inner = 15px 15px 15px 15px;$border-radius = 15px; 效果如下图： 自适应背景图片 在站点配置文件夹/themes/next/source/images/放入你的背景图片; 然后修改主题文件夹themes/source/css/_custom/custom.styl，在custom.styl开头加入如下的代码: 12345678910111213141516body &#123; background: url(/images/background.jpg); background-repeat: no-repeat; background-attachment: fixed; background-position: 50% 50%; background-size: cover; -webkit-background-size: cover; -o-background-size: cover; -moz-background-size: cover; -ms-background-size: cover; /*这是设置底部文字, 看个人需要修改*/ #footer &gt; div &gt; div &#123; color: #eee; &#125;&#125; 防止每次heox clean 后CNAME文件被删除 先把github中的CNAME文件复制一份到本地public 再安装插件 1cnpm install hexo-generator-cname --save 根目录_config.yml中添加 12Plugins:- hexo-generator-cname 并修改 1url: yoursite.com 去除valine的Powered By修改\\themes\\next\\layout\\_third-party\\comments\\valine.swig文件 123456789101112new Valine(&#123;...pageSize:'&#123;&#123; theme.valine.pageSize &#125;&#125;' || 10,&#125;);//新增以下代码即可，可以移除.info下所有子节点。var infoEle = document.querySelector('#comments .info');if (infoEle &amp;&amp; infoEle.childNodes &amp;&amp; infoEle.childNodes.length &gt; 0)&#123; infoEle.childNodes.forEach(function(item) &#123; item.parentNode.removeChild(item); &#125;);&#125; 增加词云增加之前的效果如下图： 方法比较简单，加个js脚本就好了，就加在标签的那个页面好了。 打开themes\\next\\layout\\page.swig 找到 1&#123;% if page.type === \"tags\" %&#125; 将下面这段代码: 123456789101112131415161718&lt;div class=\"tag-cloud\"&gt; &lt;div class=\"tag-cloud-title\"&gt; &#123;% set visibleTags = 0 %&#125; &#123;% for tag in site.tags %&#125; &#123;% if tag.length %&#125; &#123;% set visibleTags += 1 %&#125; &#123;% endif %&#125; &#123;% endfor %&#125; &#123;&#123; _p('counter.tag_cloud', visibleTags) &#125;&#125; &lt;/div&gt; &lt;div class=\"tag-cloud-tags\"&gt; &#123;% if not theme.tagcloud %&#125; &#123;&#123; tagcloud(&#123;min_font: 12, max_font: 30, amount: 200, color: true, start_color: '#ccc', end_color: '#111'&#125;) &#125;&#125; &#123;% else %&#125; &#123;&#123; tagcloud(&#123;min_font: 13, max_font: 31, amount: 1000, color: true, start_color: '#9733EE', end_color: '#FF512F'&#125;) &#125;&#125; &#123;% endif %&#125; &lt;/div&gt;&lt;/div&gt; 换成下面这段代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;div class=\"tag-cloud\"&gt; &lt;!-- &lt;div class=\"tag-cloud-title\"&gt; &#123;&#123; _p('counter.tag_cloud', site.tags.length) &#125;&#125; &lt;/div&gt; --&gt; &lt;div class=\"tag-cloud-tags\" id=\"tags\"&gt; &#123;&#123; tagcloud(&#123;min_font: 16, max_font: 16, amount: 300, color: true, start_color: '#fff', end_color: '#fff'&#125;) &#125;&#125; &lt;/div&gt;&lt;/div&gt;&lt;br&gt;&lt;script type=\"text/javascript\"&gt; var alltags=document.getElementById('tags'); var tags=alltags.getElementsByTagName('a'); for (var i = tags.length - 1; i &gt;= 0; i--) &#123; var r=Math.floor(Math.random()*75+130); var g=Math.floor(Math.random()*75+100); var b=Math.floor(Math.random()*75+80); tags[i].style.background = \"rgb(\"+r+\",\"+g+\",\"+b+\")\"; &#125;&lt;/script&gt;&lt;style type=\"text/css\"&gt; div#posts.posts-expand .tag-cloud a&#123; background-color: #f5f7f1; border-radius: 6px; padding-left: 10px; padding-right: 10px; margin-top: 18px; &#125; .tag-cloud a&#123; background-color: #f5f7f1; border-radius: 4px; padding-right: 5px; padding-left: 5px; margin-right: 5px; margin-left: 0px; margin-top: 8px; margin-bottom: 0px; &#125; .tag-cloud a:before&#123; content: \"📜\"; &#125; .tag-cloud-tags&#123; text-align: left; counter-reset: tags; &#125;&lt;/style&gt; 效果如下图： 代码块Mac Panel特效先上效果图： 能设置阴影效果和实现文本编辑功能，不过文本只存在浏览器页面上，不会真正保存。 实现步骤引入JS这里需要新建两个js文件events.js和codeblock.js，路径位于/themes/next/scripts/包下。 events.js代码： 1234567// mac Panel效果代码块相关var exec = require('child_process').exec;// new 后自动打开编辑器hexo.on('new', function(data)&#123; exec('open -a MacDown ' + data.path);&#125;); codeblock.js代码： 12345678910111213141516171819202122// mac Panel效果代码块相关var attributes = [ 'autocomplete=\"off\"', 'autocorrect=\"off\"', 'autocapitalize=\"off\"', 'spellcheck=\"false\"', 'contenteditable=\"true\"']var attributesStr = attributes.join(' ')hexo.extend.filter.register('after_post_render', function (data) &#123; while (/&lt;figure class=\"highlight ([a-zA-Z]+)\"&gt;.*?&lt;\\/figure&gt;/.test(data.content)) &#123; data.content = data.content.replace(/&lt;figure class=\"highlight ([a-zA-Z]+)\"&gt;.*?&lt;\\/figure&gt;/, function () &#123; var language = RegExp.$1 || 'plain' var lastMatch = RegExp.lastMatch lastMatch = lastMatch.replace(/&lt;figure class=\"highlight /, '&lt;figure class=\"iseeu highlight /') return '&lt;div class=\"highlight-wrap\"' + attributesStr + 'data-rel=\"' + language.toUpperCase() + '\"&gt;' + lastMatch + '&lt;/div&gt;' &#125;) &#125; return data&#125;) 引入CSS在/themes/next/source/css/_common/components/highlight/目录下新建macPanel.styl文件，内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// mac Panel效果代码块相关.highlight-wrap[data-rel] &#123; position: relative; overflow: hidden; border-radius: 5px; //box-shadow: 0 10px 30px 0px rgba(0, 0, 0, 0.4); box-shadow:18px 18px 15px 0px rgba(0,0,0,.4) margin: 35px 0; ::-webkit-scrollbar &#123; height: 10px; &#125; ::-webkit-scrollbar-track &#123; -webkit-box-shadow: inset 0 0 6px rgba(0, 0, 0, 0.3); border-radius: 10px; &#125; ::-webkit-scrollbar-thumb &#123; border-radius: 10px; -webkit-box-shadow: inset 0 0 6px rgba(0, 0, 0, 0.5); &#125; &amp;::before &#123; color: white; content: attr(data-rel); height: 38px; line-height: 38px; //background: #21252b; background: #108414de; color: #fff; font-size: 16px; //position: absolute; top: 0; left: 0; width: 100%; //font-family: 'Source Sans Pro', sans-serif; font-weight: bold; padding: 0px 80px; text-indent: 15px; float: left; &#125; &amp;::after &#123; content: ' '; position: absolute; -webkit-border-radius: 50%; border-radius: 50%; background: #fc625d; width: 12px; height: 12px; top: 0; left: 20px; margin-top: 13px; -webkit-box-shadow: 20px 0px #fdbc40, 40px 0px #35cd4b; box-shadow: 20px 0px #fdbc40, 40px 0px #35cd4b; z-index: 3; &#125;&#125; 此css是根据我本地的样式做过调整，注释的代码为原有的，根据需要调整样式即可。 配置引用在/themes/next/source/css/_common/components/highlight/highlight.styl文件中引入刚才新建的macPanel.styl： 1@require \"macPanel\" 配置在文件的顶部位置即可。 到此Mac Panel已配置完成，根据需要可调整主题配置文件中的highlight_theme选项，选择自己喜欢的样式。 可能遇到的问题如果在配置完毕后，hexo启动报错，可将站点配置文件里的highlight属性auto_detect改成false： 123456highlight: enable: true line_number: true- auto_detect: true+ auto_detect: false tab_replace: 如果还是有问题，可仔细检查一下刚才新建的文件、修改的配置文件，有什么地方配置错了，或者是语法上的错误,修改后重新启动即可看到效果。 为文章生成永久链接hexo默认的文章链接形式为year/:month/:day/:title，是按照年、月、日、标题来生成的。当把文章源文件名改掉之后，链接也会改变，这很不友好。并且如果文章标题是中文的，那么该路径就会出现中文字符。在路径中出现了中文字符很容易引发各种问题，而且也不利于seo，因为路径包含了年月日三个层级，层级太深不利于百度蜘蛛抓取。 解决办法就是利用其它的插件来生成唯一的路径，这样就算文件标题随意修改，而不会导致原本的链接失效而造成站点下存在大量的死链。 安装插件1cnpm install hexo-abbrlink --save 注意：执行此命令可能会不成功，提示你缺少相应的依赖，比如babel-eslint、mini-css-extract-plugin、webpack-cli…使用npm命令安装即可。比如： 1npm install eslint@4.x babel-eslint@8 --save-dev 配置修改根目录站点配置文件config.yml，改为： 1234permalink: posts/:abbrlink.html # 此处可以自己设置，也可以直接使用 /:abbrlinkabbrlink: alg: crc32 #算法： crc16(default) and crc32 rep: hex #进制： dec(default) and hex 这里将页面都添加了 .html 的后缀，用来伪装成静态页面(虽说Hexo的页面本身就是静态页面)，这样可以直接从路径就知道这是个静态页面，方便seo。 生成的链接将会是这样的(官方样例)： 12345678910crc16 &amp; hexhttps://post.zz173.com/posts/66c8.htmlcrc16 &amp; dechttps://post.zz173.com/posts/65535.htmlcrc32 &amp; hexhttps://post.zz173.com/posts/8ddf18fb.htmlcrc32 &amp; dechttps://post.zz173.com/posts/1690090958.html 生成完后，原md文件的Front-matter 内会增加abbrlink 字段，值为生成的ID 。这个字段确保了在我们修改了Front-matter 内的博客标题title或创建日期date字段之后而不会改变链接地址。","tags":"hexo"},{"title":"Java并发-ThreadLocal","url":"/posts/94ca0535.html","text":"简介ThreadLocal并非是一个线程的本地实现版本，它并不是一个Thread，而是threadlocalvariable(线程局部变量)。 线程局部变量(ThreadLocal)的功用就是为每一个使用该变量的线程都提供一个变量值的副本，是Java中一种较为特殊的线程绑定机制，每一个线程都可以独立地改变自己的副本，而不会和其它线程的副本冲突。 从线程的角度看，每个线程都保持一个对其线程局部变量副本的隐式引用，只要线程是活动的并且 ThreadLocal 实例是可访问的；在线程消失之后，其线程局部实例的所有副本都会被垃圾回收（除非存在对这些副本的其他引用）。 通过ThreadLocal存取的数据，总是与当前线程相关，也就是说，JVM 为每个运行的线程，绑定了私有的本地实例存取空间，从而为多线程环境常出现的并发访问问题提供了一种隔离机制。 ThreadLocal是如何做到为每一个线程维护变量的副本的呢？ 实现思路很简单，在ThreadLocal类中有一个Map，用于存储每一个线程的变量的副本。概括起来说，对于多线程资源共享的问题，同步机制采用了“以时间换空间”的方式，而ThreadLocal采用了“以空间换时间”的方式。前者仅提供一份变量，让不同的线程排队访问，而后者为每一个线程都提供了一份变量，因此可以同时访问而互不影响。 内部结构 实现原理 从上面ThreadLocal类图结构可知，Thread类中有两个变量threadLocals和inheritableThreadLocals，二者都是ThreadLocal内部类ThreadLocalMap类型的变量。通过查看内部类ThreadLocalMap可以发现实际上它类似于一个HashMap。在默认情况下，每个线程中的这两个变量都为null，只有当线程第一次调用ThreadLocal的set或者get方法的时候才会创建他们。 每个线程的本地变量不是存放在ThreadLocal实例中，而是放在调用线程的ThreadLocals变量里面，也就是说，ThreadLocal类型的本地变量是存放在具体的线程空间上，其本身相当于一个装载本地变量的工具壳，通过set方法将value添加到调用线程的threadLocals中，当调用线程调用get方法时候能够从它的threadLocals中取出变量。如果调用线程一直不终止，那么这个本地变量将会一直存放在他的threadLocals中，所以不使用本地变量的时候需要调用remove方法将threadLocals中删除不用的本地变量。 核心APIThreadLocal类提供如下几个核心方法： 123public T get()public void set(T value)public void remove() set方法12345678910111213141516171819public void set(T value) &#123; //获取当前线程（调用者线程） Thread t = Thread.currentThread(); //以当前线程作为key值，去查找对应的线程变量，找到对应的map ThreadLocalMap map = getMap(t); //如果map不为null，就直接添加本地变量，key为当前线程，值为添加的本地变量值 if (map != null) map.set(this, value); //如果map为null，说明首次添加，需要首先创建出对应的map else createMap(t, value);&#125;/** *获取线程自己的变量threadLocals，并绑定到当前调用线程的成员变量threadLocals上 */ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 如果调用getMap方法返回值不为null，就直接将value值设置到threadLocals中（key为当前线程引用，值为本地变量）；如果getMap方法返回null说明是第一次调用set方法（前面说到过，threadLocals默认值为null，只有调用set方法的时候才会创建map），这个时候就需要调用createMap方法创建threadLocals; 123void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; createMap方法不仅创建了threadLocals，同时也将要添加的本地变量值添加到了threadLocals中。 get方法123456789101112131415161718192021222324252627282930313233public T get() &#123; //获取当前线程 Thread t = Thread.currentThread(); //获取当前线程的threadLocals变量 ThreadLocalMap map = getMap(t); //如果threadLocals变量不为null，就可以在map中查找到本地变量的值 if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; &#125; &#125; //执行到此处，threadLocals为null，调用该更改初始化当前线程的threadLocals变量 return setInitialValue();&#125;private T setInitialValue() &#123; //protected T initialValue() &#123;return null;&#125; T value = initialValue(); //获取当前线程 Thread t = Thread.currentThread(); //以当前线程作为key值，去查找对应的线程变量，找到对应的map ThreadLocalMap map = getMap(t); //如果map不为null，就直接添加本地变量，key为当前线程，值为添加的本地变量值 if (map != null) map.set(this, value); //如果map为null，说明首次添加，需要首先创建出对应的map else createMap(t, value); return value;&#125; 在get方法的实现中，首先获取当前调用者线程，如果当前线程的threadLocals不为null，就直接返回当前线程绑定的本地变量值，否则执行setInitialValue方法初始化threadLocals变量。在setInitialValue方法中，类似于set方法的实现，都是判断当前线程的threadLocals变量是否为null，是则添加本地变量（这个时候由于是初始化，所以添加的值为null），否则创建threadLocals变量，同样添加的值为null。 remove方法1234567public void remove() &#123; //获取当前线程绑定的threadLocals ThreadLocalMap m = getMap(Thread.currentThread()); //如果map不为null，就移除当前线程中指定ThreadLocal实例的本地变量 if (m != null) m.remove(this); &#125; remove方法判断该当前线程对应的threadLocals变量是否为null，不为null就直接删除当前线程中指定的threadLocals变量。 ThreadLocalMap ThreadLocalMap是ThreadLocal的内部类，没有实现Map接口，用独立的方式实现了Map的功能，其内部的Entry也独立实现。 123456789101112131415161718192021222324252627282930/** * 是继承自WeakReference的一个类，该类中实际存放的key是 * 指向ThreadLocal的弱引用和与之对应的value值(该value值 * 就是通过ThreadLocal的set方法传递过来的值) * 由于是弱引用，当get方法返回null的时候意味着坑能引用 */static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** value就是和ThreadLocal绑定的 */ Object value; //k：ThreadLocal的引用，被传递给WeakReference的构造方法 Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125;//WeakReference构造方法(public class WeakReference&lt;T&gt; extends Reference&lt;T&gt; )public WeakReference(T referent) &#123; super(referent); //referent：ThreadLocal的引用&#125;//Reference构造方法 Reference(T referent) &#123; this(referent, null);//referent：ThreadLocal的引用&#125;Reference(T referent, ReferenceQueue&lt;? super T&gt; queue) &#123; this.referent = referent; this.queue = (queue == null) ? ReferenceQueue.NULL : queue;&#125; 从上面的代码可以看出，当前ThreadLocal的引用k被传递给WeakReference的构造函数，所以ThreadLocalMap中的key为ThreadLocal的弱引用。当一个线程调用ThreadLocal的set方法设置变量的时候，当前线程的ThreadLocalMap就会存放一个记录，这个记录的key值为ThreadLocal的弱引用，value就是通过set设置的值。如果当前线程一直存在且没有调用该ThreadLocal的remove方法，如果这个时候别的地方还有对ThreadLocal的引用，那么当前线程中的ThreadLocalMap中会存在对ThreadLocal变量的引用和value对象的引用，是不会释放的，就会造成内存泄漏。 考虑这个ThreadLocal变量没有其他强依赖，如果当前线程还存在，由于线程的ThreadLocalMap里面的key是弱引用，所以当前线程的ThreadLocalMap里面的ThreadLocal变量的弱引用在gc的时候就被回收，但是对应的value还是存在的这就可能造成内存泄漏(因为这个时候ThreadLocalMap会存在key为null但是value不为null的entry项)。 总结：THreadLocalMap中的Entry的key使用的是ThreadLocal对象的弱引用，在没有其他地方对ThreadLoca依赖，ThreadLocalMap中的ThreadLocal对象就会被回收掉，但是对应的不会被回收，这个时候Map中就可能存在key为null但是value不为null的项，这需要实际的时候使用完毕及时调用remove方法避免内存泄漏。","tags":"java"},{"title":"Redis为什么这么快","url":"/posts/8b544b71.html","text":"前言Redis本质上是一个基于键值对(Key-Value)类型的内存数据库，Redis的Value可以由String，hash，list，set，zset，Bitmaps，HyperLogLog等多种数据结构和算法组成。整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过 10万次读写操作，是已知性能最快的Key-Value DB。可用于缓存、事件发布或订阅、高速队列等场景。该数据库使用ANSI C语言编写，支持网络，提供字符串、哈希、列表、队列、集合结构直接存取，基于内存，可持久化。Redis 内置了 复制（replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（transactions） 和不同级别的 磁盘持久化（persistence）， 并通过 Redis哨兵（Sentinel）和自动 分区（Cluster）提供高可用性（high availability）。官方给出的性能可以达到10W+qps，那么Redis到底快在哪呢？ 开发语言现在我们都用高级语言来编程，比如Java、python等。也许你会觉得C语言很古老，但是它真的很有用，毕竟unix系统就是用C实现的，所以C语言是非常贴近操作系统的语言。Redis就是用C语言开发的，所以执行会比较快。 纯内存访问Redis将所有数据放在内存中，非数据同步正常工作中，是不需要从磁盘读取数据的，0次IO。内存响应时间大约为100纳秒，这是Redis速度快的重要基础。 单线程第一，单线程简化算法的实现，并发的数据结构实现不但困难且测试也麻烦。第二，单线程避免了线程切换以及加锁释放锁带来的消耗，对于服务端开发来说，锁和线程切换通常是性能杀手。 当然了，单线程也会有它的缺点，也是Redis的噩梦：阻塞。如果执行一个命令过长，那么会造成其他命令的阻塞，对于Redis是十分致命的，所以Redis是面向快速执行场景的数据库。 除了Redis之外，Node.js也是单线程，Nginx也是单线程，但他们都是服务器高性能的典范。 非阻塞多路I/O复用机制先说一下传统的阻塞I/O是如何工作的：当使用read或者write对某一文件描述符（File Descriptor FD）进行读写的时候，如果数据没有收到，那么该线程会被挂起，直到收到数据。阻塞模型虽然易于理解，但是在需要处理多个客户端任务的时候，不会使用阻塞模型。 I/O多路复用实际上是指多个连接的管理可以在同一进程。多路是指网络连接，复用只是同一个线程。在网络服务中，I/O多路复用起的作用是一次性把多个连接的事件通知业务代码处理，处理的方式由业务代码来决定。在I/O多路复用模型中，最重要的函数调用就是I/O 多路复用函数，该方法能同时监控多个文件描述符（fd）的读写情况，当其中的某些fd可读/写时，该方法就会返回可读/写的fd个数。 Redis使用epoll作为I/O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll的read、write、close等都转换成事件，不在网络I/O上浪费过多的时间。实现对多个FD读写的监控，提高性能。 举个例子:比如一个tcp服务器处理20个客户端socket。A方案：顺序处理，如果第一个socket因为网卡读数据处理慢了，一阻塞，后面都玩蛋去。 B方案：每个socket请求都创建一个分身子进程来处理，不说每个进程消耗大量系统资源，光是进程切换就够操作系统累的了。 C方案（I/O复用模型，epoll）：将用户socket对应的fd注册进epoll（实际上服务器和操作系统之间传递的不是socket的fd而是fd_set的数据结构），然后epoll只告诉哪些需要读/写的socket，只需要处理那些活跃的、有变化的socket fd的就好了。这样，整个过程只在调用epoll的时候才会阻塞，收发客户消息是不会阻塞的。","tags":"redis"},{"title":"Redis - 常用数据类型及命令","url":"/posts/2853eeb9.html","text":"概述Redis中存储数据是通过key-value格式存储数据的，其中value可以定义五种数据类型： String（字符类型） Hash（散列类型） List（列表类型） Set（集合类型） SortedSet（有序集合类型，简称zset） 注意：在redis中的命令语句中，命令是忽略大小写的，而key是不忽略大小写的。 String类型赋值语法：set key value 12127.0.0.1:6379&gt; set k1 v1OK 取值语法：get key 12127.0.0.1:6379&gt; get k1&quot;v1&quot; 取值并赋值语法：getset key value 1234127.0.0.1:6379&gt; getset k1 v2&quot;v1&quot;127.0.0.1:6379&gt; get k1&quot;v2&quot; 递增数字语法：INCR key 123456127.0.0.1:6379&gt; incr num(integer) 1127.0.0.1:6379&gt; incr num(integer) 2127.0.0.1:6379&gt; incr num(integer) 3 增加指定的整数语法：INCRBY key increment 123456127.0.0.1:6379&gt; incrby num 2(integer) 5127.0.0.1:6379&gt; incrby num 2(integer) 7127.0.0.1:6379&gt; incrby num 2(integer) 9 递减数值语法：DECR key 1234 127.0.0.1:6379&gt; decr num(integer) 9127.0.0.1:6379&gt; decr num(integer) 8 减少指定的整数语法：DECRBY key decrement 12345678127.0.0.1:6379&gt; decr num(integer) 6127.0.0.1:6379&gt; decr num(integer) 5127.0.0.1:6379&gt; decrby num 3(integer) 2127.0.0.1:6379&gt; decrby num 3(integer) -1 仅当不存在时赋值语法：setnx key value 12345678redis&gt; EXISTS k1 # k1 不存在(integer) 0redis&gt; SETNX k1 &quot;v1&quot; # k1设置成功(integer) 1redis&gt; SETNX k1 &quot;v2&quot; # 尝试覆盖 k1，失败(integer) 0redis&gt; GET k1 # 没有被覆盖&quot;v1&quot; 向尾部追加值APPEND命令，向键值的末尾追加value。如果键不存在则将该键的值设置为value，即相当于 SET key value。返回值是追加后字符串的总长度。 语法：APPEND key value 123456127.0.0.1:6379&gt; set str helloOK127.0.0.1:6379&gt; append str &quot; world!&quot;(integer) 12127.0.0.1:6379&gt; get str &quot;hello world!&quot; 获取字符串长度STRLEN命令，返回键值的长度，如果键不存在则返回0。 语法：STRLEN key 123456127.0.0.1:6379&gt; strlen str (integer) 0127.0.0.1:6379&gt; set str helloOK127.0.0.1:6379&gt; strlen str (integer) 5 同时设置/获取多个键值语法：MSET key value [key value …]MGET key [key …] 1234567127.0.0.1:6379&gt; mset k1 v1 k2 v2 k3 v3OK127.0.0.1:6379&gt; get k1&quot;v1&quot;127.0.0.1:6379&gt; mget k1 k31) &quot;v1&quot;2) &quot;v3&quot; Hash类型hash叫散列类型，它提供了字段和字段值的映射。字段值只能是字符串类型，不支持散列类型、集合类型等其它类型。如下： 赋值HSET命令不区分插入和更新操作，当执行插入操作时HSET命令返回1，当执行更新操作时0。 一次只能设置一个字段值 语法：HSET key field value 12127.0.0.1:6379&gt; hset user username zhangsan (integer) 1 一次可以设置多个字段值 语法：HMSET key field value [field value ...] 12127.0.0.1:6379&gt; hmset user age 20 username lisi OK 当值不存在才赋值当字段不存在时赋值，类似HSET，区别在于如果字段存在，该命令不执行任何操作语法：HSETNX key field value12127.0.0.1:6379&gt; hsetnx user age 30 (integer) 0 如果user中没有age字段则设置age值为30，否则不做任何操作 取值 一次只能获取一个字段值 语法：HGET key field 12127.0.0.1:6379&gt; hget user username&quot;lisi“ 一次可以获取多个字段值 语法：HMGET key field [field ...] 123127.0.0.1:6379&gt; hmget user age username1) &quot;20&quot;2) &quot;lisi&quot; 获取所有字段值 语法：HGETALL key 12345127.0.0.1:6379&gt; hgetall user1) &quot;age&quot;2) &quot;20&quot;3) &quot;username&quot;4) &quot;lisi&quot; 删除字段 可以删除一个或多个字段，返回值是被删除的字段个数 语法：HDEL key field [field ...] 123456127.0.0.1:6379&gt; hdel user age(integer) 1127.0.0.1:6379&gt; hdel user age name(integer) 0127.0.0.1:6379&gt; hdel user age username(integer) 1 增加数字语法：HINCRBY key field increment 123456#将用户的年龄加2127.0.0.1:6379&gt; hincrby user age 2 (integer) 22#获取用户的年龄127.0.0.1:6379&gt; hget user age &quot;22&quot; 判断字段是否存在语法：HEXISTS key field 123456#查看user中是否有age字段127.0.0.1:6379&gt; hexists user age (integer) 1#查看user中是否有name字段127.0.0.1:6379&gt; hexists user name (integer) 0 只获取字段名或字段值语法： 12HKEYS keyHVALS key 12345678127.0.0.1:6379&gt; hmset user age 20 name lisi OK127.0.0.1:6379&gt; hkeys user1) &quot;age&quot;2) &quot;name&quot;127.0.0.1:6379&gt; hvals user1) &quot;20&quot;2) &quot;lisi&quot; 获取字段数量语法：HLEN key 12127.0.0.1:6379&gt; hlen user(integer) 2 获取所有字段作用：获得hash的所有信息，包括key和value 语法：hgetall key List类型Redis的列表类型（list）可以存储一个有序的字符串列表，常用的操作是向列表两端添加元素，或者获得列表的某一个片段。 列表类型内部是使用双向链表（double linked list）实现的，所以向列表两端添加元素的时间复杂度为O(1)，获取越接近两端的元素速度就越快。这意味着即使是一个有几千万个元素的列表，获取头部或尾部的10条记录也是极快的。 向列表左边增加元素语法：LPUSH key value [value ...] 12127.0.0.1:6379&gt; lpush list:1 1 2 3(integer) 3 向列表右边增加元素语法：RPUSH key value [value ...] 12127.0.0.1:6379&gt; rpush list:1 4 5 6(integer) 6 查看列表语法：LRANGE key start stop LRANGE命令是列表类型最常用的命令之一，获取列表中的某一片段，将返回start、stop之间的所有元素（包含两端的元素），索引从0开始。索引可以是负数，如：“-1”代表最后边的一个元素。 1234127.0.0.1:6379&gt; lrange list:1 0 21) &quot;3&quot;2) &quot;2&quot;3) &quot;1&quot; 从列表两端弹出元素LPOP命令从列表左边弹出一个元素，会分两步完成： 第一步是将列表左边的元素从列表中移除 第二步是返回被移除的元素值。语法：123LPOP keyRPOP key 1234127.0.0.1:6379&gt; lpop list:1&quot;3&quot;127.0.0.1:6379&gt; rpop list:1&quot;6&quot; 获取列表中元素的个数语法：LLEN key 12127.0.0.1:6379&gt; llen list:1(integer) 4 删除列表中指定个数的值LREM命令会删除列表中前count个值为value的元素，返回实际删除的元素个数。根据count值的不同，该命令的执行方式会有所不同： 当count&gt;0时， LREM会从列表左边开始删除。 当count&lt;0时， LREM会从列表后边开始删除。 当count=0时， LREM删除所有值为value的元素。 语法：LREM key count value 获得指定索引的元素值语法：LINDEX key index 12127.0.0.1:6379&gt; lindex list:1 2&quot;4&quot; 设置指定索引的元素值语法：LSET key index value 1234567127.0.0.1:6379&gt; lset list:1 2 2OK127.0.0.1:6379&gt; lrange list:1 0 -11) &quot;2&quot;2) &quot;1&quot;3) &quot;2&quot;4) &quot;5&quot; 只保留列表指定片段, 指定范围和LRANGE一致语法：LTRIM key start stop 1234567891011127.0.0.1:6379&gt; lrange list:1 0 -11) &quot;2&quot;2) &quot;1&quot;3) &quot;2&quot;4) &quot;5&quot;127.0.0.1:6379&gt; ltrim list:1 0 2OK127.0.0.1:6379&gt; lrange list:1 0 -11) &quot;2&quot;2) &quot;1&quot;3) &quot;2&quot; 向列表中插入元素该命令首先会在列表中从左到右查找值为pivot的元素，然后根据第二个参数是BEFORE还是AFTER来决定将value插入到该元素的前面还是后面。 语法：LINSERT key BEFORE|AFTER pivot value 1234567891011127.0.0.1:6379&gt; lrange list 0 -11) &quot;3&quot;2) &quot;2&quot;3) &quot;1&quot;127.0.0.1:6379&gt; linsert list after 3 4(integer) 4127.0.0.1:6379&gt; lrange list 0 -11) &quot;3&quot;2) &quot;4&quot;3) &quot;2&quot;4) &quot;1&quot; 将元素从一个列表转移到另一个列表中语法：RPOPLPUSH source destination 12345678127.0.0.1:6379&gt; rpoplpush list newlist &quot;1&quot;127.0.0.1:6379&gt; lrange newlist 0 -11) &quot;1&quot;127.0.0.1:6379&gt; lrange list 0 -11) &quot;3&quot;2) &quot;4&quot;3) &quot;2&quot; Set类型set类型即集合类型，其中的数据是不重复且没有顺序。 集合类型和列表类型的对比： 集合类型的常用操作是向集合中加入或删除元素、判断某个元素是否存在等，由于集合类型的Redis内部是使用值为空的散列表实现，所有这些操作的时间复杂度都为0(1)。Redis还提供了多个集合之间的交集、并集、差集的运算。 增加/删除元素语法：SADD key member [member ...] 1234127.0.0.1:6379&gt; sadd set a b c(integer) 3127.0.0.1:6379&gt; sadd set a(integer) 0 语法：SREM key member [member ...] 12127.0.0.1:6379&gt; srem set c d(integer) 1 获得集合中的所有元素语法：SMEMBERS key 123127.0.0.1:6379&gt; smembers set1) &quot;b&quot;2) &quot;a” 判断元素是否在集合中语法：SISMEMBER key member 1234127.0.0.1:6379&gt; sismember set a(integer) 1127.0.0.1:6379&gt; sismember set h(integer) 0 集合运算命令 集合的差集运算 A-B : 属于A并且不属于B的元素构成的集合。 语法：SDIFF key [key ...] 12345678127.0.0.1:6379&gt; sadd setA 1 2 3(integer) 3127.0.0.1:6379&gt; sadd setB 2 3 4(integer) 3127.0.0.1:6379&gt; sdiff setA setB 1) &quot;1&quot;127.0.0.1:6379&gt; sdiff setB setA 1) &quot;4&quot; 集合的交集运算 A ∩ B : 属于A且属于B的元素构成的集合。 语法：SINTER key [key ...] 123127.0.0.1:6379&gt; sinter setA setB 1) &quot;2&quot;2) &quot;3&quot; 集合的并集运算 A ∪ B : 属于A或者属于B的元素构成的集合 语法：SUNION key [key ...] 12345127.0.0.1:6379&gt; sunion setA setB1) &quot;1&quot;2) &quot;2&quot;3) &quot;3&quot;4) &quot;4&quot; 获得集合中元素的个数语法：SCARD key 123456127.0.0.1:6379&gt; smembers setA 1) &quot;1&quot;2) &quot;2&quot;3) &quot;3&quot;127.0.0.1:6379&gt; scard setA (integer) 3 从集合中弹出一个元素注意：由于集合是无序的，所有SPOP命令会从集合中随机选择一个元素弹出 语法：SPOP key 12127.0.0.1:6379&gt; spop setA &quot;1&quot; ZSet类型在集合类型的基础上，有序集合类型为集合中的每个元素都关联一个分数，这使得我们不仅可以完成插入、删除和判断元素是否存在在集合中，还能够获得分数最高或最低的前N个元素、获取指定分数范围内的元素等与分数有关的操作。 在某些方面有序集合和列表类型有些相似： 二者都是有序的。 二者都可以获得某一范围的元素。 但是，二者有着很大区别： 列表类型是通过链表实现的，获取靠近两端的数据速度极快，而当元素增多后，访问中间数据的速度会变慢。 有序集合类型使用散列表实现，所以即使读取位于中间部分的数据也很快。 列表中不能简单的调整某个元素的位置，但是有序集合可以（通过更改分数实现） 有序集合要比列表类型更耗内存。 增加元素向有序集合中加入一个元素和该元素的分数，如果该元素已经存在则会用新的分数替换原有的分数。返回值是新加入到集合中的元素个数，不包含之前已经存在的元素。 语法：ZADD key score member [score member ...] 1234127.0.0.1:6379&gt; zadd scoreboard 80 zhangsan 89 lisi 94 wangwu (integer) 3127.0.0.1:6379&gt; zadd scoreboard 97 lisi (integer) 0 获得排名在某个范围的元素列表按照元素分数从小到大的顺序返回索引从start到stop之间的所有元素（包含两端的元素） 语法：ZRANGE key start stop [WITHSCORES] 1234127.0.0.1:6379&gt; zrange scoreboard 0 21) &quot;zhangsan&quot;2) &quot;wangwu&quot;3) &quot;lisi“ 按照元素分数从大到小的顺序返回索引从start到stop之间的所有元素（包含两端的元素）语法：ZREVRANGE key start stop [WITHSCORES] 1234127.0.0.1:6379&gt; zrevrange scoreboard 0 21) &quot;lisi&quot;2) &quot;wangwu&quot;3) &quot;zhangsan&quot; 如果需要获得元素的分数的可以在命令尾部加上WITHSCORES参数 12345127.0.0.1:6379&gt; zrange scoreboard 0 1 WITHSCORES1) &quot;zhangsan&quot;2) &quot;80&quot;3) &quot;wangwu&quot;4) &quot;94&quot; 获取元素的分数语法：ZSCORE key member 12127.0.0.1:6379&gt; zscore scoreboard lisi &quot;97&quot; 删除元素移除有序集key中的一个或多个成员，不存在的成员将被忽略。当key存在但不是有序集类型时，返回一个错误。 语法：ZREM key member [member ...] 12127.0.0.1:6379&gt; zrem scoreboard lisi(integer) 1 获得指定分数范围的元素语法：ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count] 12345127.0.0.1:6379&gt; ZRANGEBYSCORE scoreboard 90 97 WITHSCORES1) &quot;wangwu&quot;2) &quot;94&quot;127.0.0.1:6379&gt; ZRANGEBYSCORE scoreboard 70 100 limit 1 21) &quot;wangwu&quot; 增加某个元素的分数返回值是更改后的分数 语法：ZINCRBY key increment member 12127.0.0.1:6379&gt; ZINCRBY scoreboard 4 lisi &quot;101&quot; 获得集合中元素的数量语法：ZCARD key 12127.0.0.1:6379&gt; ZCARD scoreboard(integer) 3 获得指定分数范围内的元素个数语法：ZCOUNT key min max 12127.0.0.1:6379&gt; ZCOUNT scoreboard 80 90(integer) 1 按照排名范围删除元素语法：ZREMRANGEBYRANK key start stop 1234127.0.0.1:6379&gt; ZREMRANGEBYRANK scoreboard 0 1(integer) 2 127.0.0.1:6379&gt; ZRANGE scoreboard 0 -11) &quot;lisi&quot; 按照分数范围删除元素语法：ZREMRANGEBYSCORE key min max 1234127.0.0.1:6379&gt; zadd scoreboard 84 zhangsan (integer) 1127.0.0.1:6379&gt; ZREMRANGEBYSCORE scoreboard 80 100(integer) 1 获取元素的排名 从小到大 语法：ZRANK key member 12127.0.0.1:6379&gt; ZRANK scoreboard lisi (integer) 0 从大到小 语法：ZREVRANK key member 12127.0.0.1:6379&gt; ZREVRANK scoreboard zhangsan (nil) 通用命令keys作用：返回满足给定pattern 的所有key 语法：keys pattern 123456127.0.0.1:6379&gt; keys mylist*1) &quot;mylist&quot;2) &quot;mylist5&quot;3) &quot;mylist6&quot;4) &quot;mylist7&quot;5) &quot;mylist8&quot; del作用：删除指定的key 语法：DEL key 12127.0.0.1:6379&gt; del test(integer) 1 exists作用：确认一个key 是否存在 语法：exists key 示例：从结果来看，数据库中不存在HongWan 这个key，但是age 这个key 是存在的 1234127.0.0.1:6379&gt; exists HongWan(integer) 0127.0.0.1:6379&gt; exists age(integer) 1 expire作用：设置生存时间，到期后数据销毁。 EXPIRE key seconds 设置key的生存时间（单位：秒）key在多少秒后会自动删除 TTL key 查看key生于的生存时间 PERSIST key 清除生存时间 PEXPIRE key milliseconds 生存时间设置单位为：毫秒 123456789101112127.0.0.1:6379&gt; set test 1 设置test的值为1OK127.0.0.1:6379&gt; get test 获取test的值&quot;1&quot;127.0.0.1:6379&gt; EXPIRE test 5 设置test的生存时间为5秒(integer) 1127.0.0.1:6379&gt; TTL test 查看test的生于生成时间还有1秒删除(integer) 1127.0.0.1:6379&gt; TTL test(integer) -2127.0.0.1:6379&gt; get test 获取test的值，已经删除(nil) rename作用：重命名key 语法：rename oldkey newkey 123456127.0.0.1:6379&gt; keys *1) &quot;age&quot;127.0.0.1:6379&gt; rename age age_newOK127.0.0.1:6379&gt; keys *1) &quot;age_new&quot; type作用：显示指定key的数据类型 语法：type key 123456127.0.0.1:6379&gt; type addrstring127.0.0.1:6379&gt; type myzset2zset127.0.0.1:6379&gt; type mylistlist","tags":"redis"},{"title":"阿里巴巴连接池DruidDataSource的一个bug","url":"/posts/d2af9ee0.html","text":"问题使用阿里巴巴的数据库连接池Druid，当应用程序连接数据库，老是报错：caused by wait mills 5000,active 0,maxactive 20连接数据库超时，但是使用单独的jdbc连接却是可以连接的。 解决经过反复测试，发现问题所在，原来是连接池参数&lt;property name=&quot;validationQuery&quot; value=&quot;select 1&quot;&gt;配置错误。虽然是配置错误，但是连接池版本是1.0.10，太旧，导致没有把真正的报错提示出来ora-00923 未找到要求的关键字from，而是报这个错：caused by wait mills 5000,active 0,maxactive 20。也就是说，本来是因为配置错误导致的，但是因为阿里巴巴连接池DruidDataSource的bug，把这个错误隐藏起来了，一直没有把真正的错误报出来。 总结将Druid版本升级到最新的稳定版本，DruidDataSource配置成如下： 123456789&lt;property name=\"minIdle\" value=\"1\" /&gt;&lt;property name=\"validationQuery\" value=\"SELECT 1 FROM DUAL\" /&gt;&lt;property name=\"testOnBorrow\" value=\"true\" /&gt;&lt;property name=\"poolPreparedStatements\" value=\"true\" /&gt;&lt;property name=\"initialSize\" value=1 /&gt; 参数说明 validationQuery SQL查询,用来验证从连接池取出的连接,在将连接返回给调用者之前.如果指定, 则查询必须是一个SQL SELECT并且必须返回至少一行记录。 testOnBorrow true–指明是否在从池中取出连接前进行检验,如果检验失败, 则从池中去除连接并尝试取出另一个。 注意: 设置为true后如果要生效,validationQuery参数必须设置为非空字符串 。 testOnReturn false–指明是否在归还到池中前进行检验。 注意: 设置为true后如果要生效,validationQuery参数必须设置为非空字符串 。 testWhileIdle false–指明连接是否被空闲连接回收器(如果有)进行检验.如果检测失败, 则连接将被从池中去除。 注意: 设置为true后如果要生效,validationQuery参数必须设置为非空字符串 timeBetweenEvictionRunsMillis -1–在空闲连接回收器线程运行期间休眠的时间值,以毫秒为单位. 如果设置为非正数,则不运行空闲连接回收器线程。 numTestsPerEvictionRun 3–在每次空闲连接回收器线程(如果有)运行时检查的连接数量 。 minEvictableIdleTimeMillis 1000 * 60 * 30–连接在池中保持空闲而不被空闲连接回收器线程(如果有)回收的最小时间值，单位毫秒。","tags":"druid mysql"},{"title":"Mybatis异常There is no getter for property named 'XXX' in class","url":"/posts/53121faf.html","text":"在集成Mybatis的项目中定义接口并实现映射SQL时，遇到过一个很奇怪的问题，如下： 定义接口： 1UserCouponBo getUserCouponInfoById(Long userCouponId); 然后对应的sql的xml如下： 12345678&lt;select id=\"selectUserCouponInfoById\" parameterType=\"java.lang.Long\" resultMap=\"baseResultMap\"&gt; select amount,receive_time from user_coupon &lt;where&gt; &lt;if test=\"userCouponId != null\"&gt; id = #&#123;userCouponId,jdbcType=BIGINT&#125; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 上面的接口就是通过id查询指定的优惠券信息，个人感觉该sql写的不够优雅。就是这个接口，报错：There is no gettery for property…!!!这是为什么呢？原因是在if里面用了Mybatis的内置对象，&lt;if test=&quot;id != null&quot;&gt;，Mybatis默认采用OGNL解析参数，所以会自动采用对象树的形式取long.xxx值，如果没在方法中定义，则会抛出异常。 解决方案一：把#{xxx}修改为#{_parameter}即可 12345678&lt;select id=\"selectUserCouponInfoById\" parameterType=\"java.lang.Long\" resultMap=\"baseResultMap\"&gt; select amount,receive_time from user_coupon &lt;where&gt; &lt;if test=\"_parameter != null\"&gt; id = #&#123;_parameter&#125; &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 解决解决方案二：在方法中提前定义。 1UserCouponBo getUserCouponInfoById(@Param(\"userCouponId\") Long userCouponId); 给userCouponId加@Param注解，定义一下就可以了。","tags":"mybatis"},{"title":"Java并发-ReentrantReadWriteLock","url":"/posts/b29432a8.html","text":"概述ReadWriteLock，顾名思义，是读写锁。它维护了一对相关的锁 — — “读取锁”和“写入锁”，一个用于读取操作，另一个用于写入操作。 “读取锁”用于只读操作，它是“共享锁”，能同时被多个线程获取。 “写入锁”用于写入操作，它是“独占锁”，写入锁只能被一个线程锁获取。注意：不能同时存在读取锁和写入锁！ReadWriteLock是一个接口。ReentrantReadWriteLock是它的实现类，ReentrantReadWriteLock包括子类ReadLock和WriteLock。读写锁底层也是通过AQS框架实现的，通过之前的文章可知，如果使用AQS框架，在这个类内部必定有一个AQS框架的子类，AQS子类无非就是实现如下几点： 第一点：对共享资源state进行操作第二点：如果是独占模式下对资源的获取和释放，那么必须实现tryAcquire()方法和tryRelease()方法。第三点：如果是共享模式下对资源的获取和释放，那么必须实现tryAcquireShared()方法和tryReleaseShared()方法。 而读写锁ReentrantReadWriteLock即包含独占模式下资源的获取和释放(写锁)，也包含共享模式下资源的获取和释放(读锁)，所以需要上面的四个方法都需要实现。 用state一个整形变量怎样去维护读和写两种状态共享资源state是一个整形变量，在读写锁中又必须维护读和写两种状态，所以只能按位把state分割成两个部分，一个整形有32位，高16位代表读，低16位代表写。如图所示：![img][link1] 123456789101112//读状态占用位数static final int SHARED_SHIFT = 16;//每一次增加的读状态：(1&lt;&lt;16),因为读状态是state的高16位static final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT);//读状态或写状态最大的数量static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1;//用来计算写的同步状态static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;//计算读锁的数量static int sharedCount(int c) &#123; return c &gt;&gt;&gt; SHARED_SHIFT; &#125;//计算写锁的数量static int exclusiveCount(int c) &#123; return c &amp; EXCLUSIVE_MASK; &#125; 读操作，因为高16位为读操作，要想获取读的数量，只需将state无符号右移16位即可：state&gt;&gt;&gt;16。读最大的数量：65535(二进制表示：11111111110000000000000000) 写操作，因为低16位为写操作，要向获取写数量，只需要把state的高16位抹去就可以了，很容易想到“按位与”操作：state&amp;1111111111111111。写最大的数量：65535(二进制表示：00000000000000001111111111111111) 共享锁12345678910111213141516171819202122232425262728293031323334353637383940414243444546public static class ReadLock implements Lock, java.io.Serializable &#123; private static final long serialVersionUID = -5992448646407690164L; // ReentrantReadWriteLock的AQS对象 private final Sync sync; protected ReadLock(ReentrantReadWriteLock lock) &#123; sync = lock.sync; &#125; // 获取“共享锁” public void lock() &#123; sync.acquireShared(1); &#125; // 如果线程是中断状态，则抛出一场，否则尝试获取共享锁。 public void lockInterruptibly() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; // 尝试获取“共享锁” public boolean tryLock() &#123; return sync.tryReadLock(); &#125; // 在指定时间内，尝试获取“共享锁” public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout)); &#125; // 释放“共享锁” public void unlock() &#123; sync.releaseShared(1); &#125; // 新建条件 public Condition newCondition() &#123; throw new UnsupportedOperationException(); &#125; public String toString() &#123; int r = sync.getReadLockCount(); return super.toString() + \"[Read locks = \" + r + \"]\"; &#125;&#125; ReadLock中的sync是一个Sync对象，Sync继承于AQS类，即Sync就是一个锁。ReentrantReadWriteLock中也有一个Sync对象，而且ReadLock中的sync和ReentrantReadWriteLock中的sync是对应关系。即ReentrantReadWriteLock和ReadLock共享同一个AQS对象，共享同一把锁。 获取共享锁获取共享锁的思想(即lock函数的步骤)，是先通过tryAcquireShared()尝试获取共享锁。尝试成功的话，则直接返回；尝试失败的话，则通过doAcquireShared()不断的循环并尝试获取锁，若有需要，则阻塞等待。doAcquireShared()在循环中每次尝试获取锁时，都是通过tryAcquireShared()来进行尝试的。下面看看“获取共享锁”的详细流程。 lock()123public void lock() &#123; sync.acquireShared(1);&#125; acquireShared()Sync继承于AQS，acquireShared()定义在AQS中。源码如下： 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; acquireShared()首先会通过tryAcquireShared()来尝试获取锁。尝试成功的话，则不再做任何动作(因为已经成功获取到锁了)。尝试失败的话，则通过doAcquireShared()来获取锁。doAcquireShared()会获取到锁了才返回。 tryAcquireShared()123456789101112131415161718192021222324252627282930313233343536protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); // 获取“锁”的状态 int c = getState(); // 如果“锁”是“互斥锁”，并且获取锁的线程不是current线程；则返回-1。 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; // 获取“读取锁”的共享计数 int r = sharedCount(c); // 如果“不需要阻塞等待”，并且“读取锁”的共享计数小于MAX_COUNT； // 则通过CAS函数更新“锁的状态”，将“读取锁”的共享计数+1。 if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; // 第1次获取“读取锁”。 if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; // 如果想要获取锁的线程(current)是第1个获取锁(firstReader)的线程 &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; // HoldCounter是用来统计该线程获取“读取锁”的次数。 HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != current.getId()) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); // 将该线程获取“读取锁”的次数+1。 rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current);&#125; tryAcquireShared()的作用是尝试获取“共享锁”。如果在尝试获取锁时，“不需要阻塞等待”并且“读取锁的共享计数小于MAX_COUNT”，则直接通过CAS函数更新“读取锁的共享计数”，以及将“当前线程获取读取锁的次数+1”。否则，通过fullTryAcquireShared()获取读取锁。 fullTryAcquireShared()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758final int fullTryAcquireShared(Thread current) &#123; HoldCounter rh = null; for (;;) &#123; // 获取“锁”的状态 int c = getState(); // 如果“锁”是“互斥锁”，并且获取锁的线程不是current线程；则返回-1。 if (exclusiveCount(c) != 0) &#123; if (getExclusiveOwnerThread() != current) return -1; // 如果“需要阻塞等待”。 // (01) 当“需要阻塞等待”的线程是第1个获取锁的线程的话，则继续往下执行。 // (02) 当“需要阻塞等待”的线程获取锁的次数=0时，则返回-1。 &#125; else if (readerShouldBlock()) &#123; // 如果想要获取锁的线程(current)是第1个获取锁(firstReader)的线程 if (firstReader == current) &#123; &#125; else &#123; if (rh == null) &#123; rh = cachedHoldCounter; if (rh == null || rh.tid != current.getId()) &#123; rh = readHolds.get(); if (rh.count == 0) readHolds.remove(); &#125; &#125; // 如果当前线程获取锁的计数=0,则返回-1。 if (rh.count == 0) return -1; &#125; &#125; // 如果“不需要阻塞等待”，则获取“读取锁”的共享统计数； // 如果共享统计数超过MAX_COUNT，则抛出异常。 if (sharedCount(c) == MAX_COUNT) throw new Error(\"Maximum lock count exceeded\"); // 将线程获取“读取锁”的次数+1。 if (compareAndSetState(c, c + SHARED_UNIT)) &#123; // 如果是第1次获取“读取锁”，则更新firstReader和firstReaderHoldCount。 if (sharedCount(c) == 0) &#123; firstReader = current; firstReaderHoldCount = 1; // 如果想要获取锁的线程(current)是第1个获取锁(firstReader)的线程， // 则将firstReaderHoldCount+1。 &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; if (rh == null) rh = cachedHoldCounter; if (rh == null || rh.tid != current.getId()) rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); // 更新线程的获取“读取锁”的共享计数 rh.count++; cachedHoldCounter = rh; // cache for release &#125; return 1; &#125; &#125;&#125; fullTryAcquireShared()会根据“是否需要阻塞等待”，“读取锁的共享计数是否超过限制”等等进行处理。如果不需要阻塞等待，并且锁的共享计数没有超过限制，则通过CAS尝试获取锁，并返回1。 doAcquireShared()1234567891011121314151617181920212223242526272829303132private void doAcquireShared(int arg) &#123; // addWaiter(Node.SHARED)的作用是，创建“当前线程”对应的结点，并将该线程添加到同步队列中。 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; // 获取“node”的前一结点 final Node p = node.predecessor(); // 如果“当前线程”是同步队列的表头，则尝试获取共享锁。 if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; // 如果“当前线程”不是同步队列的表头，则通过shouldParkAfterFailedAcquire()判断是否需要等待， // 需要的话，则通过parkAndCheckInterrupt()进行阻塞等待。若阻塞等待过程中，线程被中断过，则设置interrupted为true。 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; doAcquireShared()的作用是获取共享锁。它会首先创建线程对应的同步队列的结点，然后将该结点添加到同步队列中。同步队列是管理获取锁的等待线程的队列。如果“当前线程”是同步队列的表头，则尝试获取共享锁；否则，则需要通过shouldParkAfterFailedAcquire()判断是否阻塞等待，需要的话，则通过parkAndCheckInterrupt()进行阻塞等待。doAcquireShared()会通过for循环，不断的进行上面的操作；目的就是获取共享锁。需要注意的是：doAcquireShared()在每一次尝试获取锁时，是通过tryAcquireShared()来执行的！ 释放共享锁释放共享锁的思想，是先通过tryReleaseShared()尝试释放共享锁。尝试成功的话，则通过doReleaseShared()唤醒“其他等待获取共享锁的线程”，并返回true；否则的话，返回flase。 unlock()123public void unlock() &#123; sync.releaseShared(1);&#125; 该函数实际上调用releaseShared(1)释放共享锁。 releaseShared()1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; releaseShared()的目的是让当前线程释放它所持有的共享锁。它首先会通过tryReleaseShared()去尝试释放共享锁。尝试成功，则直接返回；尝试失败，则通过doReleaseShared()去释放共享锁。 tryReleaseShared()123456789101112131415161718192021222324252627282930313233343536protected final boolean tryReleaseShared(int unused) &#123; // 获取当前线程，即释放共享锁的线程。 Thread current = Thread.currentThread(); // 如果想要释放锁的线程(current)是第1个获取锁(firstReader)的线程， // 并且“第1个获取锁的线程获取锁的次数”=1，则设置firstReader为null； // 否则，将“第1个获取锁的线程的获取次数”-1。 if (firstReader == current) &#123; // assert firstReaderHoldCount &gt; 0; if (firstReaderHoldCount == 1) firstReader = null; else firstReaderHoldCount--; // 获取rh对象，并更新“当前线程获取锁的信息”。 &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != current.getId()) rh = readHolds.get(); int count = rh.count; if (count &lt;= 1) &#123; readHolds.remove(); if (count &lt;= 0) throw unmatchedUnlockException(); &#125; --rh.count; &#125; for (;;) &#123; // 获取锁的状态 int c = getState(); // 将锁的获取次数-1。 int nextc = c - SHARED_UNIT; // 通过CAS更新锁的状态。 if (compareAndSetState(c, nextc)) return nextc == 0; &#125;&#125; tryReleaseShared()的作用是尝试释放共享锁。 doReleaseShared()1234567891011121314151617181920212223242526private void doReleaseShared() &#123; for (;;) &#123; // 获取CLH队列的头节点 Node h = head; // 如果头节点不为null，并且头节点不等于tail节点。 if (h != null &amp;&amp; h != tail) &#123; // 获取头节点对应的线程的状态 int ws = h.waitStatus; // 如果头节点对应的线程是SIGNAL状态，则意味着“头节点的下一个节点所对应的线程”需要被unpark唤醒。 if (ws == Node.SIGNAL) &#123; // 设置“头节点对应的线程状态”为空状态。失败的话，则继续循环。 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // 唤醒“头节点的下一个节点所对应的线程”。 unparkSuccessor(h); &#125; // 如果头节点对应的线程是空状态，则设置“文件点对应的线程所拥有的共享锁”为其它线程获取锁的空状态。 else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; // 如果头节点发生变化，则继续循环。否则，退出循环。 if (h == head) // loop if head changed break; &#125;&#125; doReleaseShared()会释放“共享锁”。它会从前往后的遍历同步队列，依次“唤醒”然后“执行”队列中每个节点对应的线程；最终的目的是让这些线程释放它们所持有的锁。 公平/非公平共享锁和互斥锁ReentrantLock一样，ReadLock也分为公平锁和非公平锁。 公平锁和非公平锁的区别，体现在判断是否需要阻塞的函数readerShouldBlock()是不同的。 公平锁的readerShouldBlock()的源码如下： 123final boolean readerShouldBlock() &#123; return hasQueuedPredecessors();&#125; 在公平共享锁中，如果在当前线程的前面有其他线程在等待获取共享锁，则返回true；否则，返回false。 非公平锁的readerShouldBlock()的源码如下： 123final boolean readerShouldBlock() &#123; return apparentlyFirstQueuedIsExclusive();&#125; 在非公平共享锁中，它会无视当前线程的前面是否有其他线程在等待获取共享锁。只要该非公平共享锁对应的线程不为null，则返回true。","tags":"java j.u.c"},{"title":"深入理解Spring中的注解","url":"/posts/f989cad5.html","text":"概述Spring中的注解大概可以分为两类： Spring的bean容器相关的注解，或者说bean工厂相关的注解； Springmvc相关的注解。 Spring的bean容器相关的注解有：@Required,@Autowired,@PostConstruct,@PreDestory,还有Spring3.0开始支持的JSR-330标准javax.inject.*中的注解：@Inject,@Named,@Qualifer,@Provider,@Scope,@Singleton。 Springmvc相关的注解有：@Controller,@RequestMapping,@RequestParam,@ResponseBody等等。 要理解Spring中的注解，先要理解Java中的注解。 Java中的注解@OverrideJdk1.5开始引入注解，最熟悉常见的应该是@Override，它的定义如下： 12345678910111213141516171819/** * Indicates that a method declaration is intended to override a * method declaration in a supertype. If a method is annotated with * this annotation type compilers are required to generate an error * message unless at least one of the following conditions hold: * The method does override or implement a method declared in a * supertype. * The method has a signature that is override-equivalent to that of * any public method declared in Object. * * @author Peter von der Ah&amp;eacute; * @author Joshua Bloch * @jls 9.6.1.4 @Override * @since 1.5 */@Target(ElementType.METHOD)@Retention(RetentionPolicy.SOURCE)public @interface Override &#123;&#125; 从注释可以看出，@Override的作用是，提示编译器，使用了@Override注解的方法必须override父类或者java.lang.Object中的一个同名方法。我们看到@Override的定义中使用到了 @Target, @Retention，它们就是所谓的“元注解”——就是定义注解的注解，或者说注解注解的注解。 @Retention看下@Retention注解定义： 12345678910111213141516/** * Indicates how long annotations with the annotated type are to * be retained. If no Retention annotation is present on * an annotation type declaration, the retention policy defaults to * RetentionPolicy.CLASS. */@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Retention &#123; /** * Returns the retention policy. * @return the retention policy */ RetentionPolicy value();&#125; @Retention用于提示注解被保留多长时间，有三种取值： 12345678910111213141516171819public enum RetentionPolicy &#123; /** * Annotations are to be discarded by the compiler. */ SOURCE, /** * Annotations are to be recorded in the class file by the compiler * but need not be retained by the VM at run time. This is the default * behavior. */ CLASS, /** * Annotations are to be recorded in the class file by the compiler and * retained by the VM at run time, so they may be read reflectively. * * @see java.lang.reflect.AnnotatedElement */ RUNTIME&#125; RetentionPolicy.SOURCE 保留在源码级别，被编译器抛弃(@Override就是此类)；RetentionPolicy.CLASS被编译器保留在编译后的类文件级别，但是被虚拟机丢弃；RetentionPolicy.RUNTIME保留至运行时，可以被反射读取。 @Target1234567891011121314151617181920212223package java.lang.annotation;/** * Indicates the contexts in which an annotation type is applicable. The * declaration contexts and type contexts in which an annotation type may be * applicable are specified in JLS 9.6.4.1, and denoted in source code by enum * constants of java.lang.annotation.ElementType * @since 1.5 * @jls 9.6.4.1 @Target * @jls 9.7.4 Where Annotations May Appear */@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Target &#123; /** * Returns an array of the kinds of elements an annotation type * can be applied to. * @return an array of the kinds of elements an annotation type * can be applied to */ ElementType[] value();&#125; @Target用于提示该注解使用的地方，取值有： 12345678910111213141516171819202122232425262728public enum ElementType &#123; /** Class, interface (including annotation type), or enum declaration */ TYPE, /** Field declaration (includes enum constants) */ FIELD, /** Method declaration */ METHOD, /** Formal parameter declaration */ PARAMETER, /** Constructor declaration */ CONSTRUCTOR, /** Local variable declaration */ LOCAL_VARIABLE, /** Annotation type declaration */ ANNOTATION_TYPE, /** Package declaration */ PACKAGE, /** * Type parameter declaration * @since 1.8 */ TYPE_PARAMETER, /** * Use of a type * @since 1.8 */ TYPE_USE&#125; 分别表示该注解可以被使用的地方： 1) 类,接口,注解,enum;2) 属性域；3）方法；4）参数；5）构造函数；6）局部变量；7）注解类型；8）包。 所以： 1234@Target(ElementType.METHOD)@Retention(RetentionPolicy.SOURCE)public @interface Override &#123;&#125; 表示 @Override 只能使用在方法上，保留在源码级别，被编译器处理，然后抛弃掉。 @Documented12345678910111213/** * Indicates that annotations with a type are to be documented by javadoc * and similar tools by default. This type should be used to annotate the * declarations of types whose annotations affect the use of annotated * elements by their clients. If a type declaration is annotated with * Documented, its annotations become part of the public API * of the annotated elements. */@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Documented &#123;&#125; 表示注解是否能被 javadoc 处理并保留在文档中。 使用 元注解 来自定义注解 和 处理自定义注解有了元注解，就可以使用它来自定义我们需要的注解。结合自定义注解和AOP或者过滤器，十分强大。比如可以使用注解来实现权限的细粒度的控制——在类或者方法上使用权限注解，然后在AOP或者过滤器中进行拦截处理。下面是一个关于登录的权限的注解的实现： 12345678/** * 不需要登录注解 */@Target(&#123; ElementType.METHOD, ElementType.TYPE &#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface NoLogin &#123;&#125; 自定义了一个注解 @NoLogin, 可以被用于 方法 和 类 上，注解一直保留到运行期，可以被反射读取到。该注解的含义是：被 @NoLogin 注解的类或者方法，即使用户没有登录，也是可以访问的。下面就是对注解进行处理了： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 检查登录拦截器 * 如不需要检查登录可在方法或者controller上加上@NoLogin */public class CheckLoginInterceptor implements HandlerInterceptor &#123; private static final Logger logger = Logger.getLogger(CheckLoginInterceptor.class); @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; if (!(handler instanceof HandlerMethod)) &#123; logger.warn(\"当前操作handler不为HandlerMethod=\" + handler.getClass().getName() + \",req=\" + request.getQueryString()); return true; &#125; HandlerMethod handlerMethod = (HandlerMethod) handler; String methodName = handlerMethod.getMethod().getName(); // 判断是否需要检查登录 NoLogin noLogin = handlerMethod.getMethod().getAnnotation(NoLogin.class); if (null != noLogin) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"当前操作methodName=\" + methodName + \"不需要检查登录情况\"); &#125; return true; &#125; noLogin = handlerMethod.getMethod().getDeclaringClass().getAnnotation(NoLogin.class); if (null != noLogin) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"当前操作methodName=\" + methodName + \"不需要检查登录情况\"); &#125; return true; &#125; if (null == request.getSession().getAttribute(CommonConstants.SESSION_KEY_USER)) &#123; logger.warn(\"当前操作\" + methodName + \"用户未登录,ip=\" + request.getRemoteAddr()); response.getWriter().write(JsonConvertor.convertFailResult(ErrorCodeEnum.NOT_LOGIN).toString()); // 返回错误信息 return false; &#125; return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; &#125;&#125; 上面我们定义了一个登录拦截器，首先使用反射来判断方法上是否被 @NoLogin 注解： NoLogin noLogin = handlerMethod.getMethod().getAnnotation(NoLogin.class);然后判断类是否被 @NoLogin注解： noLogin = handlerMethod.getMethod().getDeclaringClass().getAnnotation(NoLogin.class); 如果被注解了，就返回 true，如果没有被注解，就判断是否已经登录，没有登录则返回错误信息给前台和false.这是一个简单的使用 注解 和 过滤器 来进行权限处理的例子。扩展开来，那么我们就可以使用注解，来表示某方法或者类，只能被具有某种角色，或者具有某种权限的用户所访问，然后在过滤器中进行判断处理。 Spring的bean容器相关的注解 @Autowired 是我们使用得最多的注解，其实就是 autowire=byType 就是根据类型的自动注入依赖（基于注解的依赖注入），可以被使用在属性域，方法，构造函数上。 @Qualifier 就是 autowire=byName, @Autowired注解判断多个bean类型相同时，就需要使用 @Qualifier(&quot;xxBean&quot;) 来指定依赖的bean的id： 123456@Controller@RequestMapping(\"/user\")public class HelloController &#123; @Autowired @Qualifier(\"userService\") private UserService userService; @Resource 属于JSR-250标准，用于属性域和方法上。也是 byName 类型的依赖注入。使用方式：@Resource(name=&quot;xxBean&quot;). 不带参数的 @Resource 默认值类名首字母小写。 JSR-330标准javax.inject.*中的注解(@Inject, @Named, @Qualifier, @Provider, @Scope, @Singleton)。@Inject就相当于@Autowired, @Named 就相当于 @Qualifier, 另外 @Named 用在类上还有 @Component的功能。 @Component, @Controller, @Service, @Repository, 这几个注解不同于上面的注解，上面的注解都是将被依赖的bean注入进来，而这几个注解的作用都是生产bean, 这些注解都是注解在类上，将类注解成spring的bean工厂中一个一个的bean。@Controller, @Service, @Repository基本就是语义更加细化的@Component。 @PostConstruct 和 @PreDestroy 不是用于依赖注入，而是bean 的生命周期。类似于 init-method(InitializeingBean)和destory-method(DisposableBean)。 Spring中注解的处理spring中注解的处理基本都是通过实现接口 BeanPostProcessor 来进行的： 1234public interface BeanPostProcessor &#123; Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;&#125; 相关的处理类有：AutowiredAnnotationBeanPostProcessor，CommonAnnotationBeanPostProcessor，PersistenceAnnotationBeanPostProcessor，RequiredAnnotationBeanPostProcessor。 这些处理类，可以通过 &lt;context:annotation-config/&gt; 配置 隐式的配置进spring容器。这些都是依赖注入的处理，还有生产bean的注解(@Component， @Controller, @Service, @Repository)的处理： &lt;context:component-scan base-package=&quot;net.aazj.service,net.aazj.aop&quot; /&gt; 这些都是通过指定扫描的基包路径来进行的，将他们扫描进spring的bean容器。注意 &lt;context:component-scan/&gt; 也会默认将 AutowiredAnnotationBeanPostProcessor，CommonAnnotationBeanPostProcessor 配置进来。所以&lt;context:annotation-config/&gt;是可以省略的。另外&lt;context:component-scan/&gt;也可以扫描@Aspect风格的AOP注解，但是需要在配置文件中加入 &lt;aop:aspectj-autoproxy/&gt;进行配合。 Spring注解和JSR-330标准注解的区别","tags":"spring"},{"title":"Java并发-ReentrantLock","url":"/posts/fd3ef277.html","text":"概述在Jdk5.0之前，协调对共享对象的访问可以使用的机制只有synchronized和volatile。synchronized关键字实现了内置锁，而volatile关键字保证了多线程的内存可见性。在大多数情况下，这些机制都能很好地完成工作，但却无法实现一些更高级的功能，例如，无法中断一个正在等待获取锁的线程，无法实现限定时间的获取锁机制，无法实现非阻塞结构的加锁规则等。而这些更灵活的加锁机制通常都能够提供更好的活跃性或性能。因此，在Jdk5.0中增加了一种新的机制：ReentrantLock。ReentrantLock类实现了Lock接口，并提供了与synchronized相同的互斥性和内存可见性，它的底层是通过AQS来实现多线程同步的。与内置锁相比ReentrantLock不仅提供了更丰富的加锁机制，而且在性能上也不逊色于内置锁(在以前的版本中甚至优于内置锁)。 synchronized关键字Java提供了内置锁来支持多线程的同步，JVM根据synchronized关键字来标识同步代码块。当线程进入同步代码块时会自动获取锁，退出同步代码块时会自动释放锁。一个线程获得锁后其他线程将会被阻塞。每个Java对象都可以用做一个实现同步的锁，synchronized关键字可以用来修饰对象方法，静态方法和代码块。当修饰对象方法和静态方法时锁分别是方法所在的对象和Class对象，当修饰代码块时需提供额外的对象作为锁。每个Java对象之所以可以作为锁，是因为在对象头中关联了一个monitor对象(管程)。线程进入同步代码块时会自动持有monitor对象，退出时会自动释放monitor对象，当monitor对象被持有时其他线程将会被阻塞。当然这些同步操作都由JVM底层帮你实现了，但以synchronized关键字修饰的方法和代码块在底层实现上还是有些区别的。synchronized关键字修饰的方法是隐式同步的，即无需通过字节码指令来控制的，JVM可以根据方法表中的ACC_SYNCHRONIZED访问标志来区分一个方法是否是同步方法；而synchronized关键字修饰的代码块是显式同步的，它是通过monitorenter和monitorexit字节码指令来控制线程对管程的持有和释放。monitor对象内部持有_count字段，_count等于0表示管程未被持有，_count大于0表示管程已被持有，每次持有线程重入时_count都会加1，每次持有线程退出时_count都会减1，这就是内置锁重入性的实现原理。另外，monitor对象内部还有两条队列_EntryList和_WaitSet，对应着AQS的同步队列和条件队列，当线程获取锁失败时会到_EntryList中阻塞，当调用锁对象的wait方法时线程将会进入_WaitSet中等待，这是内置锁的线程同步和条件等待的实现原理。 ReentrantLock和Synchronized的对比synchronized关键字是Java提供的内置锁机制，其同步操作由底层JVM实现，而ReentrantLock是java.util.concurrent包提供的显式锁，其同步操作由AQS同步器提供支持。ReentrantLock在加锁和内存上提供的语义与内置锁相同，此外它还提供了一些其他功能，包括定时的锁等待，可中断的锁等待，公平锁，以及实现非块结构的加锁。在早期的JDK版本中ReentrantLock在性能上还占有一定的优势，既然ReentrantLock拥有这么多优势，为什么还要使用synchronized关键字呢？事实上确实有许多人使用ReentrantLock来替代synchronized关键字的加锁操作。但是内置锁仍然有它特有的优势，内置锁为许多开发人员所熟悉，使用方式也更加的简洁紧凑，因为显式锁必须手动在finally块中调用unlock，所以使用内置锁相对来说会更加安全些。同时未来更加可能会去提升synchronized而不是ReentrantLock的性能。因为synchronized是JVM的内置属性，它能执行一些优化，例如对线程封闭的锁对象的锁消除优化，通过增加锁的粒度来消除内置锁的同步，而如果通过基于类库的锁来实现这些功能，则可能性不大。所以当需要一些高级功能时才应该使用ReentrantLock，这些功能包括：可定时的，可轮询的与可中断的锁获取操作，公平队列，以及非块结构的锁。否则，还是应该优先使用synchronized。 获取锁和释放锁首先通过一个例子来了解下ReentrantLock的用法：如果有一个共享变量count，有10个线程对它进行累加，每一个线程累加1000次，这段代码怎样设计呢？ 有很多种办法，可以利用synchronized关键字，也可以利用原子类AtomicInteger,那我们利用ReentrantLock怎样处理的？ 123456789101112131415161718192021222324252627282930package main.java.com.study.lock;/** * @author: whb * @description: ReentrantLock测试类 */public class ReentrantLockTest &#123; private static int count = 0; //默认是获取一个非公平锁 private static ReentrantLock lock = new ReentrantLock(); public static void main(String[] args) throws InterruptedException &#123; for (int i = 0; i &lt; 10; i++) &#123; new Thread(() -&gt; &#123; try &#123; //执行前先加锁 lock.lock(); for (int j = 0; j &lt; 1000; j++) &#123; count++; &#125; &#125; finally &#123; //最后释放锁 lock.unlock(); &#125; &#125;).start(); &#125; Thread.sleep(5000); System.out.println(\"count=\" + count); &#125;&#125; 以下是获取锁和释放锁这两个操作的API。 12345678//获取锁的操作public void lock() &#123; sync.lock();&#125;//释放锁的操作public void unlock() &#123; sync.release(1);&#125; 锁的获取和释放的源码并没有更多的逻辑，而核心的逻辑分别委托给Sync对象的lock方法和release方法。那么Sync又是什么呢？在AQS的文章中提到过，在并发包中锁的底层实现都是通过AQS框架实现的。如果想实现独占锁，子类只需要实现如下方法： 1：获取锁：tryAcquire()2：释放锁：tryRelease() 如果想实现共享锁： 1: 获取锁：tryAcquireShared()2: 释放锁：tryReleaseShared() Sync就是AQS的子类,并且是独占锁模式。 在ReentrantLock中有两种模式：一种是非公平模式获取锁，另一种是公平模式获取锁。默认情况下是非公平的。 1234567891011121314151617181920212223242526272829303132public class ReentrantLock implements Lock, java.io.Serializable &#123; private final Sync sync; abstract static class Sync extends AbstractQueuedSynchronizer &#123; abstract void lock(); &#125; //实现非公平锁的同步器 static final class NonfairSync extends Sync &#123; final void lock() &#123; ... &#125; &#125; //实现公平锁的同步器 static final class FairSync extends Sync &#123; final void lock() &#123; ... &#125; &#125; //默认构造器：非公平锁 public ReentrantLock() &#123; sync = new NonfairSync(); &#125; //带参构造器：fair=true表示是公平模式获取锁;fair=false表示是非公平模式获取锁 public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); &#125;&#125; 调用默认无参构造器会将NonfairSync实例赋值给sync，此时锁是非公平锁。有参构造器允许通过参数来指定是将FairSync实例还是NonfairSync实例赋值给sync。NonfairSync和FairSync都是继承自Sync类并重写了lock()方法，所以公平锁和非公平锁在获取锁的方式上有些区别。再来看看释放锁的操作，每次调用unlock()方法都只是去执行sync.release(1)操作，这步操作会调用AbstractQueuedSynchronizer类的release()方法，下面看一下： 123456789101112131415//释放锁的操作(独占模式)public final boolean release(int arg) &#123; //尝试释放锁 if (tryRelease(arg)) &#123; //获取head结点 Node h = head; //如果head结点不为空并且等待状态不等于0就去唤醒后继结点 if (h != null &amp;&amp; h.waitStatus != 0) &#123; //唤醒后继结点 unparkSuccessor(h); &#125; return true; &#125; return false;&#125; 这个release方法是AQS提供的释放锁操作的API，它首先会去调用tryRelease方法去尝试获取锁，tryRelease方法是抽象方法，它的实现逻辑在子类Sync里面。 123456789101112131415161718//尝试释放锁protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; //如果持有锁的线程不是当前线程就抛出异常 if (Thread.currentThread() != getExclusiveOwnerThread()) &#123; throw new IllegalMonitorStateException(); &#125; boolean free = false; //如果同步状态为0则表明锁被释放 if (c == 0) &#123; //设置锁被释放的标志为真 free = true; //设置占用线程为空 setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; 这个tryRelease方法首先会获取当前同步状态，并将当前同步状态减去传入的参数值得到新的同步状态，然后判断新的同步状态是否等于0，如果等于0则表明当前锁被释放，然后先将锁的释放状态置为真，再将当前占有锁的线程清空，最后调用setState方法设置新的同步状态并返回锁的释放状态。 公平锁/非公平锁ReentrantLock是公平锁还是非公平锁是基于sync指向的是哪个具体实例。在构造时会为成员变量sync赋值，如果赋值为NonfairSync实例则表明是非公平锁，如果赋值为FairSync实例则表明为公平锁。如果是公平锁，线程将按照它们发出请求的顺序来获得锁，但在非公平锁上，则允许插队行为：当一个线程请求非公平的锁时，如果在发出请求的同时该锁的状态变为可用，那么这个线程将跳过队列中所有等待的线程直接获得这个锁。 非公平锁12345678910111213141516171819202122232425//非公平同步器static final class NonfairSync extends Sync &#123; //实现父类的抽象获取锁的方法 final void lock() &#123; //使用CAS方式设置同步状态 if (compareAndSetState(0, 1)) &#123; //如果设置成功则表明锁没被占用 setExclusiveOwnerThread(Thread.currentThread()); &#125; else &#123; //否则表明锁已经被占用, 调用acquire让线程去同步队列排队获取 acquire(1); &#125; &#125; //尝试获取锁的方法 protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125;//以不可中断模式获取锁(独占模式)public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) &#123; selfInterrupt(); &#125;&#125; 可以看到在非公平锁的lock方法中，线程第一步就会以CAS方式将同步状态的值从0改为1。其实这步操作就等于去尝试获取锁，如果更改成功则表明线程刚来就获取了锁，而不必再去同步队列里面排队了。如果更改失败则表明线程刚来时锁还未被释放，所以接下来就调用acquire方法。这个acquire方法是继承自AbstractQueuedSynchronizer的方法：线程进入acquire方法后首先去调用tryAcquire方法尝试去获取锁，由于NonfairSync覆盖了tryAcquire方法，并在方法中调用了父类Sync的nonfairTryAcquire方法，所以这里会调用到nonfairTryAcquire方法去尝试获取锁。下面看看这个方法具体做了些什么。 123456789101112131415161718192021222324252627//非公平的获取锁final boolean nonfairTryAcquire(int acquires) &#123; //获取当前线程 final Thread current = Thread.currentThread(); //获取当前同步状态 int c = getState(); //如果同步状态为0则表明锁没有被占用 if (c == 0) &#123; //使用CAS更新同步状态 if (compareAndSetState(0, acquires)) &#123; //设置目前占用锁的线程 setExclusiveOwnerThread(current); return true; &#125; //否则的话就判断持有锁的是否是当前线程 &#125;else if (current == getExclusiveOwnerThread()) &#123; //如果锁是被当前线程持有的, 就直接修改当前同步状态 int nextc = c + acquires; if (nextc &lt; 0) &#123; throw new Error(\"Maximum lock count exceeded\"); &#125; setState(nextc); return true; &#125; //如果持有锁的不是当前线程则返回失败标志 return false;&#125; nonfairTryAcquire方法是Sync的方法，可以看到线程进入此方法后首先去获取同步状态，如果同步状态为0就使用CAS操作更改同步状态，其实这又是获取了一遍锁。如果同步状态不为0表明锁被占用，此时会先去判断持有锁的线程是否是当前线程，如果是的话就将同步状态加1，否则的话这次尝试获取锁的操作宣告失败。于是会调用addWaiter方法将线程添加到同步队列。综上来看，在非公平锁的模式下一个线程在进入同步队列之前会尝试获取两遍锁，如果获取成功则不进入同步队列排队，否则才进入同步队列排队。 公平锁1234567891011121314151617181920212223242526272829303132333435363738394041424344//实现公平锁的同步器static final class FairSync extends Sync &#123; //实现父类的抽象获取锁的方法 final void lock() &#123; //调用acquire让线程去同步队列排队获取 acquire(1); &#125; //尝试获取锁的方法 protected final boolean tryAcquire(int acquires) &#123; //获取当前线程 final Thread current = Thread.currentThread(); //获取当前同步状态 int c = getState(); //如果同步状态0则表示锁没被占用 if (c == 0) &#123; //判断同步队列是否有前驱结点 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; //如果没有前驱结点且设置同步状态成功就表示获取锁成功 setExclusiveOwnerThread(current); return true; &#125; //否则判断是否是当前线程持有锁 &#125;else if (current == getExclusiveOwnerThread()) &#123; //如果是当前线程持有锁就直接修改同步状态 int nextc = c + acquires; if (nextc &lt; 0) &#123; throw new Error(\"Maximum lock count exceeded\"); &#125; setState(nextc); return true; &#125; //如果不是当前线程持有锁则获取失败 return false; &#125;&#125;//判断是否有前驱结点public final boolean hasQueuedPredecessors() &#123; Node t = tail; Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());&#125; 调用公平锁的lock方法时会直接调用acquire方法。同样的，acquire方法首先会调用FairSync重写的tryAcquire方法来尝试获取锁。在该方法中也是首先获取同步状态的值，如果同步状态为0则表明此时锁刚好被释放，这时和非公平锁不同的是它会先去调用hasQueuedPredecessors方法查询同步队列中是否有人在排队，如果没人在排队才会去修改同步状态的值，可以看到公平锁在这里采取礼让的方式而不是自己马上去获取锁。除了这一步和非公平锁不一样之外，其他的操作都是一样的。综上所述，可以看到公平锁在进入同步队列之前只检查了一遍锁的状态，即使是发现了锁是开的也不会自己马上去获取，而是先让同步队列中的线程先获取，所以可以保证在公平锁下所有线程获取锁的顺序都是先来后到的，这也保证了获取锁的公平性。 那么为什么不希望所有锁都是公平的呢？毕竟公平是一种好的行为，而不公平是一种不好的行为。由于线程的挂起和唤醒操作存在较大的开销而影响系统性能，特别是在竞争激烈的情况下公平锁将导致线程频繁的挂起和唤醒操作，而非公平锁可以减少这样的操作，所以在性能上将会优于公平锁。另外，由于大部分线程使用锁的时间都是非常短暂的，而线程的唤醒操作会存在延时情况，有可能在A线程被唤醒期间B线程马上获取了锁并使用完释放了锁，这就导致了双赢的局面，A线程获取锁的时刻并没有推迟，但B线程提前使用了锁，并且吞吐量也获得了提高。 条件队列的实现机制内置条件队列存在一些缺陷，每个内置锁都只能有一个相关联的条件队列，这导致多个线程可能在同一个条件队列上等待不同的条件谓词，那么每次调用notifyAll时都会将所有等待的线程唤醒，当线程醒来后发现并不是自己等待的条件谓词，转而又会被挂起。这导致做了很多无用的线程唤醒和挂起操作，而这些操作将会大量浪费系统资源，降低系统的性能。如果想编写一个带有多个条件谓词的并发对象，或者想获得除了条件队列可见性之外的更多控制权，就需要使用显式的Lock和Condition而不是内置锁和条件队列。一个Condition和一个Lock关联在一起，就像一个条件队列和一个内置锁相关联一样。要创建一个Condition，可以在相关联的Lock上调用Lock.newCondition方法。下面看一个使用Condition的示例。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package main.java.com.study.producerconsumer.v2;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;/** * @author: whb * @description: 缓冲区 */public class ConditionBuffer &#123; private final Lock lock = new ReentrantLock(); /** * 不满 */ final Condition notFull = lock.newCondition(); /** * 不空 */ final Condition notEmpty = lock.newCondition(); /** * 缓冲区 */ final Object[] items = new Object[100]; int putptr, takeptr, count; //生产方法 public void put(Object x) throws InterruptedException &#123; lock.lock(); try &#123; while (count == items.length) &#123; //队列已满, 线程在notFull队列上等待 notFull.await(); &#125; items[putptr] = x; if (++putptr == items.length) &#123; putptr = 0; &#125; ++count; //生产成功, 唤醒notEmpty队列的结点 notEmpty.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125; //消费方法 public Object take() throws InterruptedException &#123; lock.lock(); try &#123; while (count == 0) &#123; //队列为空, 线程在notEmpty队列上等待 notEmpty.await(); &#125; Object x = items[takeptr]; if (++takeptr == items.length) &#123; takeptr = 0; &#125; --count; //消费成功, 唤醒notFull队列的结点 notFull.signal(); return x; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 一个lock对象可以产生多个条件队列，这里产生了两个条件队列notFull和notEmpty。当容器已满时再调用put方法的线程需要进行阻塞，等待条件谓词为真(容器不满)才醒来继续执行；当容器为空时再调用take方法的线程也需要阻塞，等待条件谓词为真(容器不空)才醒来继续执行。这两类线程是根据不同的条件谓词进行等待的，所以它们会进入两个不同的条件队列中阻塞，等到合适时机再通过调用Condition对象上的API进行唤醒。下面是newCondition方法的实现代码。 1234567891011//创建条件队列public Condition newCondition() &#123; return sync.newCondition();&#125;abstract static class Sync extends AbstractQueuedSynchronizer &#123; //新建Condition对象 final ConditionObject newCondition() &#123; return new ConditionObject(); &#125;&#125; ReentrantLock上的条件队列的实现都是基于AbstractQueuedSynchronizer的，在调用newCondition方法时所获得的Condition对象就是AQS的内部类ConditionObject的实例。所有对条件队列的操作都是通过调用ConditionObject对外提供的API来完成的。","tags":"java j.u.c"},{"title":"Java并发-LockSupport","url":"/posts/2c562869.html","text":"概述LockSupport是用来创建锁和其他同步类的基本线程阻塞原语。 方法列表12345678910111213141516// 返回提供给最近一次尚未解除阻塞的 park 方法调用的 blocker 对象，如果该调用不受阻塞，则返回 null。static Object getBlocker(Thread t)// 为了线程调度，禁用当前线程，除非许可可用。static void park()// 为了线程调度，在许可可用之前禁用当前线程。static void park(Object blocker)// 为了线程调度禁用当前线程，最多等待指定的等待时间，除非许可可用。static void parkNanos(long nanos)// 为了线程调度，在许可可用前禁用当前线程，并最多等待指定的等待时间。static void parkNanos(Object blocker, long nanos)// 为了线程调度，在指定的时限前禁用当前线程，除非许可可用。static void parkUntil(long deadline)// 为了线程调度，在指定的时限前禁用当前线程，除非许可可用。static void parkUntil(Object blocker, long deadline)// 如果给定线程的许可尚不可用，则使其可用。static void unpark(Thread thread) 原理LockSupport中的park() 和 unpark() 的作用分别是阻塞线程和解除阻塞线程，而且park()和unpark()不会遇到Thread.suspend 和 Thread.resume所可能引发的死锁 问题。因为park() 和 unpark()有许可的存在，unpark()为线程提供“许可(permit)”，线程调用park()则等待“许可” ；调用 park() 的线程和另一个试图将其 unpark() 的线程之间的竞争将保持活性。 这个有点像信号量，可是这个“许可”是不能叠加的，“许可”是一次性的。 比如：线程B连续调用了三次unpark函数，当线程A调用park函数就使用掉这个“许可”，假设线程A再次调用park，则进入等待状态。注意。unpark函数能够先于park调用。比方线程B调用unpark函数，给线程A发了一个“许可”，那么当线程A调用park时。它发现已经有“许可”了。那么它会立即再继续执行。 代码示例1123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package main.java.com.study.lock.lockSupport;import java.util.concurrent.locks.LockSupport;/** * @author: whb * @description: LockSupport测试类 */public class LockSupportDemoOne &#123; public static void main(String args[]) &#123; Thread thread = Thread.currentThread(); ThreadParkService service = new ThreadParkService(thread); System.out.println(Thread.currentThread().getName() + \" start1\"); service.start(); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" center\"); LockSupport.park(thread); System.out.println(\"end\"); &#125;&#125;class ThreadParkService extends Thread &#123; private Thread thread; public ThreadParkService(Thread thread) &#123; this.thread = thread; &#125; @Override public void run() &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" wakup before\"); LockSupport.unpark(thread);//解锁后线程2立马就可以执行了。 try &#123; System.out.println(\"解锁后休息三秒哦\"); Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" wakup after\"); &#125;&#125; 执行结果1123456main start1 Thread-0 wakup before 解锁后休息三秒哦 main center end Thread-0 wakup after 结果说明1 主线程main先打印了自己的东西，主线程到了park时被阻塞了。线程1异步执行打印了 wakup beforemain center打印在“解锁后休息3s哦”说明线程1中的unpark先与park执行。线程1执行了unpark了，这个时候主线程中的park立马被唤醒，开始执行了end。然后线程1等待了3s后执行了wakup after。 总结1 unpark，可以在park之前执行。它们一对一,不管什么时候park只要有unpark过一次就好了。park被阻塞后，unpark执行后park立即被唤醒。与wait与notify不同，notify唤醒wait后，还必须等待notify代码块中的代码执行完毕后wait才能执行。 代码示例21234567891011121314151617181920212223242526272829303132333435363738394041424344package main.java.com.study.lock.lockSupport;import java.util.concurrent.locks.LockSupport;/** * @author: whb * @description: LockSupport测试示例 */public class LockSupportDemoTwo &#123; public static void main(String args[]) &#123; Thread thread = Thread.currentThread(); ThreadParkService2 service2 = new ThreadParkService2(thread); System.out.println(Thread.currentThread().getName() + \" start2\"); service2.start(); System.out.println(\" 漂亮的分割线---\"); ThreadParkService service = new ThreadParkService(service2); System.out.println(Thread.currentThread().getName() + \" start1\"); service.start(); &#125;&#125;class ThreadParkService2 extends Thread &#123; private Thread thread; public ThreadParkService2(Thread thread) &#123; this.thread = thread; &#125; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + \"-线程2开始park before\"); //阻塞当前执行的线程，不能阻塞其他线程，看源码哦。里面阻塞时并不需要任何传参。 LockSupport.park(this); //这里并不会阻塞thread线程，阻塞的还是当前线程。thread只是做一个标记方便被锁的对象。 //LockSupport.park(thread); System.out.println(Thread.currentThread().getName() + \"-线程2park after\"); &#125;&#125; 执行结果212345678main start2 漂亮的分割线— Thread-0-线程2开始park before main start1 Thread-1 wakup before 解锁后休息三秒哦 Thread-0-线程2park after Thread-1 wakup after 结果说明2其实看结果就是线程2阻塞了，线程1唤醒了线程2.就这么简单。 总结 park()与park(Object obj)有什么区别？park()是可以不需要参数的哦，就是说加锁时，不需要指定对象。那么它是怎么加锁的呢？源码如下： 123456public static void park(Object blocker) &#123; Thread t = Thread.currentThread(); setBlocker(t, blocker);//记录当前线程等待的对象（阻塞对象）； UNSAFE.park(false, 0L);//阻塞当前线程； setBlocker(t, null);//当前线程等待对象置为null。&#125; 可以看出来，阻塞的时候UNSAFE.park(false, 0L);根本不需要外面的入参数。 那么setBlocker是用来干吗的呢？ 它是用来做监控用的，当前被阻塞的对象是那个，可以通过LockSupport中的get之类的方法来获取当前被阻塞的对象。UNSAFE.park(false, 0L);锁住的是当前正在执行的线程。 代码示例2中线程2有一个参数，把主线程传过去了， 想用线程2来阻塞主线程。 main中： 123Thread thread = Thread.currentThread(); ThreadParkService2 service2 = new ThreadParkService2(thread); … 线程2中： 1LockSupport.park(thread); 这样是不行的，前面说过park阻塞的是当前正在执行的线程，和外面传递进来的值无关。所以这里被阻塞的还是线程2。 unpark需要带上参数，这样才知道解锁那个线程。LockSupport.park 锁住的是Thread.currentThread()当前线程。 Thread.currentThread()与this类继承了Thread类后，可以使用this.getName();获取当前线程的名称，但是Thread.currentThread().getName()也获取线程名称。那么它们有什么区别呢？ 继承了Thread类后使用this.getName()获取的当前对象的线程名称，而Thread.currentThread().getName()获取的是当前正在运行的线程的名称。 park和wait的区别 unpark可以先于park执行，notify不能先于wait执行，不然就不能唤醒了。 unpark需要指定唤醒的线程，而notify是随机唤醒一个wait。 unpark解锁后park立即可以执行，notify解锁后wait需要等待notify所在的synchronized代码块执行完毕后wait才能继续执行。 wait必须在Synchronizer里面才能有效，unpark则不用。 wait是对象锁，park则是线程锁。 应用示例123456789101112131415161718192021222324252627282930313233343536373839package main.java.com.study.lock.lockSupport;import java.util.concurrent.locks.LockSupport;/** * @author: whb * @description: 阻塞原语测试 */public class LockSupportTest &#123; /** * 主线程 */ private static Thread mainThread; public static void main(String[] args) &#123; ThreadA ta = new ThreadA(\"ta\"); //获取主线程 mainThread = Thread.currentThread(); System.out.println(Thread.currentThread().getName() + \" start ta\"); //启动线程ta ta.start(); System.out.println(Thread.currentThread().getName() + \" block\"); //主线程阻塞 LockSupport.park(mainThread); System.out.println(Thread.currentThread().getName() + \" continue\"); &#125; static class ThreadA extends Thread &#123; public ThreadA(String name) &#123; super(name); &#125; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + \" wakeup others.\"); LockSupport.unpark(mainThread); &#125; &#125;&#125; 执行结果：","tags":"java j.u.c"},{"title":"Java并发-CountDownLatch","url":"/posts/bbc8910e.html","text":"概述CountDownLatch(闭锁)是一个很有用的工具类，利用它我们可以拦截一个或多个线程使其在某个条件成熟后再执行。它的内部提供了一个计数器，在构造闭锁时必须指定计数器的初始值，且计数器的初始值必须大于0。另外它还提供了一个countDown方法来操作计数器的值，每调用一次countDown方法计数器都会减1，直到计数器的值减为0时就代表条件已成熟，所有因调用await方法而阻塞的线程都会被唤醒。这就是CountDownLatch的内部机制，看起来很简单，无非就是阻塞一部分线程让其在达到某个条件之后再执行。但是CountDownLatch的应用场景却比较广泛，只要你脑洞够大利用它就可以玩出各种花样。最常见的一个应用场景是开启多个线程同时执行某个任务，等到所有任务都执行完再统计汇总结果。下图动态演示了闭锁阻塞线程的整个过程。 上图演示了有5个线程因调用await方法而被阻塞，它们需要等待计数器的值减为0才能继续执行。计数器的初始值在构造闭锁时被指定，后面随着每次countDown方法的调用而减1。 构造器12345//构造器public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException(\"count &lt; 0\"); this.sync = new Sync(count);&#125; CountDownLatch只有一个带参构造器，必须传入一个大于0的值作为计数器初始值，否则会报错。可以看到在构造方法中只是去new了一个Sync对象并赋值给成员变量sync。和其他同步工具类一样，CountDownLatch的实现依赖于AQS，它是AQS共享模式下的一个应用。CountDownLatch实现了一个内部类Sync并用它去继承AQS，这样就能使用AQS提供的大部分方法了。下面来看一下Sync内部类的代码。 123456789101112131415161718192021222324252627282930313233343536373839//同步器private static final class Sync extends AbstractQueuedSynchronizer &#123; //构造器 Sync(int count) &#123; setState(count); &#125; //获取当前同步状态 int getCount() &#123; return getState(); &#125; //尝试获取锁 //返回负数：表示当前线程获取失败 //返回零值：表示当前线程获取成功, 但是后继线程不能再获取了 //返回正数：表示当前线程获取成功, 并且后继线程同样可以获取成功 protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1; &#125; //尝试释放锁 protected boolean tryReleaseShared(int releases) &#123; for (;;) &#123; //获取同步状态 int c = getState(); //如果同步状态为0, 则不能再释放了 if (c == 0) &#123; return false; &#125; //否则的话就将同步状态减1 int nextc = c-1; //使用CAS方式更新同步状态 if (compareAndSetState(c, nextc)) &#123; return nextc == 0; &#125; &#125; &#125;&#125; 可以看到Sync的构造方法会将同步状态的值设置为传入的参数值。之后每次调用countDown方法都会将同步状态的值减1，这也就是计数器的实现原理。在平时使用CountDownLatch工具类时最常用的两个方法就是await方法和countDown方法。调用await方法会阻塞当前线程直到计数器为0，调用countDown方法会将计数器的值减1直到减为0。 阻塞线程await123456789101112131415161718//导致当前线程等待, 直到state减少到0, 或者线程被打断public void await() throws InterruptedException &#123; //以响应线程中断方式获取 sync.acquireSharedInterruptibly(1);&#125;//以可中断模式获取锁(共享模式)public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; //首先判断线程是否中断, 如果是则抛出异常 if (Thread.interrupted()) &#123; throw new InterruptedException(); &#125; //1.尝试去获取锁 if (tryAcquireShared(arg) &lt; 0) &#123; //2. 如果获取失败则进人该方法 doAcquireSharedInterruptibly(arg); &#125;&#125; 当线程调用await方法时其实是调用到了AQS的acquireSharedInterruptibly方法，该方法是以响应线程中断的方式来获取锁的。在acquireSharedInterruptibly方法首先会去调用tryAcquireShared方法尝试获取锁。Sync里面重写的tryAcquireShared方法的逻辑，方法的实现逻辑很简单，就是判断当前同步状态是否为0，如果为0则返回1表明可以获取锁，否则返回-1表示不能获取锁。如果tryAcquireShared方法返回1则线程能够不必等待而继续执行，如果返回-1那么后续就会去调用doAcquireSharedInterruptibly方法让线程进入到同步队列里面等待。这就是调用await方法会阻塞当前线程的原理。 唤醒线程countDown123456789101112131415//减少state的方法public void countDown() &#123; sync.releaseShared(1);&#125;//释放锁的操作(共享模式)public final boolean releaseShared(int arg) &#123; //1.尝试去释放锁 if (tryReleaseShared(arg)) &#123; //2.如果释放成功就唤醒其他线程 doReleaseShared(); return true; &#125; return false;&#125; countDown方法里面调用了releaseShared方法，该方法同样是AQS里面的方法。releaseShared方法里面首先是调用tryReleaseShared方法尝试释放锁，tryReleaseShared方法在AQS里面是一个抽象方法，它的具体实现逻辑在子类Sync类里面，在上面贴出的Sync类代码里可以找到该方法。tryReleaseShared方法如果返回true表示释放成功，返回false表示释放失败，只有当将同步状态减1后该同步状态恰好为0时才会返回true，其他情况都是返回false。那么当tryReleaseShared返回true之后就会马上调用doReleaseShared方法去唤醒同步队列的所有线程。这样就解释了为什么最后一次调用countDown方法将计数器减为0后就会唤醒所有被阻塞的线程。 总结 CountDownLatch是通过“共享锁”实现的。在创建CountDownLatch中时，会传递一个int类型参数count，该参数是“锁计数器”的初始状态，表示该“共享锁”最多能被count个线程同时获取。当某线程调用该CountDownLatch对象的await()方法时，该线程会等待“共享锁”可用时，才能获取“共享锁”进而继续运行。而“共享锁”可用的条件，就是“锁计数器”的值为0！而“锁计数器”的初始值为count，每当一个线程调用该CountDownLatch对象的countDown()方法时，才将“锁计数器”-1；通过这种方式，必须有count个线程调用countDown()之后，“锁计数器”才为0，而前面提到的等待线程才能继续运行！ 应用示例在玩欢乐斗地主时必须等待三个玩家都到齐才可以进行发牌。 123456789101112131415161718192021222324252627public class Player extends Thread &#123; private static int count = 1; private final int id = count++; private CountDownLatch latch; public Player(CountDownLatch latch) &#123; this.latch = latch; &#125; @Override public void run() &#123; System.out.println(\"【玩家\" + id + \"】已入场\"); latch.countDown(); &#125; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch latch = new CountDownLatch(3); System.out.println(\"牌局开始, 等待玩家入场...\"); new Player(latch).start(); new Player(latch).start(); new Player(latch).start(); latch.await(); System.out.println(\"玩家已到齐, 开始发牌...\"); &#125; &#125; 运行结果显示发牌操作一定是在所有玩家都入场后才进行。将latch.await()注释掉，对比下看看结果。 可以看到在注释掉latch.await()这行之后，就不能保证在所有玩家入场后才开始发牌了。","tags":"java j.u.c"},{"title":"Java并发-Semaphore","url":"/posts/44092bd5.html","text":"概述Semaphore(信号量)是AQS共享模式的一个应用，可以允许多个线程同时对共享资源进行操作，并且可以有效的控制并发数，利用它可以很好的实现流量控制。Semaphore提供了一个许可证的概念，可以把这个许可证看作车票，只有成功获取车票的人才能够上车，并且车票是有数量的，不可能毫无限制的发下去，这样就会导致车辆超载。所以当车票发完的时候(车辆满载)，其他人就只能等下一趟车。如果中途有人下车，那么他的位置将会空闲出来，因此如果这时其他人想要上车的话就又可以获得车票了。 构造器123456789//构造器1public Semaphore(int permits) &#123; sync = new NonfairSync(permits);&#125;//构造器2public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits);&#125; Semaphore提供了两个带参构造器，没有提供无参构造器。这两个构造器都必须传入一个初始的许可证数量，使用构造器1构造出来的信号量在获取许可证时会采用非公平方式获取，使用构造器2可以通过参数指定获取许可证的方式(公平or非公平)。Semaphore主要对外提供了两类API，获取许可证和释放许可证，默认的是获取和释放一个许可证，也可以传入参数来同时获取和释放多个许可证。 获取许可证12345678910111213141516171819//获取一个许可证(响应中断)public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125;//获取一个许可证(不响应中断)public void acquireUninterruptibly() &#123; sync.acquireShared(1);&#125;//尝试获取许可证(非公平获取)public boolean tryAcquire() &#123; return sync.nonfairTryAcquireShared(1) &gt;= 0;&#125;//尝试获取许可证(定时获取)public boolean tryAcquire(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));&#125; 上面的API是Semaphore提供的默认获取许可证操作。每次只获取一个许可证。除了直接获取还提供了尝试获取，直接获取操作在失败之后可能会阻塞线程，而尝试获取则不会。另外还需注意的是tryAcquire方法是使用非公平方式尝试获取的。平时比较常用到的是acquire方法去获取许可证。acquire方法里面直接就是调用sync.acquireSharedInterruptibly(1)，这个方法是AQS里面的方法，下面再来回顾一下这个方法。 123456789101112//以可中断模式获取锁(共享模式)public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; //首先判断线程是否中断, 如果是则抛出异常 if (Thread.interrupted()) &#123; throw new InterruptedException(); &#125; //1.尝试去获取锁，获取成功直接返回 if (tryAcquireShared(arg) &lt; 0) &#123; //2. 如果获取失败则进入该方法 doAcquireSharedInterruptibly(arg); &#125;&#125; acquireSharedInterruptibly方法首先就是去调用tryAcquireShared方法去尝试获取，tryAcquireShared在AQS里面是抽象方法，FairSync和NonfairSync这两个派生类实现了该方法的逻辑。FairSync实现的是公平获取的逻辑，而NonfairSync实现的非公平获取的逻辑。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859abstract static class Sync extends AbstractQueuedSynchronizer &#123; //非公平方式尝试获取 final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; //获取可用许可证 int available = getState(); //获取剩余许可证 int remaining = available - acquires; //1.如果remaining小于0则直接返回remaining //2.如果remaining大于0则先更新同步状态再返回remaining if (remaining &lt; 0 || compareAndSetState(available, remaining)) &#123; return remaining; &#125; &#125; &#125;&#125;//非公平同步器static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = -2694183684443567898L; NonfairSync(int permits) &#123; super(permits); &#125; //尝试获取许可证 protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires); &#125;&#125;//公平同步器static final class FairSync extends Sync &#123; private static final long serialVersionUID = 2014338818796000944L; FairSync(int permits) &#123; super(permits); &#125; //尝试获取许可证 protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; //判断同步队列前面有没有人排队 if (hasQueuedPredecessors()) &#123; //如果有的话就直接返回-1，表示尝试获取失败 return -1; &#125; //获取可用许可证 int available = getState(); //获取剩余许可证 int remaining = available - acquires; //1.如果remaining小于0则直接返回remaining //2.如果remaining大于0则先更新同步状态再返回remaining if (remaining &lt; 0 || compareAndSetState(available, remaining)) &#123; return remaining; &#125; &#125; &#125;&#125; NonfairSync的tryAcquireShared方法直接调用的是nonfairTryAcquireShared方法，这个方法是在父类Sync里面的。非公平获取锁的逻辑是先取出当前同步状态(同步状态表示许可证个数)，将当前同步状态减去传入的参数，如果结果不小于0的话证明还有可用的许可证，那么就直接使用CAS操作更新同步状态的值，最后不管结果是否小于0都会返回该结果值。这里要了解tryAcquireShared方法返回值的含义，返回负数表示获取失败，零表示当前线程获取成功但后续线程不能再获取，正数表示当前线程获取成功并且后续线程也能够获取。再来看看acquireSharedInterruptibly方法的代码。 123456789101112131415//以可中断模式获取锁(共享模式)public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; //首先判断线程是否中断, 如果是则抛出异常 if (Thread.interrupted()) &#123; throw new InterruptedException(); &#125; //1.尝试去获取锁 //负数：表示获取失败 //零值：表示当前线程获取成功, 但是后继线程不能再获取了 //正数：表示当前线程获取成功, 并且后继线程同样可以获取成功 if (tryAcquireShared(arg) &lt; 0) &#123; //2. 如果获取失败则进人该方法 doAcquireSharedInterruptibly(arg); &#125;&#125; 如果返回的remaining小于0的话就代表获取失败，因此tryAcquireShared(arg) &lt; 0就为true，所以接下来就会调用doAcquireSharedInterruptibly方法，这个方法是AQS的方法，它会将当前线程包装成结点放入同步队列尾部，并且有可能挂起线程。这也是当remaining小于0时线程会排队阻塞的原因。而如果返回的remaining&gt;=0的话就代表当前线程获取成功，因此tryAcquireShared(arg) &lt; 0就为flase，所以就不会再去调用doAcquireSharedInterruptibly方法阻塞当前线程了。以上是非公平获取的整个逻辑，而公平获取时仅仅是在此之前先去调用hasQueuedPredecessors方法判断同步队列是否有人在排队，如果有的话就直接return -1表示获取失败，否则才继续执行下面和非公平获取一样的步骤。 释放许可1234//释放一个许可证public void release() &#123; sync.releaseShared(1);&#125; 调用release方法是释放一个许可证，它的操作很简单，就调用了AQS的releaseShared方法，下面来看看这个方法。 12345678910//释放锁的操作(共享模式)public final boolean releaseShared(int arg) &#123; //1.尝试去释放锁 if (tryReleaseShared(arg)) &#123; //2.如果释放成功就唤醒其他线程 doReleaseShared(); return true; &#125; return false;&#125; AQS的releaseShared方法首先调用tryReleaseShared方法尝试释放锁，这个方法的实现逻辑在子类Sync里面。Semaphore重写了tryReleaseShared()，它的源码如下： 12345678910111213protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; // 获取“可以获得的信号量的许可数” int current = getState(); // 获取“释放releases个信号量许可之后，剩余的信号量许可数” int next = current + releases; if (next &lt; current) // overflow throw new Error(\"Maximum permit count exceeded\"); // 设置“可以获得的信号量的许可数”为next。 if (compareAndSetState(current, next)) return true; &#125;&#125; tryReleaseShared方法里面采用for循环进行自旋，首先获取同步状态，将同步状态加上传入的参数，然后以CAS方式更新同步状态，更新成功就返回true并跳出方法，否则就继续循环直到成功为止。如果tryReleaseShared()尝试释放共享锁失败，则会调用doReleaseShared()去释放共享锁。doReleaseShared()的源码如下： 1234567891011121314151617181920212223242526private void doReleaseShared() &#123; for (;;) &#123; // 获取同步队列的头节点 Node h = head; // 如果头节点不为null，并且头节点不等于tail节点。 if (h != null &amp;&amp; h != tail) &#123; // 获取头节点对应的线程的状态 int ws = h.waitStatus; // 如果头节点对应的线程是SIGNAL状态，则意味着“头节点的下一个节点所对应的线程”需要被unpark唤醒。 if (ws == Node.SIGNAL) &#123; // 设置“头节点对应的线程状态”为空状态。失败的话，则继续循环。 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // 唤醒“头节点的下一个节点所对应的线程”。 unparkSuccessor(h); &#125; // 如果头节点对应的线程是空状态，则设置“文件点对应的线程所拥有的共享锁”为其它线程获取锁的空状态。 else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; // 如果头节点发生变化，则继续循环。否则，退出循环。 if (h == head) // loop if head changed break; &#125;&#125; doReleaseShared()会释放“共享锁”。它会从前往后的遍历同步队列，依次“唤醒”然后“执行”队列中每个节点对应的线程；最终的目的是让这些线程释放它们所持有的信号量。 应用示例利用Semaphore实现数据库连接池。 连接池代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118package main.java.com.study.lock.semaphore;import java.util.concurrent.Semaphore;import java.util.concurrent.TimeUnit;/** * @author: whb * @description: 连接池 */public class ConnectPool &#123; /** * 连接池大小 */ private int size; /** * 连接集合 */ private Connect[] connects; /** * 连接状态标志 */ private boolean[] connectFlag; /** * 剩余可用连接数 */ private volatile int available; /** * 信号量 */ private Semaphore semaphore; public ConnectPool(int size) &#123; this.size = size; this.available = size; semaphore = new Semaphore(size, true); connects = new Connect[size]; connectFlag = new boolean[size]; initConnects(); &#125; /** * 初始化连接 */ private void initConnects() &#123; //生成指定数量的连接 for (int i = 0; i &lt; this.size; i++) &#123; connects[i] = new Connect(); &#125; &#125; /** * 获取连接 */ private synchronized Connect getConnect() &#123; for (int i = 0; i &lt; connectFlag.length; i++) &#123; //遍历集合找到未使用的连接 if (!connectFlag[i]) &#123; //将连接设置为使用中 connectFlag[i] = true; //可用连接数减一 available--; System.out.println(\"【\" + Thread.currentThread().getName() + \"】已获取连接，剩余可用连接：\" + available); //返回连接 return connects[i]; &#125; &#125; return null; &#125; /** * 打开链接 * * @return */ public Connect openConnect() throws InterruptedException &#123; //获取许可 semaphore.acquire(); //获取连接 return getConnect(); &#125; /** * 释放连接 */ public synchronized void release(Connect connect) &#123; for (int i = 0; i &lt; this.size; i++) &#123; if (connect == connects[i]) &#123; //将连接设置为未使用 connectFlag[i] = false; //可用连接加一 available++; System.out.println(\"【\" + Thread.currentThread().getName() + \"】已释放连接，剩余可用连接：\" + available); //释放许可 semaphore.release(); &#125; &#125; &#125;&#125;class Connect &#123; private static int count = 1; private int id = count++; public Connect() &#123; //模拟打开一个连接很耗费资源，需要等待1秒 try &#123; TimeUnit.MILLISECONDS.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"连接#\" + id + \"#已与数据库建立通道！\"); &#125; @Override public String toString() &#123; return \"【\" + id + \"】\"; &#125;&#125; 测试代码： 123456789101112131415161718192021222324252627package main.java.com.study.lock.semaphore;/** * @author: whb * @description: 测试连接池 */public class TestConnectPool extends Thread &#123; private static ConnectPool pool = new ConnectPool(3); @Override public void run() &#123; try &#123; Connect connect = pool.openConnect(); Thread.sleep(100); pool.release(connect); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; for (int i = 0; i &lt; 10; i++) &#123; new TestConnectPool().start(); &#125; &#125;&#125; 执行结果：","tags":"java j.u.c"},{"title":"Java并发-CyclicBarrier","url":"/posts/3a683baa.html","text":"概述现实生活中经常会遇到这样的情景，在进行某个活动前需要等待人全部都齐了才开始。例如吃饭时要等全家人都上座了才动筷子，旅游时要等全部人都到齐了才出发，比赛时要等运动员都上场后才开始。在J.U.C包中提供了一个同步工具类能够很好的模拟这类场景，它就是CyclicBarrier类。利用CyclicBarrier类可以实现一组线程相互等待，当所有线程都到达某个屏障点后再进行后续的操作。下图演示了这一过程。 成员变量在CyclicBarrier类的内部有一个计数器，每个线程在到达屏障点的时候都会调用await方法将自己阻塞，此时计数器会减1，当计数器减为0的时候所有因调用await方法而被阻塞的线程将被唤醒。这就是实现一组线程相互等待的原理，下面看下CyclicBarrier有哪些成员变量。 1234567891011121314151617//同步操作锁private final ReentrantLock lock = new ReentrantLock();//线程拦截器private final Condition trip = lock.newCondition();//每次拦截的线程数private final int parties;//换代前执行的任务private final Runnable barrierCommand;//表示栅栏的当前代private Generation generation = new Generation();//计数器private int count;//静态内部类Generationprivate static class Generation &#123; boolean broken = false;&#125; CyclicBarrier内部是通过条件队列trip来对线程进行阻塞的，并且其内部维护了两个int型的变量parties和count。parties表示每次拦截的线程数，该值在构造时进行赋值。count是内部计数器，它的初始值和parties相同，以后随着每次await方法的调用而减1，直到减为0就将所有线程唤醒。CyclicBarrier有一个静态内部类Generation，该类的对象代表栅栏的当前代，就像玩游戏时代表的本局游戏，利用它可以实现循环等待。barrierCommand表示换代前执行的任务，当count减为0时表示本局游戏结束，需要转到下一局。在转到下一局游戏之前会将所有阻塞的线程唤醒，在唤醒所有线程之前你可以通过指定barrierCommand来执行自己的任务。 构造器123456789101112131415//构造器1public CyclicBarrier(int parties, Runnable barrierAction) &#123; if (parties &lt;= 0) throw new IllegalArgumentException(); // parties表示“必须同时到达barrier的线程个数”。 this.parties = parties; // count表示“处在等待状态的线程个数”。 this.count = parties; // barrierCommand表示“parties个线程到达barrier时，会执行的动作”。 this.barrierCommand = barrierAction;&#125;//构造器2public CyclicBarrier(int parties) &#123; this(parties, null);&#125; CyclicBarrier有两个构造器，其中构造器1是它的核心构造器，在这里可以指定要拦截的线程数以及结束时要执行的任务，还可以看到计数器count的初始值被设置为parties。 等待方法12345678910111213//非定时等待public int await() throws InterruptedException, BrokenBarrierException &#123; try &#123; return dowait(false, 0L); &#125; catch (TimeoutException toe) &#123; throw new Error(toe); &#125;&#125;//定时等待public int await(long timeout, TimeUnit unit) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; return dowait(true, unit.toNanos(timeout));&#125; 不管是定时等待还是非定时等待，它们都调用了dowait方法，只不过是传入的参数不同而已。下面看下dowait方法都做了些什么。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081//核心等待方法private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; final ReentrantLock lock = this.lock; //获取独占锁 lock.lock(); try &#123; //保存当前的generation final Generation g = generation; //检查当前栅栏是否被打翻 if (g.broken) &#123; throw new BrokenBarrierException(); &#125; //检查当前线程是否被中断 if (Thread.interrupted()) &#123; //如果当前线程被中断会做以下三件事 //1.打翻当前栅栏 //2.唤醒拦截的所有线程 //3.抛出中断异常 breakBarrier(); throw new InterruptedException(); &#125; //每次都将计数器的值减1 int index = --count; //计数器的值减为0则需唤醒所有线程并转换到下一代 if (index == 0) &#123; boolean ranAction = false; try &#123; //唤醒所有线程前先执行指定的任务 final Runnable command = barrierCommand; if (command != null) &#123; command.run(); &#125; ranAction = true; //唤醒所有线程并转到下一代 nextGeneration(); return 0; &#125; finally &#123; //确保在任务未成功执行时能将所有线程唤醒 if (!ranAction) &#123; breakBarrier(); &#125; &#125; &#125; //当前线程一直阻塞，直到“有parties个线程到达barrier” 或 “当前线程被中断” 或 “超时”这3者之一发生，当前线程才继续执行。 for (;;) &#123; try &#123; //根据传入的参数来决定是定时等待还是非定时等待 if (!timed) &#123; trip.await(); &#125;else if (nanos &gt; 0L) &#123; nanos = trip.awaitNanos(nanos); &#125; &#125; catch (InterruptedException ie) &#123; //若当前线程在等待期间被中断则打翻栅栏唤醒其他线程 if (g == generation &amp;&amp; ! g.broken) &#123; breakBarrier(); throw ie; &#125; else &#123; //若在捕获中断异常前已经完成在栅栏上的等待, 则直接调用中断操作 Thread.currentThread().interrupt(); &#125; &#125; //如果线程因为打翻栅栏操作而被唤醒则抛出异常 if (g.broken) &#123; throw new BrokenBarrierException(); &#125; //如果线程因为换代操作而被唤醒则返回计数器的值 if (g != generation) &#123; return index; &#125; //如果线程因为时间到了而被唤醒则打翻栅栏并抛出异常 if (timed &amp;&amp; nanos &lt;= 0L) &#123; breakBarrier(); throw new TimeoutException(); &#125; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125; 在dowait方法中每次都将count减1，减完后立马进行判断看看是否等于0，如果等于0的话就会先去执行之前指定好的任务，执行完之后再调用nextGeneration方法将栅栏转到下一代，在该方法中会将所有线程唤醒，将计数器的值重新设为parties，最后会重新设置栅栏代次，在执行完nextGeneration方法之后就意味着游戏进入下一局。如果计数器此时还不等于0的话就进入for循环，根据参数来决定是调用trip.awaitNanos(nanos)还是trip.await()方法，这两方法对应着定时和非定时等待。如果在等待过程中当前线程被中断就会执行breakBarrier方法，该方法叫做打破栅栏，意味着游戏在中途被掐断，设置generation的broken状态为true并唤醒所有线程。同时这也说明在等待过程中有一个线程被中断整盘游戏就结束，所有之前被阻塞的线程都会被唤醒。线程醒来后会执行下面三个判断，看看是否因为调用breakBarrier方法而被唤醒，如果是则抛出异常；看看是否是正常的换代操作而被唤醒，如果是则返回计数器的值；看看是否因为超时而被唤醒，如果是的话就调用breakBarrier打破栅栏并抛出异常。这里还需要注意的是，如果其中有一个线程因为等待超时而退出，那么整盘游戏也会结束，其他线程都会被唤醒。下面贴出nextGeneration方法和breakBarrier方法的具体代码。 12345678910111213141516171819//切换栅栏到下一代private void nextGeneration() &#123; //唤醒条件队列所有线程 trip.signalAll(); //设置计数器的值为需要拦截的线程数 count = parties; //重新设置栅栏代次 generation = new Generation();&#125;//打翻当前栅栏private void breakBarrier() &#123; //将当前栅栏状态设置为打翻 generation.broken = true; //设置计数器的值为需要拦截的线程数 count = parties; //唤醒所有线程 trip.signalAll();&#125; 应用示例赛马:通过在控制台不停的打印各赛马的当前轨迹，以达到动态显示的效果。整场比赛有多个轮次，每一轮次各个赛马都会随机走上几步然后调用await方法进行等待，当所有赛马走完一轮的时候将会执行任务将所有赛马的当前轨迹打印到控制台上。这样每一轮下来各赛马的轨迹都在不停的增长，当其中某个赛马的轨迹最先增长到指定的值的时候将会结束整场比赛，该赛马成为整场比赛的胜利者！程序如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283class Horse implements Runnable &#123; private static int counter = 0; private final int id = counter++; private int strides = 0; private static Random rand = new Random(47); private static CyclicBarrier barrier; public Horse(CyclicBarrier b) &#123; barrier = b; &#125; @Override public void run() &#123; try &#123; while(!Thread.interrupted()) &#123; synchronized(this) &#123; //赛马每次随机跑几步 strides += rand.nextInt(3); &#125; barrier.await(); &#125; &#125; catch(Exception e) &#123; e.printStackTrace(); &#125; &#125; public String tracks() &#123; StringBuilder s = new StringBuilder(); for(int i = 0; i &lt; getStrides(); i++) &#123; s.append(\"*\"); &#125; s.append(id); return s.toString(); &#125; public synchronized int getStrides() &#123; return strides; &#125; public String toString() &#123; return \"Horse \" + id + \" \"; &#125; &#125;public class HorseRace implements Runnable &#123; private static final int FINISH_LINE = 75; private static List&lt;Horse&gt; horses = new ArrayList&lt;Horse&gt;(); private static ExecutorService exec = Executors.newCachedThreadPool(); @Override public void run() &#123; StringBuilder s = new StringBuilder(); //打印赛道边界 for(int i = 0; i &lt; FINISH_LINE; i++) &#123; s.append(\"=\"); &#125; System.out.println(s); //打印赛马轨迹 for(Horse horse : horses) &#123; System.out.println(horse.tracks()); &#125; //判断是否结束 for(Horse horse : horses) &#123; if(horse.getStrides() &gt;= FINISH_LINE) &#123; System.out.println(horse + \"won!\"); exec.shutdownNow(); return; &#125; &#125; //休息指定时间再到下一轮 try &#123; TimeUnit.MILLISECONDS.sleep(200); &#125; catch(InterruptedException e) &#123; System.out.println(\"barrier-action sleep interrupted\"); &#125; &#125; public static void main(String[] args) &#123; CyclicBarrier barrier = new CyclicBarrier(7, new HorseRace()); for(int i = 0; i &lt; 7; i++) &#123; Horse horse = new Horse(barrier); horses.add(horse); exec.execute(horse); &#125; &#125; &#125; 程序的运行结果如下：","tags":"java j.u.c"},{"title":"Hello World","url":"/posts/4a17b156.html","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":"hexo"},{"title":"Java并发-AQS源码分析之条件队列","url":"/posts/68b8bf54.html","text":"概述通过之前的分析，深入了解了AbstractQueuedSynchronizer的内部结构和一些设计理念，知道了AbstractQueuedSynchronizer内部维护了一个同步状态和两个排队区，这两个排队区分别是同步队列和条件队列。拿ATM机取款举例，ATM机如下图所示： 同步队列是主要的排队区，如果ATM机没开放，所有想要进入人都得在这里排队。而条件队列主要是为条件等待设置的，想象一下如果一个人通过排队终于成功获取锁进入了ATM机，但在取款之前发现自己没带银行卡，碰到这种情况虽然很无奈，但是它也必须接受这个事实，这时它只好乖乖的出去先准备好银行卡(进入条件队列等待)，当然在出去之前还得把锁给释放了好让其他人能够进来，在准备好了银行卡(条件满足)之后它又得重新回到同步队列中去排队。当然进入房间的人并不都是因为没带银行卡，可能还有其他一些原因必须中断操作先去条件队列中去排队，所以条件队列可以有多个，依不同的等待条件而设置不同的条件队列。同步队列和条件队列的区别： 同步队列的头结点为head，而条件队列的头结点为firstWaiter; 同步队列的尾结点为tail，而条件队列的尾结点为lastWaiter; 同步队列的头结点没有和任何线程绑定，而条件队列的firstWaiter绑定了线程。 同步队列是一条双向链表，而条件队列是一条单向链表。 Condition接口定义了条件队列中的所有操作，AbstractQueuedSynchronizer内部的ConditionObject类实现了Condition接口，下面看看Condition接口都定义了哪些操作。 123456789101112131415161718192021222324public interface Condition &#123; //响应线程中断的条件等待 void await() throws InterruptedException; //不响应线程中断的条件等待 void awaitUninterruptibly(); //设置相对时间的条件等待(不进行自旋) long awaitNanos(long nanosTimeout) throws InterruptedException; //设置相对时间的条件等待(进行自旋) boolean await(long time, TimeUnit unit) throws InterruptedException; //设置绝对时间的条件等待 boolean awaitUntil(Date deadline) throws InterruptedException; //唤醒条件队列中的头结点 void signal(); //唤醒条件队列的所有结点 void signalAll(); &#125; Condition接口虽然定义了这么多方法，但总共就分为两类，以await开头的是线程进入条件队列等待的方法，以signal开头的是将条件队列中的线程“唤醒”的方法。需要注意的是，调用signal方法可能唤醒线程也可能不会唤醒线程，什么时候会唤醒线程这得看情况，但是调用signal方法一定会将线程从条件队列中移到同步队列尾部。await方法分为5种，分别是响应线程中断等待，不响应线程中断等待，设置相对时间不自旋等待，设置相对时间自旋等待，设置绝对时间等待；signal方法只有2种，分别是只唤醒条件队列头结点和唤醒条件队列所有结点的操作。同一类的方法基本上是相通的。 响应线程中断的条件等待123456789101112131415161718192021222324252627282930313233343536//响应线程中断的条件等待public final void await() throws InterruptedException &#123; //如果线程被中断则抛出异常 if (Thread.interrupted()) &#123; throw new InterruptedException(); &#125; //将当前线程包装秤结点添加到条件队列尾部 Node node = addConditionWaiter(); //在进入条件等待之前先完全释放锁 int savedState = fullyRelease(node); int interruptMode = 0; //线程一直在while循环里进行条件等待，直到线程被唤醒或者线程被中断并且进入同步队列中 while (!isOnSyncQueue(node)) &#123; //进行条件等待的线程都在这里被挂起, 线程被唤醒的情况有以下几种： //1.同步队列的前驱结点已取消 //2.设置同步队列的前驱结点的状态为SIGNAL失败 //3.前驱结点释放锁后唤醒当前结点 LockSupport.park(this); //当前线程醒来后立马检查是否被中断, 如果是则代表结点取消条件等待, 此时需要将结点移出条件队列 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) &#123; break; &#125; &#125; //线程醒来后就会以独占模式获取锁，如果获取时发生了中断，如果在调用await()方法时被中断，则依然是THROW_IE if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) &#123; interruptMode = REINTERRUPT; &#125; //这步操作主要为防止线程在signal之前中断而导致没与条件队列断绝联系 if (node.nextWaiter != null) &#123; unlinkCancelledWaiters(); &#125; //根据中断模式进行响应的中断处理 if (interruptMode != 0) &#123; reportInterruptAfterWait(interruptMode); &#125;&#125; 上述代码整个流程总结如下： 第一步：首先判断当前线程是否中断，如果被中断，则抛出异常，如果没有被中断，则继续下面的流程。第二步：通过调用addConditionWaiter()将当前线程封装成Node节点存放到Condition队列的尾部。第三步：因为当前线程已经获取了锁，所以调用await需要释放资源，所以通过调用fullyRelease()释放资源，也就是释放锁，因为这个锁是独占锁并且可以重入，所以要全部把资源释放，从fully字面上也可以理解。第四步：通过while循环判断当前线程是否在同步队列上，如果没有在同步队列上，则需要阻塞当前线程，然后调用checkInterruptWaiting()方法判断是否被中断过，如果被中断过，则跳出while循环。第五步：通过调用acquireQueued()方法获取资源，如果在调用这个方法时被中断，则中断类型变成REINTERRUPT(稍后处理中断)，这个方法返回值只是记录是否被中断过，并不会响应中断。第六步：如果是因为中断，此时waitStatus=0,但是此时它仍在条件队列中，所以需要从条件队列中清除。第七步：如果被中断，则调用reportInterruptAfterWait()方法处理不同的中断类型。 第一步：将线程添加到条件队列 1234567891011121314151617private Node addConditionWaiter() &#123; //获取条件队列尾结点 Node t = lastWaiter; // 如果尾结点被取消，则从条件队列中清除 if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; //将当前线程包装成Node结点，并且waitStatus状态是CONDITION。 Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node;&#125; 将当前线程封装成Node节点，然后加入到Condition的尾部，在加入之前需要检查以下尾部节点t是否还在等待Condition条件，如果被signal或者被中断，则调用清除方法将尾节点从Condition队列中清除掉。 第二步：完全将锁释放 1234567891011121314151617181920212223//完全释放锁final int fullyRelease(Node node) &#123; //判断资源是否释放成功 boolean failed = true; try &#123; //获取当前的同步状态 int savedState = getState(); //使用当前的同步状态去释放锁 if (release(savedState)) &#123; failed = false; //如果释放锁成功就返回当前同步状态 return savedState; &#125; else &#123; //如果释放锁失败就抛出运行时异常 throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; //保证没有成功释放锁就将该结点设置为取消状态 if (failed) &#123; node.waitStatus = Node.CANCELLED; &#125; &#125;&#125; 将当前线程包装成结点添加到条件队列尾部后，紧接着就调用fullyRelease方法释放锁。注意，方法名为fullyRelease也就这步操作会完全的释放锁，因为锁是可重入的，所以在进行条件等待前需要将锁全部释放了，不然的话别人就获取不了锁了。如果释放锁失败的话就会抛出一个运行时异常，如果成功释放了锁的话就返回之前的同步状态。 第三步：进行条件等待 1234567891011121314151617181920212223242526272829303132333435363738//线程一直在while循环里进行条件等待while (!isOnSyncQueue(node)) &#123; //进行条件等待的线程都在这里被挂起, 线程被唤醒的情况有以下几种： //1.同步队列的前驱结点已取消 //2.设置同步队列的前驱结点的状态为SIGNAL失败 //3.前驱结点释放锁后唤醒当前结点 LockSupport.park(this); //当前线程醒来后立马检查是否被中断, 如果是则代表结点取消条件等待, 此时需要将结点移出条件队列 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) &#123; break; &#125;&#125;//检查条件等待时的线程中断情况private static final int REINTERRUPT = 1;private static final int THROW_IE = -1;private int checkInterruptWhileWaiting(Node node) &#123; //中断请求在signal操作之前：THROW_IE //中断请求在signal操作之后：REINTERRUPT //期间没有收到任何中断请求：0 return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0;&#125;//将取消条件等待的结点从条件队列转移到同步队列中final boolean transferAfterCancelledWait(Node node) &#123; //如果这步CAS操作成功的话就表明中断发生在signal方法之前 if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) &#123; //状态修改成功后就将该结点放入同步队列尾部 enq(node); return true; &#125; //到这里表明CAS操作失败, 说明中断发生在signal方法之后 while (!isOnSyncQueue(node)) &#123; //如果sinal方法还没有将结点转移到同步队列, 就通过自旋等待一下 Thread.yield(); &#125; return false;&#125; 在以上两个操作完成了之后就会进入while循环，可以看到while循环里面首先调用LockSupport.park(this)将线程挂起了，所以线程就会一直在这里阻塞。在调用signal方法后仅仅只是将结点从条件队列转移到同步队列中去，至于会不会唤醒线程需要看情况。如果转移结点时发现同步队列中的前驱结点已取消，或者是更新前驱结点的状态为SIGNAL失败，这两种情况都会立即唤醒线程，否则的话在signal方法结束时就不会去唤醒已在同步队列中的线程，而是等到它的前驱结点来唤醒。当然，线程阻塞在这里除了可以调用signal方法唤醒之外，线程还可以响应中断，如果线程在这里收到中断请求就会继续往下执行。可以看到线程醒来后会马上检查是否是由于中断唤醒的还是通过signal方法唤醒的，如果是因为中断唤醒的同样会将这个结点转移到同步队列中去，只不过是通过调用transferAfterCancelledWait方法来实现的。最后执行完这一步之后就会返回中断情况并跳出while循环。 第四步：结点移出条件队列 1234567891011121314151617181920212223//线程醒来后就会以独占模式获取锁if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) &#123; interruptMode = REINTERRUPT;&#125;//这步操作主要为防止线程在signal之前中断而导致没与条件队列断绝联系if (node.nextWaiter != null) &#123; unlinkCancelledWaiters();&#125;//根据中断模式进行响应的中断处理if (interruptMode != 0) &#123; reportInterruptAfterWait(interruptMode);&#125;//结束条件等待后根据中断情况做出相应处理private void reportInterruptAfterWait(int interruptMode) throws InterruptedException &#123; //如果中断模式是THROW_IE就抛出异常 if (interruptMode == THROW_IE) &#123; throw new InterruptedException(); //如果中断模式是REINTERRUPT就自己挂起 &#125; else if (interruptMode == REINTERRUPT) &#123; selfInterrupt(); &#125;&#125; 当线程终止了while循环也就是条件等待后，就会回到同步队列中。不管是因为调用signal方法回去的还是因为线程中断导致的，结点最终都会在同步队列中。这时就会调用acquireQueued方法执行在同步队列中获取锁的操作。也就是说，结点从条件队列出来后又是乖乖的走独占模式下获取锁的那一套，等这个结点再次获得锁之后，就会调用reportInterruptAfterWait方法来根据这期间的中断情况做出相应的响应。如果中断发生在signal方法之前，interruptMode就为THROW_IE，再次获得锁后就抛出异常；如果中断发生在signal方法之后，interruptMode就为REINTERRUPT，再次获得锁后就重新中断。 不响应线程中断的条件等待1234567891011121314151617181920212223//不响应线程中断的条件等待public final void awaitUninterruptibly() &#123; //将当前线程添加到条件队列尾部 Node node = addConditionWaiter(); //完全释放锁并返回当前同步状态 int savedState = fullyRelease(node); boolean interrupted = false; //结点一直在while循环里进行条件等待 while (!isOnSyncQueue(node)) &#123; //条件队列中所有的线程都在这里被挂起 LockSupport.park(this); //线程醒来发现中断并不会马上去响应 if (Thread.interrupted()) &#123; interrupted = true; &#125; &#125; if (acquireQueued(node, savedState) || interrupted) &#123; //在这里响应所有中断请求, 满足以下两个条件之一就会将自己挂起 //1.线程在条件等待时收到中断请求 //2.线程在acquireQueued方法里收到中断请求 selfInterrupt(); &#125;&#125; 设置相对时间的条件等待(不进行自旋)123456789101112131415161718192021222324252627282930313233343536373839404142434445//设置定时条件等待(相对时间), 不进行自旋等待public final long awaitNanos(long nanosTimeout) throws InterruptedException &#123; //如果线程被中断则抛出异常 if (Thread.interrupted()) &#123; throw new InterruptedException(); &#125; //将当前线程添加到条件队列尾部 Node node = addConditionWaiter(); //在进入条件等待之前先完全释放锁 int savedState = fullyRelease(node); long lastTime = System.nanoTime(); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; //判断超时时间是否用完了 if (nanosTimeout &lt;= 0L) &#123; //如果已超时就需要执行取消条件等待操作 transferAfterCancelledWait(node); break; &#125; //将当前线程挂起一段时间, 线程在这期间可能被唤醒, 也可能自己醒来 LockSupport.parkNanos(this, nanosTimeout); //线程醒来后先检查中断信息 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) &#123; break; &#125; long now = System.nanoTime(); //超时时间每次减去条件等待的时间 nanosTimeout -= now - lastTime; lastTime = now; &#125; //线程醒来后就会以独占模式获取锁 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) &#123; interruptMode = REINTERRUPT; &#125; //由于transferAfterCancelledWait方法没有把nextWaiter置空, 所有这里要再清理一遍 if (node.nextWaiter != null) &#123; unlinkCancelledWaiters(); &#125; //根据中断模式进行响应的中断处理 if (interruptMode != 0) &#123; reportInterruptAfterWait(interruptMode); &#125; //返回剩余时间 return nanosTimeout - (System.nanoTime() - lastTime);&#125; 设置相对时间的条件等待(进行自旋)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//设置定时条件等待(相对时间), 进行自旋等待public final boolean await(long time, TimeUnit unit) throws InterruptedException &#123; if (unit == null) &#123; throw new NullPointerException(); &#125; //获取超时时间的毫秒数 long nanosTimeout = unit.toNanos(time); //如果线程被中断则抛出异常 if (Thread.interrupted()) &#123; throw new InterruptedException(); &#125; //将当前线程添加条件队列尾部 Node node = addConditionWaiter(); //在进入条件等待之前先完全释放锁 int savedState = fullyRelease(node); //获取当前时间的毫秒数 long lastTime = System.nanoTime(); boolean timedout = false; int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; //如果超时就需要执行取消条件等待操作 if (nanosTimeout &lt;= 0L) &#123; timedout = transferAfterCancelledWait(node); break; &#125; //如果超时时间大于自旋时间, 就将线程挂起一段时间 if (nanosTimeout &gt;= spinForTimeoutThreshold) &#123; LockSupport.parkNanos(this, nanosTimeout); &#125; //线程醒来后先检查中断信息 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) &#123; break; &#125; long now = System.nanoTime(); //超时时间每次减去条件等待的时间 nanosTimeout -= now - lastTime; lastTime = now; &#125; //线程醒来后就会以独占模式获取锁 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) &#123; interruptMode = REINTERRUPT; &#125; //由于transferAfterCancelledWait方法没有把nextWaiter置空, 所有这里要再清理一遍 if (node.nextWaiter != null) &#123; unlinkCancelledWaiters(); &#125; //根据中断模式进行响应的中断处理 if (interruptMode != 0) &#123; reportInterruptAfterWait(interruptMode); &#125; //返回是否超时标志 return !timedout;&#125; 设置绝对时间的条件等待1234567891011121314151617181920212223242526272829303132333435363738394041//设置定时条件等待(绝对时间)public final boolean awaitUntil(Date deadline) throws InterruptedException &#123; if (deadline == null) &#123; throw new NullPointerException(); &#125; //获取绝对时间的毫秒数 long abstime = deadline.getTime(); //如果线程被中断则抛出异常 if (Thread.interrupted()) &#123; throw new InterruptedException(); &#125; //将当前线程添加到条件队列尾部 Node node = addConditionWaiter(); //在进入条件等待之前先完全释放锁 int savedState = fullyRelease(node); boolean timedout = false; int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; //如果超时就需要执行取消条件等待操作 if (System.currentTimeMillis() &gt; abstime) &#123; timedout = transferAfterCancelledWait(node); break; &#125; //将线程挂起一段时间, 期间线程可能被唤醒, 也可能到了点自己醒来 LockSupport.parkUntil(this, abstime); //线程醒来后先检查中断信息 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) &#123; break; &#125; &#125; //线程醒来后就会以独占模式获取锁 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) &#123; interruptMode = REINTERRUPT; &#125; //由于transferAfterCancelledWait方法没有把nextWaiter置空, 所有这里要再清理一遍 if (node.nextWaiter != null) &#123; unlinkCancelledWaiters(); &#125; //根据中断模式进行响应的中断处理 if (interruptMode != 0) &#123; reportInterruptAfterWait(interruptMode); &#125; //返回是否超时标志 return !timedout;&#125; 唤醒条件队列中的头结点123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//唤醒条件队列中的下一个结点public final void signal() &#123; //判断当前线程是否独占模式持有锁，如果不是则抛出异常 if (!isHeldExclusively()) &#123; throw new IllegalMonitorStateException(); &#125; //获取条件队列中的第一个结点 Node first = firstWaiter; //如果条件队列中有排队者 if (first != null) &#123; //唤醒条件队列中的头结点 doSignal(first); &#125;&#125;//唤醒条件队列中的头结点private void doSignal(Node first) &#123; do &#123; //1.将firstWaiter引用向后移动一位 if ( (firstWaiter = first.nextWaiter) == null) &#123; lastWaiter = null; &#125; //2.将头结点的后继结点引用置空 first.nextWaiter = null; //3.将头结点转移到同步队列, 转移完成后有可能唤醒线程 //4.如果transferForSignal操作失败就去唤醒下一个结点 &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null);&#125;//将指定结点从条件队列转移到同步队列中final boolean transferForSignal(Node node) &#123; //将等待状态从CONDITION设置为0 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) &#123; //如果更新状态的操作失败就直接返回false //可能是transferAfterCancelledWait方法先将状态改变了, 导致这步CAS操作失败 return false; &#125; //将该结点添加到同步队列尾部，返回前驱结点 Node p = enq(node); int ws = p.waitStatus; if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) &#123; //出现以下情况就会唤醒当前线程 //1.前驱结点是取消状态 //2.更新前驱结点的状态为SIGNAL操作失败 LockSupport.unpark(node.thread); &#125; return true;&#125; 可以看到signal方法最终的核心就是去调用transferForSignal方法，在transferForSignal方法中首先会用CAS操作将结点的状态从CONDITION设置为0，然后再调用enq方法将该结点添加到同步队列尾部。我们再看到接下来的if判断语句，这个判断语句主要是用来判断什么时候会去唤醒线程，出现这两种情况就会立即唤醒线程，一种是当发现前驱结点的状态是取消状态时，还有一种是更新前驱结点的状态失败时。这两种情况都会马上去唤醒线程，否则的话就仅仅只是将结点从条件队列中转移到同步队列中就完了，而不会立马去唤醒结点中的线程。signalAll方法也大致类似，只不过它是去循环遍历条件队列中的所有结点，并将它们转移到同步队列，转移结点的方法也还是调用transferForSignal方法。 唤醒条件队列的所有结点1234567891011121314151617181920212223242526272829//唤醒条件队列后面的全部结点public final void signalAll() &#123; //判断当前线程是否持有锁 if (!isHeldExclusively()) &#123; throw new IllegalMonitorStateException(); &#125; //获取条件队列头结点 Node first = firstWaiter; if (first != null) &#123; //唤醒条件队列的所有结点 doSignalAll(first); &#125;&#125;//唤醒条件队列的所有结点private void doSignalAll(Node first) &#123; //先把头结点和尾结点的引用置空 lastWaiter = firstWaiter = null; do &#123; //先获取后继结点的引用 Node next = first.nextWaiter; //把即将转移的结点的后继引用置空 first.nextWaiter = null; //将结点从条件队列转移到同步队列 transferForSignal(first); //将引用指向下一个结点 first = next; &#125; while (first != null);&#125;","tags":"java j.u.c"},{"title":"Java并发-AQS源码分析之独占模式","url":"/posts/f8b27f2e.html","text":"AQS为在独占模式下获取锁分别提供三种获取方式： 不响应线程中断获取; 响应线程中断获取; 设置超时时间获取。 这三种方式整体步骤大致是相同的，只有少部分不同的地方：第一种在获取时会忽略中断;而第二种则是获取时响应中断;第三种是获取时，如果超时则立即返回。 不响应线程中断获取锁123456//不响应中断方式获取(独占模式)public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) &#123; selfInterrupt(); &#125;&#125; acquire方法是获取锁的基础，这个方法会忽略中断，意思是说如果节点对应的线程中断，则acquire()方法会忽略，只有从同步队列中返回true才最终调用selfInterrupt方法响应中断。代码很简单，但是它按照顺序执行了下图所示的4个步骤。 第一步：!tryAcquire(arg) 尝试获取资源state 1234//尝试获取锁（独占模式）protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125; 这时候来了一个人，他首先尝试着去敲了敲门，如果发现门没锁(tryAcquire(arg)=true)，那就直接进去了。如果发现门锁了(tryAcquire(arg)=false)，就执行下一步。这个tryAcquire方法决定了什么时候锁是开着的，什么时候锁是关闭的。这个方法必须要让子类去覆盖，重写里面的判断逻辑。 第二步：addWaiter(Node.EXCLUSIVE) 获取资源失败，则封装成Node结点加入到同步队列中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445//将当前线程包装成结点并添加到同步队列尾部private Node addWaiter(Node mode) &#123; //指定持有锁的模式 Node node = new Node(Thread.currentThread(), mode); //获取同步队列尾结点引用 Node pred = tail; //如果尾结点不为空, 表明同步队列已存在结点 if (pred != null) &#123; //1.指向当前尾结点 node.prev = pred; //2.设置当前结点为尾结点（由于是多线程，可能并发修改尾结点，所以通过CAS修改） if (compareAndSetTail(pred, node)) &#123; //3.将旧的尾结点的后继指向新的尾结点 pred.next = node; return node; &#125; &#125; //否则表明同步队列是空的，还没有进行初始化 enq(node); return node;&#125;//结点入队操作private Node enq(final Node node) &#123; for (;;) &#123; //获取同步队列尾结点引用 Node t = tail; //如果尾结点为空说明同步队列还没有初始化 if (t == null) &#123; //初始化同步队列（调用无参构造器创建一个结点，然后通过CAS设置head结点，如果成功则将头结点head赋值给tail结点） if (compareAndSetHead(new Node())) &#123; tail = head; &#125; &#125; else &#123; //1.指向当前尾结点 node.prev = t; //2.设置当前结点为尾结点 if (compareAndSetTail(t, node)) &#123; //3.将旧的尾结点的后继指向新的尾结点 t.next = node; return t; &#125; &#125; &#125;&#125; 执行到这一步表明第一次获取锁失败，那么这个人就给自己领了块号码牌进入排队区去排队了，在领号码牌的时候会声明自己想要以什么样的方式来占用房间(独占模式or共享模式)。注意，这时候他并没有坐下来休息(将自己挂起)。 第三步：acquireQueued(addWaiter(Node.EXCLUSIVE), arg) 在同步队列中获取资源。其实这个方法非常的好理解，前面已经尝试获取资源，但是失败了，并且加到了同步队列中，在等待中可以判断自己是否可以休息以下，如果可以休息，那就等待着其他线程唤醒自己，在继续获取资源，直到成功才返回。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667//以不可中断方式获取锁(独占模式)final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; //判断是否中断的标记 boolean interrupted = false; //自旋 for (;;) &#123; //获取给定结点的前驱结点的引用 final Node p = node.predecessor(); //如果当前结点的前驱结点是头结点head，就尝试去获取锁 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //说明获取成功，将给定结点设置为head结点 setHead(node); //为了帮助垃圾收集, 将上一个head结点的后继清空 p.next = null; //设置获取成功状态 failed = false; //返回中断的状态, 整个循环执行到这里才是出口 return interrupted; &#125; //否则说明锁的状态还是不可获取, 这时判断是否可以挂起当前线程 //第一个条件：如果获取锁失败，判断是否应该休息 //第二个条件：第一个条件为true，说明自己可以休息了则调用park方法休息 //如果判断结果为真则挂起当前线程, 否则继续循环, 在这期间线程不响应中断 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) &#123; interrupted = true; &#125; &#125; &#125; finally &#123; //在最后确保如果获取失败就取消获取 if (failed) &#123; cancelAcquire(node); &#125; &#125;&#125;//判断是否可以将当前结点挂起private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; //获取前驱结点的等待状态 int ws = pred.waitStatus; //如果前驱结点状态为SIGNAL, 表明前驱结点会唤醒当前结点, 所以当前结点可以安心的挂起了 if (ws == Node.SIGNAL) &#123; return true; &#125; //节点状态只有CANCEL(-1)时才大于0，说明这个节点取消了。那就需要把取消的节点从同步队列中移除掉 if (ws &gt; 0) &#123; //下面的操作是清理同步队列中所有已取消的前驱结点 do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; //到这里表示前驱结点状态不是SIGNAL也不是CANCEL, 很可能还是等于0, 这样的话前驱结点就不会去唤醒当前结点了 //所以当前结点必须要确保前驱结点的状态为SIGNAL才能安心的挂起自己 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125;//挂起当前线程private final boolean parkAndCheckInterrupt() &#123; //挂起当前线程 LockSupport.park(this); //返回当前线程是否被中断过 return Thread.interrupted();&#125; 领完号码牌进入排队区后就会立马执行这个方法，当一个结点首次进入排队区后有两种情况，一种是发现他前面的那个人已经离开座位进入房间了，那他就不坐下来休息了，会再次去敲一敲门看看那小子有没有完事。如果里面的人刚好完事出来了，都不用他叫自己就直接冲进去了。否则，就要考虑坐下来休息一会儿了，但是他还是不放心，如果他坐下来睡着后没人提醒他怎么办？他就在前面那人的座位上留一个小纸条，好让从里面出来的人看到纸条后能够唤醒他。还有一种情况是，当他进入排队区后发现前面还有好几个人在座位上排队呢，那他就可以安心的坐下来咪一会儿了，但在此之前他还是会在前面那人(此时已经睡着了)的座位上留一个纸条，好让这个人在走之前能够去唤醒自己。当一切事情办妥了之后，他就安安心心的睡觉了，注意，我们看到整个for循环就只有一个出口，那就是等线程成功的获取到锁之后才能出去，在没有获取到锁之前就一直是挂在for循环的parkAndCheckInterrupt()方法里头。线程被唤醒后也是从这个地方继续执行for循环。 第四步：selfInterrupt() 1234//当前线程将自己中断private static void selfInterrupt() &#123; Thread.currentThread().interrupt();&#125; 由于上面整个线程一直是挂在for循环的parkAndCheckInterrupt()方法里头，没有成功获取到锁之前不响应任何形式的线程中断，只有当线程成功获取到锁并从for循环出来后，他才会查看在这期间是否有人要求中断线程，如果是的话再去调用selfInterrupt()方法将自己挂起。 响应线程中断获取锁123456789 public final void acquireInterruptibly(int arg) throws InterruptedException &#123; //首先判断线程是否中断过，如果被中断则直接抛出异常 if (Thread.interrupted()) throw new InterruptedException(); //如果没有被中断过，则尝试获取资源 if (!tryAcquire(arg)) //说明获取资源失败，则需要加入到同步队列，在同步队列中获取资源 doAcquireInterruptibly(arg);&#125; 1234567891011121314151617181920212223242526272829//以可中断模式获取锁(独占模式)private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; //将当前线程包装成结点添加到同步队列中 final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; //获取当前结点的前驱结点 final Node p = node.predecessor(); //如果p是head结点, 那么当前线程就再次尝试获取锁 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; //获取锁成功后返回 return; &#125; //如果满足条件就挂起当前线程, 此时响应中断并抛出异常 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) &#123; //线程被唤醒后如果发现中断请求就抛出异常 throw new InterruptedException(); &#125; &#125; &#125; finally &#123; if (failed) &#123; cancelAcquire(node); &#125; &#125;&#125; 响应线程中断方式和不响应线程中断方式获取锁流程上大致上是相同的。唯一的一点区别就是线程从parkAndCheckInterrupt方法中醒来后会检查线程是否中断，如果是的话就抛出InterruptedException异常，而不响应线程中断获取锁是在收到中断请求后只是设置一下中断状态，并不会立马结束当前获取锁的方法，一直到结点成功获取到锁之后才会根据中断状态决定是否将自己挂起。 设置超时时间获取锁12345678public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; ////判断是否被中断过，如果中断过直接抛异常 if (Thread.interrupted()) throw new InterruptedException(); ////尝试获取资源，如果失败添加到同步队列中，从同步队列中获取资源 return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445//以限定超时时间获取锁(独占模式)private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; //获取系统当前时间 long lastTime = System.nanoTime(); //将当前线程包装成结点添加到同步队列中 final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; //获取当前结点的前驱结点 final Node p = node.predecessor(); //如果前驱是head结点, 那么当前线程就再次尝试获取锁 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //更新head结点 setHead(node); p.next = null; failed = false; return true; &#125; //超时时间用完了就直接退出循环 if (nanosTimeout &lt;= 0) &#123; return false; &#125; //如果超时时间大于自旋时间, 那么等判断可以挂起线程之后就会将线程挂起一段时间 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) &#123; //将当前线程挂起一段时间, 之后再自己醒来 LockSupport.parkNanos(this, nanosTimeout); &#125; //获取系统当前时间 long now = System.nanoTime(); //超时时间每次都减去获取锁的时间间隔 nanosTimeout -= now - lastTime; //再次更新lastTime lastTime = now; //在获取锁的期间收到中断请求就抛出异常 if (Thread.interrupted()) &#123; throw new InterruptedException(); &#125; &#125; &#125; finally &#123; if (failed) &#123; cancelAcquire(node); &#125; &#125;&#125; 设置超时时间获取首先会去获取一下锁，第一次获取锁失败后会根据情况，如果传入的超时时间大于自旋时间那么就会将线程挂起一段时间，否则的话就会进行自旋，每次获取锁之后都会将超时时间减去获取一次锁所用的时间。一直到超时时间小于0也就说明超时时间用完了，那么这时就会结束获取锁的操作然后返回获取失败标志。注意在以超时时间获取锁的过程中是可以响应线程中断请求的。 独占模式下释放锁1234567891011121314151617181920212223242526272829303132333435363738394041//释放锁的操作(独占模式)public final boolean release(int arg) &#123; //尝试释放（该方法需要子类去实现） if (tryRelease(arg)) &#123; //尝试成功，获取head结点 Node h = head; //如果head结点不为空并且等待状态不等于0就去唤醒后继结点 if (h != null &amp;&amp; h.waitStatus != 0) &#123; //唤醒后继结点 unparkSuccessor(h); &#125; return true; &#125; return false;&#125;//唤醒后继结点private void unparkSuccessor(Node node) &#123; //获取给定结点的等待状态 int ws = node.waitStatus; //如果状态小于0，通过CAS将状态更新为0，因为此时给定的结点释放资源 if (ws &lt; 0) &#123; compareAndSetWaitStatus(node, ws, 0); &#125; //获取给定结点的后继结点，即下一个需要被唤醒的结点 Node s = node.next; //后继结点为空或者等待状态为取消状态 if (s == null || s.waitStatus &gt; 0) &#123; s = null; //从后向前遍历队列找到第一个不是取消状态的结点 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) &#123; if (t.waitStatus &lt;= 0) &#123; s = t; &#125; &#125; &#125; //唤醒给定结点后面首个不是取消状态的结点 if (s != null) &#123; LockSupport.unpark(s.thread); &#125;&#125; 线程持有锁进入房间后就会去办自己的事情，等事情办完后它就会释放锁并离开房间。通过tryRelease方法可以拨动密码锁进行解锁，tryRelease方法是需要让子类去覆盖的，不同的子类实现的规则不一样，也就是说不同的子类设置的密码不一样。像在ReentrantLock当中，房间里面的人每调用tryRelease方法一次，state就减1，直到state减到0的时候密码锁就开了。这个过程就像在不停的转动密码锁的转轮，而每次转动转轮数字只是减少1。CountDownLatch和这个也有点类似，只不过它不是一个人在转，而是多个人每人都去转一下，集中大家的力量把锁给开了。线程出了房间后它会找到自己原先的座位，也就是找到head结点。看看座位上有没有人给它留了小纸条，如果有的话它就知道有人睡着了需要让它帮忙唤醒，那么它就会去唤醒那个线程。如果没有的话就表明同步队列中暂时还没有人在等待，也没有人需要它唤醒，所以它就可以安心的离去了。","tags":"java j.u.c"},{"title":"Java并发-AQS源码分析之共享模式","url":"/posts/edbda32.html","text":"AQS为在共享模式下获取锁分别提供三种获取方式： 不响应线程中断获取; 响应线程中断获取; 设置超时时间获取。 这三种方式整体步骤大致是相同的，只有少部分不同的地方：第一种方式，如果当前线程在获取资源时被中断了，它会忽略这个中断，当获取资源返回后才对中断进行处理;第二种方式则不同，如果当前线程获取资源时被中断，它会抛出中断异常;第三种方式在中断的基础上添加了超时返回的功能。 不响应线程中断的获取12345678910111213141516//以不可中断模式获取锁(共享模式)public final void acquireShared(int arg) &#123; //1.尝试去获取锁，如果获取成功，则流程结束 if (tryAcquireShared(arg) &lt; 0) &#123; //2.如果获取失败就进入这个方法：将当前线程包装成Node结点放入到同步队列尾部并按照条件判断是否挂起，等待被唤醒 doAcquireShared(arg); &#125;&#125;//尝试去获取锁(共享模式，该方法需要子类去实现，返回值需要遵循以下三个定义)//负数：表示获取失败//零值：表示当前结点获取成功, 但是后继结点不能再获取了//正数：表示当前结点获取成功, 并且后继结点同样可以获取成功protected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException();&#125; 调用acquireShared方法是不响应线程中断获取锁的方式。在该方法中，首先调用tryAcquireShared去尝试获取锁，tryAcquireShared方法返回一个获取锁的状态，这里AQS规定了返回状态若是负数代表当前结点获取锁失败，若是0代表当前结点获取锁成功，但后继结点不能再获取了，若是正数则代表当前结点获取锁成功，并且这个锁后续结点也同样可以获取成功。子类在实现tryAcquireShared方法获取锁的逻辑时，返回值需要遵守这个约定。如果调用tryAcquireShared的返回值小于0，就代表这次尝试获取锁失败了，接下来就调用doAcquireShared方法将当前线程添加进同步队列。下面看下doAcquireShared方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344//在同步队列中获取(共享模式)private void doAcquireShared(int arg) &#123; //将当前线程包装成SHARED共享模式的结点添加到同步队列中 final Node node = addWaiter(Node.SHARED); //是否获取失败 boolean failed = true; try &#123; //是否中断 boolean interrupted = false; //自旋，判断什么时候能够尝试获取资源，什么时候能够挂起 for (;;) &#123; //获取当前结点的前驱结点 final Node p = node.predecessor(); //如果前驱结点为head结点就再次尝试去获取锁 if (p == head) &#123; //再次尝试去获取锁并返回获取状态 //r &lt; 0, 表示获取失败 //r = 0, 表示当前结点获取成功, 但是后继结点不能再获取了 //r &gt; 0, 表示当前结点获取成功, 并且后继结点同样可以获取成功 int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; //到这里说明当前结点已经获取锁成功了, 此时它会将锁的状态信息传播给后继结点 setHeadAndPropagate(node, r); //帮助垃圾回收 p.next = null; //如果在线程阻塞期间收到中断请求, 就在这一步响应该请求 if (interrupted) &#123; selfInterrupt(); &#125; failed = false; return; &#125; &#125; //每次获取锁失败后都会判断是否可以将线程挂起, 如果可以的话就会在parkAndCheckInterrupt方法里将线程挂起 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) &#123; interrupted = true; &#125; &#125; &#125; finally &#123; if (failed) &#123; cancelAcquire(node); &#125; &#125;&#125; 进入doAcquireShared方法首先是调用addWaiter方法将当前线程包装成结点放到同步队列尾部。这个添加结点的过程跟独占模式是一样的。结点进入同步队列后，如果它发现在它前面的结点就是head结点，因为head结点的线程已经获取锁进入房间里面了，那么下一个获取锁的结点就轮到自己了，所以当前结点先不会将自己挂起，而是再一次去尝试获取锁，如果前面那人刚好释放锁离开了，那么当前结点就能成功获得锁，如果前面那人还没有释放锁，那么就会调用shouldParkAfterFailedAcquire方法，在这个方法里面会将head结点的状态改为SIGNAL，只有保证前面结点的状态为SIGNAL，当前结点才能放心的将自己挂起，所有线程都会在parkAndCheckInterrupt方法里面被挂起。如果当前结点恰巧成功的获取了锁，那么接下来就会调用setHeadAndPropagate方法将自己设置为head结点，并且唤醒后面同样是共享模式的结点。下面看下setHeadAndPropagate方法具体的操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//设置head结点并传播锁的状态(共享模式)private void setHeadAndPropagate(Node node, int propagate) &#123; //获取当前的头结点 Node h = head; //将给定的成功获取资源的结点设置为head结点 setHead(node); //有5个条件： //第一个条件：propagate&gt;0:这个值是通过调用tryAcquireShared()获取的，表示剩余的资源，上面说了state&gt;0表示获取资源成功，且还有剩余的资源。 //第二个条件：h==null：表示老的头结点head的引用为null。 //第三个条件：h.waitStatus&lt;0：老的头结点head的节点状态，有两种取值可能：SIGNAL(-1)和PROPAGATE(-3)。 //第四个条件：(h=head)==null //第五个条件：h.waitStatus&lt;0：新设置的头结点head的节点状态，有两种取值可能：SIGNAL(-1)和PROPAGATE(-3)。 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; //获取给定结点的后继结点 Node s = node.next; //如果给定结点的后继结点为空, 或者它的状态是共享状态 if (s == null || s.isShared()) &#123; //唤醒后继结点 doReleaseShared(); &#125; &#125;&#125;//释放锁的操作(共享模式)private void doReleaseShared() &#123; for (;;) &#123; //获取同步队列的head结点 Node h = head; if (h != null &amp;&amp; h != tail) &#123; //获取head结点的等待状态 int ws = h.waitStatus; //如果head结点的状态为SIGNAL, 表明后面有人在排队 if (ws == Node.SIGNAL) &#123; //先把head结点的等待状态更新为0 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) &#123; continue; &#125; //再去唤醒后继结点 unparkSuccessor(h); //如果head结点的状态为0, 表明此时后面没人在排队, 就只是将head状态修改为PROPAGATE &#125;else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) &#123; continue; &#125; &#125; //只有保证期间head结点没被修改过才能跳出循环 if (h == head) &#123; break; &#125; &#125;&#125; 调用setHeadAndPropagate方法首先将自己设置成head结点，然后再根据传入的tryAcquireShared方法的返回值来决定是否要去唤醒后继结点。前面已经讲到当返回值大于0就表明当前结点成功获取了锁，并且后面的结点也可以成功获取锁。这时当前结点就需要去唤醒后面同样是共享模式的结点，注意，每次唤醒仅仅只是唤醒后一个结点，如果后一个结点不是共享模式的话，当前结点就直接进入房间而不会再去唤醒更后面的结点了。共享模式下唤醒后继结点的操作是在doReleaseShared方法进行的，共享模式和独占模式的唤醒操作基本也是相同的，都是去找到自己座位上的牌子(等待状态)，如果牌子上为SIGNAL表明后面有人需要让它帮忙唤醒，如果牌子上为0则表明队列此时并没有人在排队。在独占模式下是如果发现没人在排队就直接离开队列了，而在共享模式下如果发现队列后面没人在排队，当前结点在离开前仍然会留个小纸条(将等待状态设置为PROPAGATE)告诉后来的人这个锁的可获取状态。那么后面来的人在尝试获取锁的时候可以根据这个状态来判断是否直接获取锁。 响应线程中断获取锁123456789101112131415161718192021222324252627282930313233343536373839404142//以可中断模式获取锁(共享模式)public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; //首先判断线程是否中断, 如果是则抛出异常 if (Thread.interrupted()) &#123; throw new InterruptedException(); &#125; //1.尝试去获取锁 if (tryAcquireShared(arg) &lt; 0) &#123; //2. 如果获取失败则进人该方法 doAcquireSharedInterruptibly(arg); &#125;&#125;//以可中断模式获取(共享模式)private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; //将当前结点插入同步队列尾部 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; //获取当前结点的前驱结点 final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) &#123; //如果线程在阻塞过程中收到过中断请求, 那么就会立马在这里抛出异常 throw new InterruptedException(); &#125; &#125; &#125; finally &#123; if (failed) &#123; cancelAcquire(node); &#125; &#125;&#125; 响应线程中断获取锁的方式和不响应线程中断获取锁的方式在流程上基本是相同的，唯一的区别就是在哪里响应线程的中断请求。在不响应线程中断获取锁时，线程从parkAndCheckInterrupt方法中被唤醒，唤醒后就立马返回是否收到中断请求，即使是收到了中断请求也会继续自旋直到获取锁后才响应中断请求将自己给挂起。而响应线程中断获取锁会在线程被唤醒后立马响应中断请求，如果在阻塞过程中收到了线程中断就会立马抛出InterruptedException异常。 设置超时时间获取锁1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//以限定超时时间获取锁(共享模式)public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) &#123; throw new InterruptedException(); &#125; //1.调用tryAcquireShared尝试去获取锁 //2.如果获取失败就调用doAcquireSharedNanos return tryAcquireShared(arg) &gt;= 0 || doAcquireSharedNanos(arg, nanosTimeout);&#125;//以限定超时时间获取锁(共享模式)private boolean doAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException &#123; long lastTime = System.nanoTime(); final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; //获取当前结点的前驱结点 final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; failed = false; return true; &#125; &#125; //如果超时时间用完了就结束获取, 并返回失败信息 if (nanosTimeout &lt;= 0) &#123; return false; &#125; //1.检查是否满足将线程挂起要求(保证前驱结点状态为SIGNAL) //2.检查超时时间是否大于自旋时间 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) &#123; //若满足上面两个条件就将当前线程挂起一段时间 LockSupport.parkNanos(this, nanosTimeout); &#125; long now = System.nanoTime(); //超时时间每次减去获取锁的时间 nanosTimeout -= now - lastTime; lastTime = now; //如果在阻塞时收到中断请求就立马抛出异常 if (Thread.interrupted()) &#123; throw new InterruptedException(); &#125; &#125; &#125; finally &#123; if (failed) &#123; cancelAcquire(node); &#125; &#125;&#125; 流程同前面两种获取锁的方式，主要是理解超时的机制是怎样的。如果第一次获取锁失败会调用doAcquireSharedNanos方法并传入超时时间，进入方法后会根据情况再次去获取锁，如果再次获取失败就要考虑将线程挂起了。这时会判断超时时间是否大于自旋时间，如果是的话就会将线程挂起一段时间，否则就继续尝试获取，每次获取锁之后都会将超时时间减去获取锁的时间，一直这样循环直到超时时间用尽，如果还没有获取到锁的话就会结束获取并返回获取失败标识。在整个期间线程是响应线程中断的。 共享模式下释放锁1234567891011121314151617181920212223242526272829303132333435363738394041424344//释放锁的操作(共享模式)public final boolean releaseShared(int arg) &#123; //1.尝试去释放锁 if (tryReleaseShared(arg)) &#123; //2.如果释放成功就唤醒其他线程 doReleaseShared(); return true; &#125; return false;&#125;//尝试去释放锁(共享模式)protected boolean tryReleaseShared(int arg) &#123; throw new UnsupportedOperationException();&#125;//释放锁的操作(共享模式)private void doReleaseShared() &#123; for (;;) &#123; //获取同步队列的head结点 Node h = head; //判断队列中是否有结点 if (h != null &amp;&amp; h != tail) &#123; //获取head结点的等待状态 int ws = h.waitStatus; //如果head结点的状态为SIGNAL, 表明后面有人在排队 if (ws == Node.SIGNAL) &#123; //先把head结点的等待状态更新为0（有两个地方调用这个方法） if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) &#123; continue; &#125; //再去唤醒后继结点 unparkSuccessor(h); //如果head结点的状态为0, 表明此时后面没人在排队, 就只是将head状态修改为PROPAGATE &#125;else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) &#123; continue; &#125; &#125; //只有保证期间head结点没被修改过才能跳出循环 if (h == head) &#123; break; &#125; &#125;&#125; 线程在房间办完事之后就会调用releaseShared方法释放锁，首先调用tryReleaseShared方法尝试释放锁，该方法的判断逻辑由子类实现。如果释放成功就调用doReleaseShared方法去唤醒后继结点。走出房间后它会找到原先的座位(head结点)，看看座位上是否有人留了小纸条(状态为SIGNAL)，如果有就去唤醒后继结点。如果没有(状态为0)就代表队列没人在排队，那么在离开之前它还要做最后一件事情，就是在自己座位上留下小纸条(状态设置为PROPAGATE)，告诉后面的人锁的获取状态，整个释放锁的过程和独占模式唯一的区别就是在这最后一步操作。 PS：上面说了doReleaseShared()的代码流程，这个方法有两处地方调用： 第一处调用的地方：刚刚释放资源的老的head调用，在代码中就是releaseShared()方法中调用。 第二处调用的地方：刚刚设置新的头结点head调用，在代码中就是setHeadAndPropagate()方法中调用。 上面的方法看到head节点的状态要么是SIGNAL(SIGNAL——&gt;0),要么是0(0——&gt;PROPAGATE)，这些状态怎样来的？ 状态为SIGNAL的由来：头结点的后继节点被挂起了，挂起的同时会将它的前驱节点状态置为SIGNAL，以便于被唤醒。 状态为0的由来：这个状态是默认状态，后继节点没有被挂起就尝试获取资源成功了，此时并没有调用判断挂起的方法，所以头结点的状态没有变化。 第一个分析的重点：如果只有刚刚释放资源的老的head调用了此方法，这个时候没有竞争，如果头结点head的waitStatus等于SIGNAL，则首先将SIGNAL——&gt;0,如果成功则调用unparkSuccessor()方法唤醒下一个节点。如果头结点head的waitStatus等于0，则将0——&gt;PROPAGATE,不成功则继续循环。 第二个分析的重点：如果刚刚释放资源的老head，和刚获取资源设置新的头结点的head同时调用这个方法，那么两者获取的head可能有所不同，前者老head获取的h可能是自己，也可能是新的head，后者新head获取的h一定是自己。但是不管head获取的是老的，还是新的，都能够顺利的唤醒下一个节点，只不过可能多唤醒一次而已，这并不影响结果。 第三个分析的重点：最后为什么会判断h==head？如果头结点head发生变化，可能其他线程获取了资源把head改变了，为了使自己的唤醒动作传递，必须重试。 其实doReleaseShared()方法就是能够保证唤醒下面的节点，并且能够传递下去。","tags":"java j.u.c"},{"title":"Java并发-AQS源码分析之概要分析","url":"/posts/115e562c.html","text":"AbstractQueuedSynchronizer是做什么的java.util.concurrent这个包下有很多类，比如ReentrantLock、CountDownLatch、CyclicBarrrier、Semaphore等，它们的实现中都有一个内部类Sync，这个类继承了AbstractQueuedSynchronizer（简称AQS），所有的锁机制的实现都依赖于Sync内部类，也可以说这些类的实现就是依赖于AQS。那么AQS内部到底实现了什么以至于这些类都要依赖于它呢？可以这样说，AQS为这些类提供了基础设施，也就是提供了一个密码锁，这些类拥有了密码锁之后可以自己来设置密码锁的密码。此外，AQS还提供了一个排队区，并且提供了一个线程训导员，我们知道线程就像一个原始的野蛮人，它不懂得讲礼貌，它只会横冲直撞，所以你得一步一步去教它，告诉它什么时候需要去排队了，要到哪里去排队，排队前要做些什么，排队后要做些什么。这些教化工作全部都由AQS帮你完成了，从它这里教化出来的线程都变的非常文明懂礼貌，不再是原始的野蛮人，所以以后我们只需要和这些文明的线程打交道就行了，千万不要和原始线程有过多的接触！ 为何说AQS提供了一把密码锁1234567891011121314151617181920212223//同步队列的头结点private transient volatile Node head; //同步队列的尾结点private transient volatile Node tail;//同步状态private volatile int state;//获取同步状态protected final int getState() &#123; return state;&#125;//设置同步状态protected final void setState(int newState) &#123; state = newState;&#125;//以CAS方式设置同步状态protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; 上面的代码列出了AQS的所有成员变量，可以看到AQS的成员变量只有三个，分别是同步队列头结点引用，同步队列尾结点引用以及同步状态。注意，这三个成员变量都使用了volatile关键字进行修饰，这就确保了多个线程对它的修改都是内存可见的。整个类的核心就是这个同步状态，可以看到同步状态其实就是一个int型的变量，大家可以把这个同步状态看成一个密码锁，而且还是从房间里面锁起来的密码锁，state具体的值就相当于密码控制着密码锁的开合。当然这个锁的密码是多少就由各个子类来规定了，例如在ReentrantLock中，state等于0表示锁是开的，state大于0表示锁是锁着的，而在Semaphore中，state大于0表示锁是开的，state等于0表示锁是锁着的。 AQS的排队区是怎样实现的 AQS内部其实有两个排队区，一个是同步队列，一个是条件队列。从上图可以看出，同步队列只有一条，而条件队列可以有多条。同步队列的结点分别持有前后结点的引用，而条件队列的结点只有一个指向后继结点的引用。图中T表示线程，每个结点包含一个线程，线程在获取锁失败后首先进入同步队列排队，而想要进入条件队列该线程必须持有锁才行。接下来看看队列中每个结点的结构。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172//同步队列的结点static final class Node &#123; static final Node SHARED = new Node(); //表示当前线程以共享模式持有锁 static final Node EXCLUSIVE = null; //表示当前线程以独占模式持有锁 static final int CANCELLED = 1; //表示当前结点已经取消获取锁 static final int SIGNAL = -1; //表示后继结点的线程需要运行 static final int CONDITION = -2; //表示当前结点在条件队列中排队 static final int PROPAGATE = -3; //表示后继结点可以直接获取锁(PROPAGATE为下一个acquireShared无条件传播的状态，用于共享模式) volatile int waitStatus; //表示当前结点的等待状态（默认值为0） volatile Node prev; //表示同步队列中的前驱结点 volatile Node next; //表示同步队列中的后继结点 volatile Thread thread; //当前结点持有的线程引用 Node nextWaiter; //表示条件队列中的后继结点 /** * 当前结点状态是否是共享模式 */ final boolean isShared() &#123; return nextWaiter == SHARED; &#125; /** * 返回当前结点的前驱结点 */ final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) &#123; throw new NullPointerException(); &#125; else &#123; return p; &#125; &#125; /** * 空构造函数：主要用于初始化头结点(head)或者创建共享模式 */ Node() &#123;&#125; /** * 默认用这个构造器（主要用于把节点添加到队列中） * * @param thread 当前线程 * @param mode 结点模式 */ Node(Thread thread, Node mode) &#123; //注意持有模式是赋值给nextWaiter this.nextWaiter = mode; this.thread = thread; &#125; /** * 只在条件队列中用到 * * @param thread 当前线程 * @param waitStatus 结点状态 */ Node(Thread thread, int waitStatus) &#123; this.waitStatus = waitStatus; this.thread = thread; &#125;&#125; Node代表同步队列和条件队列中的一个结点，它是AQS的内部类。Node有很多属性，比如持有模式，等待状态，同步队列中的前驱和后继，以及条件队列中的后继引用等等。可以把同步队列和条件队列看成是排队区，每个结点看成是排队区的座位，将线程看成是排队的客人。客人刚来时会先去敲敲门，看看锁有没有开，如果锁没开它就会去排队区领取一个号码牌，声明自己想要以什么样的方式来持有锁，最后再到队列的末尾进行排队。 怎样理解独占模式和共享模式前面讲到每个客人在排队前会领取一个号码牌，声明自己想要以什么样的方式来占有锁，占有锁的方式分为独占模式和共享模式，那么怎样来理解独占模式和共享模式呢？打个比方，大家联想一下去食堂吃饭，正好有一个桌子空着，独占模式的人比较霸道，老子要么就不坐，坐下来就不允许别人坐，自己一个人独自占用整个桌子。共享模式的人就没那么讲究了，当它发现这个桌子可以用，自己坐下还不算，还得热心的问下后面的人介不介意一起，如果后面的人不介意一起那就不用再排队了， 当然如果后面的人介意那就只好留在队列里继续排队了。 怎样理解结点的等待状态每个结点都有一个等待状态，这个等待状态分为CANCELLED，SIGNAL，CONDITION，PROPAGATE四种状态。可以将这个等待状态看作是挂在座位旁边的牌子，标识当前座位上的人的等待状态。这个牌子的状态不仅自己可以修改，其他人也可以修改。例如当这个线程在排队过程中已经打算放弃了，它就会将自己座位上的牌子设置为CANCELLED，这样其他人看到了就可以将它清理出队列。还有一种情况是，当线程在座位上要睡着之前，它怕自己睡过了头，就会将前面位置上的牌子改为SIGNAL，因为每个人在离开队列前都会回到自己座位上看一眼，如果看到牌子上状态为SIGNAL，它就会去唤醒下一个人。只有保证前面位置上的牌子为SIGNAL，当前线程才会安心的睡去。CONDITION状态表示该线程在条件队列中排队，PROPAGATE状态提醒后面来的线程可以直接获取锁，这个状态只在共享模式用到。 结点进入同步队列时会进行哪些操作123456789101112131415161718192021222324//结点入队操作, 返回前一个结点private Node enq(final Node node) &#123; for (;;) &#123; //获取同步队列尾结点引用 Node t = tail; //如果尾结点为空说明同步队列还没有初始化 if (t == null) &#123; //初始化同步队列 if (compareAndSetHead(new Node())) &#123; tail = head; &#125; &#125; else &#123; //1.指向当前尾结点 node.prev = t; //2.设置当前结点为尾结点 if (compareAndSetTail(t, node)) &#123; //3.将旧的尾结点的后继指向新的尾结点 t.next = node; //for循环唯一的出口 return t; &#125; &#125; &#125;&#125; 注意，入队操作使用一个死循环，只有成功将结点添加到同步队列尾部才会返回，返回结果是同步队列原先的尾结点。下图演示了整个操作过程。 添加尾结点的顺序，分为三步：指向尾结点，CAS更改尾结点，将旧尾结点的后继指向当前结点。在并发环境中这三步操作不一定能保证完成，所以在清空同步队列所有已取消的结点这一操作中，为了寻找非取消状态的结点，不是从前向后遍历而是从后向前遍历的。还有就是每个结点进入队列中时它的等待状态是为0，只有后继结点的线程需要挂起时才会将前面结点的等待状态改为SIGNAL。","tags":"java j.u.c"},{"title":"由剔除Intellij中Mybatis的Mapper自动注入警告引入对注解的学习","url":"/posts/8b9fb30a.html","text":"起源相信使用Mybatis的小伙们一定经常编写类似如下的代码： 可以看到 userMapper 下有个红色警告。虽然代码本身并没有问题，能正常运行，但有个警告总归有点恶心。先看下警告信息： Spring team recommends: “Always use constructor based dependency injection in your beans. Always use assertions for mandatory dependencies.” 原因众所周知，IDEA是非常智能的，它可以理解Spring的上下文。然而 UserMapper 这个接口是Mybatis的，IDEA理解不了。 而 @Autowired 注解，默认情况下要求依赖对象（也就是 userMapper ）必须存在。而IDEA认为这个对象的实例/代理是个null，所以就友好地给个提示。按照提示修改如下： 123456private final UserMapper userMapper;@Autowiredpublic UserServiceImpl(UserMapper userMapper) &#123; this.userMapper = userMapper;&#125; 此时仍然存在一个问题： 1Could not autowire. 自动注入 bean， spring帮助我们完成了，但是同时Spring提供了一些注解来显式的注明bean之间的引用关系，其中最为熟知的自然是@Controller,@Service,@Repository,@Component等。这里其实给UserMapper接口加上@Repository,@Component就可以解决，那么他们之间有什么区别？ 区别Spring不但支持自己定义的@Autowired注解，还支持几个由JSR-250规范定义的注解，它们分别是@Resource、@PostConstruct以及@PreDestroy。 @Resource的作用相当于@Autowired，只不过@Autowired按byType自动注入，而@Resource默认按 byName自动注入罢了。@Resource有两个属性是比较重要的，分是name和type，Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不指定name也不指定type属性，这时将通过反射机制使用byName自动注入策略。 @Resource装配顺序 如果同时指定了name和type，则从Spring上下文中找到唯一匹配的bean进行装配，找不到则抛出异常 如果指定了name，则从上下文中查找名称（id）匹配的bean进行装配，找不到则抛出异常 如果指定了type，则从上下文中找到类型匹配的唯一bean进行装配，找不到或者找到多个，都会抛出异常 如果既没有指定name，又没有指定type，则自动按照byName方式进行装配；如果没有匹配，则回退为一个原始类型进行匹配，如果匹配则自动装配； @Autowired 与@Resource的区别 1、@Autowired与@Resource都可以用来装配bean. 都可以写在字段上,或写在setter方法上。 2、@Autowired默认按类型装配（这个注解是属于spring的），默认情况下必须要求依赖对象必须存在，如果要允许null值，可以设置它的required属性为false，如：@Autowired(required=false) ，如果我们想使用名称装配可以结合@Qualifier注解进行使用，如下： 12@Autowired()@Qualifier(\"baseDao\")privateBaseDao baseDao; 3、@Resource（这个注解属于J2EE的），默认按照名称进行装配，名称可以通过name属性进行指定，如果没有指定name属性，当注解写在字段上时，默认取字段名进行装配查找，如果注解写在setter方法上默认取属性名进行装配。当找不到与名称匹配的bean时才按照类型进行装配。但是需要注意的是，如果name属性一旦指定，就只会按照名称进行装配。 12@Resource(name=\"baseDao\")privateBaseDao baseDao; 推荐使用：@Resource注解在字段上，这样就不用写setter方法了，并且这个注解是属于J2EE的，减少了与spring的耦合。这样代码看起就比较优雅。 Spring @Qualifier注解@Autowired是根据类型进行自动装配的。如果当Spring上下文中存在不止一个UserDao类型的bean时，就会抛出BeanCreationException异常;如果Spring上下文中不存在UserDao类型的bean，也会抛出BeanCreationException异常。我们可以使用@Qualifier配合@Autowired来解决这些问题。如下： 可能存在多个UserDao实例 123@Autowired @Qualifier(\"userServiceImpl\") public IUserService userService; 或者 1234@Autowired public void setUserDao(@Qualifier(\"userDao\") UserDao userDao) &#123; this.userDao = userDao; &#125; 这样Spring会找到id为userServiceImpl和userDao的bean进行装配。 可能不存在UserDao实例 12@Autowired(required = false) public IUserService userService 总结@Autowired 默认按type注入@Qualifier(“baseDao”) 一般作为@Autowired()的修饰用@Resource(name=”baseDao”) 默认按name注入，可以通过name和type属性进行选择性注入 一般@Autowired和@Qualifier一起用，@Resource单独用。当然没有冲突的话@Autowired也可以单独用。 常用注解声明Bean的注解1234//定义控制层Bean,如Action@Controller@Controller(\"Bean的名称\") 1234//定义业务逻辑层Bean@Service @Service(\"Bean的名称\") 1234//定义DAO层/数据访问层Bean@Repository @Repository(\"Bean的名称\") 12//定义Bean, 不好归类时使用.@Component 自动装配Bean12//默认按类型匹配,自动装配(Srping提供的)，可以写在成员属性上,或写在setter方法上@Autowired 12//一定要找到匹配的Bean，否则抛异常。 默认值就是true@Autowired(required=true) 123//按名称装配Bean,与@Autowired组合使用，解决按类型匹配找到多个Bean问题。@Autowired@Qualifier(\"bean的名字\") 123456//JSR-250提供的,默认按名称装配,当找不到名称匹配的bean再按类型装配.可以写在成员属性上,或写在setter方法上@Resource //可以通过@Resource(name=\"beanName\") 指定被注入的bean的名称, 要是未指定name属性, 默认使用成员属性的变量名,一般不用写name属性.@Resource(name=\"beanName\") 12//是JSR-330提供的,按类型装配，功能比@Autowired少，没有使用的必要。@Inject Java配置类 @Configuration 声明当前类为配置类，相当于xml形式的Spring配置（类上） @Bean 注解在方法上，声明当前方法的返回值为一个bean，替代xml中的方式（方法上） @Configuration 声明当前类为配置类，其中内部组合了@Component注解，表明这个类是一个bean（类上） @ComponentScan 用于对Component进行扫描，相当于xml中的（类上） @WishlyConfiguration 为@Configuration与@ComponentScan的组合注解，可以替代这两个注解 切面（AOP）Spring支持AspectJ的注解式切面编程。 @Aspect 声明一个切面（类上） 使用@After、@Before、@Around定义建言（advice），可直接将拦截规则（切点）作为参数。 @After 在方法执行之后执行（方法上） @Before 在方法执行之前执行（方法上） @Around 在方法执行之前与之后执行（方法上） @PointCut 声明切点 在java配置类中使用@EnableAspectJAutoProxy注解开启Spring对AspectJ代理的支持（类上） 定义Bean的作用域和生命过程1234567891011121314//设置Spring容器如何新建Bean实例（方法上，得有@Bean）@Scope(\"prototype\")其设置类型包括：Singleton （单例,一个Spring容器中只有一个bean实例，默认模式）,Protetype （每次调用新建一个bean）,Request （web项目中，给每个http request新建一个bean）,Session （web项目中，给每个http session新建一个bean）,GlobalSession（给每一个 global http session新建一个Bean实例） 12//相当于init-method,使用在方法上，当Bean初始化时执行。@PostConstruct 12//相当于destory-method，使用在方法上，当Bean销毁时执行。@PreDestroy 声明式事务1@Transactional @Value@Value 为属性注入值（属性上）支持如下方式的注入： 注入普通字符 12@Value(\"Tom\")String name; 注入操作系统属性 12@Value(\"#&#123;systemProperties['os.name']&#125;\")String osName; 注入表达式结果 12@Value(\"#&#123;T(java.lang.Math).random() * 100&#125;\")String randomNumber; 注入其他bean属性 12@Value(\"#&#123;demoClass.name&#125;\")String name; 注入文件资源 12@Value(\"classpath:com/springboot/study/hello/test.txt\")String resourceFile; 注入网站资源 12@Value(\"http://www.baiduc.om\")Resource url; 注入配置文件 12@Value(\"$&#123;book.name&#125;\")String bookName; 环境切换 @Profile 通过设定Environment的ActiveProfiles来设定当前context需要使用的配置环境。（类或方法上） @Conditional Spring4中可以使用此注解定义条件化的bean，通过实现Condition接口，并重写matches方法，从而决定该bean是否被实例化。（方法上） 异步 @EnableAsync 配置类中，通过此注解开启对异步任务的支持，叙事性AsyncConfigurer接口（类上） @Async 在实际执行的bean方法使用该注解来申明其是一个异步任务（方法上或类上所有的方法都将异步，需要@EnableAsync开启异步任务） 定时任务 @EnableScheduling 在配置类上使用，开启计划任务的支持（类上） @Scheduled 来申明这是一个任务，包括cron,fixDelay,fixRate等类型（方法上，需先开启计划任务的支持） @Enable*这些注解主要用来开启对xxx的支持。 @EnableAspectJAutoProxy 开启对AspectJ自动代理的支持 @EnableAsync 开启异步方法的支持 @EnableScheduling 开启计划任务的支持 @EnableWebMvc 开启Web MVC的配置支持 @EnableConfigurationProperties 开启对@ConfigurationProperties注解配置Bean的支持 @EnableJpaRepositories 开启对SpringData JPA Repository的支持 @EnableTransactionManagement 开启注解式事务的支持 @EnableCaching 开启注解式的缓存支持 测试@RunWith 运行器，Spring中通常用于对JUnit的支持 1@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration 用来加载配置ApplicationContext，其中classes属性用来加载配置类 1@ContextConfiguration(classes=&#123;Test.class&#125;) SpringMVC @EnableWebMvc 在配置类中开启Web MVC的配置支持，如一些ViewResolver或者MessageConverter等，若无此句，重写WebMvcConfigurerAdapter方法（用于对SpringMVC的配置）。 @Controller 声明该类为SpringMVC中的Controller @RequestMapping 用于映射Web请求，包括访问路径和参数（类或方法上） @ResponseBody 支持将返回值放在response内，而不是一个页面，通常用户返回json数据（返回值旁或方法上） @RequestBody 允许request的参数在request体中，而不是直接连接在地址后面。（放在参数前） @PathVariable 用于接收路径参数，比如@RequestMapping(“/hello/{name}”)申明的路径，将注解放在参数前，即可获取该值，通常作为Restful的接口实现方法。 @RestController 该注解为一个组合注解，相当于@Controller和@ResponseBody的组合，注解在类上，意味着，该Controller的所有方法都默认加上了@ResponseBody。 @ControllerAdvice 通过该注解，我们可以将对于控制器的全局配置放置在同一个位置，注解了@Controller的类的方法可使用@ExceptionHandler、@InitBinder、@ModelAttribute注解到方法上，这对所有注解了 @RequestMapping的控制器内的方法有效。 @ExceptionHandler 用于全局处理控制器里的异常 @InitBinder 用来设置WebDataBinder，WebDataBinder用来自动绑定前台请求参数到Model中。 @ModelAttribute 本来的作用是绑定键值对到Model里，在@ControllerAdvice中是让全局的@RequestMapping都能获得在此处设置的键值对。 为什么建议构造器注入构造器注入与域注入 热门文章 Why field injection is evil 给出总结：Field injection: less code to write; unsafe code; more complicated to test; Constructor injection: safe code; more code to write (see the hint to Lombok); easy to test; Spring 的博客上指出 Setter injection versus constructor injection and the use of @Required 解决方案书归正传，说下如何剔除Intellij中Mybatis的Mapper自动注入警告。 方法1：为 @Autowired 注解设置required = false 使用 @Autowired 注解时，若希望允许null值，可设置required = false，像这样： 12@Autowired(required = false)private UserMapper userMapper; 这样就不会有警告了。原因很好理解：IDEA认为userMapper是个null，给了警告；加上required = false后，使用 @Autowired 注解不再去校验userMapper是否存在了。也就不会有警告了。 方法2：用 @Resource 替换 @Autowired 12@Resourceprivate UserMapper userMapper; 方法3：在Mapper接口上加上@Repository注解 123@Repositorypublic interface UserMapper extends Mapper&lt;User&gt; &#123;&#125; 这样也能让你的 12@Autowiredprivate UserMapper userMapper; 不再报错。当然，如果你用@Component替换@Repository也是可以的。原理大致：IDEA不是认为 userMapper 是个null嘛…加个@Repository注解骗一下IDEA就OK了…… 方法4：用Lombok 123456@Service@RequiredArgsConstructor(onConstructor = @__(@Autowired))public class TestService &#123; private final UserMapper userMapper; ...&#125; Lombok生成的代码是这样的： 123456789@Servicepublic class TestService &#123; private final UserMapper userMapper; @Autowired public TestService(final UserMapper userMapper) &#123; this.userMapper = userMapper; &#125; ...&#125; 但如果自己手写成Lombok生成的代码，IDEA依然会给你报警告 。我猜，应该是IDEA的Lombok插件把IDEA搞懵逼了…所以不提示了… 方法5：把IDEA的警告关闭掉个人没试过。 方法6：安装mybatis plugin据说安装mybatis plugin可以解决该问题。","tags":"spring idea"},{"title":"修改GitHub项目语言显示问题","url":"/posts/559b1d56.html","text":"概述当我们上传项目到GitHub上，有时候项目显示的语言并非是我们自己项目所示的语言，这就导致我们在快速检索，或者外部访问者访问时不能够搜索到我们的项目，所以，此时就很有必要修改下语言。 修改GitHub语言1、在本地项目中或者GitHub项目中新建一个 .gitattributes的文件，输入以下内容： 12345*.yml linguist-language=Java *.html linguist-language=Java *.js linguist-language=Java *.xml linguist-language=Java*.css linguist-language=Java 需要说明的是，假如我们的项目中有很多的诸如.html、.js等文件，在GitHub上会显示为HTML、JavaScript，所以.gitattributes文件内容的意思就是将忽略.xx什么什么文件，然后将其语言更改为Java，如果你的项目是其他语言，诸如C++等就将Java修改为C++等。当然了，这样修改也许还不能将你的项目语言修改成功，所以你需要去查询你项目中所有尽可能的后缀名文件影响语言的情况考虑，要根据GitHub给你当前项目设定的是什么语言，就从什么语言去考虑就好了。所以在.gitattributes文件中添加多一些属性就解决了。如下： 123456789*.md linguist-language=Java *.yml linguist-language=Java *.html linguist-language=Java *.js linguist-language=Java *.xml linguist-language=Java*.css linguist-language=Java *.sql linguist-language=Java*.uml linguist-language=Java *.cmd linguist-language=Java","tags":"github"},{"title":"Linux-服务器状态、性能相关命令","url":"/posts/c91a35ad.html","text":"服务器状态分析查看CPU的信息 查看物理CPU个数 查看每个物理CPU的核数 逻辑CPU的个数逻辑CPU = 物理CPU个数*核数 查看内存使用情况 total：内存总数 user：已使用内存数 free：空闲内存数 shared：多进程共享内存数 buffers：缓冲内存数 cached：缓存内存数 可用内存 = free+buffers+cached 已用内存 = used-buffers-cached swap 交换内存数，此项可判断内存是否够用的标准 查看硬盘及分区信息 检查文件系统的磁盘空间占用情况 服务器性能分析查看硬盘I/O性能 查看服务器的平均负载 监控服务器的整体性能 proces r:等待运行的进程数 b:非中断睡眠状态的进程数 w:被交换出去的可运行进程数 memory swpd:虚拟内存使用情况 fres:空闲的内存 buff:用作缓存的内存数（单位:KB） swap si:从磁盘交换到内存的交换页数量 so:从内存交换到磁盘的交换页数量（单位:kb/秒） io bi:发送到块设备的块数 bo:从块设备接收到的块数（单位:块/秒） system in:每秒的中断数，包括时钟中断 cs:每秒的环境（上下文）切换数 cpu us:CPU使用时间 sy:CPU系统使用时间 id:闲置时间（单位:百分比） 标准情况下:r小于5,b约为0 如果user + sys 小于70 表示系统性能较好；如果大于等于85以上，表示性能比较糟糕 查看Linux服务器的其他参数查看系统内核的版本号","tags":"linux"},{"title":"MySQL规范","url":"/posts/33a2a570.html","text":"数据库命名规范 所有数据库对象名称必须使用小写字母并用下划线分割。 所有数据库对象名称禁止使用 MySQL 保留关键字（如果表名中包含关键字查询时，需要将其用单引号括起来）。 数据库对象的命名要能做到见名识意，并且最后不要超过32 个字符。 临时库表必须以 tmp_ 为前缀并以日期为后缀，备份表必须以 bak_ 为前缀并以日期 ( 时间戳 ) 为后缀。 所有存储相同数据的列名和列类型必须一致（一般作为关联列，如果查询时关联列类型不一致会自动进行数据类型隐式转换，会造成列上的索引失效，导致查询效率降低）。 数据库基本设计规范 没有特殊要求（即 InnoDB 无法满足的功能如：列存储，存储空间数据等）的情况下，所有表必须使用 InnoDB 存储引擎（MySQL5.5 之前默认使用 Myisam，5.6 以后默认的为 InnoDB）InnoDB 支持事务，支持行级锁，更好的恢复性，高并发下性能更好。 数据库和表的字符集统一使用 UTF8，兼容性更好。统一字符集可以避免由于字符集转换产生的乱码，不同的字符集进行比较前需要进行转换会造成索引失效。 所有表和字段都需要添加注释，使用 comment 从句添加表和列的备注 从一开始就进行数据字典的维护。 尽量控制单表数据量的大小，建议控制在500万以内，500万并不是 MySQL 数据库的限制，过大会造成修改表结构、备份、恢复都会有很大的问题，可以用历史数据归档（应用于日志数据），分库分表（应用于业务数据）等手段来控制数据量大小。 谨慎使用 MySQL 分区表。分区表在物理上表现为多个文件，在逻辑上表现为一个表。谨慎选择分区键，跨分区查询效率可能更低，建议采用物理分表的方式管理大数据。 尽量做到冷热数据分离，减小表的宽度。MySQL 限制每个表最多存储 4096 列，并且每一行数据的大小不能超过 65535 字节。减少磁盘 IO，保证热数据的内存缓存命中率（表越宽，把表装载进内存缓冲池时所占用的内存也就越大,也会消耗更多的 IO） 更有效的利用缓存，避免读入无用的冷数据；经常一起使用的列放到一个表中（避免更多的关联操作） 禁止在数据库中存储图片，文件等大的二进制数据。通常文件很大，会短时间内造成数据量快速增长，数据库进行数据库读取时，通常会进行大量的随机 IO 操作，文件很大时，IO 操作很耗时。通常存储于文件服务器，数据库只存储文件地址信息。 禁止在线上做数据库压力测试。 禁止从开发环境，测试环境直接连接生产环境数据库。 数据库字段设计规范 优先选择符合存储需要的最小的数据类型 列的字段越大，建立索引时所需要的空间也就越大，这样一页中所能存储的索引节点的数量也就越少，在遍历时所需要的IO次数也就越多，索引的性能也就越差。 将字符串转换成数字类型存储，如：将IP地址转换成整形数据。MySQL 提供了两个方法来处理 IP 地址inet_aton 把ip转为无符号整型(4-8位)inet_ntoa 把整型的ip转为地址 插入数据前，先用 inet_aton 把 IP 地址转为整型，可以节省空间。显示数据时，使用 inet_ntoa 把整型的 IP 地址转为地址显示即可。 对于非负型的数据（如自增 ID、整型 IP）来说，要优先使用无符号整型来存储,因为无符号相对于有符号可以多出一倍的存储空间。SIGNED INT -21474836482147483647UNSIGNED INT 04294967295 VARCHAR(N) 中的 N 代表的是字符数，而不是字节数。使用 UTF8 存储 255 个汉字 Varchar(255)=765 个字节。过大的长度会消耗更多的内存。 避免使用 TEXT、BLOB 数据类型 最常见的TEXT类型可以存储64k的数据，建议把 BLOB 或是TEXT列分离到单独的扩展表中。MySQL 内存临时表不支持 TEXT、BLOB 这样的大数据类型，如果查询中包含这样的数据，在排序等操作时，就不能使用内存临时表，必须使用磁盘临时表进行。而且对于这种数据，MySQL 还是要进行二次查询，会使 SQL 性能变得很差，但是不是说一定不能使用这样的数据类型。如果一定要使用，建议把 BLOB 或是 TEXT 列分离到单独的扩展表中，查询时一定不要使用 select * 而只需要取出必要的列，不需要 TEXT 列的数据时不要对该列进行查询。 TEXT 或 BLOB 类型只能使用前缀索引,因为 MySQL 对索引字段长度是有限制的，所以 TEXT 类型只能使用前缀索引，并且 TEXT 列上是不能有默认值的。 避免使用 ENUM 类型 修改 ENUM 值需要使用 ALTER 语句 ENUM 类型的 ORDER BY 操作效率低，需要额外操作 禁止使用数值作为 ENUM 的枚举值 尽可能把所有列定义为 NOT NULL 索引 NULL 列需要额外的空间来保存，所以要占用更多的空间。进行比较和计算时要对 NULL 值做特别的处理。 使用 TIMESTAMP（4 个字节）或 DATETIME 类型（8 个字节）存储时间 TIMESTAMP 存储的时间范围 1970-01-01 00:00:01 ~ 2038-01-19-03:14:07。 TIMESTAMP 占用 4 字节和 INT 相同，但比 INT 可读性高，超出 TIMESTAMP 取值范围的使用 DATETIME 类型存储。 经常会有人用字符串存储日期型的数据（不正确的做法）： 缺点 1：无法用日期函数进行计算和比较。缺点 2：用字符串存储日期要占用更多的空间。 同财务相关的金额类数据必须使用 decimal 类型 非精准浮点：float，double精准浮点：decimalDecimal 类型为精准浮点数，在计算时不会丢失精度。占用空间由定义的宽度决定，每 4 个字节可以存储 9 位数字，并且小数点要占用一个字节。可用于存储比 bigint 更大的整型数据。 索引设计规范 限制每张表上的索引数量，建议单张表索引不超过 5 个 索引并不是越多越好！索引可以提高效率同样也可以降低效率；索引可以增加查询效率，但同样也会降低插入和更新的效率，甚至有些情况下会降低查询效率。因为 MySQL 优化器在选择如何优化查询时，会根据统一信息，对每一个可以用到的索引来进行评估，以生成出一个最好的执行计划，如果同时有很多个索引都可以用于查询，就会增加 MySQL 优化器生成执行计划的时间，同样会降低查询性能。 禁止给表中的每一列都建立单独的索引 5.6版本之前，一个 SQL 只能使用到一个表中的一个索引，5.6 以后，虽然有了合并索引的优化方式，但是还是远远没有使用一个联合索引的查询方式好 每个 InnoDB 表必须有个主键 InnoDB 是一种索引组织表：数据的存储的逻辑顺序和索引的顺序是相同的。每个表都可以有多个索引，但是表的存储顺序只能有一种 InnoDB是按照主键索引的顺序来组织表的。 不要使用更新频繁的列作为主键，不适用多列主键（相当于联合索引） 不要使用 UUID、MD5、HASH、字符串列作为主键（无法保证数据的顺序增长）。主键建议使用自增 ID 值。 如何选择索引列的顺序建立索引的目的是希望通过索引进行数据查找，减少随机 IO，增加查询性能 ，索引能过滤出越少的数据，则从磁盘中读入的数据也就越少。 区分度最高的放在联合索引的最左侧（区分度 = 列中不同值的数量 / 列的总行数）。 尽量把字段长度小的列放在联合索引的最左侧（因为字段长度越小，一页能存储的数据量越大，IO 性能也就越好）。 使用最频繁的列放到联合索引的左侧（这样可以比较少的建立一些索引）。 避免建立冗余索引和重复索引因为这样会增加查询优化器生成执行计划的时间。 重复索引示例：primary key(id)、index(id)、unique index(id)冗余索引示例：index(a,b,c)、index(a,b)、index(a) 优先考虑覆盖索引对于频繁的查询优先考虑使用覆盖索引。 覆盖索引：就是包含了所有查询字段(where,select,ordery by,group by包含的字段)的索引 覆盖索引的好处： 避免 InnoDB 表进行索引的二次查询。InnoDB 是以聚集索引的顺序来存储的，对于 InnoDB 来说，二级索引在叶子节点中所保存的是行的主键信息，如果是用二级索引查询数据的话，在查找到相应的键值后，还要通过主键进行二次查询才能获取我们真实所需要的数据。而在覆盖索引中，二级索引的键值中可以获取所有的数据，避免了对主键的二次查询 ，减少了 IO 操作，提升了查询效率。 可以把随机 IO 变成顺序 IO 加快查询效率。由于覆盖索引是按键值的顺序存储的，对于 IO 密集型的范围查找来说，对比随机从磁盘读取每一行的数据 IO 要少的多，因此利用覆盖索引在访问时也可以把磁盘的随机读取的 IO 转变成索引查找的顺序 IO。 数据库 SQL 开发规范 建议使用预编译语句进行数据库操作 预编译语句可以重复使用这些计划，减少 SQL 编译所需要的时间，还可以解决动态 SQL 所带来的 SQL 注入的问题， 只传参数，比传递 SQL 语句更高效 相同语句可以一次解析，多次使用，提高处理效率。 避免数据类型的隐式转换 隐式转换会导致索引失效。如：select name,phone from customer where id = &#39;111&#39;; 充分利用表上已经存在的索引 避免使用双 % 号的查询条件。如a like &#39;%123%&#39;，（如果无前置 %，只有后置 %，是可以用到列上的索引的） 使用 left join 或 not exists 来优化 not in 操作,因为 not in 也通常会使用索引失效。 数据库设计时，应该要对以后扩展进行考虑 程序连接不同的数据库使用不同的账号，进制跨库查询 禁止使用 SELECT * 必须使用 SELECT &lt;字段列表&gt; 查询 消耗更多的 CPU 和 IO 以网络带宽资源 无法使用覆盖索引 可减少表结构变更带来的影响 禁止使用不含字段列表的 INSERT 语句 如：insert into values (&#39;a&#39;,&#39;b&#39;,&#39;c&#39;);应使用：insert into t(c1,c2,c3) values (&#39;a&#39;,&#39;b&#39;,&#39;c&#39;); 避免使用子查询，可以把子查询优化为 JOIN 操作 通常子查询在 in 子句中，且子查询中为简单 SQL ( 不包含 union、group by、order by、limit 从句 ) 时，才可以把子查询转化为关联查询进行优化。 子查询性能差的原因： 子查询的结果集无法使用索引，通常子查询的结果集会被存储到临时表中，不论是内存临时表还是磁盘临时表都不会存在索引，所以查询性能会受到一定的影响。特别是对于返回结果集比较大的子查询，其对查询性能的影响也就越大。由于子查询会产生大量的临时表也没有索引，所以会消耗过多的 CPU 和 IO 资源，产生大量的慢查询。 避免使用 JOIN 关联太多的表 对于 MySQL 来说，是存在关联缓存的，缓存的大小可以由 join_buffer_size 参数进行设置。 在 MySQL 中，对于同一个 SQL 多关联（join）一个表，就会多分配一个关联缓存，如果在一个 SQL 中关联的表越多，所占用的内存也就越大。 如果程序中大量的使用了多表关联的操作，同时 join_buffer_size 设置的也不合理的情况下，就容易造成服务器内存溢出的情况，就会影响到服务器数据库性能的稳定性。 同时对于关联操作来说，会产生临时表操作，影响查询效率 MySQL 最多允许关联 61 个表，建议不超过 5 个。 减少同数据库的交互次数 数据库更适合处理批量操作 合并多个相同的操作到一起，可以提高处理效率 对应同一列进行 or 判断时，使用 in 代替 or In 的值不要超过 500 个， in 操作可以更有效的利用索引，or 大多数情况下很少能利用到索引。 禁止使用 order by rand() 进行随机排序 会把表中所有符合条件的数据装载到内存中，然后在内存中对所有数据根据随机生成的值进行排序，并且可能会对每一行都生成一个随机值，如果满足条件的数据集非常大，就会消耗大量的 CPU 和 IO 及内存资源。 推荐在程序中获取一个随机值，然后从数据库中获取数据的方式。 WHERE从句中禁止对列进行函数转换和计算 对列进行函数转换或计算时会导致无法使用索引。 在明显不会有重复值时使用 UNION ALL 而不是 UNION UNION 会把两个结果集的所有数据放到临时表中后再进行去重操作。UNION ALL 不会再对结果集进行去重操作。 拆分复杂的大 SQL 为多个小 SQL 大 SQL：逻辑上比较复杂，需要占用大量 CPU 进行计算的SQL 。MySQL：一个 SQL 只能使用一个 CPU 进行计算。SQL 拆分后可以通过并行执行来提高处理效率。","tags":"mysql"},{"title":"OOM常见原因及解决","url":"/posts/a5594ffa.html","text":"Java heap space当堆内存（Heap Space）没有足够空间存放新创建的对象时，就会抛出 java.lang.OutOfMemoryError:Javaheap space 错误（根据实际生产经验，可以对程序日志中的 OutOfMemoryError 配置关键字告警，一经发现，立即处理）。 原因分析 Javaheap space 错误产生的常见原因可以分为以下几类： 1、请求创建一个超大对象，通常是一个大数组。 2、超出预期的访问量/数据量，通常是上游系统请求流量飙升，常见于各类促销/秒杀活动，可以结合业务流量指标排查是否有尖状峰值。 3、过度使用终结器（Finalizer），该对象没有立即被 GC。 4、内存泄漏（Memory Leak），大量对象引用没有释放，JVM 无法对其自动回收，常见于使用了 File 等资源没有回收。 解决方案 针对大部分情况，通常只需要通过 -Xmx 参数调高 JVM 堆内存空间即可。如果仍然没有解决，可以参考以下情况做进一步处理： 1、如果是超大对象，可以检查其合理性，比如是否一次性查询了数据库全部结果，而没有做结果数限制。 2、如果是业务峰值压力，可以考虑增加机器资源，或者做限流降级。 3、如果是内存泄漏，需要找到持有的对象，修改代码设计，比如关闭没有释放的连接。 GC overhead limit exceeded当 Java 进程花费 98% 以上的时间执行 GC，但只恢复了不到 2% 的内存，且该动作连续重复了 5 次，就会抛出 java.lang.OutOfMemoryError:GC overhead limit exceeded错误。简单地说，就是应用程序已经基本耗尽了所有可用内存， GC 也无法回收。 此类问题的原因与解决方案跟 Javaheap space 非常类似，可以参考。 Permgen space该错误表示永久代（Permanent Generation）已用满，通常是因为加载的 class 数目太多或体积太大。 原因分析 永久代存储对象主要包括以下几类： 1、加载/缓存到内存中的 class 定义，包括类的名称，字段，方法和字节码； 2、常量池； 3、对象数组/类型数组所关联的 class； 4、JIT 编译器优化后的 class 信息。 PermGen 的使用量与加载到内存的 class 的数量/大小正相关。 解决方案 根据 Permgen space 报错的时机，可以采用不同的解决方案，如下： 1、程序启动报错，修改 -XX:MaxPermSize 启动参数，调大永久代空间。 2、应用重新部署时报错，很可能是没有应用没有重启，导致加载了多份 class 信息，只需重启 JVM 即可解决。 3、运行时报错，应用程序可能会动态创建大量 class，而这些 class 的生命周期很短暂，但是 JVM 默认不会卸载 class，可以设置 -XX:+CMSClassUnloadingEnabled 和 -XX:+UseConcMarkSweepGC这两个参数允许 JVM 卸载 class。 如果上述方法无法解决，可以通过 jmap 命令 dump 内存对象 jmap-dump:format=b,file=dump.hprof&lt;process-id&gt;，然后利用 Eclipse MAT https://www.eclipse.org/mat 功能逐一分析开销最大的 classloader 和重复 class。 MetaspaceJDK 1.8 使用 Metaspace 替换了永久代（Permanent Generation），该错误表示 Metaspace 已被用满，通常是因为加载的 class 数目太多或体积太大。 此类问题的原因与解决方法跟 Permgenspace 非常类似，可以参考。需要特别注意的是调整 Metaspace 空间大小的启动参数为 -XX:MaxMetaspaceSize。 Unable to create new native thread每个 Java 线程都需要占用一定的内存空间，当 JVM 向底层操作系统请求创建一个新的 native 线程时，如果没有足够的资源分配就会报此类错误。 原因分析 JVM 向 OS 请求创建 native 线程失败，就会抛出 Unableto create new native thread，常见的原因包括以下几类： 1、线程数超过操作系统最大线程数 ulimit 限制； 2、线程数超过 kernel.pid_max（只能重启）； 3、native 内存不足； 该问题发生的常见过程主要包括以下几步： 1、JVM 内部的应用程序请求创建一个新的 Java 线程； 2、JVM native 方法代理了该次请求，并向操作系统请求创建一个 native 线程； 3、操作系统尝试创建一个新的 native 线程，并为其分配内存； 4、如果操作系统的虚拟内存已耗尽，或是受到 32 位进程的地址空间限制，操作系统就会拒绝本次 native 内存分配； 5、JVM 将抛出 java.lang.OutOfMemoryError:Unable to create new native thread 错误。 解决方案 1、升级配置，为机器提供更多的内存； 2、降低 Java Heap Space 大小； 3、修复应用程序的线程泄漏问题； 4、限制线程池大小； 5、使用 -Xss 参数减少线程栈的大小； 6、调高 OS 层面的线程最大数：执行 ulimia-a 查看最大线程数限制，使用 ulimit-u xxx 调整最大线程数限制。 ulimit -a …. 省略部分内容 ….. max user processes (-u) 16384 Out of swap space?该错误表示所有可用的虚拟内存已被耗尽。虚拟内存（Virtual Memory）由物理内存（Physical Memory）和交换空间（Swap Space）两部分组成。当运行时程序请求的虚拟内存溢出时就会报 Outof swap space?错误。 原因分析 该错误出现的常见原因包括以下几类： 1、地址空间不足； 2、物理内存已耗光； 3、应用程序的本地内存泄漏（native leak），例如不断申请本地内存，却不释放。 4、执行 jmap-histo:live&lt;pid&gt; 命令，强制执行 Full GC；如果几次执行后内存明显下降，则基本确认为 Direct ByteBuffer 问题。 解决方案 1、升级地址空间为 64 bit； 2、使用 Arthas 检查是否为 Inflater/Deflater 解压缩问题，如果是，则显式调用 end 方法。 3、Direct ByteBuffer 问题可以通过启动参数 -XX:MaxDirectMemorySize 调低阈值。 4、升级服务器配置/隔离部署，避免争用。 Kill process or sacrifice child有一种内核作业（Kernel Job）名为 Out of Memory Killer，它会在可用内存极低的情况下“杀死”（kill）某些进程。OOM Killer 会对所有进程进行打分，然后将评分较低的进程“杀死”，具体的评分规则可以参考 Surviving the Linux OOM Killer。 不同于其他的 OOM 错误， Killprocessorsacrifice child 错误不是由 JVM 层面触发的，而是由操作系统层面触发的。 原因分析 默认情况下，Linux 内核允许进程申请的内存总量大于系统可用内存，通过这种“错峰复用”的方式可以更有效的利用系统资源。 然而，这种方式也会无可避免地带来一定的“超卖”风险。例如某些进程持续占用系统内存，然后导致其他进程没有可用内存。此时，系统将自动激活 OOM Killer，寻找评分低的进程，并将其“杀死”，释放内存资源。 解决方案 1、升级服务器配置/隔离部署，避免争用。 2、OOM Killer 调优。 Requested array size exceeds VM limitJVM 限制了数组的最大长度，该错误表示程序请求创建的数组超过最大长度限制。 JVM 在为数组分配内存前，会检查要分配的数据结构在系统中是否可寻址，通常为 Integer.MAX_VALUE-2。 此类问题比较罕见，通常需要检查代码，确认业务是否需要创建如此大的数组，是否可以拆分为多个块，分批执行。 Direct buffer memoryJava 允许应用程序通过 Direct ByteBuffer 直接访问堆外内存，许多高性能程序通过 Direct ByteBuffer 结合内存映射文件（Memory Mapped File）实现高速 IO。 原因分析 Direct ByteBuffer 的默认大小为 64 MB，一旦使用超出限制，就会抛出 Directbuffer memory 错误。 解决方案 1、Java 只能通过 ByteBuffer.allocateDirect 方法使用 Direct ByteBuffer，因此，可以通过 Arthas 等在线诊断工具拦截该方法进行排查。 2、检查是否直接或间接使用了 NIO，如 netty，jetty 等。 3、通过启动参数 -XX:MaxDirectMemorySize 调整 Direct ByteBuffer 的上限值。 4、检查 JVM 参数是否有 -XX:+DisableExplicitGC 选项，如果有就去掉，因为该参数会使 System.gc() 失效。 5、检查堆外内存使用代码，确认是否存在内存泄漏；或者通过反射调用 sun.misc.Cleaner 的 clean() 方法来主动释放被 Direct ByteBuffer 持有的内存空间。 6、内存容量确实不足，升级配置。 Tomcat中java.lang.OutOfMemoryError: Java heap space异常处理原因分析Heap size：JVM堆的设置是指java程序运行过程中JVM可以调配使用的内存空间的设置。JVM在启动的时候会自动设置Heap size的值， 其初始空间(即-Xms)是物理内存的1/64，最大空间(-Xmx)是物理内存的1/4。 可以利用JVM提供的-Xmn -Xms -Xmx等选项进行设置。Heap size 的大小是Young Generation 和Tenured Generaion之和。 提示：在JVM中如果98％的时间是用于GC且可用的Heap size 不足2％的时候将抛出此异常信息。 Heap Size 最大不要超过可用物理内存的80％，一般的要将-Xms和-Xmx选项设置为相同，而-Xmn为1/4的-Xmx值。 解决方案手动设置Heap size，修改TOMCAT_HOME/bin/catalina.sh 在 1“echo &quot;Using CATALINA_BASE: $CATALINA_BASE&quot;” 上面加入以下行： 1JAVA_OPTS=&quot;-server -Xms800m -Xmx800m -XX:MaxNewSize=256m&quot; Tomcat中java.lang.OutOfMemoryError: PermGen space异常处理原因分析PermGen space的全称是Permanent Generation space,是指内存的永久保存区域, 这块内存主要是被JVM存放Class和Meta信息的,Class在被Loader时就会被放到PermGen space中, 它和存放类实例(Instance)的Heap区域不同,GC(Garbage Collection)不会在主程序运行期对 PermGen space进行清理，所以如果你的应用中有很多CLASS的话,就很可能出现PermGen space错误, 这种错误常见在web服务器对JSP进行pre compile的时候。如果你的WEB APP下都用了大量的第三方jar, 其大小 超过了jvm默认的大小(4M)那么就会产生此错误信息了。 解决方案手动设置MaxPermSize大小 修改TOMCAT_HOME/bin/catalina.sh,在 1“echo &quot;Using CATALINA_BASE: $CATALINA_BASE&quot;” 上面加入以下行： 1JAVA_OPTS=&quot;-server -XX:PermSize=64M -XX:MaxPermSize=128m 建议：将相同的第三方jar文件移置到tomcat/shared/lib目录下，这样可以达到减少jar 文档重复占用内存的目的。","tags":"java"},{"title":"Java - 面试题总结","url":"/posts/382a766.html","text":"Java里面所有的不变的属性需要用final修饰吗 答：没必要。你可以实现相同的功能通过以下操作：设为非final的private 变量，且只有在构造函数中才能修改。不设set方法，如果是一个可变对象，不要泄露任何指向这个对象的引用。 设置一个引用变量为final 只能确保这个变量不会被赋予一个不同的引用，但是你仍然可以改变引用变量的属性值。 String的subString()实现原理 答：substring取原来string的一部分创建一个新的对象。这个问题主要想问substring可能导致的内存泄露风险。 直到Java1.7， substring 拥有原来的字符数组的引用，这意味着即使是五字符这么小的字符串，也可能会导致一个1GB字符数组无法被垃圾回收，因为有一个强引用。 这个问题在Java1.7中已经被修复，原来的字符数组不会被引用，但是会导致创建substring耗时会有点长，以前时间复杂度是 O(1), Java 7之后时间复杂度是 O(n)。 Java中如何处理写存储过程或者读存储过程时遇到的错误 答： 一个存储过程应该在操作错误时返回错误码，但是如果存储过程本身出问题，捕获 SQLException 是唯一选择。 工厂模式和抽象工厂模式有什么区别 答：抽象工场模式提供一个多层级的抽象。考虑不同的工厂继承自同一个抽象工厂，代表基于工厂的不同对象结构的创建，例如， AutomobileFactory,UserFactory,RoleFactory等都继承自 AbstractFactory。每一个独立的工厂代表那种类型物体的创造器。 下面是一个工厂模式和抽象工厂模式的UML图： 什么时候重写 hashCode()和 equals()方法 答：当需要通过业务逻辑校验两个对象是否相等，而不是通过两个对象是否执行同一地址。例如两个员工对象在 emp_id 相等的时候相等，即使它们是通过不同的代码创建出来的两个不同对象。 另外，如果你使用一个对象作为 HashMap的key，你必须重写这两个方法。 作为java equals-hashcode约束的一部分，当你重写equals的时候，必须重写hashcode. 否则你不能在Set，Map这样的类里面使用，因为他们通过equals()方法来保证逻辑正确性。 双引号直接创建字符串和使用new()创建字符串有什么区别 答: 使用new()创建String对象，实例被创建在堆中, 不会被添加到String常量池中，当通过字面量创建时，会被放到堆中的永久区的String常量池中。 Stringstr = newString(“Test”) 不会把str放到String常量池中，需要调用String.intern()方法，才会把它放到String常量池中。 当使用String字面量创建String对象时，如通过String s = “Test”, java会自动放入String常量池中。 另外，如果把”Test”这样的String字面量传进去，也会创建另外一个对象:”Test” 在String常量池。 什么是不可变对象，如何写一个不可变类 答：不可变对象是指Java类的对象一单被创建，不能被修改。任何不可变对象对象的修改在创建时候就已经完成，例如，Java中String是不可变的。 大多数不可变类是final的, 这样可以防止因子类重写方法而导致不可变失效。 你也可以实现相同的功能通过让成员非final但是private，且除了构造方法任何其他方法无法修改。 另外，要确保没有暴露不可变对象的内部，尤其是它包含可变成员的时候。 同时，当你从客户端接收到可变的对象时，例如 java.util.Date, 使用clone() 方法 来获取一个独立的拷贝，防止恶意修改可变对象带来的风险。 相同的优化需要在返回一个可变成员时执行。返回另一个独立拷贝给客户端；不要返回可变对象的原始引用。","tags":"java 面试题"},{"title":"Java - 锁机制","url":"/posts/dd749e64.html","text":"公平锁/非公平锁公平锁是指多个线程按照申请锁的顺序来获取锁。 非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象。 对于Java ReentrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。 对于Synchronized而言，也是一种非公平锁。由于其并不像ReentrantLock是通过AQS的来实现线程调度，所以并没有任何办法使其变成公平锁。 可重入锁/不可重入锁可重入锁广义上的可重入锁指的是可重复可递归调用的锁，在外层使用锁之后，在内层仍然可以使用，并且不发生死锁（前提得是同一个对象或者class），这样的锁就叫做可重入锁。ReentrantLock和synchronized都是可重入锁。 1234567synchronized void setA() throws Exception&#123; Thread.sleep(1000); setB();&#125;synchronized void setB() throws Exception&#123; Thread.sleep(1000);&#125; 不可重入锁不可重入锁，与可重入锁相反，不可递归调用，递归调用就发生死锁。下面看一个使用自旋锁模拟不可重入锁的例子： 123456789101112131415161718192021222324252627282930313233package main.java.com.study.lock;import java.util.concurrent.atomic.AtomicReference;/** * @author: whb * @description: 自旋锁模拟不可重入锁 */public class UnReentrantLock &#123; private AtomicReference&lt;Thread&gt; owner = new AtomicReference&lt;&gt;(); /** * 加锁 */ public void lock() &#123; Thread current = Thread.currentThread(); //经典的自旋语法 for (; ; ) &#123; if (!owner.compareAndSet(null, current)) &#123; return; &#125; &#125; &#125; /** * 解锁 */ public void unlock() &#123; Thread current = Thread.currentThread(); owner.compareAndSet(current, null); &#125;&#125; 代码也比较简单，使用原子引用来存放线程，同一线程两次调用lock()方法，如果不执行unlock()释放锁的话，第二次调用自旋的时候就会产生死锁，这个锁就不是可重入的，而实际上同一个线程不必每次都去释放锁再来获取锁，这样的调度切换是很耗资源的。把它变成可重入锁 1234567891011121314151617181920212223242526272829303132333435363738394041424344package main.java.com.study.lock;import java.util.concurrent.atomic.AtomicReference;/** * @author: whb * @description: 自旋锁模拟可重入锁 */public class ReentrantLock &#123; private AtomicReference&lt;Thread&gt; owner = new AtomicReference&lt;&gt;(); //记录重入次数 private volatile int state = 0; /** * 加锁 */ public void lock() &#123; Thread current = Thread.currentThread(); if (current == owner.get()) &#123; state++; return; &#125; for (; ; ) &#123; if (!owner.compareAndSet(null, current)) &#123; return; &#125; &#125; &#125; /** * 释放锁 */ public void unlock() &#123; Thread current = Thread.currentThread(); if (current == owner.get()) &#123; if (state != 0) &#123; state--; &#125; else &#123; owner.compareAndSet(current, null); &#125; &#125; &#125;&#125; 在执行每次操作之前，判断当前锁持有者是否是当前对象，采用state计数，不用每次去释放锁。 J.U.C包中ReentrantLock中可重入锁实现，看下非公平锁的锁获取实现： 123456789101112131415161718final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false;&#125; 在AQS中维护了一个private volatile int state来计数重入次数，避免了频繁的持有释放操作，这样既提升了效率，又避免了死锁。 独占锁/共享锁独占锁该锁每一次只能被一个线程所持有。 共享锁该锁可被多个线程共有，典型的就是ReentrantReadWriteLock里的读锁，它的读锁是可以被共享的，但是它的写锁确每次只能被独占。 另外读锁的共享可保证并发读是非常高效的，但是读写和写写，写读都是互斥的。 独占锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独占或者共享。对于Synchronized而言，当然是独占锁。 互斥锁/读写锁互斥锁在访问共享资源之前进行加锁操作，在访问完成之后进行解锁操作。加锁后，任何其他试图再次加锁的线程会被阻塞，直到当前进程解锁。如果解锁时有一个以上的线程阻塞，那么所有该锁上的线程都被变成就绪状态， 第一个变为就绪状态的线程又执行加锁操作，那么其他的线程又会进入等待。在这种方式下，只有一个线程能够访问被互斥锁保护的资源。 读写锁读写锁既是互斥锁，又是共享锁，read模式是共享，write是互斥(排它锁)的。读写锁在Java中的具体实现就是ReadWriteLock。 读写锁有三种状态：读加锁状态、写加锁状态和不加锁状态。 一次只有一个线程可以占有写模式的读写锁，但是多个线程可以同时占有读模式的读写锁。 只有一个线程可以占有写状态的锁，但可以有多个线程同时占有读状态锁，这也是它可以实现高并发的原因。当其处于写状态锁下，任何想要尝试获得锁的线程都会被阻塞，直到写状态锁被释放；如果是处于读状态锁下，允许其它线程获得它的读状态锁，但是不允许获得它的写状态锁，直到所有线程的读状态锁被释放；为了避免想要尝试写操作的线程一直得不到写状态锁，当读写锁感知到有线程想要获得写状态锁时，便会阻塞其后所有想要获得读状态锁的线程。所以读写锁非常适合资源的读操作远多于写操作的情况。 悲观锁/乐观锁悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。 乐观锁总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。 分段锁分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。 并发容器类的加锁机制是基于粒度更小的分段锁，分段锁也是提升多并发程序性能的重要手段之一。 在并发程序中，串行操作是会降低可伸缩性，并且上下文切换也会减低性能。在锁上发生竞争时将导致这两种问题，使用独占锁时保护受限资源的时候，基本上是采用串行方式—-每次只能有一个线程能访问它。所以对于可伸缩性来说最大的威胁就是独占锁。 三种方式降低锁的竞争程度：1、减少锁的持有时间 2、降低锁的请求频率 3、使用带有协调机制的独占锁，这些机制允许更高的并 无锁/偏向锁/轻量级锁/重量级锁锁的四种状态 无锁状态； 偏向锁状态； 轻量级锁状态； 重量级锁状态； 这四种状态都不是Java语言中的锁，而是Jvm为了提高锁的获取与释放效率而做的优化(使用synchronized时)。锁的状态是通过对象监视器在对象头中的字段来表明的。四种状态会随着竞争的情况逐渐升级，而且是不可逆的过程，即不可降级。 Java对象头以Hotspot虚拟机为例，Hotspot的对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）。 Mark Word：默认存储对象的HashCode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。 Klass Point：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 MonitorMonitor可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个Java对象就有一把看不见的锁，称为内部锁或者Monitor锁。Monitor是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联，同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。 synchronized通过Monitor来实现线程同步，Monitor是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步。“阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长”。这种方式就是synchronized最初实现同步的方式，这就是JDK 6之前synchronized效率低的原因。这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”，JDK 6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。所以目前锁一共有4种状态，级别从低到高依次是：无锁、偏向锁、轻量级锁和重量级锁。锁状态只能升级不能降级。下面给出四种锁状态对应的的Mark Word内容，然后再分别讲解四种锁状态的思路以及特点： 无锁无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。上面我们介绍的CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。 偏向锁偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。 轻量级锁是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。 重量级锁升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。 自旋锁CAS算法我们知道CAS算法是乐观锁的一种实现方式，CAS算法中又涉及到自旋锁，先回顾下CAS算法：CAS是英文单词Compare and Swap（比较并交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数 需要读写的内存值 V 进行比较的值 A 拟写入的新值 B 更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B，否则不会执行任何操作。一般情况下是一个自旋操作，即不断的重试。 CAS存在的问题 ABA问题。CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。ABA问题的解决思路就是在变量前面添加版本号，每次变量更新的时候都把版本号加一，这样变化过程就从“A－B－A”变成了“1A－2B－3A”。JDK从1.5开始提供了AtomicStampedReference类来解决ABA问题，具体操作封装在compareAndSet()中。compareAndSet()首先检查当前引用和当前标志与预期引用和预期标志是否相等，如果都相等，则以原子方式将引用值和标志的值设置为给定的更新值。 循环时间长开销大。CAS操作如果长时间不成功，会导致其一直自旋，给CPU带来非常大的开销。 只能保证一个共享变量的原子操作。对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。 Java从1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。 自旋锁在介绍自旋锁前，我们需要介绍一些前提知识来帮助大家明白自旋锁的概念。阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。如果物理机器有多个处理器，能够让两个或以上的线程同时并行执行，我们就可以让后面那个请求锁的线程不放弃CPU的执行时间，看看持有锁的线程是否很快就会释放锁。而为了让当前线程“稍等一下”，我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。这就是自旋锁。 1234567891011121314public class SpinLock &#123; private AtomicReference&lt;Thread&gt; cas = new AtomicReference&lt;Thread&gt;(); public void lock() &#123; Thread current = Thread.currentThread(); // 利用CAS while (!cas.compareAndSet(null, current)) &#123; // DO nothing &#125; &#125; public void unlock() &#123; Thread current = Thread.currentThread(); cas.compareAndSet(current, null); &#125;&#125; lock（)方法利用的CAS，当第一个线程A获取锁的时候，能够成功获取到，不会进入while循环，如果此时线程A没有释放锁，另一个线程B又来获取锁，此时由于不满足CAS，所以就会进入while循环，不断判断是否满足CAS，直到A线程调用unlock方法释放了该锁。 自旋锁的缺陷 如果某个线程持有锁的时间过长，就会导致其它等待获取锁的线程进入循环等待，消耗CPU。使用不当会造成CPU使用率极高。所以，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当挂起线程。 上面Java实现的自旋锁不是公平的，即无法满足等待时间最长的线程优先获取锁。不公平的锁就会存在“线程饥饿”问题。 自旋锁的优点 自旋锁不会使线程状态发生切换，一直处于用户态，即线程一直都是active的；不会使线程进入阻塞状态，减少了不必要的上下文切换，执行速度快 非自旋锁在获取不到锁的时候会进入阻塞状态，从而进入内核态，当获取到锁的时候需要从内核态恢复，需要线程上下文切换。 （线程被阻塞后便进入内核（Linux）调度状态，这个会导致系统在用户态与内核态之间来回切换，严重影响锁的性能） 适应性自旋锁自旋锁在JDK1.4.2中引入，使用-XX:+UseSpinning来开启。JDK 6中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。在自旋锁中 另有三种常见的锁形式:TicketLock、CLHlock和MCSlock。","tags":"java"},{"title":"MySQL性能优化","url":"/posts/18d8d4e.html","text":"啦啦啦啦啦啦啦啦啦","tags":"数据库 mysql"},{"title":"Java - LongAdder","url":"/posts/d182cfa5.html","text":"CAS有没有问题呢？肯定是有的。比如说大量的线程同时并发修改一个AtomicLong，可能有很多线程会不停的自旋，进入一个无限重复的循环中。这些线程不停地获取值，然后发起CAS操作，但是发现这个值被别人改过了，于是再次进入下一个循环，获取值，发起CAS操作又失败了，再次进入下一个循环。在大量线程高并发更新AtomicLong的时候，这种问题可能会比较明显，导致大量线程空循环，自旋转，性能和效率都不是特别好。于是，Java 8推出了一个新的类，LongAdder，在AtomicLong的基础上进行了热点分离，热点分离类似于有锁操作中的减小锁粒度，尝试使用分段CAS以及自动分段迁移的方式来大幅度提升多线程高并发执行CAS操作的性能！在无锁中，也可以用类似的方式来增加CAS的成功率，从而提高性能。LongAdder原理如下图： AtomicLong的实现方式是内部有个value 变量，当多线程并发自增，自减时，均通过CAS 指令从机器指令级别操作保证并发的原子性。唯一会制约AtomicLong高效的原因是高并发，高并发意味着CAS的失败几率更高， 重试次数更多，越多线程重试，CAS失败几率又越高，变成恶性循环，AtomicLong效率降低。 在LongAdder的底层实现中，首先有一个base值，刚开始多线程来不停的累加数值，都是对base进行累加的，比如刚开始累加成了base = 5。接着如果发现并发更新的线程数量过多，就会开始施行分段CAS的机制，也就是内部会搞一个Cell数组，每个数组是一个数值分段。这时，让大量的线程分别去对不同Cell内部的value值进行CAS累加操作，这样就把CAS计算压力分散到了不同的Cell分段数值中了！这样就可以大幅度的降低多线程并发更新同一个数值时出现的无限循环的问题，大幅度提升了多线程并发更新数值的性能和效率！而且他内部实现了自动分段迁移的机制，也就是如果某个Cell的value执行CAS失败了，那么就会自动去找另外一个Cell分段内的value值进行CAS操作。这样也解决了线程空旋转、自旋不停等待执行CAS操作的问题，让一个线程过来执行CAS时可以尽快的完成这个操作。最后，如果你要从LongAdder中获取当前累加的总值，就会把base值和所有Cell分段数值加起来返回给你。LongAdder是一种以空间换时间的策略。","tags":"java j.u.c"},{"title":"MySQL-索引结构","url":"/posts/3bf347e4.html","text":"BTree索引BTree（多路搜索树，并不是二叉的）是一种常见的数据结构。 不适合： 单列索引的列不能包含null的记录，复合索引的各个列不能包含同时为null的记录，否则会全表扫描；索引失效很多时候是因为这列有null，空值不适合键值较少的列（重复数据较多的列）；假如你建立了，会发生什么情况呢？查询反而会变慢前导模糊查询不能利用索引(like ‘%XX’或者like ‘%XX%’)，该类sql语句导致索引失效 Hash散列索引Hash散列索引是根据HASH算法来构建的索引。 适合： 精确查找非常快（包括= &lt;&gt; 和in），其检索效率非常高，索引的检索可以一次定位，不像BTree 索引需要从根节点到枝节点，所以 Hash 索引的查询效率要远高于 B-Tree 索引。 不适合： 不适合模糊查询和范围查询（包括like，&gt;，&lt;，between……and等），由于 Hash 索引比较的是进行 Hash 运算之后的 Hash 值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash 算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样；不适合排序，数据库无法利用索引的数据来提升排序性能，同样是因为Hash值的大小不确定；复合索引不能利用部分索引字段查询，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。同样不适合键值较少的列（重复值较多的列）； Bitmap位图索引就是用位图表示的索引，对列的每个键值建立一个位图。相对于BTree索引，占用的空间非常小，创建和使用非常快。位图索引由于只存储键值的起止Rowid和位图,占用的空间非常少。 适合 适合决策支持系统；当select count(XX) 时,可以直接访问索引中一个位图就快速得出统计数据；当根据键值做and，or或 in(x,y,..)查询时，直接用索引的位图进行或运算,快速得出结果行数据。 不适合 不适合键值较多的列（重复值较少的列）；不适合update、insert、delete频繁的列，代价很高。到底是什么代价呢？update,insert,delete的时候会锁住键值一样的行。","tags":"数据库 mysql"},{"title":"IDEA使用FindBugs插件","url":"/posts/570da5f6.html","text":"下载安装在Idea中，打开”File”–&gt;”Settings”，或者使用快捷键”Ctrl+Alt+S”打开设置窗口： 在设置窗口找到** plugins *标签页，然后点击下方的 * Browse Repositories **： 在新打开的Browse Repositories窗口搜索findbugs，然后点击Install进行安装，因为我已经安装过了，所以不再显示install按钮： 使用FindBugs 简单说明： 鼠标移动到右边的所有图标，看看每个图标都是什么意思。大概说一下：第一竖列的红色图标是分析当前的这个文件。下面是分析是某一个类，鼠标所在的那个类。再往下是某个包，某个模块，整个项目，所有修改过的文件，等等。第二竖列则是控制分析结果的展示情况。 下面就整个实际找到的代码的问题，单独分析某个service文件，看代码里面的问题。如下图所示： Find Bugs的意思是说代码里面把SimpleDateFormat声明为静态属性，但是SimpleDateFormat是线程不安全的。在多线程使用的时候，可能就会有意想不到的问题。所以就找到个问题啦。根据提示进行修改，如下： 在上图中看到代码里有很多黄色提示，强迫症的人看着很不爽，那怎么把代码里面这些黄色的提示给关掉呢？ 点这个 ** × ** 就以啦，代码就恢复成原来的样子啦。 常见的错误信息 Bad practice 代码中的一些坏习惯 Class names should start with an upper case letter 主要包括类名的命名，以大写字母开头。 Method names should start with a lower case letter 方法名以小写字母开头。 Field names should start with a lower case letter 字段名以小写字母开头。 equals()method does not check for null argument equals()方法应该检查非空。 Class defines equals() and uses Object.hashCode() 一个类覆写了equals方法，没有覆写hashCode方法，使用了Object对象的hashCode方法。 Method ignores exceptional return value 方法忽略返回值的异常信息。 Equals method should not assume anything about the type of its argument equals(Object o)方法不能对参数o的类型做任何的假设。比较此对象与指定的对象。当且仅当该参数不为 null，并且是表示与此对象相同的类型的对象时，结果才为 true。 Comparison of String objects using == or != 用==或者！=去比较String类型的对象。 Method might ignore exception 方法可能忽略异常。 Method invokes System.exit() 在方法中调用System.exit(…)语句，考虑用RuntimeException来代替。 Method ignores result of InputStream.read() InputStream.read方法忽略返回的多个字符，如果对结果没有检查就没法正确处理用户读取少量字符请求的情况。 Dodgy code 糟糕的代码 Switch statement found where default case is missing Switch没有默认情况下执行的case语句。 Switch statement found where one case falls through to the next case Switch语句中一个分支执行后又执行了下一个分支。通常case后面要跟break 或者return语句来跳出。 Dead store to local variable 该指令为局部变量赋值，但在其后的没有对她做任何使用。通常，这表明一个错误，因为值从未使用过。 Write to static field from instance method 在实例方法写入静态字段。 Redundant nullcheck of value known to be non-null 方法中对不为空的值进行为空的判断。 Method uses the same code for two branches 此方法使用相同的代码，以实现两个有条件的分支。检查以确保这是不是一个编码错误。 Exception is caught when Exception is not thrown 在try/catch块中捕获异常，但是异常没有在try语句中抛出而RuntimeException又没有明确的被捕获。 Integral division result cast to double or float 整形数除法强制转换为double或者float类型。 Possible null pointer dereference due to return value of called method 方法的返回值没有进行是否为空的检查就重新赋值，这样可能会出现空指针异常。 Useless object created 对象创建了并没有用。 Unread public/protected field 没有用到的字段。 Internationalization 关于代码国际化相关方面的 Consider using Locale parameterized version of invoked method使用平台默认的编码格式对字符串进行大小写转换，这可能导致国际字符的转换不当。使用以下方式对字符进行转换 ** Performance ** 关于代码性能相关方面的 Boxing/unboxing to parse a primitive 类型转换 比如字符串转换成int 应该使用Integer.parseInt(“”) 代替Integer.valueOf(“”) Method concatenates string using + in aloop每次循环里的字符串+连接，都会新产生一个string对象，在java中，新建一个对象的代价是很昂贵的，特别是在循环语句中，效率较低解决办法：使用StringBuffer或者StringBuilder重用对象。 Private method is never called 私有方法没有被调用 Explicit garbage collection;extremely dubious except in benchmarking code在代码中显式的调用垃圾回收命名，这样做并不能起作用。在过去，有人在关闭操作或者finalize方法中调用垃圾回收方法导致了很多的性能浪费。这样大规模回收对象时会造成处理器运行缓慢。 Unread field:should this field be static? 没有用到的static 字段 should be a static inner class 此内部类应该使用static修饰 ** Experimental ** Method may fail to clean up stream or resource on checked exception这种方法可能无法清除（关闭，处置）一个流，数据库对象，或其他资源需要一个明确的清理行动解决方法：流的关闭都写在finally里面 Malicious code vulnerability 关于恶意破坏代码相关方面的 May expose internal representation by incorporating reference to mutable object此代码把外部可变对象引用存储到对象的内部表示。如果实例受到不信任的代码的访问和没有检查的变化危及对象和重要属性的安全。存储一个对象的副本，在很多情况下是更好的办法。 Field isn’t final but should be 此字段前应该加final Field isn’t final and can’t be protected from malicious code 此字段前应该加final Field should be package protected一个静态字段是可以被恶意代码或其他的包访问修改。可以把这种类型的字段声明为final类型的以防止这种错误。 Multithreaded correctness 关于多线程代码正确性相关方面的 Static DateFormat DateFormat 在多线程中本身就是不安全的，如果在线程范围中共享一个DateFormat的实例而不使用一个同步的方法在应用中就会出现一些奇怪的行为。 Call to static DateFormat DateFormats多线程使用本事就是不安全的,改进方法：需要创建多实例或线程同步 Correctness 关于代码正确性相关方面的 Nullcheck of value previously dereferenced 此代码之前废弃null值检查。解决办法 进行null检查 Possible null pointer dereference 可能为null Null pointer dereference 对象赋为null值后 没有被重新赋值 Possible null pointer dereference in method on exception path 在异常null值处理分支调用的方法上，可能存在对象去除引用操作 value is null and guaranteed to be dereferenced on exception path exception分支上，存在引用一个null对象的方法，引发空指针异常。 Self comparison of value with itself 方法中对一个局部变量自身进行比较运算，并可说明错误或逻辑错误。请确保您是比较正确的事情。 An apparent infinite recursive loop 明显的无限迭代循环,将导致堆栈溢出.","tags":"idea 插件"},{"title":"设计模式-责任链模式","url":"/posts/b6c1490f.html","text":"模式定义责任链模式（Chain of Responsibility） 是行为型设计模式之一，其将链中每一个节点看作是一个对象，每个节点处理的请求均不同，从而避免了请求的发送者和接收者之间的耦合关系，且内部自动维护一个下一节点对象。当一个请求从链式的首端发出时，会沿着链的路径依次传递给每一个节点对象，直至有对象处理这个请求为止。 主要作用责任链模式 解耦了请求与处理，客户只需将请求发送到链上即可，无需关心请求的具体内容和处理细节，请求会自动进行传递直至有节点对象进行处理。 UML类图 角色 Handler（抽象处理者）：它定义了一个处理请求的接口，一般设计为抽象类，由于不同的具体处理者处理请求的方式不同，因此在其中定义了抽象请求处理方法。因为每一个处理者的下家还是一个处理者，因此在抽象处理者中定义了一个抽象处理者类型的对象，作为其对下家的引用。通过该引用，处理者可以连成一条链。 ConcreteHandler（具体处理者）：它是抽象处理者的子类，可以处理用户请求，在具体处理者类中实现了抽象处理者中定义的抽象请求处理方法，在处理请求之前需要进行判断，看是否有相应的处理权限，如果可以处理请求就处理它，否则将请求转发给后继者；在具体处理者中可以访问链中下一个对象，以便请求的转发。 模式优点 对象仅需知道该请求会被处理即可，且链中的对象不需要知道链的结构，由客户端负责链的创建，降低了系统的耦合度。 请求处理对象仅需维持一个指向其后继者的引用，而不需要维持它对所有的候选处理者的引用，可简化对象的相互连接。 链路结构灵活，可以通过改变链路结构动态地新增或删减责任。 新增一个新的具体请求处理者时无须修改原有代码，只需要在客户端重新建链即可，符合 “开闭原则”。 模式缺点 一个请求可能因职责链没有被正确配置而得不到处理。 对于比较长的职责链，请求的处理可能涉及到多个处理对象，系统性能将受到一定影响，且不方便调试。 如果节点对象存在循环引用时，会造成死循环，导致系统崩溃。 适用场景 有多个对象可以处理同一个请求，具体哪个对象处理该请求待运行时刻再确定，客户端只需将请求提交到链上，而无须关心请求的处理对象是谁以及它是如何处理的。 在不明确指定接收者的情况下，向多个对象中的一个提交一个请求。 可动态指定一组对象处理请求，客户端可以动态创建职责链来处理请求，还可以改变链中处理者之间的先后次序。 使用步骤定义抽象处理者123456789101112131415161718192021222324252627package main.java.com.study.designPatterns.chain.common;/** * @author: whb * @description: 定义抽象处理者--职责的接口，也就是处理请求的接口 */public abstract class Handler &#123; /** * 持有后继的职责对象 */ protected Handler successor; /** * 设置后继的职责对象 * * @param successor 后继的职责对象 */ public void setSuccessor(Handler successor) &#123; this.successor = successor; &#125; /** * 示意处理请求的方法，虽然这个示意方法是没有传入参数， * 但实际是可以传入参数的，根据具体需要来选择是否传递参数 */ public abstract void handleRequest();&#125; 定义具体处理者123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package main.java.com.study.designPatterns.chain.common;/** * @author: whb * @description: 定义具体处理者--具体的职责对象，用来处理请求 */public class ConcreteHandler1 extends Handler &#123; @Override public void handleRequest() &#123; //根据某些条件来判断是否属于自己处理的职责范围 //判断条件比如：从外部传入的参数，或者这里主动去获取的外部数据， //如从数据库中获取等，下面这句话只是个示意 boolean someCondition = false; if (someCondition) &#123; //如果属于自己处理的职责范围，就在这里处理请求 //具体的处理代码 System.out.println(\"具体处理者1 处理请求...\"); &#125; else &#123; //如果不属于自己处理的职责范围，那就判断是否还有后继的职责对象 //如果有，就转发请求给后继的职责对象 //如果没有，什么都不做，自然结束 if (this.successor != null) &#123; this.successor.handleRequest(); &#125; &#125; &#125;&#125;package main.java.com.study.designPatterns.chain.common;/** * @author: whb * @description: 具体处理者2 */public class ConcreteHandler2 extends Handler &#123; @Override public void handleRequest() &#123; //根据某些条件来判断是否属于自己处理的职责范围 //判断条件比如：从外部传入的参数，或者这里主动去获取的外部数据， //如从数据库中获取等，下面这句话只是个示意 boolean someCondition = true; if (someCondition) &#123; //如果属于自己处理的职责范围，就在这里处理请求 //具体的处理代码 System.out.println(\"具体处理者2 处理请求...\"); &#125; else &#123; //如果不属于自己处理的职责范围，那就判断是否还有后继的职责对象 //如果有，就转发请求给后继的职责对象 //如果没有，什么都不做，自然结束 if (this.successor != null) &#123; this.successor.handleRequest(); &#125; &#125; &#125;&#125; 客户端调用1234567891011121314151617package main.java.com.study.designPatterns.chain.common;/** * @author: whb * @description: 客户端调用 */public class Client &#123; public static void main(String[] args) &#123; //先要组装职责链 Handler h1 = new ConcreteHandler1(); Handler h2 = new ConcreteHandler2(); h1.setSuccessor(h2); //然后提交请求 h1.handleRequest(); &#125;&#125; 模式示例背景很多公司都有这样的福利，就是项目组或者是部门可以向公司申请一些聚餐费用，用于组织项目组成员或者是部门成员进行聚餐活动，以增进人员之间的情感，更有利于工作中的相互合作。 申请聚餐费用的大致流程一般是：由申请人先填写申请单，然后交给领导审查，如果申请批准下来了，领导会通知申请人审批通过，然后申请人去财务核领费用，如果没有核准，领导会通知申请人审批未通过，此事也就此作罢了。 不同级别的领导，对于审批的额度是不一样的，比如：项目经理只能审批500元以内的申请；部门经理能审批1000元以内的申请；而总经理可以审核任意额度的申请。 也就是说，当某人提出聚餐费用申请的请求后，该请求会由项目经理、部门经理、总经理之中的某一位领导来进行相应的处理，但是提出申请的人并不知道最终会由谁来处理他的请求，一般申请人是把自己的申请提交给项目经理，或许最后是由总经理来处理他的请求，但是申请人并不知道应该由总经理来处理他的申请请求。 分析当某人提出聚餐费用申请的请求后，该请求会在项目经理-部门经理-总经理这样一条领导处理链上进行传递，发出请求的人并不知道谁会来处理他的请求，每个领导会根据自己的职责范围，来判断是处理请求还是把请求交给更高级的领导，只要有领导处理了，传递就结束了。 需要把每位领导的处理独立出来，实现成单独的职责处理对象，然后为它们提供一个公共的、抽象的父职责对象，这样就可以在客户端来动态的组合职责链，实现不同的功能要求了。 具体代码定义抽象处理者123456789101112131415161718192021222324252627282930package main.java.com.study.designPatterns.chain.demoTwo;/** * @author: whb * @description: 抽象处理者类，定义职责对象 */public abstract class Handler &#123; /** * 持有下一个处理请求的对象 */ protected Handler successor = null; /** * 设置下一个处理请求的对象 * * @param successor 下一个处理请求的对象 */ public void setSuccessor(Handler successor) &#123; this.successor = successor; &#125; /** * 处理聚餐费用的申请 * * @param user 申请人 * @param fee 申请的钱数 * @return 成功或失败的具体通知 */ public abstract String handleFeeRequest(String user, double fee);&#125; 定义具体处理者项目经理： 1234567891011121314151617181920212223242526272829package main.java.com.study.designPatterns.chain.demoTwo;/** * @author: whb * @description: 具体处理者--项目经理 */public class ProjectManager extends Handler &#123; @Override public String handleFeeRequest(String user, double fee) &#123; String str = \"\"; //项目经理的权限比较小，只能在500以内 if (fee &lt; 500) &#123; //为了测试，简单点，只同意小李的 if (\"小李\".equals(user)) &#123; str = \"项目经理同意\" + user + \"聚餐费用\" + fee + \"元的请求\"; &#125; else &#123; //其它人一律不同意 str = \"项目经理不同意\" + user + \"聚餐费用\" + fee + \"元的请求\"; &#125; return str; &#125; else &#123; //超过500，继续传递给级别更高的人处理 if (this.successor != null) &#123; return successor.handleFeeRequest(user, fee); &#125; &#125; return str; &#125;&#125; 部门经理： 1234567891011121314151617181920212223242526272829package main.java.com.study.designPatterns.chain.demoTwo;/** * @author: whb * @description: 具体处理者--部门经理 */public class DepManager extends Handler &#123; @Override public String handleFeeRequest(String user, double fee) &#123; String str = \"\"; //部门经理的权限只能在1000以内 if (fee &lt; 1000) &#123; //为了测试，简单点，只同意小李申请的 if (\"小李\".equals(user)) &#123; str = \"部门经理同意\" + user + \"聚餐费用\" + fee + \"元的请求\"; &#125; else &#123; //其它人一律不同意 str = \"部门经理不同意\" + user + \"聚餐费用\" + fee + \"元的请求\"; &#125; return str; &#125; else &#123; //超过1000，继续传递给级别更高的人处理 if (this.successor != null) &#123; return this.successor.handleFeeRequest(user, fee); &#125; &#125; return str; &#125;&#125; 总经理： 1234567891011121314151617181920212223242526272829package main.java.com.study.designPatterns.chain.demoTwo;/** * @author: whb * @description: 具体处理者--总经理 */public class GeneralManager extends Handler &#123; @Override public String handleFeeRequest(String user, double fee) &#123; String str = \"\"; //总经理的权限很大，只要请求到了这里，他都可以处理 if (fee &gt;= 1000) &#123; //为了测试，简单点，只同意小李的 if (\"小李\".equals(user)) &#123; str = \"总经理同意\" + user + \"聚餐费用\" + fee + \"元的请求\"; &#125; else &#123; //其它人一律不同意 str = \"总经理不同意\" + user + \"聚餐费用\" + fee + \"元的请求\"; &#125; return str; &#125; else &#123; //如果还有后继的处理对象，继续传递 if (this.successor != null) &#123; return successor.handleFeeRequest(user, fee); &#125; &#125; return str; &#125;&#125; 客户端调用1234567891011121314151617181920212223242526272829303132package main.java.com.study.designPatterns.chain.demoTwo;/** * @author: whb * @description: 测试类 */public class Client &#123; public static void main(String[] args) &#123; //先要组装职责链 Handler h1 = new GeneralManager(); Handler h2 = new DepManager(); Handler h3 = new ProjectManager(); h3.setSuccessor(h2); h2.setSuccessor(h1); //开始测试 String ret1 = h3.handleFeeRequest(\"小李\", 300); System.out.println(\"the ret1=\" + ret1); String ret2 = h3.handleFeeRequest(\"小张\", 300); System.out.println(\"the ret2=\" + ret2); String ret3 = h3.handleFeeRequest(\"小李\", 600); System.out.println(\"the ret3=\" + ret3); String ret4 = h3.handleFeeRequest(\"小张\", 600); System.out.println(\"the ret4=\" + ret4); String ret5 = h3.handleFeeRequest(\"小李\", 1200); System.out.println(\"the ret5=\" + ret5); String ret6 = h3.handleFeeRequest(\"小张\", 1200); System.out.println(\"the ret6=\" + ret6); &#125;&#125; 拓展-处理多种请求上面的示例是同一个职责链处理一种请求的情况，现在有这样的需求，还是费用申请的功能，这次是申请预支差旅费，假设还是同一流程，也就是组合同一个职责链，从项目经理-传递给部门经理-传递给总经理，虽然流程相同，但是每个处理类需要处理两种请求，它们的具体业务逻辑是不一样的。 简单的处理方式简单处理方式就是为每种业务单独定义一个方法，然后客户端根据不同的需要调用不同的方法。直接改造上面的代码，这里故意把两个方法做的有些不一样，一个是返回String类型的值，一个是返回boolean类型的值；一个返回到客户端再输出信息，一个是直接在职责处理里面就输出信息。 首先是改造职责对象的接口，添加上新的业务方法： 123456789101112131415161718192021222324252627282930313233343536373839package main.java.com.study.designPatterns.chain.demoTwo;/** * @author: whb * @description: 抽象处理者类，定义职责对象 */public abstract class Handler &#123; /** * 持有下一个处理请求的对象 */ protected Handler successor = null; /** * 设置下一个处理请求的对象 * * @param successor 下一个处理请求的对象 */ public void setSuccessor(Handler successor) &#123; this.successor = successor; &#125; /** * 处理聚餐费用的申请 * * @param user 申请人 * @param fee 申请的钱数 * @return 成功或失败的具体通知 */ public abstract String handleFeeRequest(String user, double fee); /** * 处理预支差旅费用的申请 * * @param user 申请人 * @param requestFee 申请的钱数 * @return 是否同意 */ public abstract boolean handlePreFeeRequest(String user, double requestFee);&#125; 职责的接口发生了改变，对应的处理类也要改变，这几个处理类是类似的，原有的功能不变，然后在新的实现方法里面，同样判断一下是否属于自己处理的范围，如果属于自己处理的范围那就处理，否则就传递到下一个处理。 项目经理： 123456789101112131415161718192021222324252627282930313233343536373839404142434445package main.java.com.study.designPatterns.chain.demoTwo;/** * @author: whb * @description: 具体处理者--项目经理 */public class ProjectManager extends Handler &#123; @Override public String handleFeeRequest(String user, double fee) &#123; String str = \"\"; //项目经理的权限比较小，只能在500以内 if (fee &lt; 500) &#123; //为了测试，简单点，只同意小李的 if (\"小李\".equals(user)) &#123; str = \"项目经理同意\" + user + \"聚餐费用\" + fee + \"元的请求\"; &#125; else &#123; //其它人一律不同意 str = \"项目经理不同意\" + user + \"聚餐费用\" + fee + \"元的请求\"; &#125; return str; &#125; else &#123; //超过500，继续传递给级别更高的人处理 if (this.successor != null) &#123; return successor.handleFeeRequest(user, fee); &#125; &#125; return str; &#125; @Override public boolean handlePreFeeRequest(String user, double requestNum) &#123; //项目经理的权限比较小，只能在5000以内 if (requestNum &lt; 5000) &#123; //工作需要嘛，统统同意 System.out.println(\"项目经理同意\" + user + \"预支差旅费用\" + requestNum + \"元的请求\"); return true; &#125; else &#123; //超过5000，继续传递给级别更高的人处理 if (this.successor != null) &#123; return this.successor.handlePreFeeRequest(user, requestNum); &#125; &#125; return false; &#125;&#125; 部门经理： 123456789101112131415161718192021222324252627282930313233343536373839404142434445package main.java.com.study.designPatterns.chain.demoTwo;/** * @author: whb * @description: 具体处理者--部门经理 */public class DepManager extends Handler &#123; @Override public String handleFeeRequest(String user, double fee) &#123; String str = \"\"; //部门经理的权限只能在1000以内 if (fee &lt; 1000) &#123; //为了测试，简单点，只同意小李申请的 if (\"小李\".equals(user)) &#123; str = \"部门经理同意\" + user + \"聚餐费用\" + fee + \"元的请求\"; &#125; else &#123; //其它人一律不同意 str = \"部门经理不同意\" + user + \"聚餐费用\" + fee + \"元的请求\"; &#125; return str; &#125; else &#123; //超过1000，继续传递给级别更高的人处理 if (this.successor != null) &#123; return this.successor.handleFeeRequest(user, fee); &#125; &#125; return str; &#125; @Override public boolean handlePreFeeRequest(String user, double requestFee) &#123; //部门经理的权限20000以内 if (requestFee &lt; 20000) &#123; //工作需要嘛，统统同意 System.out.println(\"部门经理同意\" + user + \"预支差旅费用\" + requestFee + \"元的请求\"); return true; &#125; else &#123; //超过20000，继续传递给级别更高的人处理 if (this.successor != null) &#123; return this.successor.handlePreFeeRequest(user, requestFee); &#125; &#125; return false; &#125;&#125; 总经理： 123456789101112131415161718192021222324252627282930313233343536373839404142434445package main.java.com.study.designPatterns.chain.demoTwo;/** * @author: whb * @description: 具体处理者--总经理 */public class GeneralManager extends Handler &#123; @Override public String handleFeeRequest(String user, double fee) &#123; String str = \"\"; //总经理的权限很大，只要请求到了这里，他都可以处理 if (fee &gt;= 1000) &#123; //为了测试，简单点，只同意小李的 if (\"小李\".equals(user)) &#123; str = \"总经理同意\" + user + \"聚餐费用\" + fee + \"元的请求\"; &#125; else &#123; //其它人一律不同意 str = \"总经理不同意\" + user + \"聚餐费用\" + fee + \"元的请求\"; &#125; return str; &#125; else &#123; //如果还有后继的处理对象，继续传递 if (this.successor != null) &#123; return successor.handleFeeRequest(user, fee); &#125; &#125; return str; &#125; @Override public boolean handlePreFeeRequest(String user, double requestFee) &#123; //总经理的权限50000以内 if (requestFee &lt; 50000) &#123; //工作需要嘛，统统同意 System.out.println(\"总经理同意\" + user + \"预支差旅费用\" + requestFee + \"元的请求\"); return true; &#125; else &#123; //如果还有后继的处理对象，继续传递 if (this.successor != null) &#123; return this.successor.handlePreFeeRequest(user, requestFee); &#125; &#125; return false; &#125;&#125; 客户端调用 12345678910111213141516171819202122232425262728293031323334353637package main.java.com.study.designPatterns.chain.demoTwo;/** * @author: whb * @description: 测试类 */public class Client &#123; public static void main(String[] args) &#123; //先要组装职责链 Handler h1 = new GeneralManager(); Handler h2 = new DepManager(); Handler h3 = new ProjectManager(); h3.setSuccessor(h2); h2.setSuccessor(h1); //开始测试申请聚餐费用 String ret1 = h3.handleFeeRequest(\"小李\", 300); System.out.println(\"the ret1=\" + ret1); String ret2 = h3.handleFeeRequest(\"小张\", 300); System.out.println(\"the ret2=\" + ret2); String ret3 = h3.handleFeeRequest(\"小李\", 600); System.out.println(\"the ret3=\" + ret3); String ret4 = h3.handleFeeRequest(\"小张\", 600); System.out.println(\"the ret4=\" + ret4); String ret5 = h3.handleFeeRequest(\"小李\", 1200); System.out.println(\"the ret5=\" + ret5); String ret6 = h3.handleFeeRequest(\"小张\", 1200); System.out.println(\"the ret6=\" + ret6); //开始测试申请差旅费用 h3.handlePreFeeRequest(\"小张\", 3000); h3.handlePreFeeRequest(\"小张\", 6000); h3.handlePreFeeRequest(\"小张\", 32000); &#125;&#125; 通用请求处理方式简单处理方式实现起来很容易，但是有一个明显的问题就是只要增加一个业务，就需要修改职责的接口，这是很不灵活的，Java开发中很强调面向接口编程，因此接口应该相对保持稳定，接口一改，需要修改的地方就太多了，频繁修改接口绝对不是个好主意。所以改造如下： 首先定义一套通用的调用框架，用一个通用的请求对象来封装请求传递的参数；然后定义一个通用的调用方法，这个方法不去区分具体业务，所有的业务都是这一个方法，在通用的请求对象里面会有一个业务的标记进行业务区分；到了职责对象里面，愿意处理就跟原来一样的处理方式，如果不愿意处理，就传递到下一个处理对象就好了。对于返回值也可以来个通用的，最简单的就是使用Object类型。 具体代码 通用的请求对象的定义 12345678910111213141516171819202122232425package main.java.com.study.designPatterns.chain.demoTwo.upgrade;/** * @author: whb * @description: 通用的请求对象 */public class RequestModel &#123; /** * 表示具体的业务类型 */ private String type; /** * 通过构造方法把具体的业务类型传递进来 * * @param type 具体的业务类型 */ public RequestModel(String type) &#123; this.type = type; &#125; public String getType() &#123; return type; &#125;&#125; 此时的通用职责处理对象，在这里要实现一个通用的调用框架 1234567891011121314151617181920212223242526272829303132333435363738package main.java.com.study.designPatterns.chain.demoTwo.upgrade;/** * @author: whb * @description: 通用职责处理对象，在这里要实现一个通用的调用框架 */public abstract class Handler &#123; /** * 持有下一个处理请求的对象 */ protected Handler successor = null; /** * 设置下一个处理请求的对象 * * @param successor 下一个处理请求的对象 */ public void setSuccessor(Handler successor) &#123; this.successor = successor; &#125; /** * 通用的请求处理方法 * * @param rm 通用的请求对象 * @return 处理后需要返回的对象 */ public Object handleRequest(RequestModel rm) &#123; if (successor != null) &#123; //这个是默认的实现，如果子类不愿意处理这个请求， //那就传递到下一个职责对象去处理 return this.successor.handleRequest(rm); &#125; else &#123; System.out.println(\"没有后续处理或者暂时不支持这样的功能处理\"); return false; &#125; &#125;&#125; 现在来加上第一个业务，就是“聚餐费用申请”的处理，为了描述具体的业务数据，需要扩展通用的请求对象，把业务数据封装进去，另外定义一个请求对象 1234567891011121314151617181920212223242526272829303132333435363738394041package main.java.com.study.designPatterns.chain.demoTwo.upgrade;/** * @author: whb * @description: 具体的业务请求对象--聚餐费用申请 */public class FeeRequestModel extends RequestModel &#123; /** * 约定具体的业务类型 */ public final static String FEE_TYPE = \"fee\"; public FeeRequestModel() &#123; super(FEE_TYPE); &#125; /** * 申请人 */ private String user; /** * 申请金额 */ private double fee; public String getUser() &#123; return user; &#125; public void setUser(String user) &#123; this.user = user; &#125; public double getFee() &#123; return fee; &#125; public void setFee(double fee) &#123; this.fee = fee; &#125;&#125; 接下来该实现职责对象的处理了，首先要覆盖父类的通用业务处理方法，然后在里面处理自己想要实现的业务，不想处理的就让父类去处理，父类会默认的传递给下一个处理对象。 项目经理： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package main.java.com.study.designPatterns.chain.demoTwo.upgrade;/** * @author: whb * @description: 具体的职责对象--项目经理 */public class ProjectManager extends Handler &#123; @Override public Object handleRequest(RequestModel rm) &#123; if (FeeRequestModel.FEE_TYPE.equals(rm.getType())) &#123; //表示聚餐费用申请 return handleFeeRequest(rm); &#125; else &#123; //其它的项目经理暂时不想处理 return super.handleRequest(rm); &#125; &#125; /** * 聚餐费用处理 * * @param rm * @return */ private Object handleFeeRequest(RequestModel rm) &#123; //先把通用的对象造型回来 FeeRequestModel frm = (FeeRequestModel) rm; String str = \"\"; //项目经理的权限比较小，只能在500以内 if (frm.getFee() &lt; 500) &#123; //为了测试，简单点，只同意小李的 if (\"小李\".equals(frm.getUser())) &#123; str = \"项目经理同意\" + frm.getUser() + \"聚餐费用\" + frm.getFee() + \"元的请求\"; &#125; else &#123; //其它人一律不同意 str = \"项目经理不同意\" + frm.getUser() + \"聚餐费用\" + frm.getFee() + \"元的请求\"; &#125; return str; &#125; else &#123; //超过500，继续传递给级别更高的人处理 if (this.successor != null) &#123; return successor.handleRequest(rm); &#125; &#125; return str; &#125;&#125; 部门经理： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package main.java.com.study.designPatterns.chain.demoTwo.upgrade;/** * @author: whb * @description: 部门经理 */public class DeptManager extends Handler &#123; @Override public Object handleRequest(RequestModel rm) &#123; if (FeeRequestModel.FEE_TYPE.equals(rm.getType())) &#123; //表示聚餐费用申请 return handleFeeRequest(rm); &#125; else &#123; //其它的部门经理暂时不想处理 return super.handleRequest(rm); &#125; &#125; /** * 聚餐费用处理 * * @param rm * @return */ private Object handleFeeRequest(RequestModel rm) &#123; //先把通用的对象造型回来 FeeRequestModel frm = (FeeRequestModel) rm; String str = \"\"; //部门经理的权限只能在1000以内 if (frm.getFee() &lt; 1000) &#123; //为了测试，简单点，只同意小李的 if (\"小李\".equals(frm.getUser())) &#123; str = \"部门经理同意\" + frm.getUser() + \"聚餐费用\" + frm.getFee() + \"元的请求\"; &#125; else &#123; //其它人一律不同意 str = \"部门经理不同意\" + frm.getUser() + \"聚餐费用\" + frm.getFee() + \"元的请求\"; &#125; return str; &#125; else &#123; //超过1000，继续传递给级别更高的人处理 if (this.successor != null) &#123; return successor.handleRequest(rm); &#125; &#125; return str; &#125;&#125; 总经理： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package main.java.com.study.designPatterns.chain.demoTwo.upgrade;/** * @author: whb * @description: 总经理 */public class GeneralManager extends Handler &#123; @Override public Object handleRequest(RequestModel rm) &#123; if (FeeRequestModel.FEE_TYPE.equals(rm.getType())) &#123; //表示聚餐费用申请 return handleFeeRequest(rm); &#125; else &#123; //其它的总经理暂时不想处理 return super.handleRequest(rm); &#125; &#125; /** * 聚餐费用处理 * * @param rm * @return */ private Object handleFeeRequest(RequestModel rm) &#123; //先把通用的对象造型回来 FeeRequestModel frm = (FeeRequestModel) rm; String str = \"\"; //总经理的权限很大，只要请求到了这里，他都可以处理 if (frm.getFee() &gt;= 1000) &#123; //为了测试，简单点，只同意小李的 if (\"小李\".equals(frm.getUser())) &#123; str = \"总经理同意\" + frm.getUser() + \"聚餐费用\" + frm.getFee() + \"元的请求\"; &#125; else &#123; //其它人一律不同意 str = \"总经理不同意\" + frm.getUser() + \"聚餐费用\" + frm.getFee() + \"元的请求\"; &#125; return str; &#125; else &#123; //如果还有后继的处理对象，继续传递 if (this.successor != null) &#123; return successor.handleRequest(rm); &#125; &#125; return str; &#125;&#125; 对于客户端，唯一的麻烦是需要知道每个业务对应的具体的请求对象，因为要封装业务数据进去. 123456789101112131415161718192021222324252627282930313233343536package main.java.com.study.designPatterns.chain.demoTwo.upgrade;/** * @author: whb * @description: 客户端调用 */public class Client &#123; public static void main(String[] args) &#123; //先要组装职责链 Handler h1 = new GeneralManager(); Handler h2 = new DeptManager(); Handler h3 = new ProjectManager(); h3.setSuccessor(h2); h2.setSuccessor(h1); //开始测试申请聚餐费用 FeeRequestModel frm = new FeeRequestModel(); frm.setFee(300); frm.setUser(\"小李\"); //调用处理 String ret1 = (String) h3.handleRequest(frm); System.out.println(\"ret1=\" + ret1); //重新设置申请金额，再调用处理 frm.setFee(800); h3.handleRequest(frm); String ret2 = (String) h3.handleRequest(frm); System.out.println(\"ret2=\" + ret2); //重新设置申请金额，再调用处理 frm.setFee(1600); h3.handleRequest(frm); String ret3 = (String) h3.handleRequest(frm); System.out.println(\"ret3=\" + ret3); &#125;&#125; 接下来看看如何在不改动现有的框架的前提下，扩展新的业务，这样才能说明这种设计的灵活性。 假如就是要实现上面示例过的另外一个功能“预支差旅费申请”。要想扩展新的业务，第一步就是新建一个封装业务数据的对象 1234567891011121314151617181920212223242526272829303132333435363738394041package main.java.com.study.designPatterns.chain.demoTwo.upgrade;/** * @author: whb * @description: 预支差旅费用请求对象 */public class PreFeeRequestModel extends RequestModel &#123; /** * 约定具体的业务类型 */ public final static String FEE_TYPE = \"preFee\"; public PreFeeRequestModel() &#123; super(FEE_TYPE); &#125; /** * 申请人 */ private String user; /** * 申请金额 */ private double fee; public String getUser() &#123; return user; &#125; public void setUser(String user) &#123; this.user = user; &#125; public double getFee() &#123; return fee; &#125; public void setFee(double fee) &#123; this.fee = fee; &#125;&#125; 对于具体进行职责处理的类，比较好的方式就是扩展出子类来，然后在子类里面实现新加入的业务，当然也可以直接在原来的对象上改。这里采用扩展出子类的方式。 123456789101112131415161718192021222324252627282930313233343536373839404142package main.java.com.study.designPatterns.chain.demoTwo.upgrade;/** * @author: whb * @description: 实现为项目经理增加预支差旅费用申请处理的功能的子对象， * 现在的项目经理既可以处理聚餐费用申请，又可以处理预支差旅费用申请 */public class ProjectManager2 extends ProjectManager &#123; @Override public Object handleRequest(RequestModel rm) &#123; if (PreFeeRequestModel.FEE_TYPE.equals(rm.getType())) &#123; //表示预支差旅费用申请 return handlePreFeeRequest(rm); &#125; else &#123; //其它的让父类去处理 return super.handleRequest(rm); &#125; &#125; /** * 预支差旅费用 * * @param rm * @return */ private Object handlePreFeeRequest(RequestModel rm) &#123; //先把通用的对象造型回来 PreFeeRequestModel frm = (PreFeeRequestModel) rm; //项目经理的权限比较小，只能在5000以内 if (frm.getFee() &lt; 5000) &#123; //工作需要嘛，统统同意 System.out.println(\"项目经理同意\" + frm.getUser() + \"预支差旅费用\" + frm.getFee() + \"元的请求\"); return true; &#125; else &#123; //超过5000，继续传递给级别更高的人处理 if (this.successor != null) &#123; return this.successor.handleRequest(rm); &#125; &#125; return false; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142package main.java.com.study.designPatterns.chain.demoTwo.upgrade;/** * @author: whb * @description: 实现为部门经理增加预支差旅费用申请处理的功能的子对象， * 现在的部门经理既可以处理聚餐费用申请，又可以处理预支差旅费用申请 */public class DeptManager2 extends ProjectManager &#123; @Override public Object handleRequest(RequestModel rm) &#123; if (PreFeeRequestModel.FEE_TYPE.equals(rm.getType())) &#123; //表示预支差旅费用申请 return handlePreFeeRequest(rm); &#125; else &#123; //其它的让父类去处理 return super.handleRequest(rm); &#125; &#125; /** * 预支差旅费用 * * @param rm * @return */ private Object handlePreFeeRequest(RequestModel rm) &#123; //先把通用的对象造型回来 PreFeeRequestModel frm = (PreFeeRequestModel) rm; //部门经理的权限在20000以内 if (frm.getFee() &lt; 20000) &#123; //工作需要嘛，统统同意 System.out.println(\"部门经理同意\" + frm.getUser() + \"预支差旅费用\" + frm.getFee() + \"元的请求\"); return true; &#125; else &#123; //超过20000，继续传递给级别更高的人处理 if (this.successor != null) &#123; return this.successor.handleRequest(rm); &#125; &#125; return false; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142package main.java.com.study.designPatterns.chain.demoTwo.upgrade;/** * @author: whb * @description: 实现为总经理增加预支差旅费用申请处理的功能的子对象， * 现在的总经理既可以处理聚餐费用申请，又可以处理预支差旅费用申请 */public class GeneralManager2 extends ProjectManager &#123; @Override public Object handleRequest(RequestModel rm) &#123; if (PreFeeRequestModel.FEE_TYPE.equals(rm.getType())) &#123; //表示预支差旅费用申请 return handlePreFeeRequest(rm); &#125; else &#123; //其它的让父类去处理 return super.handleRequest(rm); &#125; &#125; /** * 预支差旅费用 * * @param rm * @return */ private Object handlePreFeeRequest(RequestModel rm) &#123; //先把通用的对象造型回来 PreFeeRequestModel frm = (PreFeeRequestModel) rm; //总经理的权限在20000以内 if (frm.getFee() &gt;= 20000) &#123; //工作需要嘛，统统同意 System.out.println(\"总经理同意\" + frm.getUser() + \"预支差旅费用\" + frm.getFee() + \"元的请求\"); return true; &#125; else &#123; //如果还有后续，继续传递给级别更高的人处理 if (this.successor != null) &#123; return this.successor.handleRequest(rm); &#125; &#125; return false; &#125;&#125; 此时的测试类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package main.java.com.study.designPatterns.chain.demoTwo.upgrade;/** * @author: whb * @description: 拓展后的测试类 */public class Client2 &#123; public static void main(String[] args) &#123; //先要组装职责链 Handler h1 = new GeneralManager2(); Handler h2 = new DeptManager2(); Handler h3 = new ProjectManager2(); h3.setSuccessor(h2); h2.setSuccessor(h1); //开始测试申请聚餐费用 FeeRequestModel frm = new FeeRequestModel(); frm.setFee(300); frm.setUser(\"小李\"); //调用处理 String ret1 = (String) h3.handleRequest(frm); System.out.println(\"ret1=\" + ret1); //重新设置申请金额，再调用处理 frm.setFee(800); h3.handleRequest(frm); String ret2 = (String) h3.handleRequest(frm); System.out.println(\"ret2=\" + ret2); //重新设置申请金额，再调用处理 frm.setFee(1600); h3.handleRequest(frm); String ret3 = (String) h3.handleRequest(frm); System.out.println(\"ret3=\" + ret3); //开始测试申请预支差旅费用 PreFeeRequestModel pfrm = new PreFeeRequestModel(); pfrm.setFee(3000); pfrm.setUser(\"小张\"); //调用处理 h3.handleRequest(pfrm); //重新设置申请金额，再调用处理 pfrm.setFee(6000); h3.handleRequest(pfrm); //重新设置申请金额，再调用处理 pfrm.setFee(36000); h3.handleRequest(pfrm); &#125;&#125; 总结这种设计方式的好处，相当的通用和灵活，有了新业务，只需要添加实现新功能的对象就可以了，但是带来的缺陷就是可能会造成对象层次过多，或者出现较多的细粒度的对象，极端情况下，每次就扩展一个方法，会出现大量只处理一个功能的细粒度对象。","tags":"java 设计模式"},{"title":"设计模式-适配器模式","url":"/posts/210c1e9b.html","text":"模式定义将一个接口转换成客户希望的另一个接口，使接口不兼容的那些类可以一起工作，其别名为包装器(Wrapper)。 适配器模式既可以作为类结构型模式，也可以作为对象结构型模式。 主要作用提供一个转换器（适配器），将当前系统存在的一个对象转化为客户端能够访问的接口对象。 模式分类根据适配器类与适配者类的关系不同，适配器模式可分为对象适配器和类适配器两种。在对象适配器模式中，适配器与适配者之间是关联关系；在类适配器模式中，适配器与适配者之间是继承（或实现）关系。 模式角色 Target（目标抽象类）：目标抽象类定义客户所需接口，可以是一个抽象类或接口，也可以是具体类。 Adaptee（适配者类）：适配者即被适配的角色，它定义了一个已经存在的接口，这个接口需要适配，适配者类一般是一个具体类，包含了客户希望使用的业务方法，在某些情况下可能没有适配者类的源代码。 Adapter（适配器类）：适配器可以调用另一个接口，作为一个转换器，对Adaptee和Target进行适配，适配器类是适配器模式的核心，在对象适配器中，它通过继承Target并关联一个Adaptee对象使二者产生联系。 三种角色之间的关系如下： 假设当前系统中，客户端需要访问的是 Target 接口，但 Target 接口没有一个实例符合需求，而 Adaptee 实例符合需求；但是客户端无法直接使用 Adaptee（接口不兼容）；因此，我们需要一个适配器（Adapter）来进行中转，让 Adaptee 能转化为 Target 接口形式； 模式解析类适配器原理 通过继承来实现适配器功能。 具体做法 让 Adapter 实现 Target 接口，并且继承 Adaptee，这样 Adapter 就具备 Target 和 Adaptee 的特性，就可以将两者进行转化； UML类图 使用步骤创建Target接口123456789101112package main.java.com.study.designPatterns.adapter.classAdapter.demoOne;/** * @author: whb * @description: 目标类 */public interface Target &#123; /** * 这是源类Adapteee没有的方法 */ public void request();&#125; 创建源类（Adaptee）1234567891011121314package main.java.com.study.designPatterns.adapter.classAdapter.demoOne;/** * @author: whb * @description: 源类 */public class Adaptee &#123; /** * 需要适配的接口 */ public void specificRequest() &#123; System.out.println(\"需要适配的接口...\"); &#125;&#125; 创建适配器类（Adapter）123456789101112131415161718package main.java.com.study.designPatterns.adapter.classAdapter.demoOne;/** * @author: whb * @description: 适配器Adapter继承自Adaptee，同时又实现了目标(Target)接口。 */public class Adapter extends Adaptee implements Target &#123; /** * 目标接口要求调用request()这个方法名，但源类Adaptee没有方法request()， * 因此适配器补充上这个方法名。 * 但实际上request()只是调用源类Adaptee的specificRequest()方法的内容， * 所以适配器只是将specificRequest()方法作了一层封装，封装成Target可以调用的request()而已。 */ @Override public void request() &#123; this.specificRequest(); &#125;&#125; 定义具体使用目标类123456789101112package main.java.com.study.designPatterns.adapter.classAdapter.demoOne;/** * @author: whb * @description: 测试类适配器 */public class TestClassAdapter &#123; public static void main(String[] args) &#123; Target mAdapter = new Adapter(); mAdapter.request(); &#125;&#125; 对象适配器原理 通过组合来实现适配器功能。 具体做法 让 Adapter 实现 Target 接口，然后内部持有 Adaptee 实例，然后再 Target 接口规定的方法内转换 Adaptee 。 UML类图 使用步骤创建Target接口123456789101112package main.java.com.study.designPatterns.adapter.objectAdapter.demoOne;/** * @author: whb * @description: 目标类 */public interface Target &#123; /** * 这是源类Adapteee没有的方法 */ void request();&#125; 创建源类（Adaptee）1234567891011121314package main.java.com.study.designPatterns.adapter.objectAdapter.demoOne;/** * @author: whb * @description: 源类 */public class Adaptee &#123; /** * 需要适配的接口 */ public void specificRequest() &#123; System.out.println(\"需要适配的接口...\"); &#125;&#125; 创建适配器类（Adapter）12345678910111213141516171819202122232425package main.java.com.study.designPatterns.adapter.objectAdapter.demoOne;/** * @author: whb * @description: 适配器类（Adapter）（不适用继承而是委派） */public class Adapter implements Target &#123; /** * 直接关联被适配类 */ private Adaptee adaptee; /** * 可以通过构造函数传入具体需要适配的被适配类对象 */ public Adapter(Adaptee adaptee) &#123; this.adaptee = adaptee; &#125; @Override public void request() &#123; //这里使用委托的方式完成适配 this.adaptee.specificRequest(); &#125;&#125; 定义具体使用目标类1234567891011121314package main.java.com.study.designPatterns.adapter.objectAdapter.demoOne;/** * @author: whb * @description: 测试对象适配 */public class TestObjectAdapter &#123; public static void main(String[] args) &#123; //需要先创建一个被适配类的对象作为参数 Target mAdapter = new Adapter(new Adaptee()); mAdapter.request(); &#125;&#125; 优缺点适配器模式优点 将目标类和适配者类解耦，通过引入一个适配器类来重用现有的适配者类，无须修改原有结构。 增加了类的透明性和复用性，将具体的业务实现过程封装在适配者类中，对于客户端类而言是透明的，而且提高了适配者的复用性，同一个适配者类可以在多个不同的系统中复用。 灵活性和扩展性都非常好，通过使用配置文件，可以很方便地更换适配器，也可以在不修改原有代码的基础上增加新的适配器类，完全符合“开闭原则”。 缺点 过多的使用适配器，会让系统非常零乱，不易整体进行把握。 类的适配器模式优点 由于适配器类是适配者类的子类，因此可以在适配器类中置换一些适配者的方法，使得适配器的灵活性更强。 缺点 对于Java等不支持多重类继承的语言，一次最多只能适配一个适配者类，不能同时适配多个适配者； 适配者类不能为最终类，如在Java中不能为final类； 在Java等语言中，类适配器模式中的目标抽象类只能为接口，不能为类，其使用有一定的局限性。 对象的适配器模式优点 一个对象适配器可以把多个不同的适配者适配到同一个目标； 可以适配一个适配者的子类，由于适配器和适配者之间是关联关系，根据“里氏代换原则”，适配者的子类也可通过该适配器进行适配。 缺点 与类适配器模式相比，要在适配器中置换适配者类的某些方法比较麻烦。如果一定要置换掉适配者类的一个或多个方法，可以先做一个适配者类的子类，将适配者类的方法置换掉，然后再把适配者类的子类当做真正的适配者进行适配，实现过程较为复杂。 应用场景适配器的使用场景 系统需要复用现有类，而该类的接口不符合系统的需求，可以使用适配器模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作 多个组件功能类似，但接口不统一且可能会经常切换时，可使用适配器模式，使得客户端可以以统一的接口使用它们 类和对象适配器模式的使用场景 灵活使用时：选择对象的适配器模式类适配器使用对象继承的方式，是静态的定义方式；而对象适配器使用对象组合的方式，是动态组合的方式。 需要同时配源类和其子类：选择对象的适配器 对于类适配器，由于适配器直接继承了Adaptee，使得适配器不能和Adaptee的子类一起工作，因为继承是静态的关系，当适配器继承了Adaptee后，就不可能再去处理 Adaptee的子类了； 对于对象适配器，一个适配器可以把多种不同的源适配到同一个目标。换言之，同一个适配器可以把源类和它的子类都适配到目标接口。因为对象适配器采用的是对象组合的关系，只要对象类型正确，是不是子类都无所谓。 需要重新定义Adaptee的部分行为：选择类适配器 对于类适配器，适配器可以重定义Adaptee的部分行为，相当于子类覆盖父类的部分实现方法。 对于对象适配器，要重定义Adaptee的行为比较困难，这种情况下，需要定义Adaptee的子类来实现重定义，然后让适配器组合子类。虽然重定义Adaptee的行为比较困难，但是想要增加一些新的行为则方便的很，而且新增加的行为可同时适用于所有的源。 仅仅希望使用方便时：选择类适配器 对于类适配器，仅仅引入了一个对象，并不需要额外的引用来间接得到Adaptee。 对于对象适配器，需要额外的引用来间接得到Adaptee。","tags":"java 设计模式"},{"title":"设计模式-策略模式","url":"/posts/ea641220.html","text":"模式定义定义一系列算法，将每一个算法封装起来，并让它们可以相互替换。策略模式让算法独立于使用它的客户而变化。 主要作用(解决的问题)将算法的责任和本身进行解耦，使得： 算法可独立于使用外部而变化。 客户端方便根据外部条件选择不同策略来解决不同问题。 模式原理UML类图 模式优点1。 策略类之间可以自由切换由于策略类都实现同一个接口，所以使它们之间可以自由切换。 易于扩展增加一个新的策略只需要添加一个具体的策略类即可，基本不需要改变原有的代码，符合“开闭原则“。 避免使用多重条件选择语句（if else），充分体现面向对象设计思想。 模式缺点 客户端必须知道所有的策略类，并自行决定使用哪一个策略类。 策略模式将造成产生很多策略类，可以通过使用享元模式在一定程度上减少对象的数量。 应用场景 如果在一个系统里面有许多类，它们之间的区别仅在于它们的行为，那么使用策略模式可以动态地让一个对象在许多行为中选择一种行为。 一个系统需要动态地在几种算法中选择一种。那么这些算法可以包装到一个个的具体算法类里面，而这些具体算法类都是一个抽象算法类的子类。换言之，这些具体算法类均有统一的接口，由于多态性原则，客户端可以选择使用任何一个具体算法类，并只持有一个数据类型是抽象算法类的对象。 一个系统的算法使用的数据不可以让客户端知道。策略模式可以避免让客户端涉及到不必要接触到的复杂的和只与算法有关的数据。 如果一个对象有很多的行为，如果不用恰当的模式，这些行为就只好使用多重的条件选择语句来实现。此时，使用策略模式，把这些行为转移到相应的具体策略类里面，就可以避免使用难以维护的多重条件选择语句，并体现面向对象设计的概念。 模式示例示例背景背景：假设有一家百货公司，最近在定年度的促销活动冲突：每个节日用同一个促销活动太枯燥，没吸引力解决方案：针对不同节目使用不同促销活动进行促销 使用步骤定义抽象策略角色（Strategy）百货公司所有促销活动的共同接口 123456789101112package main.java.com.study.designPatterns.strategy.demoOne;/** * @author: whb * @description: 定义抽象策略角色：百货公司所有促销活动的共同接口 */public abstract class Strategy &#123; /** * 活动展示 */ public abstract void show();&#125; 定义具体策略角色（Concrete Strategy）春节促销活动12345678910111213package main.java.com.study.designPatterns.strategy.demoOne;/** * @author: whb * @description: 定义具体策略角色：春节促销活动 */public class StrategyA extends Strategy &#123; @Override public void show() &#123; System.out.println(\"为春节准备的促销活动A\"); &#125;&#125; 中秋促销活动12345678910111213package main.java.com.study.designPatterns.strategy.demoOne;/** * @author: whb * @description: 定义具体策略角色：中秋促销活动 */public class StrategyB extends Strategy &#123; @Override public void show() &#123; System.out.println(\"为中秋节准备的促销活动B\"); &#125;&#125; 圣诞促销活动12345678910111213package main.java.com.study.designPatterns.strategy.demoOne;/** * @author: whb * @description: 定义策略角色：圣诞促销活动 */public class StrategyC extends Strategy &#123; @Override public void show() &#123; System.out.println(\"为圣诞节准备的促销活动C\"); &#125;&#125; 定义环境角色（Context）用于连接上下文，即把促销活动推销给客户，这里可以理解为销售员 1234567891011121314151617181920212223242526272829303132333435363738package main.java.com.study.designPatterns.strategy.demoOne;/** * @author: whb * @description: 定义环境角色：用于连接上下文，把促销活动推销给用户，这里可以理解为销售员 */public class SalesMan &#123; //持有抽象策略角色的引用 private Strategy strategy; /** * 生成销售员实例时告诉销售员什么节日（构造方法） * 使得让销售员根据传入的参数（节日）选择促销活动（这里使用一个简单的工厂模式） */ public SalesMan(String festival) &#123; switch (festival) &#123; //春节就使用春节促销活动 case \"A\": strategy = new StrategyA(); break; //中秋节就使用中秋节促销活动 case \"B\": strategy = new StrategyB(); break; //圣诞节就使用圣诞节促销活动 case \"C\": strategy = new StrategyC(); break; &#125; &#125; /** * 向客户展示促销活动 */ public void salesManShow() &#123; strategy.show(); &#125;&#125; 客户端调用让销售员进行促销活动的落地 123456789101112131415161718192021222324252627package main.java.com.study.designPatterns.strategy.demoOne;/** * @author: whb * @description: 客户端调用 */public class Client &#123; public static void main(String[] args) &#123; SalesMan mSalesMan; //春节来了，使用春节促销活动 System.out.println(\"对于春节：\"); mSalesMan = new SalesMan(\"A\"); mSalesMan.salesManShow(); //中秋节来了，使用中秋节促销活动 System.out.println(\"对于中秋节：\"); mSalesMan = new SalesMan(\"B\"); mSalesMan.salesManShow(); //圣诞节来了，使用圣诞节促销活动 System.out.println(\"对于圣诞节：\"); mSalesMan = new SalesMan(\"C\"); mSalesMan.salesManShow(); &#125;&#125;","tags":"java 设计模式"},{"title":"多线程面试题总结","url":"/posts/e3e73bdc.html","text":"多线程的优缺点优点： 多线程技术使程序的响应速度更快。 当前没有进行处理的任务可以将处理器时间让给其它任务。 占用大量处理时间的任务可以定期将处理器时间让给其它任务。 可以随时停止任务。 可以分别设置各个任务的优先级以及优化性能。 缺点 等候使用共享资源时造成程序的运行速度变慢。 对线程进行管理要求额外的cpu开销。 可能出现线程死锁情况。即较长时间的等待或资源竞争以及死锁等症状。 在java中守护线程和本地线程区别 java中的线程分为两种：守护线程（Daemon）和用户线程（User）。 任何线程都可以设置为守护线程和用户线程，通过方法Thread.setDaemon(bool on)；true则把该线程设置为守护线程，反之则为用户线程。Thread.setDaemon()必须在Thread.start()之前调用，否则运行时会抛出异常。 两者的区别： 唯一的区别是判断虚拟机(JVM)何时离开，Daemon是为其他线程提供服务，如果全部的User Thread已经撤离，Daemon 没有可服务的线程，JVM撤离。也可以理解为守护线程是JVM自动创建的线程（但不一定），用户线程是程序创建的线程；比如JVM的垃圾回收线程是一个守护线程，当所有线程已经撤离，不再产生垃圾，守护线程自然就没事可干了，当垃圾回收线程是Java虚拟机上仅剩的线程时，Java虚拟机会自动离开。 扩展：Thread Dump打印出来的线程信息，含有daemon字样的线程即为守护进程，可能会有：服务守护进程、编译守护进程、windows下的监听Ctrl+break的守护进程、Finalizer守护进程、引用处理守护进程、GC守护进程。 线程与进程的区别 进程是操作系统分配资源的最小单元，线程是操作系统调度的最小单元。一个程序至少有一个进程,一个进程至少有一个线程。 什么是多线程中的上下文切换 多线程会共同使用一组计算机上的CPU，而线程数大于给程序分配的CPU数量时，为了让各个线程都有执行的机会，就需要轮转使用CPU。不同的线程切换使用CPU发生的切换数据等就是上下文切换。 死锁与活锁的区别，死锁与饥饿的区别 死锁：是指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。 产生死锁的必要条件： 互斥条件：所谓互斥就是进程在某一时间内独占资源。 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 不剥夺条件:进程已获得资源，在末使用完之前，不能强行剥夺。 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。 活锁：任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败。 活锁和死锁的区别在于，处于活锁的实体是在不断的改变状态，所谓的“活”， 而处于死锁的实体表现为等待；活锁有可能自行解开，死锁则不能。 饥饿：一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行的状态。 Java中导致饥饿的原因： 高优先级线程吞噬所有的低优先级线程的CPU时间。 线程被永久堵塞在一个等待进入同步块的状态，因为其他线程总是能在它之前持续地对该同步块进行访问。 线程在等待一个本身也处于永久等待完成的对象(比如调用这个对象的wait方法)，因为其他线程总是被持续地获得唤醒。 start()方法和run()方法的区别start()方法： 用start方法来启动线程，真正实现了多线程运行，这时无需等待run方法体代码执行完毕而直接继续执行下面的代码。 通过调用Thread类的start()方法来启动一个线程，这时此线程处于就绪（可运行）状态，并没有运行，一旦得到CPU时间片，就开始执行run()方法。 run()方法： run()方法只是类的一个普通方法而已，如果直接调用Run方法，程序中依然只有主线程这一个线程，其程序执行路径还是只有一条。 总结： 调用start方法方可启动线程。 run方法只是thread的一个普通方法调用，还是在主线程里执行。 把需要并行处理的代码放在run()方法中，start()方法启动线程将自动调用run()方法，这是由jvm的内存机制规定的。 run()方法必须是public访问权限，返回值类型为void。 Runnable接口和Callable接口的相同点和不同点相同点： Callable和Runnable都是接口； Callable和Runnable都一科应用于Executors； 不同点： Callable要实现call()方法，Runnable要实现run()方法； call()方法可以有返回值，run()方法不能有返回值； call(0方法可以抛出Checked Exception，run()方法不可以； Runnable接口在Jdk1.1中就有了，Callable在JDK1.5才有； voliate关键字的作用 多线程使用volatile关键字修饰的变量，保证了其在多线程之间的可见性，即每次读取到volatile变量，一定是最新的数据。 Java代码执行中，为了获取更好的性能JVM可能会对指令进行重排序，多线程下可能会出现一些意想不到的问题。使用volatile则会对禁止语义重排序，当然这也一定程度上降低了代码执行效率。 CyclicBarrier和CountDownLatch的区别 CountDownLatch CyclicBarrier 减计数方式 加计数方式 计数为0时唤醒所有等待的线程 计数达到指定值时唤醒所有等待的线程 计数为0无法重置 计数达到指定值时，计数置为0重新开始 调用countDown()方法计数减一，调用await()方法只进行阻塞，对计数没有影响 调用await()方法计数加1，若加1后的值不等于构造方法的值，则线程阻塞 不能重复利用 可重复使用 voliate和synchronized对比 volatile本质是在告诉jvm当前变量在寄存器中的值是不确定的,需要从主存中读取,synchronized则是锁定当前变量,只有当前线程可以访问该变量,其他线程被阻塞住。 volatile仅能使用在变量级别,synchronized则可以使用在变量,方法以及类级别。 volatile仅能实现变量的修改可见性,而synchronized则可以保证变量的修改可见性和原子性。 volatile不会造成线程的阻塞,而synchronized可能会造成线程的阻塞。 怎么唤醒一个阻塞的线程 如果线程是因为调用了wait()、sleep()或者join()方法而导致的阻塞，可以中断线程，并且通过抛出InterruptedException来唤醒它； 如果线程遇到了IO阻塞，无能为力，因为IO是操作系统实现的，Java代码并没有办法直接接触到操作系统。 sleep方法和wait方法的相同点和不同点相同点： 二者都可以让线程处于阻塞； 不同点： 首先sleep方法是Thread类中定义的方法，而wait方法是Object类中定义的方法。 sleep方法必须人为地为其指定休眠时间。wait方法既可以指定时间，也可以不指定时间。 sleep方法时间到了，线程处于临时阻塞状态或者运行状态。wait方法如果没有被设置时间，就必须要通过notify或者notifyAll来唤醒。 sleep方法不一定非要定义在同步中。wait方法必须定义在同步中。 当二者都定义在同步中时，线程执行到sleep，不会释放锁。线程执行到wait，会释放锁。 生产者和消费者模型的作用 通过平衡生产者的生产能力和消费者的消费能力来提升整个系统的运行效率，这是生产者消费者模型最重要的作用。 解耦，这是生产者消费者模型附带的作用，解耦意味着生产者和消费者之间的联系少，联系越少越可以独自发展而不需要收到相互的制约。 Executor.submit()和Executor.execute()的区别 前者返回一个 Future对象，可以用于找到工作线程的运行结果。 在异常处理上也不一样，在任务抛出异常时，如果是通过 execute()提交的，会抛出无需捕获的异常（如果你没有特殊处理，会打印错误栈道System.err）。如果是通过 submit()提交的，任何异常，无论是不是checked exception，都是返回的一部分，Future.get将把异常包在 ExecutionExeption中，向上层抛出。 ThreadLocal的作用 ThreadLocal用来解决多线程程序的并发问题。 ThreadLocal并不是一个Thread,而是Thread的局部变量,当使用ThreadLocal维护变量时,ThreadLocal为每个使用该变量的线程提供独立的变量副本,所以每个线程都可以独立地改变自己的副本,而不会影响其它线程所对应的副本。 从线程的角度看，目标变量就象是线程的本地变量，这也是类名中“Local”所要表达的意思。 线程局部变量并不是Java的新发明,Java没有提供在语言级支持(语法上),而是变相地通过ThreadLocal的类提供支持。 wait方法和notify/notifyAll方法在放弃对象监视器时的区别 wait()方法立即释放对象监视器； notify()/notifyAll()方法则会等待线程剩余代码执行完毕才会放弃对象监视器。 Lock和synchronized对比 Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现； synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁； Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断； 通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。 Lock可以提高多个线程进行读操作的效率。 在JDK1.5中，synchronized是性能低效的。因为这是一个重量级操作，它对性能最大的影响是阻塞式的实现，挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给系统的并发性带来了很大的压力。相比之下使用Java提供的Lock对象，性能更高一些。但是，JDK1.6，发生了变化，对synchronize加入了很多优化措施，有自适应自旋，锁消除，锁粗化，轻量级锁，偏向锁等等。导致在JDK1.6上synchronize的性能并不比Lock差。因此。提倡优先考虑使用synchronized来进行同步。 ReadWriteLock是什么 ReadWriteLock是一个读写锁接口，ReentrantReadWriteLock是ReadWriteLock接口的一个具体实现，实现了读写的分离，读锁是共享的，写锁是独占的，读和读之间不会互斥，读和写、写和读、写和写之间才会互斥，提升了读写的性能。 FutureTask是什么 FutureTask表示一个异步运算的任务。FutureTask里面可以传入一个Callable的具体实现类，可以对这个异步运算的任务的结果进行等待获取、判断是否已经完成、取消任务等操作。由于FutureTask也是Runnable接口的实现类，所以FutureTask也可以放入线程池中。 Java中用到的线程调度算法 抢占式。一个线程用完CPU之后，操作系统会根据线程优先级、线程饥饿情况等数据算出一个总的优先级并分配下一个时间片给某个线程执行。 乐观锁和悲观锁 乐观锁：对于并发间操作产生的线程安全问题持乐观状态，乐观锁认为竞争不总是会发生，因此它不需要持有锁，将比较-设置这两个动作作为一个原子操作尝试去修改内存中的变量，如果失败则表示发生冲突，那么就应该有相应的重试逻辑。悲观锁：对于并发间操作产生的线程安全问题持悲观状态，悲观锁认为竞争总是会发生，因此每次对某资源进行操作时，都会持有一个独占的锁，就像synchronized，直接对操作资源上了锁。 编写一个死锁程序死锁现象描述：线程A和线程B相互等待对方持有的锁导致程序无限死循环下去。 死锁的实现步骤： 两个线程里面分别持有两个Object对象：lock1和lock2。这两个lock作为同步代码块的锁； 线程1的run()方法中同步代码块先获取lock1的对象锁，Thread.sleep(xxx)，时间不需要太多，100毫秒差不多了，然后接着获取lock2的对象锁。这么做主要是为了防止线程1启动一下子就连续获得了lock1和lock2两个对象的对象锁; 线程2的run)(方法中同步代码块先获取lock2的对象锁，接着获取lock1的对象锁，当然这时lock1的对象锁已经被线程1锁持有，线程2肯定是要等待线程1释放lock1的对象锁的这样，线程1″睡觉”睡完，线程2已经获取了lock2的对象锁了，线程1此时尝试获取lock2的对象锁，便被阻塞，此时一个死锁就形成了。 代码实现：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class DeadLock &#123; public void run() &#123; TestDeadLock tl = new TestDeadLock(); new Thread(tl, \"线程A\").start(); new Thread(tl, \"线程B\").start(); &#125; class TestDeadLock implements Runnable &#123; private Object objA = new Object(); private Object objB = new Object(); private boolean flag = true; @Override public void run() &#123; if (flag) &#123; flag = false; synchronized (objA) &#123; System.out.println(Thread.currentThread().getName() + \"锁住资源A，等待资源B\"); try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (objB) &#123; System.out.println(Thread.currentThread().getName() + \"获得资源B\"); &#125; &#125; &#125; else &#123; flag = true; synchronized (objB) &#123; System.out.println(Thread.currentThread().getName() + \"锁住资源B，等待资源A\"); try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (objA) &#123; System.out.println(Thread.currentThread().getName() + \"获得资源A\"); &#125; &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; new DeadLock().run(); &#125;&#125;输出结果是：线程A锁住资源A，等待资源B线程B锁住资源B，等待资源A Java中如何避免死锁 死锁发生是因为两个线程试图获取被对方持有的资源。但是要想发生这种情况，必须满足以下四个条件： 相互排斥 —— 至少一个进程必须处于非共享模式； 保持并等待 —— 必须有一个进程持有一个资源并等待另一个资源； 没有抢占 —— 资源不能被抢占； 循环等待 —— 存在进程集合。通过中断循环等待可以避免死锁。可以通过在代码中指定获取和释放锁的顺序来达到这一目的。 如果多个锁通过一致的顺序被获取和释放，不会有互相等待对方释放锁的情况。 为什么使用Executor框架 每次执行任务创建线程 new Thread()比较消耗性能，创建一个线程是比较耗时、耗资源的。 调用 new Thread()创建的线程缺乏管理，被称为野线程，而且可以无限制的创建，线程之间的相互竞争会导致过多占用系统资源而导致系统瘫痪，还有线程之间的频繁交替也会消耗很多系统资源。 直接使用new Thread() 启动的线程不利于扩展，比如定时执行、定期执行、定时定期执行、线程中断等都不便实现。 能复用已存在并空闲的线程从而减少线程对象的创建从而减少了消亡线程的开销。 可有效控制最大并发线程数，提高系统资源使用率，同时避免过多资源竞争。 框架中已经有定时、定期、单线程、并发数控制等功能。 在Java Concurrency API中有哪些原子类 原子类：AtomicBoolean，AtomicInteger，AtomicLong，AtomicReference 原子数组：AtomicIntegerArray,AtomicLongArray，AtomicReferenceArray 原子属性更新器：AtomicLongFieldUpdater,AtomicIntegerFieldUpdater，AtomicReferenceFieldUpdater 解决ABA问题的原子类：AtomicMarkableReference(通过引入一个boolean来反映中间有没有变过）,AtomicStampedReference（通过引入一个int来累加来反映中间有没有变过） Java Concurrency API中的Lock接口(Lock interface)是什么？对比同步它有什么优势？Lock接口比同步方法和同步块提供了更具扩展性的锁操作。他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。 它的优势有： 可以使锁更公平 可以使线程在等待锁的时候响应中断 可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间 可以在不同的范围，以不同的顺序获取和释放锁 整体上来说Lock是synchronized的扩展版，Lock提供了无条件的、可轮询的(tryLock方法)、定时的(tryLock带参方法)、可中断的(lockInterruptibly)、可多条件队列的(newCondition方法)锁操作。另外Lock的实现类基本都支持非公平锁(默认)和公平锁，synchronized只支持非公平锁，当然，在大部分情况下，非公平锁是高效的选择。 什么是阻塞队列？阻塞队列的实现原理是什么？如何使用阻塞队列来实现生产者-消费者模型？阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。 这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。 阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。 JDK7提供了7个阻塞队列。分别是： ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。 LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。 PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。 DelayQueue：一个使用优先级队列实现的无界阻塞队列。 SynchronousQueue：一个不存储元素的阻塞队列。 LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。 LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。 Java 5之前实现同步存取时，可以使用普通的一个集合，然后在使用线程的协作和线程同步可以实现生产者，消费者模式，主要的技术就是用好，wait ,notify,notifyAll,sychronized这些关键字。而在java 5之后，可以使用阻塞队列来实现，此方式大大简少了代码量，使得多线程编程更加容易，安全方面也有保障。 BlockingQueue接口是Queue的子接口，它的主要用途并不是作为容器，而是作为线程同步的的工具，因此他具有一个很明显的特性，当生产者线程试图向BlockingQueue放入元素时，如果队列已满，则线程被阻塞，当消费者线程试图从中取出一个元素时，如果队列为空，则该线程会被阻塞，正是因为它所具有这个特性，所以在程序中多个线程交替向BlockingQueue中放入元素，取出元素，它可以很好的控制线程之间的通信。 阻塞队列使用最经典的场景就是socket客户端数据的读取和解析，读取数据的线程不断将数据放入队列，然后解析线程不断从队列取数据解析。 什么叫线程安全？servlet是线程安全吗? 线程安全是编程中的术语，指某个函数、函数库在多线程环境中被调用时，能够正确地处理多个线程之间的共享变量，使程序功能正确完成。 Servlet不是线程安全的，servlet是单实例多线程的，当多个线程同时访问同一个方法，是不能保证共享变量的线程安全性的。 Struts2的action是多实例多线程的，是线程安全的，每个请求过来都会new一个新的action分配给这个请求，请求完成后销毁。 SpringMVC的Controller是线程安全的吗？不是的，和Servlet类似的处理流程 Struts2好处是不用考虑线程安全问题；Servlet和SpringMVC需要考虑线程安全问题，但是性能可以提升不用处理太多的gc，可以使用ThreadLocal来处理多线程的问题。 Java中interrupted 和 isInterrupted方法的区别interrupt interrupt方法用于中断线程。调用该方法的线程的状态为将被置为”中断”状态。 注意：线程中断仅仅是置线程的中断状态位，不会停止线程。需要用户自己去监视线程的状态为并做处理。支持线程中断的方法（也就是线程中断后会抛出interruptedException的方法）就是在监视线程的中断状态，一旦线程的中断状态被置为“中断状态”，就会抛出中断异常。 interrupted 查询当前线程的中断状态，并且清除原状态。如果一个线程被中断了，第一次调用interrupted则返回true，第二次和后面的就返回false了。 isInterrupted 仅仅是查询当前线程的中断状态。","tags":"多线程 面试题"},{"title":"设计模式-观察者模式","url":"/posts/4eed4967.html","text":"模式定义观察者模式（Observer Pattern），又叫 发布-订阅（Publish/Subscribe）模式、模型-视图（Model/View）模式、源-监听器（Source/Listener）模式 或 从属者（Dependents）模式。 观察者模式 是对象的行为模式，定义了一种一对多的依赖关系，一个主题对象可被多个观察者对象同时监听，使得每当主题对象状态变化时，所有依赖于它的对象都会得到通知并被自动更新。 观察者模式 核心：松耦合观察者与被观察者，以类似于消息/广播发送的机制联动两者，使被观察者的变动能通知到感兴趣的观察者们，从而做出相应的响应。 主要作用当系统一方行为依赖于另一方行为的变动时，可使用 观察者模式 松耦合联动双方，使得一方的变动可以通知到感兴趣的另一方对象，从而让另一方对象对此做出响应。 UML类图 角色 抽象主题（Subject）：目标又称为主题，指被观察的对象（Observable）。在目标中定义了一个观察者集合，一个观察目标可以接受任意数量的观察者来观察，它提供一系列方法来增加和删除观察者对象，同时它定义了通知方法notify()。目标类可以是接口，也可以是抽象类或具体类。 具体主题（ConcreteSubject）：具体被观察者，是目标类（抽象主题）的子类，通常它包含有经常发生改变的数据，当它的状态发生改变时，向它的各个观察者发出通知；同时它还实现了在目标类中定义的抽象业务逻辑方法（如果有的话）。如果无须扩展目标类，则具体目标类可以省略。 抽象观察者（Observer）：观察者将对观察目标的改变做出反应，观察者一般定义为接口，该接口声明了更新数据的方法update()，因此又称为抽象观察者。 具体观察者（ConcrereObserver）：在具体观察者中维护一个指向具体目标对象的引用，它存储具体观察者的有关状态，这些状态需要和具体目标的状态保持一致；它实现了在抽象观察者Observer中定义的update()方法。通常在实现时，可以调用具体目标类的attach()方法将自己添加到目标类的集合中或通过detach()方法将自己从目标类的集合中删除。 模式优点 观察者和被观察者是松耦合（抽象耦合）的，符合 依赖倒置原则； 分离了表示层（观察者）和数据逻辑层（被观察者），并且建立了一套触发机制，使得数据的变化可以响应到多个表示层上； 支持广播通信，实现了一对多的通讯机制，支持事件注册机制，支持兴趣分发机制，当被观察者触发事件时，只有感兴趣的观察者可以接收到通知； 观察者模式满足 “开闭原则” 的要求，增加新的具体观察者无须修改原有系统代码，在具体观察者与观察目标之间不存在关联关系的情况下，增加新的观察目标也很方便。 模式缺点 如果一个观察目标对象有很多直接和间接观察者，将所有的观察者都通知到会花费很多时间； 事件通知呈线性关系，如果其中一个观察者处理事件卡壳，会影响后续的观察者接收该事件； 如果观察者和被观察者之间存在循环依赖，则可能造成两者之间的循环调用，导致系统崩溃； 观察者模式没有相应的机制让观察者知道所观察的目标对象是怎么发生变化的，而仅仅只是知道观察目标发生了变化。 适用场景 一个抽象模型有两个方面，其中一个方面依赖于另一个方面，将这两个方面封装在独立的对象中使它们可以各自独立地改变和复用。 一个对象的改变将导致一个或多个其他对象也发生改变，而并不知道具体有多少对象将发生改变，也不知道这些对象是谁。 需要在系统中创建一个触发链，A对象的行为将影响B对象，B对象的行为将影响C对象……，可以使用观察者模式创建一种链式触发机制。 实现类似广播机制的功能，无需知道具体收听者，只需分发广播，系统中感兴趣的对象会自动接收该广播； 使用步骤抽象观察者123456789101112package main.java.com.study.designPatterns.observer.demoOne;/** * @author: whb * @description: 抽象观察者 */public interface IObserver&lt;E&gt; &#123; /** * 更新数据 */ void update(E event);&#125; 抽象主题者123456789101112131415161718192021222324252627282930package main.java.com.study.designPatterns.observer.demoOne;/** * @author: whb * @description: 抽象主题 */public interface ISubject&lt;E&gt; &#123; /** * 注册 * * @param observer * @return */ boolean attach(IObserver&lt;E&gt; observer); /** * 取消注册 * * @param observer * @return */ boolean detach(IObserver&lt;E&gt; observer); /** * 通知 * * @param event */ void notify(E event);&#125; 具体观察者12345678910111213package main.java.com.study.designPatterns.observer.demoOne;/** * @author: whb * @description: 具体观察者 */public class ConcreteObserver&lt;E&gt; implements IObserver&lt;E&gt; &#123; @Override public void update(E event) &#123; System.out.println(\"receive event：\" + event); &#125;&#125; 具体主题者1234567891011121314151617181920212223242526272829303132package main.java.com.study.designPatterns.observer.demoOne;import java.util.ArrayList;import java.util.List;/** * @author: whb * @description: 具体主题者 */public class ConcreteSubject&lt;E&gt; implements ISubject&lt;E&gt; &#123; /** * 观察者集合 */ private List&lt;IObserver&lt;E&gt;&gt; mObservers = new ArrayList&lt;&gt;(); @Override public boolean attach(IObserver&lt;E&gt; observer) &#123; return !this.mObservers.contains(observer) &amp;&amp; this.mObservers.add(observer); &#125; @Override public boolean detach(IObserver&lt;E&gt; observer) &#123; return this.mObservers.remove(observer); &#125; @Override public void notify(E event) &#123; for (IObserver&lt;E&gt; observer : this.mObservers) &#123; observer.update(event); &#125; &#125;&#125; 客户端调用123456789101112131415161718package main.java.com.study.designPatterns.observer.demoOne;/** * @author: whb * @description: 客户端调用 */public class Client &#123; public static void main(String[] args) &#123; // 被观察者 ISubject&lt;String&gt; observable = new ConcreteSubject&lt;&gt;(); // 观察者 IObserver&lt;String&gt; observer = new ConcreteObserver&lt;&gt;(); // 注册 observable.attach(observer); // 通知 observable.notify(\"hello\"); &#125;&#125;","tags":"java 设计模式"},{"title":"设计模式-代理模式","url":"/posts/e3d6aa41.html","text":"模式定义给目标对象提供一个代理对象，并由代理对象控制对目标对象的引用。 主要作用通过引入代理对象的方式来间接访问目标对象。 解决的问题防止直接访问目标对象给系统带来的不必要复杂性。 模式原理UML类图 模式组成 抽象主题角色（Subject）：抽象主题类 的主要职责是声明 真实主题 与 代理 的共同接口方法，该类可以是接口也可以是抽象类； 真实主题角色（RealSubject）：该类也被称为 被委托类 或 被代理类，该类定义了代理所表示的真实对象，是负责执行系统真正的逻辑业务对象； 代理主题角色（Proxy）：也被称为 委托类 或 代理类，其内部持有 RealSubject 的引用，因此具备完全的对 RealSubject 的代理权； 模式优点 协调调用者和被调用者，降低了系统的耦合度。 代理对象作为客户端和目标对象之间的中介，起到了保护目标对象的作用。 职责清晰：真实主题角色 只负责实现实际的业务逻辑，无需关心其他非本职责的事务，通过后期代理的访问控制，可以扩展或缩减实际事务，符合设计模式 单一职责原则，代码简洁清晰； 高扩展性：真实主题角色 负责实际业务逻辑，可能经常性变动，但是由于其与 代理类 都实现了 抽象主题，因此，真实主题 的改变不会影响到代理类，符合设计模式 依赖倒置原则，里氏替换原则 和 开闭原则； 智能化：主要是基于动态代理的实现，可以在程序运行时生成一个合适的代理类； 模式缺点 由于在客户端和真实主题之间增加了代理对象，因此会造成请求的处理速度变慢； 实现代理模式需要额外的工作（有些代理模式的实现非常复杂），从而增加了系统实现的复杂度。 应用场景当无法或不想直接引用某个对象或访问某个对象存在困难时，可以通过也给代理对象来间接访问； 模式示例示例背景背景：假设希望买一台最新的顶配Mac电脑冲突：国内还没上，只有美国才有解决方案：寻找代购进行购买 示例步骤静态代理创建抽象对象接口(Subject)声明你（真实对象）需要让代购（代理对象）帮忙做的事（买Mac） 12345678910111213package main.java.com.study.designPatterns.proxy.demoOne;/** * @author: whb * @description: 抽象对象接口，声明你（真实对象）需要让代购（代理对象）帮忙做的事（买Mac） */public interface Subject &#123; /** * 买mac本 */ public void buyMac();&#125; 创建真实对象类（RealSubject）12345678910111213package main.java.com.study.designPatterns.proxy.demoOne;/** * @author: whb * @description: 真实对象类 */public class RealSubject implements Subject &#123; @Override public void buyMac() &#123; System.out.println(\"买一台mac本...\"); &#125;&#125; 创建代理对象类(Proxy)1234567891011121314151617181920212223242526272829package main.java.com.study.designPatterns.proxy.demoOne;/** * @author: whb * @description: 创建代理对象 */public class ProxySubject implements Subject &#123; /** * 引用真实对象示例 */ private RealSubject realSubject; public ProxySubject(RealSubject realSubject) &#123; this.realSubject = realSubject; &#125; @Override public void buyMac() &#123; //调用真实对象的方法，进行代理购买 realSubject.buyMac(); //代理对象额外的操作 this.wrapMac(); &#125; public void wrapMac() &#123; System.out.println(\"用盒子包装好mac...\"); &#125;&#125; 客户端调用12345678910111213package main.java.com.study.designPatterns.proxy.demoOne;/** * @author: whb * @description: 静态代理客户端调用 */public class StaticProxyClient &#123; public static void main(String[] args) &#123; Subject proxy = new StaticProxy(); proxy.buyMac(); &#125;&#125; 上面代码描绘的代理模式，更加细分的话一般称为静态代理模式，为什么称为静态代理？因为代理对象需要与目标对象实现一样的接口（也就是RealSubject和ProxSubject实现buyMac接口）。假设现在有这种情况，为了保守起见不仅找代购，还通过其他多种渠道购买，这种情况下就会有很多代理类，代理类如果太多会出现什么样的问题？一旦接口增加方法，目标对象与代理对象都要维护，这样的话代码改起来就相当烦琐和冗余。为了解决这个问题，Java给我们提供了一种解决方式，这种解决方式大家一般称为动态代理。 动态代理动态代理的类123456789101112131415161718192021222324252627282930313233343536package main.java.com.study.designPatterns.proxy.demoOne;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;/** * @author: whb * @description: 动态代理 */public class DynamicProxy &#123; /** * 维护一个目标对象 */ private Object object; public DynamicProxy(Object object) &#123; this.object = object; &#125; /** * 给目标对象生成代理对象 */ public Object getProxyInstance() &#123; return Proxy.newProxyInstance(object.getClass().getClassLoader(), object.getClass().getInterfaces(), new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(\"------------开始动态代理-----------\" + \"\\n\"); //执行目标方法 Object returnValue = method.invoke(object, args); System.out.println(\"------------结束动态代理-----------\"); return returnValue; &#125; &#125;); &#125;&#125; 动态代理客户端调用123456789101112131415161718package main.java.com.study.designPatterns.proxy.demoOne;/** * @author: whb * @description: 动态代理客户端调用 */public class DynamicProxyClient &#123; public static void main(String[] args) &#123; //动态代理需要传入接口对象，也就是接口子类 Subject subject = new ProxySubject(new RealSubject()); //将接口库对象传进代理类，使用代理方法 Subject proxy = (Subject) new DynamicProxy(subject).getProxyInstance(); //执行方法【代理对象】 proxy.buyMac(); &#125;&#125; 虽然相对于静态代理，动态代理大大减少了我们的开发任务，同时减少了对业务接口的依赖，降低了耦合度。但是还是有一点点小小的遗憾之处，那就是它始终无法摆脱仅支持interface代理的桎梏，因为它的设计注定了这个遗憾。回想一下那些动态生成的代理类的继承关系图，它们已经注定有一个共同的父类叫Proxy。Java的继承机制注定了这些动态代理类们无法实现对class的动态代理，原因是多继承在Java中本质上就行不通。 CGLIB动态代理 JDK实现动态代理需要实现类通过接口定义业务方法，对于没有接口的类，如何实现动态代理呢，这就需要CGLib了。CGLib采用了非常底层的字节码技术，其原理是通过字节码技术为一个类创建子类，并在子类中采用方法拦截的技术拦截所有父类方法的调用，顺势织入横切逻辑。但因为采用的是继承，所以不能对final修饰的类进行代理。JDK动态代理与CGLib动态代理均是实现Spring AOP的基础。 CGLIB代理类1234567891011121314151617181920212223242526272829303132package main.java.com.study.designPatterns.proxy.cglibProxy;import net.sf.cglib.proxy.Enhancer;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;import java.lang.reflect.Method;/** * @author: whb * @description: Cglib代理类 */public class CglibProxy implements MethodInterceptor &#123; private Object target; public Object getInstance(final Object target) &#123; this.target = target; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(this.target.getClass()); enhancer.setCallback(this); return enhancer.create(); &#125; @Override public Object intercept(Object object, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; System.out.println(\"----------开启事务---------\"); Object result = methodProxy.invokeSuper(object, args); System.out.println(\"-----------结束事务---------\"); return result; &#125;&#125; CGLIB代理测试类123456789101112131415package main.java.com.study.designPatterns.proxy.cglibProxy;/** * @author: whb * @description: Cglib动态代理测试 */public class TestCglibProxy &#123; public static void main(String[] args) &#123; UserDao userDao = new UserDaoImpl(); CglibProxy cglibProxy = new CglibProxy(); UserDaoImpl userDaoCglibProxy = (UserDaoImpl) cglibProxy.getInstance(userDao); userDaoCglibProxy.save(); &#125;&#125; CGLIB创建的动态代理对象比JDK创建的动态代理对象的性能更高，但是CGLIB创建代理对象时所花费的时间却比JDK多得多。所以对于单例的对象，因为无需频繁创建对象，用CGLIB合适，反之使用JDK方式要更为合适一些。同时由于CGLib由于是采用动态创建子类的方法，对于final修饰的方法无法进行代理。","tags":"java 设计模式"},{"title":"Java-HashMap、ConcurrentHashMap解析","url":"/posts/bf7c5065.html","text":"Hash表Hash表也叫散列表，是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。存放记录的数组叫做哈希表。在HashMap中，就是将所给的“键”通过哈希函数得到“索引”，然后把内容存在数组中，这样就形成了“键”和内容的映射关系。 在了解哈希表之前，先大概了解下其他数据结构在新增，查找等基础操作执行性能： 数组：采用一段连续的存储单元来存储数据。对于指定下标的查找，时间复杂度为O(1)；通过给定值进行查找，需要遍历数组，逐一比对给定关键字和数组元素，时间复杂度为O(n)，当然，对于有序数组，则可采用二分查找，插值查找，斐波那契查找等方式，可将查找复杂度提高为O(logn)；对于一般的插入删除操作，涉及到数组元素的移动，其平均复杂度也为O(n)。对应到集合实现，代表就是ArrayList。 线性链表：对于链表的新增，删除等操作（在找到指定操作位置后），仅需处理结点间的引用即可，时间复杂度为O(1)，而查找操作需要遍历链表逐一进行比对，复杂度为O(n)。对应的集合类是LinkedList。 二叉树：对一棵相对平衡的有序二叉树，对其进行插入，查找，删除等操作，平均复杂度均为O(logn)。对应的集合类有TreeSet和TreeMap。 哈希表：相比上述几种数据结构，在哈希表中进行添加，删除，查找等操作，性能十分之高，不考虑哈希冲突的情况下，仅需一次定位即可完成，时间复杂度为O(1)。对应的集合类就是HashMap。 哈希表的主干是数组。要新增或查找某个元素，通过把当前元素的关键字 通过某个函数映射到数组中的某个位置，通过数组下标一次定位就可完成操作。即： 1存储位置 = f(关键字) 其中，这个函数f一般称为哈希函数，这个函数的设计好坏会直接影响到哈希表的优劣。这会涉及到哈希冲突。举个例子，比如要在哈希表中执行插入操作：查找操作同理，先通过哈希函数计算出实际存储地址，然后从数组中对应地址取出即可。 当我们对某个元素进行哈希运算，得到一个存储地址，然后要进行插入的时候，发现已经被其他元素占用了，其实这就是所谓的哈希冲突，也叫哈希碰撞。哈希函数的设计至关重要，好的哈希函数会尽可能地保证计算简单和散列地址分布均匀。但是，数组是一块连续的固定长度的内存空间，再好的哈希函数也不能保证得到的存储地址绝对不发生冲突。那么哈希冲突如何解决呢？哈希冲突的解决方案有多种:开放定址法（发生冲突，继续寻找下一块未被占用的存储地址）、再散列函数法、链地址法。而HashMap即是采用了链地址法，也就是数组+链表的方式。 简单来说，HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的，如果定位到的数组位置不含链表（当前entry的next指向null）,那么对于查找，添加等操作很快，仅需一次寻址即可；如果定位到的数组包含链表，对于添加操作，其时间复杂度依然为O(1)，因为最新的Entry会插入链表头部，急需要简单改变引用链即可，而对于查找操作来讲，此时就需要遍历链表，然后通过key对象的equals方法逐一比对查找。所以，性能考虑，HashMap中的链表出现越少，性能才会越好。 HashMap-Jdk1.7类定义123public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable 简介 继承AbstractMap抽象类； 实现Map接口，拥有一组Map通用操作； 实现Cloneable接口，可进行拷贝（浅拷贝）； 实现了Serializable接口，可实现序列化； 允许键/值为空对象（null）； 非线程安全，可通过Collections类的静态方法synchronizedMap获得线程安全的HashMap； 不保证有序性（如插入顺序），也不保证顺序不随时间变化； 数据结构HashMap 采用的数据结构 = 数组（主） + 单链表（副），该结构又称拉链法，具体描述如下: 当实例化一个HashMap时，系统会创建一个长度为Capacity的Entry数组，这个长度被称为容量(Capacity)，在这个数组中可以存放元素的位置称之为“桶”(bucket)，每个bucket都有自己的索引，系统可以根据索引快速的查找bucket中的元素。 每个bucket中存储一个元素，即一个Entry对象，但每一个Entry对象可以带一个引用变量，用于指向下一个元素，因此，在一个桶中，就有可能生成一个Entry链。 Entry是HashMap的基本组成单元，每一个Entry包含一个key-value键值对。 Entry是HashMap中的一个静态内部类。代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081/** * Entry类实现了Map.Entry接口 * 即 实现了getKey()、getValue()、equals(Object o)和hashCode()等方法**/ static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; // 键 V value; // 值 Entry&lt;K,V&gt; next; // 指向下一个结点 ，也是一个Entry对象，从而形成解决hash冲突的单链表 int hash; // 对key的hashcode值进行hash运算后得到的值，存储在Entry，避免重复计算 /** * 构造方法，创建一个Entry * 参数：哈希值h，键值k，值v、下一个结点n */ Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125; // 返回 与 此项 对应的键 public final K getKey() &#123; return key; &#125; // 返回 与 此项 对应的值 public final V getValue() &#123; return value; &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; /** * 判断2个Entry是否相等，必须key和value都相等，才返回true */ public final boolean equals(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; Object k1 = getKey(); Object k2 = e.getKey(); if (k1 == k2 || (k1 != null &amp;&amp; k1.equals(k2))) &#123; Object v1 = getValue(); Object v2 = e.getValue(); if (v1 == v2 || (v1 != null &amp;&amp; v1.equals(v2))) return true; &#125; return false; &#125; /** * hashCode（） */ public final int hashCode() &#123; return Objects.hashCode(getKey()) ^ Objects.hashCode(getValue()); &#125; public final String toString() &#123; return getKey() + \"=\" + getValue(); &#125; /** * 当向HashMap中添加元素时，即调用put(k,v)时， * 对已经在HashMap中k位置进行v的覆盖时，会调用此方法 * 此处没做任何处理 */ void recordAccess(HashMap&lt;K,V&gt; m) &#123; &#125; /** * 当从HashMap中删除了一个Entry时，会调用该函数 * 此处没做任何处理 */ void recordRemoval(HashMap&lt;K,V&gt; m) &#123; &#125; &#125; 所以，HashMap的整体结构如下： 重要属性12345678910111213141516171819202122232425262728293031323334353637// 1. 容量（capacity）： HashMap中数组的长度// a. 容量范围：必须是2的幂 &amp; &lt;最大容量（2的30次方）// b. 初始容量 = 哈希表创建时的容量// 默认容量 = 16 = 1&lt;&lt;4 = 00001中的1向左移4位 = 10000 = 十进制的2^4=16static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; //最大容量 = 2的30次方（若传入的容量过大，将被最大值替换） static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 2. 加载因子(Load factor)：HashMap在其容量自动增加前可达到多满的一种尺度// a. 加载因子越大、填满的元素越多 = 空间利用率高、但冲突的机会加大、查找效率变低（因为链表变长了）// b. 加载因子越小、填满的元素越少 = 空间利用率小、冲突的机会减小、查找效率高（链表不长）// 实际加载因子final float loadFactor;//默认装载因子 = 0.75 static final float DEFAULT_LOAD_FACTOR = 0.75f; // 3. 扩容阈值（threshold）：当哈希表的大小 ≥ 扩容阈值时，就会扩容哈希表（即扩充HashMap的容量） // a. 扩容 = 对哈希表进行resize操作（即重建内部数据结构），从而哈希表将具有大约两倍的桶数// b. 扩容阈值 = 容量 x 加载因子int threshold; // 存储数据的Entry类型 数组，长度 = 2的幂// HashMap的实现方式 = 拉链法，Entry数组上的每个元素本质上是一个单向链表transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE; //HashMap内部的存储结构是一个数组，此处数组为空，即没有初始化之前的状态 static final Entry&lt;?,?&gt;[] EMPTY_TABLE = &#123;&#125;; //实际存储的key-value键值对的个数transient int size;//用于快速失败，由于HashMap非线程安全，在对HashMap进行迭代时，如果期间其他线程的参与导致HashMap的结构发生变化了（比如put，remove等操作），需要抛出异常ConcurrentModificationExceptiontransient int modCount;//默认的threshold值 static final int ALTERNATIVE_HASHING_THRESHOLD_DEFAULT = Integer.MAX_VALUE; 加载因子详述加载因子过大 填充的元素越多，空间利用率也就越高； 冲突概率加大，链表边长，查找效率变小； 加载因子过小 冲突概率减小，链表变短，查找效率变高； 填充的元素越少，空间利用率越低； 使用建议 在查找效率&amp;空间利用率之间寻找一种平衡，即所谓的“空间效率换时间效率” or “时间效率换空间效率”； 若空间内存充足，可选择“空间效率换时间效率”策略，即通过设置过小的加载因子提高查询速度，但也要考虑频繁扩容带来的性能损耗； 若空间内存不足，可选择“时间效率换空间效率”策略，即通过设置过大的加载因子提高空间利用率，但牺牲了查询速率； 加载因子可自定义修改，但非特殊情况不建议修改（默认值=0.75）； 构造方法HashMap有4个构造器，其他构造器如果用户没有传入initialCapacity 和loadFactor这两个参数，会使用默认值。initialCapacity默认为16，loadFactory默认为0.75。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//计算Hash值时的key transient int hashSeed = 0; /** * 构造函数1：默认构造函数（无参） * 加载因子 &amp; 容量 = 默认 = 0.75、16 */ public HashMap() &#123; // 实际上是调用构造函数3：指定“容量大小”和“加载因子”的构造函数 // 传入的指定容量 &amp; 加载因子 = 默认 this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR); &#125; /** * 构造函数2：指定“容量大小”的构造函数 * 加载因子 = 默认 = 0.75 、容量 = 指定大小 */ public HashMap(int initialCapacity) &#123; // 实际上是调用指定“容量大小”和“加载因子”的构造函数 // 只是在传入的加载因子参数 = 默认加载因子 this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; /** * 构造函数3：指定“容量大小”和“加载因子”的构造函数 * 加载因子 &amp; 容量 = 自己指定 */ public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0)//参数有效性检查 throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY)//参数有效性检查 initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor))//参数有效性检查 throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); // 设置 加载因子 this.loadFactor = loadFactor; // 设置 扩容阈值 = 初始容量 threshold = initialCapacity; init();//init方法在HashMap中没有实际实现，不过在其子类如 linkedHashMap中就会有对应实现&#125; /** * 构造函数4：包含“子Map”的构造函数 * 即 构造出来的HashMap包含传入Map的映射关系 * 加载因子 &amp; 容量 = 默认 */ public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; // 设置容量大小 &amp; 加载因子 = 默认 this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR); inflateTable(threshold);//初始化HashMap底层的数组结构 putAllForCreate(m);//添加m中的元素 &#125; 在常规构造器中，并没有马上为数组table分配内存空间（有一个入参为指定Map的构造器例外），事实上是在执行第一次put操作的时候才真正构建table数组。 put操作源码如下： 12345678910111213141516171819202122232425262728293031323334353637public V put(K key, V value) // 1. 若哈希表未初始化（即 table为空) // 则使用构造函数设置的阈值(即初始容量) 初始化数组table if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; // 2. 判断key是否为空值null // 2.1 若key == null，则将该键-值 存放到数组table 中的第1个位置，即table [0] // （本质：key = Null时，hash值 = 0，故存放到table[0]中） // 该位置永远只有1个value，新传进来的value会覆盖旧的value if (key == null) return putForNullKey(value); // 2.2 若 key ≠ null，则计算存放数组 table 中的位置（下标、索引） // a. 根据键值key计算hash值 int hash = hash(key); // b. 根据hash值 最终获得 key对应存放的数组Table中位置 int i = indexFor(hash, table.length); // 3. 判断该key对应的值是否已存在（通过遍历 以该数组元素为头结点的链表 逐个判断） for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; // 3.1 若该key已存在（即 key-value已存在 ），则用 新value 替换 旧value if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; //并返回旧的value &#125; &#125; //保证并发访问时，若HashMap内部结构发生变化，快速响应失败 modCount++; // 3.2 若 该key不存在，则将“key-value”添加到table中 addEntry(hash, key, value, i); return null;&#125; 根据源码分析所作出的流程图： inflateTable–初始化哈希表123456789101112131415private void inflateTable(int toSize) &#123; // 1. 将传入的容量大小转化为：&gt;传入容量大小的最小的2的次幂 // 即如果传入的是容量大小是19，那么转化后，初始化容量大小为32（即2的5次幂） int capacity = roundUpToPowerOf2(toSize);-&gt;&gt;分析1 // 2. 重新计算阈值 threshold = 容量 * 加载因子 threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); // 3. 使用计算后的初始容量（已经是2的次幂） 初始化数组table（作为数组长度） // 即 哈希表的容量大小 = 数组大小（长度） table = new Entry[capacity]; //用该容量初始化table //初始化哈希种子 initHashSeedAsNeeded(capacity); &#125; inflateTable这个方法用于为主干数组table在内存中分配存储空间，通过roundUpToPowerOf2(toSize)可以确保capacity为大于或等于toSize的最接近toSize的二次幂，比如toSize=13,则capacity=16;to_size=16,capacity=16;to_size=17,capacity=32。 123456private static int roundUpToPowerOf2(int number) &#123; //若容量超过了最大值，初始化容量设置为最大值 ；否则，设置为：&gt;传入容量大小的最小的2的次幂 return number &gt;= MAXIMUM_CAPACITY ? MAXIMUM_CAPACITY : (number &gt; 1) ? Integer.highestOneBit((number - 1) &lt;&lt; 1) : 1;&#125; putForNullKey1234567891011121314151617181920212223private V putForNullKey(V value) &#123; // 遍历以table[0]为首的链表，寻找是否存在key==null 对应的键值对 // 1. 若有：则用新value 替换 旧value；同时返回旧的value值 for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // 2 .若无key==null的键，那么调用addEntry（），将空键 &amp; 对应的值封装到Entry中，并放到table[0]中 addEntry(0, null, value, 0); // 注： // a. addEntry（）的第1个参数 = hash值 = 传入0 // b. 即 说明：当key = null时，也有hash值 = 0，所以HashMap的key 可为null // c. 对比HashTable，由于HashTable对key直接hashCode（），若key为null时，会抛出异常，所以HashTable的key不可为null // d. 此处只需知道是将 key-value 添加到HashMap中即可 return null; &#125; 计算Hash值123456789101112// 计算Hash值：将 键key 转换成 哈希码（hash值）操作 = 使用hashCode() + 4次位运算 + 5次异或运算（9次扰动）final int hash(Object k) &#123; int h = hashSeed; //key是String类型的就使用另外的哈希算法 if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); //扰动函数 h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; hash方法的最后两行是真正计算hash值的算法，计算hash码的算法被称为扰动函数，所谓的扰动函数就是把所有东西杂糅到一起，可以看到这里使用了四个向右移位运算。目的就是将h的高位值与低位值混合一下，以此增加低位值的随机性。定位数组的下标是根据hash码的低位值来确定的。key的hash码是通过hashCode方法来生成的，而一个糟糕的hashCode方法生成的hash码的低位值可能会有很大的重复。为了使得hash码在数组上映射的比较均匀，扰动函数就派上用场了，把高位值的特性糅合进低位值，增加低位值的随机性，从而使散列分布的更加松散，以此提高性能。下图举了个例子帮助理解。 计算索引值（数组下标）1234567/** * 计算索引位置 */ static int indexFor(int h, int length) &#123; return h &amp; (length-1); // 将对哈希码扰动处理后的结果 与运算(&amp;) （数组长度-1），最终得到存储在数组table的位置（即数组下标、索引）&#125; h&amp;（length-1）保证获取的index一定在数组范围内，举个例子，默认容量16，length-1=15，h=18,转换成二进制计算为: 1234 1 0 0 1 0&amp; 0 1 1 1 1__________________ 0 0 0 1 0 = 2 最终计算出的index=2。有些版本的对于此处的计算会使用 取模运算，也能保证index一定在数组范围内，不过位运算对计算机来说，性能更高一些（HashMap中有大量位运算） 所以最终存储位置的确定流程是这样的： addEntry–添加键值对1234567891011121314151617181920212223/** * 添加键值对（Entry ）到 HashMap中 * @param hash--key对应的hash值 * @param key--键 * @param value--值 * @param bucketIndex--出入数组table的索引位置--&gt;数组下标 */void addEntry(int hash, K key, V value, int bucketIndex) &#123; // 1. 插入前，先判断容量是否足够，若不足够，则进行扩容（2倍）、重新计算Hash值、重新计算存储数组下标 // 如果HashMap的大小大于阀值并且哈希表对应槽位的值不为空 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; //因为HashMap的大小大于阀值, 表明即将发生哈希冲突, 所以进行扩容 //2倍扩容 resize(2 * table.length); //重新计算该key对应的hash值 hash = (null != key) ? hash(key) : 0; //重新计算该key对应的hash值的存储数组下标 bucketIndex = indexFor(hash, table.length); &#125; //在这里表明HashMap的大小没有超过阀值, 所以不需要扩容 //创建1个新的数组元素(Entry)并放入数组中 createEntry(hash, key, value, bucketIndex);&#125; 流程如下（键值对的添加方式–&gt;单链表的头插法）： resize–数组扩容12345678910111213141516171819202122/** * 对哈希表进行扩容，当容量不足时（容量 &gt; 阈值），则扩容（扩到2倍） */void resize(int newCapacity) &#123; // 1. 保存旧数组（old table） Entry[] oldTable = table; // 2. 保存旧容量（old capacity ），即数组长度 int oldCapacity = oldTable.length; // 3. 若旧容量已经是系统默认最大容量了，那么将阈值设置成整型的最大值，退出 if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; // 4. 根据新容量（2倍容量）新建1个数组，即新table Entry[] newTable = new Entry[newCapacity]; // 5. 将旧数组上的数据（键值对）转移到新table中，从而完成扩容 transfer(newTable, initHashSeedAsNeeded(newCapacity)); // 6. 将当前哈希表设置为新的哈希表 table = newTable; // 7. 更新哈希表阈值 threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125; 流程如下： transfer–数据转移123456789101112131415161718192021222324252627282930313233343536 /** * 将旧数组上的数据（键值对）转移到新table中，从而完成扩容 * 过程：按旧链表的正序遍历链表、在新链表的头部依次插入 */ void transfer(Entry[] newTable) &#123; // 1. src引用了旧数组 Entry[] src = table; // 2. 获取新数组的大小 = 获取新容量大小 int newCapacity = newTable.length; // 3. 通过遍历 旧数组，将旧数组上的数据（键值对）转移到新数组中 for (int j = 0; j &lt; src.length; j++) &#123; // 3.1 取得旧数组的每个元素 Entry&lt;K,V&gt; e = src[j]; if (e != null) &#123; // 3.2 释放旧数组的对象引用（for循环后，旧数组不再引用任何对象） src[j] = null; do &#123; // 3.3 遍历 以该数组元素为首 的链表 // 注：转移链表时，因是单链表，故要保存下1个结点，否则转移后链表会断开 Entry&lt;K,V&gt; next = e.next; // 3.4 重新计算每个元素的存储位置 int i = indexFor(e.hash, newCapacity); // 3.5 将元素放在数组上：采用单链表的头插入方式 = 在链表头上存放数据 = 将数组位置的原有数据放在后1个指针、将需放入的数据放到数组位置中 // 即 扩容后，可能出现逆序：按旧链表的正序遍历链表、在新链表的头部依次插入 e.next = newTable[i]; newTable[i] = e; // 3.6 访问下1个Entry链上的元素，如此不断循环，直到遍历完该链表上的所有结点 e = next; &#125; while (e != null); // 如此不断循环，直到遍历完数组上的所有数据元素 &#125; &#125; &#125; 流程如下： createEntry–添加键值对123456789101112131415/** * 创建1个新的数组元素（Entry） 并放入到数组中 */ void createEntry(int hash, K key, V value, int bucketIndex) &#123; // 1. 把table中该位置原来的Entry保存 Entry&lt;K,V&gt; e = table[bucketIndex]; // 2. 在table中该位置新建一个Entry：将原头结点位置（数组上）的键值对 放入到（链表）后1个结点中、将需插入的键值对 放入到头结点中（数组上）-&gt; 从而形成链表 // 即 在插入元素时，是在链表头插入的，table中的每个位置永远只保存最新插入的Entry，旧的Entry则放入到链表中（即 解决Hash冲突） table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); // 3. 哈希表的键值对数量计数增加 size++; &#125; 总结向 HashMap 添加数据（成对 放入 键 - 值对）的全流程： get操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * 从HashMap中获取数据 */ public V get(Object key) &#123; // 1. 当key == null时，则到 以哈希表数组中的第1个元素（即table[0]）为头结点的链表去寻找对应 key == null的键 if (key == null) return getForNullKey(); // 2. 当key ≠ null时，去获得对应值 Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue(); &#125; /** * 当key == null时，则到 以哈希表数组中的第1个元素（即table[0]）为头结点的链表去寻找对应 key == null的键 */ private V getForNullKey() &#123; if (size == 0) &#123; return null; &#125; // 遍历以table[0]为头结点的链表，寻找 key==null 对应的值 for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; // 从table[0]中取key==null的value值 if (e.key == null) return e.value; &#125; return null; &#125; /** * 当key ≠ null时，去获得对应值 */ final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; // 1. 根据key值，通过hash（）计算出对应的hash值 int hash = (key == null) ? 0 : hash(key); // 2. 根据hash值计算出对应的数组下标 // 3. 遍历 以该数组下标的数组元素为头结点的链表所有结点，寻找该key对应的值 for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; // 若 hash值 &amp; key 相等，则证明该Entry = 我们要的键值对 // 通过equals（）判断key是否相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null; &#125; 流程如下： 其他操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132 /** * 判断HashMap是否为空，即无键值对；size == 0时 表示为 空 */public boolean isEmpty() &#123; return size == 0; &#125; /** * 返回哈希表中所有 键值对的数量 = 数组中的键值对 + 链表中的键值对 */public int size() &#123; return size; &#125; /** * 清空哈希表，即删除所有键值对 * 原理：将数组table中存储的Entry全部置为null、size置为0 */ public void clear() &#123; modCount++; Arrays.fill(table, null); size = 0;&#125; /** * 将指定Map中的键值对 复制到 此Map中 */ public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; // 1. 统计需复制多少个键值对 int numKeysToBeAdded = m.size(); if (numKeysToBeAdded == 0) return; // 2. 若table还没初始化，先用刚刚统计的复制数去初始化table if (table == EMPTY_TABLE) &#123; inflateTable((int) Math.max(numKeysToBeAdded * loadFactor, threshold)); &#125; // 3. 若需复制的数目 &gt; 阈值，则需先扩容 if (numKeysToBeAdded &gt; threshold) &#123; int targetCapacity = (int)(numKeysToBeAdded / loadFactor + 1); if (targetCapacity &gt; MAXIMUM_CAPACITY) targetCapacity = MAXIMUM_CAPACITY; int newCapacity = table.length; while (newCapacity &lt; targetCapacity) newCapacity &lt;&lt;= 1; if (newCapacity &gt; table.length) resize(newCapacity); &#125; // 4. 开始复制（实际上不断调用Put函数插入） for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) put(e.getKey(), e.getValue());&#125; /** * 删除该键值对 */ public V remove(Object key) &#123; Entry&lt;K,V&gt; e = removeEntryForKey(key); return (e == null ? null : e.value); &#125; final Entry&lt;K,V&gt; removeEntryForKey(Object key) &#123; if (size == 0) &#123; return null; &#125; // 1. 计算hash值 int hash = (key == null) ? 0 : hash(key); // 2. 计算存储的数组下标位置 int i = indexFor(hash, table.length); Entry&lt;K,V&gt; prev = table[i]; Entry&lt;K,V&gt; e = prev; while (e != null) &#123; Entry&lt;K,V&gt; next = e.next; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; modCount++; size--; // 若删除的是table数组中的元素（即链表的头结点） // 则删除操作 = 将头结点的next引用存入table[i]中 if (prev == e) table[i] = next; //否则 将以table[i]为头结点的链表中，当前Entry的前1个Entry中的next 设置为 当前Entry的next（即删除当前Entry = 直接跳过当前Entry） else prev.next = next; e.recordRemoval(this); return e; &#125; prev = e; e = next; &#125; return e; &#125; /** * 判断是否存在该键的键值对；是 则返回true * 原理：调用get（），判断是否为Null */public boolean containsKey(Object key) &#123; return getEntry(key) != null; &#125; /** * 判断是否存在该值的键值对；是 则返回true */ public boolean containsValue(Object value) &#123; // 若value为空，则调用containsNullValue() if (value == null) return containsNullValue(); // 若value不为空，则遍历链表中的每个Entry，通过equals（）比较values 判断是否存在 Entry[] tab = table; for (int i = 0; i &lt; tab.length ; i++) for (Entry e = tab[i] ; e != null ; e = e.next) if (value.equals(e.value)) return true;//返回true return false; &#125; // value为空时调用的方法 private boolean containsNullValue() &#123; Entry[] tab = table; for (int i = 0; i &lt; tab.length ; i++) for (Entry e = tab[i] ; e != null ; e = e.next) if (e.value == null) return true; return false; &#125; 扩容导致死循环分析HashMap是线程不安全的，原因就是在多线程下并发执行put()操作导致触发扩容resize()，从而导致环形链表，使得在获取数据遍历链表时形成死循环。 resize()的源码前面已经分析过了，从源码可以看出在resize()过程中，在将旧数组上的数据转移到新数组上时，转移数据操作需要将旧链表正序遍历，然后在新链表的头部依次插入，即在转移数据、扩容后，容易出现链表逆序的情况。 假设重新计算存储位置后不变，即扩容前 1-&gt;2-&gt;3，扩容后 3-&gt;2-&gt;1，此时若（多线程）并发执行 put（）操作，一旦出现扩容情况，则 容易出现 环形链表，从而在获取数据、遍历链表时 形成死循环（Infinite Loop），即 死锁的状态，如下图： 注：由于 JDK 1.8 转移数据操作 = 按旧链表的正序遍历链表、在新链表的尾部依次插入，所以不会出现链表 逆序、倒置的情况，故不容易出现环形链表的情况。但 JDK 1.8 还是线程不安全，因为 无加同步锁保护。 HashMap-Jdk1.8数据结构在Jdk1.8中，优化了HashMap的数据结构，引入红黑树，即HashMap的数据结构 = 数组 + 链表 + 红黑树。 引入原因引入红黑树的目的在于提高HashMap的性能，即解决发生哈希碰撞后，链表过长导致索引效率慢的问题。具体就是利用红黑树快速增删改查的特点，将时间复杂度从原来的O(n)降到O(log(n))。 应用场景当链表长度&gt;8 时，将该链表转换成红黑树； 数组元素&amp;链表结点实现类Jdk1.8 HashMap中的数组元素&amp;链表结点采用Node类实现，该类源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * Node = HashMap的内部类，实现了Map.Entry接口，本质是 = 一个映射(键值对) * 实现了getKey()、getValue()、equals(Object o)和hashCode()等方法 **/ static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; // 哈希值，HashMap根据该值确定记录的位置 final K key; // key V value; // value Node&lt;K,V&gt; next;// 链表下一个结点 // 构造方法 Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; // 返回 与 此项 对应的键 public final V getValue() &#123; return value; &#125; // 返回 与 此项 对应的值 public final String toString() &#123; return key + \"=\" + value; &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; /** * 判断2个Entry是否相等，必须key和value都相等，才返回true */ public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; 红黑树结点实现类12345678910111213141516171819202122232425/** * 红黑树结点 实现类：继承自LinkedHashMap.Entry&lt;K,V&gt;类 */static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; // 属性 = 父结点、左子树、右子树、删除辅助结点 + 颜色TreeNode&lt;K,V&gt; parent; TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right;TreeNode&lt;K,V&gt; prev; boolean red; // 构造函数TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; super(hash, key, val, next); &#125; // 返回当前结点的根结点 final TreeNode&lt;K,V&gt; root() &#123; for (TreeNode&lt;K,V&gt; r = this, p;;) &#123; if ((p = r.parent) == null) return r; r = p; &#125; &#125; 重要属性12345678910111213141516171819202122232425262728293031323334/** * 主要参数 同 JDK 1.7 * 即：容量、加载因子、扩容阈值（要求、范围均相同） */// 1. 容量（capacity）： 必须是2的幂 &amp; &lt;最大容量（2的30次方）static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 默认容量 = 16 = 1&lt;&lt;4 = 00001中的1向左移4位 = 10000 = 十进制的2^4=16static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 最大容量 = 2的30次方（若传入的容量过大，将被最大值替换）// 2. 加载因子(Load factor)：HashMap在其容量自动增加前可达到多满的一种尺度 final float loadFactor; // 实际加载因子static final float DEFAULT_LOAD_FACTOR = 0.75f; // 默认加载因子 = 0.75// 3. 扩容阈值（threshold）：当哈希表的大小 ≥ 扩容阈值时，就会扩容哈希表（即扩充HashMap的容量） // a. 扩容 = 对哈希表进行resize操作（即重建内部数据结构），从而哈希表将具有大约两倍的桶数// b. 扩容阈值 = 容量 x 加载因子int threshold;// 4. 其他transient Node&lt;K,V&gt;[] table; // 存储数据的Node类型 数组，长度 = 2的幂；数组的每个元素 = 1个单链表transient int size;// HashMap的大小，即 HashMap中存储的键值对的数量 /** * 与红黑树相关的参数 */ // 1. 桶的树化阈值：即 链表转成红黑树的阈值，在存储数据时，当链表长度 &gt; 该值时，则将链表转换成红黑树 static final int TREEIFY_THRESHOLD = 8; // 2. 桶的链表还原阈值：即 红黑树转为链表的阈值，当在扩容（resize（））时（此时HashMap的数据存储位置会重新计算），在重新计算存储位置后，当原有的红黑树内数量 &lt; 6时，则将 红黑树转换成链表 static final int UNTREEIFY_THRESHOLD = 6; // 3. 最小树形化容量阈值：即 当哈希表中的容量 &gt; 该值时，才允许树形化链表 （即 将链表 转换成红黑树） // 否则，若桶内元素太多时，则直接扩容，而不是树形化 // 为了避免进行扩容、树形化选择的冲突，这个值不能小于 4 * TREEIFY_THRESHOLD static final int MIN_TREEIFY_CAPACITY = 64; 构造函数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586/** * 源码分析：主要是HashMap的构造函数 = 4个 * 仅贴出关于HashMap构造函数的源码 */public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable&#123; // 省略上节阐述的参数 /** * 构造函数1：默认构造函数（无参） * 加载因子 &amp; 容量 = 默认 = 0.75、16 */ public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; &#125; /** * 构造函数2：指定“容量大小”的构造函数 * 加载因子 = 默认 = 0.75 、容量 = 指定大小 */ public HashMap(int initialCapacity) &#123; // 实际上是调用指定“容量大小”和“加载因子”的构造函数 // 只是在传入的加载因子参数 = 默认加载因子 this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; /** * 构造函数3：指定“容量大小”和“加载因子”的构造函数 * 加载因子 &amp; 容量 = 自己指定 */ public HashMap(int initialCapacity, float loadFactor) &#123; // 指定初始容量必须非负，否则报错 if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); // HashMap的最大容量只能是MAXIMUM_CAPACITY，哪怕传入的 &gt; 最大容量 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; // 填充比必须为正 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); // 设置 加载因子 this.loadFactor = loadFactor; // 设置 扩容阈值 // 注：此处不是真正的阈值，仅仅只是将传入的容量大小转化为：&gt;传入容量大小的最小的2的幂，该阈值后面会重新计算 this.threshold = tableSizeFor(initialCapacity); &#125; /** * 构造函数4：包含“子Map”的构造函数 * 即 构造出来的HashMap包含传入Map的映射关系 * 加载因子 &amp; 容量 = 默认 */ public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; // 设置容量大小 &amp; 加载因子 = 默认 this.loadFactor = DEFAULT_LOAD_FACTOR; // 将传入的子Map中的全部元素逐个添加到HashMap中 putMapEntries(m, false); &#125;&#125;/** * 将传入的容量大小转化为：&gt;传入容量大小的最小的2的幂 * 与JDK 1.7对比：类似于JDK 1.7 中 inflateTable()里的 roundUpToPowerOf2(toSize) */static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; put操作12345678/** * 源码分析：主要分析HashMap的put函数 */public V put(K key, V value) &#123; // 1. 对传入数组的键Key计算Hash值 // 2. 再调用putVal（）添加数据进去 return putVal(hash(key), key, value, false, true);&#125; hash–计算Hash值1234567891011121314151617/** * hash(key) * 作用：计算传入数据的哈希码（哈希值、Hash值） * 该函数在JDK 1.7 和 1.8 中的实现不同，但原理一样 = 扰动函数 = 使得根据key生成的哈希码（hash值）分布更加均匀、更具备随机性，避免出现hash值冲突（即指不同key但生成同1个hash值） * JDK 1.7 做了9次扰动处理 = 4次位运算 + 5次异或运算 * JDK 1.8 简化了扰动函数 = 只做了2次扰动 = 1次位运算 + 1次异或运算 */ // JDK 1.8实现：将 键key 转换成 哈希码（hash值）操作 = 使用hashCode() + 1次位运算 + 1次异或运算（2次扰动） // 1. 取hashCode值： h = key.hashCode() // 2. 高位参与低位的运算：h ^ (h &gt;&gt;&gt; 16) static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); // a. 当key = null时，hash值 = 0，所以HashMap的key 可为null // 注：对比HashTable，HashTable对key直接hashCode（），若key为null时，会抛出异常，所以HashTable的key不可为null // b. 当key ≠ null时，则通过先计算出 key的 hashCode()（记为h），然后 对哈希码进行 扰动处理： 按位 异或（^） 哈希码自身右移16位后的二进制 &#125; putVal–存放数据到哈希表由于数据结构中加入了红黑树，所以在存放数据到哈希表中时，需进行多次数据结构的判断：数组、红黑树、链表。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185 /** * 存放数据到哈希表 */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 1. 若哈希表的数组tab为空或者长度为0，则 通过resize() 创建 // 所以，初始化哈希表的时机 = 第1次调用put函数时，即调用resize() 初始化创建 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 2. 计算插入存储的数组索引i：根据键值key计算的hash值 得到 // 此处的数组下标计算方式 = i = (n - 1) &amp; hash，同JDK 1.7中的indexFor（） // 3. 插入时，需判断是否存在Hash冲突： // 若不存在（即当前table[i] == null），则直接在该数组位置新建结点，插入完毕 // 否则，代表存在Hash冲突，即当前存储位置已存在结点，则依次往下判断： // a. 当前位置的key是否与需插入的key相同、 // b. 判断需插入的数据结构是否为红黑树 or 链表 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123;//说明待插入位置存在元素 Node&lt;K,V&gt; e; K k; // a. 判断 table[i]的元素的key是否与 需插入的key一样，若相同则 直接用新value 覆盖 旧value // 判断原则：equals（） if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) //将第一个元素赋值给e，用e来记录 e = p; // b. 继续判断：需插入的数据结构是否为红黑树 or 链表 // 若是红黑树，则直接在树中插入 or 更新键值对 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 若是链表,则在链表中插入 or 更新键值对 // i. 遍历table[i]，判断Key是否已存在：采用equals（） 对比当前遍历结点的key 与 需插入数据的key：若已存在，则直接用新value 覆盖 旧value // ii. 遍历完毕后仍无发现上述情况，则直接在链表尾部插入数据 // 注：新增结点后，需判断链表长度是否&gt;8（8 = 桶的树化阈值）：若是，则把链表转换为红黑树 else &#123; //在链表末尾插入结点 for (int binCount = 0; ; ++binCount) &#123; // 对于ii：若数组的下1个位置，表示已到表尾也没有找到key值相同结点，则新建结点 = 插入结点 // 注：此处是从链表尾插入，与JDK 1.7不同（从链表头插入，即永远都是添加到数组的位置，原来数组位置的数据则往后移） if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 插入结点后，若链表结点&gt;数阈值，则将链表转换为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st //链表转红黑树 treeifyBin(tab, hash); break; &#125; //遍历table[i]，判断Key是否已存在：采用equals（） 对比当前遍历结点的key 与 需插入数据的key if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) //相等，跳出循环 break; // 更新p指向下一个结点，继续遍历 p = e; &#125; &#125; //表示在桶中找到key值、hash值与插入元素相等的结点，直接用新value 覆盖 旧value 并 返回旧value if (e != null) &#123; // existing mapping for key //记录e的value V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) //新值替换旧值 e.value = value; afterNodeAccess(e);// 替换旧值时会调用的方法（默认实现为空） //返回旧值 return oldValue; &#125; &#125; ++modCount; // 插入成功后，判断实际存在的键值对数量size &gt; 最大容量threshold // 若 &gt; ，则进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict);// 插入成功时会调用的方法（默认实现为空） return null;&#125;/** * 向红黑树插入 or 更新数据（键值对） * 过程：遍历红黑树判断该结点的key是否与需插入的key 相同： * a. 若相同，则新value覆盖旧value * b. 若不相同，则插入 */final TreeNode&lt;K,V&gt; putTreeVal(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int h, K k, V v) &#123; Class&lt;?&gt; kc = null; boolean searched = false; TreeNode&lt;K,V&gt; root = (parent != null) ? root() : this; //从根结点开始查找合适的插入位置（与二叉搜索树查找过程相同） for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk; if ((ph = p.hash) &gt; h) dir = -1;//dir小于0，接下来查找当前结点的左孩子 else if (ph &lt; h) dir = 1;//dir大于0，接下来查找当前结点的右孩子 else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) //这里代表hash值相同，key相同 return p; /** *要进入下面这个else if,代表有以下几个含义: *1、当前结点与待插入结点 key 不同, hash 值相同; *2、ｋ是不可比较的，即ｋ并未实现 comparable&lt;K&gt; 接口 * （若 k 实现了comparable&lt;K&gt; 接口，comparableClassFor（k）返回的是ｋ的 class,而不是 null） * 或者 compareComparables(kc, k, pk) 返回值为 0 * (pk 为空 或者 按照 k.compareTo(pk) 返回值为０， * 返回值为０可能是由于 ｋ的compareTo 方法实现不当引起的，compareTo 判定相等，而上个 else if 中 equals 判定不等) */ else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) &#123; //在以当前结点为根的整个树上搜索是否存在待插入的结点（只会搜索一次） if (!searched) &#123; TreeNode&lt;K,V&gt; q, ch; searched = true; if (((ch = p.left) != null &amp;&amp; (q = ch.find(h, k, kc)) != null) || ((ch = p.right) != null &amp;&amp; (q = ch.find(h, k, kc)) != null)) return q; &#125; //如果仍未比较出大小，就需要进行仲裁了，仲裁方法为 tieBreakOrder dir = tieBreakOrder(k, pk); &#125; TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; //找到了待插入的位置，xp 为待插入结点的父结点 //注意TreeNode结点中既存在树状关系，也存在链式关系，并且是双端链表 Node&lt;K,V&gt; xpn = xp.next; TreeNode&lt;K,V&gt; x = map.newTreeNode(h, k, v, xpn); if (dir &lt;= 0) xp.left = x; else xp.right = x; xp.next = x; x.parent = x.prev = xp; if (xpn != null) ((TreeNode&lt;K,V&gt;)xpn).prev = x; //插入结点后进行二叉树的平衡操作 moveRootToFront(tab, balanceInsertion(root, x)); return null; &#125; &#125;&#125;/** * 将普通结点链表转换成树形结点链表 * 树化要满足两个条件： * 1. 链表长度大于等于 TREEIFY_THRESHOLD * 2. 桶数组容量大于等于 MIN_TREEIFY_CAPACITY * 第一个条件比较好理解，加入第二个条件，个人觉得原因如下： * 当桶数组容量比较小时，键值对结点 hash 的碰撞率可能会比较高，进而导致链表长度较长。 * 这个时候应该优先扩容，而不是立马树化。毕竟高碰撞率是因为桶数组容量较小引起的，这个是主因。 * 容量小时，优先扩容可以避免一些列的不必要的树化过程。同时，桶容量较小时，扩容会比较频繁，扩容时需要拆分红黑树并重新映射。所以在桶容量比较小的情况下，将长链表转成红黑树是一件吃力不讨好的事。 */final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; //// 如果 tab.length 小于 MIN_TREEIFY_CAPACITY， 优先进行扩容而不是树化 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; // hd 为头结点（head），tl 为尾结点（tail） TreeNode&lt;K,V&gt; hd = null, tl = null; do &#123; // 将普通结点替换成树形结点 TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null);// 将普通链表转成由树形结点链表 if ((tab[index] = hd) != null) // 将树形链表转换成红黑树 hd.treeify(tab); &#125;&#125; 流程图如下： resize–扩容123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185/** * 扩容 * 该函数有2种使用情况：1.初始化哈希表 2.当前数组容量过小，需扩容 */final Node&lt;K,V&gt;[] resize() &#123; //// 扩容前的数组（当前数组） Node&lt;K,V&gt;[] oldTab = table; //// 扩容前的数组的容量 = 长度 int oldCap = (oldTab == null) ? 0 : oldTab.length; //// 扩容前的数组的阈值 int oldThr = threshold; int newCap, newThr = 0; // 如果 table 不为空，表明已经初始化过了 if (oldCap &gt; 0) &#123; //若扩容前的数组容量超过最大值，则不再扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //若未超过最大值，则扩容为原来的2倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold /* * 初始化时，将 threshold 的值赋值给 newCap， * HashMap 使用 threshold 变量暂时保存 initialCapacity 参数的值 */ newCap = oldThr; else &#123; /* * 调用无参构造方法时，桶数组容量为默认容量， * 阈值为默认容量与默认负载因子乘积 */ newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //计算新的resize上限 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) // 创建新的桶数组，桶数组的初始化也是在这里完成的 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 把每个bucket都移动到新的buckets中 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; // 清除原来table[i]中的值 oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) //如果e是红黑树结点，走红黑树替换方式 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123;// 如果 table[j] 后是一个链表 ，将原链表拆分为两条链，分别放到newTab中 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 原索引，(e.hash &amp; oldCap) == 0 说明 在put操作通过 hash &amp; newThr //计算出的索引值等于现在的索引值。 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引+oldCap，不是原索引，就移动原来的长度 else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); //原索引放到bucket里 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 原索引+oldCap放到bucket里 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125;// 红黑树转链表阈值static final int UNTREEIFY_THRESHOLD = 6;/** *这个函数的功能是对红黑树进行rehash 操作(拆分红黑树) * 重新映射红黑树的逻辑和重新映射链表的逻辑基本一致。不同的地方在于，重新映射后，会将红黑树拆分成两条由 TreeNode 组成的链表。 * 如果链表长度小于 UNTREEIFY_THRESHOLD，则将链表转换成普通链表。否则根据条件重新将 TreeNode 链表树化。 */final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) &#123; TreeNode&lt;K,V&gt; b = this; // Relink into lo and hi lists, preserving order TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; //由于TreeNode 结点之间存在双端链表的关系，可以利用链表关系进行 rehash for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) &#123; next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; if ((e.hash &amp; bit) == 0) &#123; if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; &#125; else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; &#125; &#125; // 如果 loHead 不为空，且链表长度小于等于 6，则将红黑树转成链表 if (loHead != null) &#123; if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else &#123; tab[index] = loHead; /* * hiHead == null 时，表明扩容后， * 所有结点仍在原位置，树结构不变，无需重新树化 */ if (hiHead != null) loHead.treeify(tab); &#125; &#125; // 与上面类似 if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else &#123; tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); &#125; &#125;&#125;/** *红黑树链化 */final Node&lt;K,V&gt; untreeify(HashMap&lt;K,V&gt; map) &#123; Node&lt;K,V&gt; hd = null, tl = null; // 遍历 TreeNode 链表，并用 Node 替换 for (Node&lt;K,V&gt; q = this; q != null; q = q.next) &#123; // 替换结点类型 Node&lt;K,V&gt; p = map.replacementNode(q, null); if (tl == null) hd = p; else tl.next = p; tl = p; &#125; return hd;&#125;Node&lt;K,V&gt; replacementNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(p.hash, p.key, p.value, next);&#125; 流程如下： resize()方法中比较重要的是链表和红黑树的 rehash 操作，rehash 的实现原理如下：在扩容的时候，一般是把长度扩为原来2倍，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。如下图所示，n为table的长度，图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash1是key1对应的哈希与高位运算结果。 元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化： 因此，在扩充HashMap的时候，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图： 这个算法很巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的结点分散到新的槽中了。 get操作12345678910111213141516171819202122232425262728293031323334353637/** *从HashMap中获取数据 */public V get(Object key) &#123; Node&lt;K,V&gt; e; // 1. 计算需获取数据的hash值 // 2. 通过getNode（）获取所查询的数据 // 3. 获取后，判断数据是否为空 return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;/** * 获取所要查询的数据 */final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; // 1. 计算存放在数组table中的位置 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //根据当前传入的hash值以及参数key获取一个结点即为first,如果匹配的话返回对应的value值 // a. 先在数组中找，若存在，则直接返回 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // b. 若数组中没有，则到红黑树中寻找 if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // c. 若红黑树中也没有，则通过遍历，到链表中寻找 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 流程如下： HashMap Jdk1.7和Jdk1.8的区别数据结构 添加数据 获取数据 扩容机制 ConcurrentHashMap-Jdk1.7数据结构ConcurrentHashMap采用分段锁的设计Segment + HashEntry的方式进行实现，采用table数组＋单向链表的数据结构，结构如下： 重要属性1234567891011121314151617181920212223242526272829//默认ConcurrentHashMap的大小static final int DEFAULT_INITIAL_CAPACITY = 16;//默认加载因子，用于表示segment中包含的HashEntry元素的个数与HashEntry[]数组长度的比值。当某个segment中包含的HashEntry元素的个数超过了HashEntry[]数组的长度与装载因子的乘积时，将触发扩容操作。static final float DEFAULT_LOAD_FACTOR = 0.75f;//默认支持的最大并发数，该值表示segment[]数组的长度，也就是锁的总数。static final int DEFAULT_CONCURRENCY_LEVEL = 16;//ConcurrentHashMap的最大容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//segment分段锁的初始容量也是最小容量(即segment中HashEntry的初始容量)static final int MIN_SEGMENT_TABLE_CAPACITY = 2;//最大segment数(segments数组的最大长度)static final int MAX_SEGMENTS = 1 &lt;&lt; 16; // slightly conservative//重试加锁次数：在执行size()和containsValue(value)操作时,ConcurrentHashMap的做法是先尝试 RETRIES_BEFORE_LOCK 次( 即，2次 )通过不锁住segment的方式来统计、查询各个segment，如果2次执行过程中，容器的modCount发生了变化，则再采用加锁的方式来操作所有的segmentstatic final int RETRIES_BEFORE_LOCK = 2;//分段锁的掩码，用来计算key所在的segment在segments的数组下标final int segmentMask;//分段锁偏移量,用来查找segment在内存中的位置final int segmentShift;//segment数组，Segment 类继承于 ReentrantLock 类，从而使得 Segment 对象能充当锁的角色。final Segment&lt;K,V&gt;[] segments; 重要对象SegmentSegment 类继承于 ReentrantLock 类，从而使得 Segment 对象能充当锁的角色，并且是一个可重入锁。每个 Segment 对象维护其包含的若干个桶(即，HashEntry[])。 1234567891011121314151617181920212223242526272829static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; //最大自旋次数，若是单核则为1，多核则为64。该字段用于scanAndLockForPut、scanAndLock方法 static final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() &gt; 1 ? 64 : 1; /** * table 是由 HashEntry 对象组成的数组 * 如果散列时发生碰撞，碰撞的 HashEntry 对象就以链表的形式链接成一个链表 * table 数组的元素代表散列映射表的一个桶 * 每个 table 守护整个 ConcurrentHashMap 数据总数的一部分 * 如果并发级别为 16，table 则维护 ConcurrentHashMap 数据总数的 1/16 */ transient volatile HashEntry&lt;K,V&gt;[] table; //segment中HashEntry的总数 transient int count; //segment中数据被更新的次数 transient int modCount; //元素的阀值，当table中包含的HashEntry元素的个数超过本变量值时，触发table的扩容 transient int threshold; //加载因子 final float loadFactor; &#125; HashEntryHashEntry封装了key-value对，是一个单向链表结构，每个HashEntry结点都维护着next HashEntry结点的引用。 12345678910111213static final class HashEntry&lt;K,V&gt; &#123; final int hash; final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next; HashEntry(int hash, K key, V value, HashEntry&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125;&#125; 初始化12345678910111213141516171819202122232425262728293031323334353637383940414243public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); //保证最大并发不超过MAX_SEGMENTS(1 &lt;&lt; 16) if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; // Find power-of-two sizes best matching arguments int sshift = 0; int ssize = 1; //循环判断保证ssize是2的幂(即Segment数组的长度) //循环完sshift = 4,ssize = 16 while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1;//ssize = size &lt;&lt; 1 &#125; //segmentShift最后为16 this.segmentShift = 32 - sshift; //segmentMask最后为15 this.segmentMask = ssize - 1; //ConcurrentHashMap初始容量不超过MAXIMUM_CAPACITY(1 &lt;&lt; 30) if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //根据ConcurrentHashMap总容量initialCapacity除以Segments[]数组的长度得到单个分段锁segment中HashEntry[]的大小 int c = initialCapacity / ssize; //保证分段锁segment的总容量c不小于初始的容量 if (c * ssize &lt; initialCapacity) ++c; //cap为Segments[]数组中分段锁segment的HashEntry[]的大小,保证为2的幂 int cap = MIN_SEGMENT_TABLE_CAPACITY; while (cap &lt; c) cap &lt;&lt;= 1; // create segments and segments[0] //记住这里★ //创建一个s0,然后初始化到Segments[0]中 Segment&lt;K,V&gt; s0 = new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]); //创建Segments[]数组 Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize]; UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0] this.segments = ss;&#125; 根据用户创建new ConcurrentHashMap(....)时，传递的值或者默认值进行ConcurrentHashMap的初始化。创建一个Segments[]数组，最大数组长度是16，不可以扩容。Sement[i]的默认大小为2，负载因子为0.75，得出初始阈值为1.5，也就插入第一个元素不会触发扩容，插入第二个进行一次扩容。初始化了 Segment[0]，其他位置还是null。 put操作1234567891011121314151617public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; //判断value是否为null,如果为null则抛出空指针异常 if (value == null) throw new NullPointerException(); //计算key的HASH值 int hash = hash(key); //无符号右移segmentShift位(默认16),然后 &amp; segmentMask(默认15)得到segment在内存中的地址 int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; //判断该位置是否为null， if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) //如果获取到的segment为null s = ensureSegment(j);//初始化segment //如果为null，初始化该位置segment[j]，通过ensureSegment(j) s = ensureSegment(j); //调用Segment的put方法将数据插入到HashEntry中 return s.put(key, hash, value, false);&#125; 根据hash值获取分段锁segment的内存地址，如果获取到的segment为null，则初始化。否则就是放值。整体流程如下图： ensureSegment-初始化segment1234567891011121314151617181920212223242526272829303132private Segment&lt;K,V&gt; ensureSegment(int k) &#123; //拿到当前Segments[]数组 final Segment&lt;K,V&gt;[] ss = this.segments; //获取k所在的segment在内存中的偏移量 long u = (k &lt;&lt; SSHIFT) + SBASE; // raw offset Segment&lt;K,V&gt; seg; //获取k所在的segmen,判断segmen是否为null if ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) &#123; //初始化一个segment等于Segments[0] //Segments[0]在初始化ConcurrentHashMap时，已经初始化了一个segment放到Segments[0]。 Segment&lt;K,V&gt; proto = ss[0]; // use segment 0 as prototype //然后就是获取Segments[0]中HashEntry数组的数据 int cap = proto.table.length; float lf = proto.loadFactor; int threshold = (int)(cap * lf); //初始化一个HashEntry数组,大小和Segments[0]中的HashEntry一样。 HashEntry&lt;K,V&gt;[] tab = (HashEntry&lt;K,V&gt;[])new HashEntry[cap]; //再次获取k所在的segment(防止其他线程已经初始化好) if ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) &#123; // recheck //如果还是null，创建一个segment并通过cas设置到对应的位置 Segment&lt;K,V&gt; s = new Segment&lt;K,V&gt;(lf, threshold, tab); // 使用 while 循环，内部用 CAS，当前线程成功设值或其他线程成功设值后，退出 while ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) &#123; if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s)) break; &#125; &#125; &#125; return seg;&#125; 根据k的hash值，获取segment，如何获取不到则就初始化一个和Segment[0]一样大小的segment。并通过CAS操作，初始化到Segments[]中。 put-放值1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; //尝试获取segment的锁 //失败就通过自旋去获取锁,超过自旋最大次数时,就将操作放入到Lock锁的队列中 HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; //走到这里的线程一定获取到锁,没获取到的都放到了Lock的队列中 try &#123; //拿到segment中的HashEntry数组 HashEntry&lt;K,V&gt;[] tab = table; //得到key所在HashEntry数组的下标 int index = (tab.length - 1) &amp; hash; //获取key所在的HashEntry数组某个位置的头结点(HashEntry是一个数组加链表结构) HashEntry&lt;K,V&gt; first = entryAt(tab, index); for (HashEntry&lt;K,V&gt; e = first;;) &#123; if (e != null) &#123;//HashEntry头结点不为null K k; //找到传入的值 if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; //是否替换value,默认替换(有个putIfAbsent(key,value)就是不替换) if (!onlyIfAbsent) &#123; e.value = value; ++modCount; &#125; break; &#125; e = e.next; &#125; else &#123;//如果没有找到或HashEntry头结点为null //判断node是否已经初始化(自旋获取锁做的这些操作,这个node要么为null要么就是新建的HashEntry) if (node != null) node.setNext(first);//头插法 else node = new HashEntry&lt;K,V&gt;(hash, key, value, first);//头插法 int c = count + 1;//修改segment的元素总数 if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY)//如果超过segment的阀值并且segment没有超过最大容量,rehash //扩容 rehash(node); else //更新HashEntry数组，把新的结点放在tab的index上面 setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; break; &#125; &#125; &#125; finally &#123; unlock();//释放锁 &#125; return oldValue;&#125; 首先是尝试获取segment的锁，获取到向下执行，获取不到就通过自旋操作去获取锁。拿到锁之后，找到k所在的HashEntry数组的下标，然后获取头结点。向下遍历头结点，查找到就更新（默认），没查找到就新建一个HashEntry，通过头插法放入HashEntry数组，最后更新HashEntry。 scanAndLockForPut-获取锁1234567891011121314151617181920212223242526272829private HashEntry&lt;K,V&gt; scanAndLockForPut(K key, int hash, V value) &#123; //获取k所在的segment中的HashEntry的头结点(segment中放得是HashEntry数组,HashEntry又是个链表结构) HashEntry&lt;K,V&gt; first = entryForHash(this, hash); HashEntry&lt;K,V&gt; e = first; HashEntry&lt;K,V&gt; node = null; int retries = -1; // negative while locating node while (!tryLock()) &#123;//尝试获取k所在segment的锁。成功就直接返回、失败进入while循环进行自旋尝试获取锁 HashEntry&lt;K,V&gt; f; // to recheck first below if (retries &lt; 0) &#123; if (e == null) &#123;//所在HashEntry链表不存在，则根据传过来的key-value创建一个HashEntry if (node == null) // speculatively create node //初始化node node = new HashEntry&lt;K,V&gt;(hash, key, value, null); retries = 0; &#125; else if (key.equals(e.key))//找到要放得值,则设置segment重试次数为0 retries = 0; else //从头结点往下寻找key对应的HashEntry e = e.next; &#125; else if (++retries &gt; MAX_SCAN_RETRIES) &#123;//超过最大重试次数就将当前操作放入到Lock的队列中，改为阻塞锁获取，保证能获取成功 lock(); break; &#125; else if ((retries &amp; 1) == 0 &amp;&amp; (f = entryForHash(this, hash)) != first) &#123;//如果retries为偶数,就重新获取HashEntry链表的头结点 e = first = f; // re-traverse if entry changed retries = -1; &#125; &#125; return node;&#125; 拿到k所在的segment的HashEntry的头结点(想想segment中的数据结构)，首先尝试获取segment的锁。 获取失败 如果头结点是为null，则将传进来的key-value新建一个HashEntry,同时设置retries为0,从而再次去尝试获取segment的锁； 如果头结点不为null，并且头结点的key == 传进来的key,设置retries为0,从而再次去尝试获取segment的锁； 如果头结点不为null，并且头结点的key != 传进来的key 则获取头结点的下一个结点,再次尝试获取segment的锁； 如果retries &gt; MAX_SCAN_RETRIES 则调用reentrantlock的lock方法,将当前操作放入到lock队列中.跳出while循环； 如果retries为偶数,则再次获取对应segment的头结点，判断是否有变化，有就重新获取头结点； 获取成功：直接返回null rehash-扩容123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778private void rehash(HashEntry&lt;K,V&gt; node) &#123;//node为待新加入的结点 //获取当前segment的HashEntry数组 HashEntry&lt;K,V&gt;[] oldTable = table; //获取原HashEntry数组的长度 int oldCapacity = oldTable.length; //新HashEntry数组的长度 = 原HashEntry数组长度*2 int newCapacity = oldCapacity &lt;&lt; 1; //重新计算新HashEntry数组的阀值 threshold = (int)(newCapacity * loadFactor); //创建新HashEntry数组 HashEntry&lt;K,V&gt;[] newTable = (HashEntry&lt;K,V&gt;[]) new HashEntry[newCapacity]; //新HashEntry数组的掩码(用来计算元素在新数组中的下标位置) int sizeMask = newCapacity - 1; //遍历原HashEntry数组中的元素(segment中是一个HashEntry数组，结构是数组加链表) for (int i = 0; i &lt; oldCapacity ; i++) &#123; //获取原HashEntry[i]位置的头结点HashEntry HashEntry&lt;K,V&gt; e = oldTable[i]; //判断当前结点是否为空 if (e != null) &#123; //获取当前结点的下一个结点 HashEntry&lt;K,V&gt; next = e.next; //重新计算当前结点在新HashEntry数组中的下标 int idx = e.hash &amp; sizeMask; //如果下一个结点为空，则原HashEntry数组这个位置就一个元素，直接放到新HashEntry数组就行 if (next == null) // Single node on list newTable[idx] = e; //下个结点不为空 else &#123; // Reuse consecutive sequence at same slot //这里就是找到某个结点，从这个结点往下，都会在新数组的某个坐标下，形成新的链表 //原: //HashEntry:[0] [1]... //里面的值: 1 // 2 // 3 // 4 // 5 // 6 //新: //HashEntry:[0] [1]... //里面的值: 4 // 5 // 6 //这里最后lastRun就是4 ,idx就是新数组的下标0 HashEntry&lt;K,V&gt; lastRun = e; int lastIdx = idx; //找到第一个后续结点新的index不变的结点 for (HashEntry&lt;K,V&gt; last = next; last != null; last = last.next) &#123; int k = last.hash &amp; sizeMask; if (k != lastIdx) &#123; lastIdx = k; lastRun = last; &#125; &#125; //然后把4结点放到新数组中，这样4,5,6就都过去了 newTable[lastIdx] = lastRun; // Clone remaining nodes //剩下的就是解决1,2,3了,遍历原HashEntry数组,直到等于4为止 //这些结点采用头插法放到新HashEntry数组中 for (HashEntry&lt;K,V&gt; p = e; p != lastRun; p = p.next) &#123; V v = p.value; int h = p.hash; int k = h &amp; sizeMask; HashEntry&lt;K,V&gt; n = newTable[k];//头插法 newTable[k] = new HashEntry&lt;K,V&gt;(h, p.key, v, n); &#125; &#125; &#125; &#125; //将待新加入的元素放到新数组(头插法) int nodeIndex = node.hash &amp; sizeMask; // add the new node node.setNext(newTable[nodeIndex]); newTable[nodeIndex] = node; //segment的数组指到新数组 table = newTable;&#125; 原HashEntry数组扩大一倍，然后遍历原HashEntry数组，找到某个结点lastRun，从这个结点开始往下，都会放到新HashEntry数组的某个槽下面。接下来就是遍历剩下的数据，然后采用头插法，放到新数组中。最后就是将待新加人的结点，放到新数组中。 get操作123456789101112131415161718192021public V get(Object key) &#123; Segment&lt;K,V&gt; s; // manually integrate access methods to reduce overhead HashEntry&lt;K,V&gt;[] tab; //key的hash值 int h = hash(key); //计算出k所在的segment所在的内存地址 long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; //通过CAS操作获取segment,判断都不为null if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp; (tab = s.table) != null) &#123; //再通过CAS操作，获取的key所在的HashEntry[]数组的下标，获取到就返回，没有就返回null for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e != null; e = e.next) &#123; K k; if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k))) return e.value; &#125; &#125; return null;&#125; 计算 hash 值，找到 segment 数组中的具体位置,使用Unsafe获取对应的Segment,根据 hash 找到数组中具体的位置,从链表头开始遍历整个链表（因为Hash可能会有碰撞，所以用一个链表保存），如果找到对应的key，则返回对应的value值，否则返回null。 注：get操作不需要锁，由于其中涉及到的共享变量都使用volatile修饰，volatile可以保证内存可见性，所以不会读取到过期数据。 remove操作1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public V remove(Object key) &#123; int hash = hash(key); //key的hash值，获取segment Segment&lt;K,V&gt; s = segmentForHash(hash); return s == null ? null : s.remove(key, hash, null);&#125;final V remove(Object key, int hash, Object value) &#123; //尝试获取segment锁 if (!tryLock()) //失败就自旋 scanAndLock(key, hash); //执行到这里一定获取了segment锁 V oldValue = null; try &#123; //获取segment的HashEntry[]数组 //获取key所在的下标，然后获取头结点 HashEntry&lt;K,V&gt;[] tab = table; int index = (tab.length - 1) &amp; hash; HashEntry&lt;K,V&gt; e = entryAt(tab, index); HashEntry&lt;K,V&gt; pred = null; while (e != null) &#123; K k; HashEntry&lt;K,V&gt; next = e.next; //判断当前结点e是不是要删除的数据 if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123;//key相同 V v = e.value; //如果没有传value，或者value相同 if (value == null || value == v || value.equals(v)) &#123; if (pred == null)//要删除结点的前一个结点为null setEntryAt(tab, index, next);//直接赋值 else pred.setNext(next);//直接将当前结点的前一个结点的next设置成当前结点的下一个结点。 ++modCount; --count; oldValue = v; &#125; break; &#125; //前结点不是要找的结点,遍历下一个 pred = e; e = next; &#125; &#125; finally &#123; unlock(); &#125; return oldValue;&#125; 找到key所在HashEntry[]数组的下标，然后遍历链表，找到结点。将当前结点的上一个结点的next设置成当前结点的下一个结点。 size操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546public int size() &#123; final Segment&lt;K,V&gt;[] segments = this.segments; int size; boolean overflow; // // 是否溢出 long sum; // 存储本次循环过程中计算得到的modCount的值 long last = 0L; // 存储上一次遍历过程中计算得到的modCount的和 int retries = -1; // first iteration isn't retry try &#123; for (;;) &#123; //判断retries是否等于RETRIES_BEFORE_LOCK(值为2) //也就是默认有两次的机会，是不加锁来求size的 if (retries++ == RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); // force creation &#125; sum = 0L; size = 0; overflow = false; //遍历Segments[]数组获取里面的每一个segment，然后对modCount进行求和 //这个for嵌套在for(;;)中，默认会执行两次，如果两次值相同，就返回 //如果两次值不同，就进入到上面的if中，进行加锁。之后在进行求和 for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; sum += seg.modCount; int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; if (sum == last) break; last = sum; &#125; &#125; finally &#123; //由于只有在retries等于RETRIES_BEFORE_LOCK时才会执行强制加锁，并且由于是用的retries++， //所以强制加锁完毕后，retries的值是一定会大于RETRIES_BEFORE_LOCK的， //这样就防止正常遍历而没进行加锁时进行锁释放的情况 if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125; &#125; return overflow ? Integer.MAX_VALUE : size;&#125; 先尝试RETRIES_BEFORE_LOCK次( 即2次 )不加锁的情况下，将segment[]数组中每个segment的count累加，同时也会将每个segment的modCount进行累加。如果两次不加锁的操作后，modCountSum值是一样的，这说明在这两次累加segmentcount的过程中ConcurrentHashMap没有发生结构性变化，那么就直接返回累加的count值; 如果在两次累加segment的count操作期间ConcurrentHashMap发生了结构性改变，则会通过将所有的segment都加锁，然后重新进行count的累加操作。在完成count的累加操作后，释放所有的锁。最后返回累加的count值。 如果累加的count值大于了Integer.MAX_VALUE，则返回Integer.MAX_VALUE。 ConcurrentHashMap-Jdk1.8数据结构Java7中ConcurrentHashMap是采用了数组+链表的数据结构。要知道链表的查找效率是低下的，其平均的查找时间是O(logn)，其中n是链表的长度。当链表较长时，查找可能会成为哈希表的性能瓶颈。 针对这个问题，Java8中对ConcurrentHashMap的数据结构进行了优化，采用了数组+链表+红黑树的数据结构。当数组中某个链表的长度超过一定的阈值之后，会将其转换成红黑树，以提高查找效率。当红黑树结点数少于一定阈值后，还能降红黑树逆退化成链表。下图是Java8 ConcurrentHashMap的数据结构示意图： Java8中取消了Java7中的分段锁设计，而采用了 CAS + synchronized 来保证并发安全性。 重要属性123456789101112131415161718192021222324252627282930313233343536373839// 最大容量private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 初始容量private static final int DEFAULT_CAPACITY = 16;// 数据最大长度static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;// 默认并发度private static final int DEFAULT_CONCURRENCY_LEVEL = 16;// 默认加载因子private static final float LOAD_FACTOR = 0.75f;// 链表转红黑树的阀值，大于8时static final int TREEIFY_THRESHOLD = 8;// 红黑树转链表的阀值，小于等于6（tranfer时，lc、hc=0两个计数器分别++记录原bin、新binTreeNode数量，&lt;=UNTREEIFY_THRESHOLD 则untreeify(lo)）。// 【仅在扩容tranfer时才可能树转链表】static final int UNTREEIFY_THRESHOLD = 6;static final int MIN_TREEIFY_CAPACITY = 64;private static final int MIN_TRANSFER_STRIDE = 16;private static int RESIZE_STAMP_BITS = 16;// 2^15-1，help resize的最大线程数private static final int MAX_RESIZERS = (1 &lt;&lt; (32 - RESIZE_STAMP_BITS)) - 1;// 32-16=16，sizeCtl中记录size大小的偏移量private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;static final int MOVED = -1; // 表示正在转移static final int TREEBIN = -2; // 表示已经转换成树static final int RESERVED = -3; // hash for transient reservationsstatic final int HASH_BITS = 0x7fffffff; // usable bits of normal node hashtransient volatile Node&lt;K,V&gt;[] table;//默认没初始化的数组，用来保存元素private transient volatile Node&lt;K,V&gt;[] nextTable;//转移的时候用的数组// 可用处理器数量static final int NCPU = Runtime.getRuntime().availableProcessors();/** * 用来控制表初始化和扩容的，默认值为0，当在初始化的时候指定了大小，这会将这个大小保存在sizeCtl中，大小为数组的0.75 * 正数或0代表hash表还没有被初始化，这个数值表示初始化或下一次进行扩容的大小 * 当为负的时候，说明表正在初始化或扩容， * -1表示初始化 * -(1+n) n:表示活动的扩容线程 */private transient volatile int sizeCtl; 重要类Node-构成元素的基本类 最核心的内部类，它包装了key-value键值对，所有插入ConcurrentHashMap的数据都包装在这里面。它与HashMap中的定义很相似，但是但是有一些差别它对value和next属性设置了volatile同步锁(与JDK7的Segment相同)，它不允许调用setValue方法直接改变Node的value域，它增加了find方法辅助map.get()方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; //key的hash值 final K key; //key volatile V val; //value volatile Node&lt;K,V&gt; next; //表示链表中的下一个结点 Node(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.val = val; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return val; &#125; public final int hashCode() &#123; return key.hashCode() ^ val.hashCode(); &#125; public final String toString()&#123; return key + \"=\" + val; &#125; public final V setValue(V value) &#123; throw new UnsupportedOperationException(); &#125; public final boolean equals(Object o) &#123; Object k, v, u; Map.Entry&lt;?,?&gt; e; return ((o instanceof Map.Entry) &amp;&amp; (k = (e = (Map.Entry&lt;?,?&gt;)o).getKey()) != null &amp;&amp; (v = e.getValue()) != null &amp;&amp; (k == key || k.equals(key)) &amp;&amp; (v == (u = val) || v.equals(u))); &#125; /** * Virtualized support for map.get(); overridden in subclasses. */ Node&lt;K,V&gt; find(int h, Object k) &#123; Node&lt;K,V&gt; e = this; if (k != null) &#123; do &#123; K ek; if (e.hash == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; &#125; while ((e = e.next) != null); &#125; return null; &#125;&#125; TreeNode-树结点类 树节点类，另外一个核心的数据结构。当链表长度过长的时候，会转换为TreeNode。但是与HashMap不相同的是，它并不是直接转换为红黑树，而是把这些结点包装成TreeNode放在TreeBin对象中，由TreeBin完成对红黑树的包装。而且TreeNode在ConcurrentHashMap集成自Node类，而并非HashMap中的集成自LinkedHashMap.Entry&lt;K,V&gt;类，也就是说TreeNode带有next指针，这样做的目的是方便基于TreeBin的访问。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950static final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next, TreeNode&lt;K,V&gt; parent) &#123; super(hash, key, val, next); this.parent = parent; &#125; Node&lt;K,V&gt; find(int h, Object k) &#123; return findTreeNode(h, k, null); &#125; /** * Returns the TreeNode (or null if not found) for the given key * starting at given root. */ final TreeNode&lt;K,V&gt; findTreeNode(int h, Object k, Class&lt;?&gt; kc) &#123; if (k != null) &#123; TreeNode&lt;K,V&gt; p = this; do &#123; int ph, dir; K pk; TreeNode&lt;K,V&gt; q; TreeNode&lt;K,V&gt; pl = p.left, pr = p.right; if ((ph = p.hash) &gt; h) p = pl; else if (ph &lt; h) p = pr; else if ((pk = p.key) == k || (pk != null &amp;&amp; k.equals(pk))) return p; else if (pl == null) p = pr; else if (pr == null) p = pl; else if ((kc != null || (kc = comparableClassFor(k)) != null) &amp;&amp; (dir = compareComparables(kc, k, pk)) != 0) p = (dir &lt; 0) ? pl : pr; else if ((q = pr.findTreeNode(h, k, kc)) != null) return q; else p = pl; &#125; while (p != null); &#125; return null; &#125;&#125; TreeBin-树的头结点 这个类并不负责包装用户的key、value信息，而是包装的很多TreeNode节点。它代替了TreeNode的根节点，也就是说在实际的ConcurrentHashMap“数组”中，存放的是TreeBin对象，而不是TreeNode对象，这是与HashMap的区别。另外这个类还带有了读写锁。在构造TreeBin节点时，仅仅指定了它的hash值为TREEBIN常量，这也就是个标识。 12345678910static final class TreeBin&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; root; volatile TreeNode&lt;K,V&gt; first; volatile Thread waiter; volatile int lockState; // values for lockState static final int WRITER = 1; // set while holding write lock static final int WAITER = 2; // set when waiting for write lock static final int READER = 4; // increment value for setting read lock&#125; ForwardingNode-转移的时候放在头部的结点 一个用于连接两个table的节点类。它包含一个nextTable指针，用于指向下一张表。而且这个节点的key value next指针全部为null，它的hash值为-1. 这里面定义的find的方法是从nextTable里进行查询节点，而不是以自身为头节点进行查找。其中存储nextTable的引用。只有table发生扩容的时候，ForwardingNode才会发挥作用，作为一个占位符放在table中表示当前节点为null或则已经被移动。 1234567static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; super(MOVED, null, null, null); this.nextTable = tab; &#125;&#125; 3个原子操作在ConcurrentHashMap中使用了unSafe方法，通过直接操作内存的方式来保证并发处理的安全性，使用的是硬件的安全机制。 123456789101112131415161718192021/* * 用来返回节点数组的指定位置的节点的原子操作 */@SuppressWarnings(\"unchecked\")static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);&#125;/* * 利用CAS算法设置i位置上的Node节点（将c和table[i]比较，相同则插入v）。 */static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);&#125;/* * 设置节点位置的值，仅在上锁区被调用 */static final &lt;K,V&gt; void setTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) &#123; U.putObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, v);&#125; 构造器1234567891011121314151617//空的构造public ConcurrentHashMapDebug() &#123;&#125;//如果在实例化对象的时候指定了容量，则初始化sizeCtlpublic ConcurrentHashMapDebug(int initialCapacity) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(); int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); this.sizeCtl = cap;&#125;//当出入一个Map的时候，先设定sizeCtl为默认容量，在添加元素public ConcurrentHashMapDebug(Map&lt;? extends K, ? extends V&gt; m) &#123; this.sizeCtl = DEFAULT_CAPACITY; putAll(m);&#125; 在任何一个构造方法中，都没有对存储Map元素Node的table变量进行初始化。而是在第一次put操作的时候在进行初始化。 put操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121/* * 单纯的调用putVal方法，并且putVal的第三个参数设置为false * 当设置为false的时候表示这个value一定会设置 * true的时候，只有当这个key的value为空的时候才会设置 */public V put(K key, V value) &#123; return putVal(key, value, false);&#125;/* * 当添加一对键值对的时候，首先会去判断保存这些键值对的数组是不是初始化了， * 如果没有的话就初始化数组 * 然后通过计算hash值来确定放在数组的哪个位置 * 如果这个位置为空则直接添加，如果不为空的话，则取出这个节点来 * 如果取出来的节点的hash值是MOVED(-1)的话，则表示当前正在对这个数组进行扩容，复制到新的数组，则当前线程也去帮助复制 * 最后一种情况就是，如果这个节点，不为空，也不在扩容，则通过synchronized来加锁，进行添加操作 * 然后判断当前取出的节点位置存放的是链表还是树 * 如果是链表的话，则遍历整个链表，直到取出来的节点的key来个要放的key进行比较，如果key相等，并且key的hash值也相等的话， * 则说明是同一个key，则覆盖掉value，否则的话则添加到链表的末尾 * 如果是树的话，则调用putTreeVal方法把这个元素添加到树中去 * 最后在添加完成之后，会判断在该节点处共有多少个节点（注意是添加前的个数），如果达到8个以上了的话， * 则调用treeifyBin方法来尝试将处的链表转为树，或者扩容数组 */final V putVal(K key, V value, boolean onlyIfAbsent) &#123; //K,V都不能为空，否则的话跑出异常 if (key == null || value == null) throw new NullPointerException(); //取得key的hash值 int hash = spread(key.hashCode()); //用来计算在这个结点总共有多少个元素，用来控制扩容或者转移树 int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; //如果数组为空或数组长度为0 if (tab == null || (n = tab.length) == 0) //第一次put的时候table没有初始化则初始化table tab = initTable(); //找该 hash 值对应的数组下标，得到第一个节点 f else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //如果这个位置没有元素的话，则通过cas的方式尝试添加，注意这个时候是没有加锁的 //创建一个Node添加到数组中区，null表示的是下一个节点为空 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; /* * 如果检测到某个节点的hash值是MOVED，则表示正在进行数组扩张的数据复制阶段， * 则当前线程也会参与去复制，通过允许多线程复制的功能，依此来减少数组的复制所带来的性能损失 */ else if ((fh = f.hash) == MOVED) //数据迁移 tab = helpTransfer(tab, f); else &#123; /* * 如果在这个位置有元素的话，就采用synchronized的方式加锁， * 如果是链表的话(hash大于0)，就对这个链表的所有元素进行遍历， * 如果找到了key和key的hash值都一样的节点，则把它的值替换到 * 如果没找到的话，则添加在链表的最后面 * 否则，是树的话，则调用putTreeVal方法添加到树中去 * * 在添加完之后，会对该节点上关联的的数目进行判断， * 如果在8个以上的话，则会调用treeifyBin方法，来尝试转化为树，或者是扩容 */ V oldVal = null; synchronized (f) &#123; if (tabAt(tab, i) == f) &#123;//再次取出要存储的位置的元素，跟前面取出来的比较 if (fh &gt;= 0) &#123;//取出来的元素的hash值大于0说明是链表，当转换为树之后，hash值为-2 //用于累加，记录链表长度 binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123;//遍历这个链表 K ek; //要存的元素的hash，key跟要存储的位置的节点的相同的时候，替换掉该节点的value即可 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; //当使用putIfAbsent的时候，只有在这个key没有设置值得时候才设置 if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; //如果不是同样的hash，同样的key的时候，则判断该节点的下一个节点是否为空 if ((e = e.next) == null) &#123; //为空的话把这个要加入的节点设置为当前节点的下一个节点 pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123;//表示已经转化成红黑树类型了 Node&lt;K,V&gt; p; binCount = 2; //调用putTreeVal方法，将该元素添加到树中去 if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; //说明上面在做链表操作 if (binCount != 0) &#123; //判断是否要将链表转成红黑树，临界值和HashMap一样，也是8 if (binCount &gt;= TREEIFY_THRESHOLD) // 这个方法和 HashMap 中稍微有一点点不同，那就是它不是一定会进行红黑树转换， // 如果当前数组的长度小于 64，那么会选择进行数组扩容，而不是转换为红黑树 treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125; initTable-数组初始化12345678910111213141516171819202122232425262728293031323334353637/** * 初始化数组table， * 如果sizeCtl小于0，说明别的数组正在进行初始化，则让出执行权 * 如果sizeCtl大于0的话，则初始化一个大小为sizeCtl的数组 * 否则的话初始化一个默认大小(16)的数组 * 然后设置sizeCtl的值为数组长度的3/4 */private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; //第一次put的时候，table还没被初始化，进入while while ((tab = table) == null || tab.length == 0) &#123; //sizeCtl初始值为0，当小于0的时候表示在别的线程在初始化表或扩容 if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin //CAS一下，将sizectl设置为-1，代表抢到了锁 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; //指定了大小的时候就创建指定大小的Node数组，否则创建指定大小(16)的Node数组 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; //初始化数组，长度为16，或初始化时提供的长度 @SuppressWarnings(\"unchecked\") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; // 将这个数组赋值给 table，table 是 volatile 的 table = tab = nt; // 如果 n 为 16 的话，那么这里 sc = 12，其实就是 0.75 * n sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; //初始化后，sizeCtl长度为数组长度的3/4 sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; 主要就是初始化一个合适大小的数组，然后会设置 sizeCtl。初始化方法中的并发问题是通过对 sizeCtl 进行一个 CAS 操作来控制的。 treeifyBin-链表转红黑树12345678910111213141516171819202122232425262728293031private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) &#123; Node&lt;K,V&gt; b; int n, sc; if (tab != null) &#123; // MIN_TREEIFY_CAPACITY 为 64 // 所以，如果数组长度小于 64 的时候，其实也就是 32 或者 16 或者更小的时候，会进行数组扩容 if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) tryPresize(n &lt;&lt; 1);//数组扩容 // b是头结点 else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; synchronized (b) &#123; if (tabAt(tab, index) == b) &#123; // 下面就是遍历链表，建立一颗红黑树 TreeNode&lt;K,V&gt; hd = null, tl = null;//hd 树的头结点 for (Node&lt;K,V&gt; e = b; e != null; e = e.next) &#123; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val, null, null); //把Node组成的链表，转化为TreeNode的链表，头结点任然放在相同的位置 if ((p.prev = tl) == null) hd = p;//设置head else tl.next = p; tl = p; &#125; // 将红黑树设置到数组相应位置中 setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd)); &#125; &#125; &#125; &#125;&#125; treeifyBin 不一定就会进行红黑树转换，也可能是仅仅做数组扩容。 tryPresize-扩容1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768private final void tryPresize(int size) &#123; // c：size 的 1.5 倍，再加 1，再往上取最近的 2 的 n 次方。 // 如果给定的大小大于等于数组容量的一半，则直接使用最大容量，否则使用tableSizeFor算出来 int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1); int sc; while ((sc = sizeCtl) &gt;= 0) &#123; Node&lt;K,V&gt;[] tab = table; int n; /* * 如果数组table还没有被初始化，则初始化一个大小为sizeCtrl和刚刚算出来的c中较大的一个大小的数组 * 初始化的时候，设置sizeCtrl为-1，初始化完成之后把sizeCtrl设置为数组长度的3/4 * 为什么要在扩容的地方来初始化数组呢？这是因为如果第一次put的时候不是put单个元素， * 而是调用putAll方法直接put一个map的话，在putALl方法中没有调用initTable方法去初始化table， * 而是直接调用了tryPresize方法，所以这里需要做一个是不是需要初始化table的判断 */ if (tab == null || (n = tab.length) == 0) &#123; n = (sc &gt; c) ? sc : c; //初始化tab的时候，把sizeCtl设为-1 if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if (table == tab) &#123; @SuppressWarnings(\"unchecked\") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = nt; sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; &#125; &#125; /* * 一直扩容到的c小于等于sizeCtl或者数组长度大于最大长度的时候，则退出 * 所以在一次扩容之后，不是原来长度的两倍，而是2的n次方倍 */ else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY) break; else if (tab == table) &#123; int rs = resizeStamp(n); /* * 如果正在扩容Table的话，则帮助扩容 * 否则的话，开始新的扩容 * 在transfer操作，将第一个参数的table中的元素，移动到第二个元素的table中去， * 虽然此时第二个参数设置的是null，但是，在transfer方法中，当第二个参数为null的时候， * 会创建一个两倍大小的table */ if (sc &lt; 0) &#123; Node&lt;K,V&gt;[] nt; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; /* * transfer的线程数加一,该线程将进行transfer的帮忙 * 在transfer的时候，sc表示在transfer工作的线程数 */ if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; /* * 没有在初始化或扩容，则开始扩容 */ else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); &#125; &#125;&#125; 这个方法的核心在于 sizeCtl 值的操作，首先将其设置为一个负数，然后执行 transfer(tab, null)，再下一个循环将 sizeCtl 加 1，并执行 transfer(tab, nt)，之后可能是继续 sizeCtl 加 1，并执行 transfer(tab, nt)。所以，可能的操作就是执行 1 次 transfer(tab, null) +多次 transfer(tab, nt)，这里怎么结束循环的需要看完 transfer 源码才清楚。 transfer-数据迁移123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213/** * 把数组中的节点复制到新的数组的相同位置，或者移动到扩张部分的相同位置 * 在这里首先会计算一个步长，表示一个线程处理的数组长度，用来控制对CPU的使用， * 每个CPU最少处理16个长度的数组元素,也就是说，如果一个数组的长度只有16，那只有一个线程会对其进行扩容的复制移动操作 * 扩容的时候会一直遍历，知道复制完所有节点，没处理一个节点的时候会在链表的头部设置一个fwd节点，这样其他线程就会跳过他， * 复制后在新数组中的链表不是绝对的反序的 */private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; // stride 在单核下直接等于 n，多核模式下为 (n&gt;&gt;&gt;3)/NCPU，最小值是 16 // stride 可以理解为”步长“，有 n 个位置是需要进行迁移的， // 将这 n 个任务分为多个任务包，每个任务包有 stride 个任务 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range /* * 如果复制的目标nextTab为null的话，则初始化一个table两倍长的nextTab * 此时nextTable被设置值了(在初始情况下是为null的) * 因为如果有一个线程开始了表的扩张的时候，其他线程也会进来帮忙扩张， * 而只是第一个开始扩张的线程需要初始化下目标数组 */ if (nextTab == null) &#123; // initiating try &#123; //容量翻倍 @SuppressWarnings(\"unchecked\") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; // nextTable 是 ConcurrentHashMap 中的属性 nextTable = nextTab; // transferIndex 也是 ConcurrentHashMap 的属性，用于控制迁移的位置 transferIndex = n; &#125; int nextn = nextTab.length; // ForwardingNode--&gt;正在被迁移的 Node // 这个构造方法会生成一个Node，key、value 和 next 都为 null，关键是 hash 为 MOVED // 后面会看到，原数组中位置 i 处的节点完成迁移工作后， // 就会将位置 i 处设置为这个 ForwardingNode，用来告诉其他线程该位置已经处理过了 // 所以它其实相当于是一个标志。 ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); // advance 指的是做完了一个位置的迁移工作，可以准备做下一个位置的了 boolean advance = true; boolean finishing = false; // to ensure sweep(清扫) before committing nextTab,在完成之前重新在扫描一遍数组，看看有没完成的没 // i 是位置索引，bound 是边界，注意是从后往前 for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; // advance 为 true 表示可以进行下一个位置的迁移了 // 简单理解：i 指向了 transferIndex，bound 指向了 transferIndex-stride while (advance) &#123; int nextIndex, nextBound; if (--i &gt;= bound || finishing) advance = false; // 将 transferIndex 值赋给 nextIndex // 这里 transferIndex 一旦小于等于 0，说明原数组的所有位置都有相应的线程去处理了 else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; // nextBound 是这次迁移任务的边界，注意，是从后往前 else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; // 所有的迁移操作已经完成 if (finishing) &#123; nextTable = null; // 将新的 nextTab 赋值给 table 属性，完成迁移 table = nextTab; // 重新计算 sizeCtl：n 是原数组长度，所以 sizeCtl 得出的值将是新数组长度的 0.75 倍 sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; // sizeCtl 在迁移前会设置为 (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2 // 然后，每有一个线程参与迁移就会将 sizeCtl 加 1， // 这里使用 CAS 操作对 sizeCtl 进行减 1，代表做完了属于自己的任务 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; // 到这里，说明 (sc - 2) == resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT， // 也就是说，所有的迁移任务都做完了，也就会进入到上面的 if(finishing)&#123;&#125; 分支了 finishing = advance = true; i = n; // recheck before commit &#125; &#125; // 如果位置 i 处是空的，没有任何节点，那么放入刚刚初始化的 ForwardingNode ”空节点“ else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); // 该位置处是一个 ForwardingNode，代表该位置已经迁移过了 else if ((fh = f.hash) == MOVED) advance = true; // already processed else &#123; // 对数组该位置处的结点加锁，开始处理数组该位置处的迁移工作 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; // 头结点的 hash 大于 0，说明是链表的 Node 节点 if (fh &gt;= 0) &#123; // 需要将链表一分为二，找到原链表中的 lastRun， // 然后 lastRun 及其之后的节点是一起进行迁移的lastRun 之前的节点需要进行克隆，然后分到两个链表中 int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; /* * lastRun 表示的是需要复制的最后一个节点 * 每当新节点的hash&amp;n -&gt; b 发生变化的时候，就把runBit设置为这个结果b * 这样for循环之后，runBit的值就是最后不变的hash&amp;n的值 * 而lastRun的值就是最后一次导致hash&amp;n 发生变化的节点(假设为p节点) * 为什么要这么做呢？因为p节点后面的节点的hash&amp;n 值跟p节点是一样的， * 所以在复制到新的table的时候，它肯定还是跟p节点在同一个位置 * 在复制完p节点之后，p节点的next节点还是指向它原来的节点，就不需要进行复制了，自己就被带过去了 * 这也就导致了一个问题就是复制后的链表的顺序并不一定是原来的倒序 */ for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; //n的值为扩张前的数组的长度 if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; /* * 构造两个链表，顺序大部分和原来是反的 * 分别放到原来的位置和新增加的长度的相同位置(i/n+i) */ for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) /* * 假设runBit的值为0， * 则第一次进入这个设置的时候相当于把旧的序列的最后一次发生hash变化的节点(该节点后面可能还有hash计算后同为0的节点)设置到旧的table的第一个hash计算后为0的节点下一个节点 * 并且把自己返回，然后在下次进来的时候把它自己设置为后面节点的下一个节点 */ ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else /* * 假设runBit的值不为0， * 则第一次进入这个设置的时候相当于把旧的序列的最后一次发生hash变化的节点(该节点后面可能还有hash计算后同不为0的节点)设置到旧的table的第一个hash计算后不为0的节点下一个节点 * 并且把自己返回，然后在下次进来的时候把它自己设置为后面节点的下一个节点 */ hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; // 其中的一个链表放在新数组的位置 i setTabAt(nextTab, i, ln); // 另一个链表放在新数组的位置 i+n setTabAt(nextTab, i + n, hn); // 将原数组该位置处设置为 fwd，代表该位置已经处理完毕， // 其他线程一旦看到该位置的 hash 值为 MOVED，就不会进行迁移了 setTabAt(tab, i, fwd); // advance 设置为 true，代表该位置已经迁移完毕 advance = true; &#125; else if (f instanceof TreeBin) &#123; // 红黑树的迁移 TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; // 如果一分为二后，节点数≤6，那么将红黑树转换回链表 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; // 将ln放置在新数组的位置i setTabAt(nextTab, i, ln); // 将hn放置在新数组的位置i+n setTabAt(nextTab, i + n, hn); //将原数组该位置处设置为 fwd，代表该位置已经处理完毕， //其他线程一旦看到该位置的 hash 值为 MOVED，就不会进行迁移了 setTabAt(tab, i, fwd); // advance 设置为 true，代表该位置已经迁移完毕 advance = true; &#125; &#125; &#125; &#125; &#125;&#125; 此方法支持多线程执行，外围调用此方法的时候，会保证第一个发起数据迁移的线程，nextTab 参数为 null，之后再调用此方法的时候，nextTab 不会为 null。 先理解下并发操作的机制。原数组长度为 n，所以我们有 n 个迁移任务，让每个线程每次负责一个小任务是最简单的，每做完一个任务再检测是否有其他没做完的任务，帮助迁移就可以了，而 Doug Lea 使用了一个 stride，简单理解就是步长，每个线程每次负责迁移其中的一部分，如每次迁移 16 个小任务。所以，我们就需要一个全局的调度者来安排哪个线程执行哪几个任务，这个就是属性 transferIndex 的作用。 第一个发起数据迁移的线程会将 transferIndex 指向原数组最后的位置，然后从后往前的 stride 个任务属于第一个线程，然后将 transferIndex 指向新的位置，再往前的 stride 个任务属于第二个线程，依此类推。当然，这里说的第二个线程不是真的一定指代了第二个线程，也可以是同一个线程，这个读者应该能理解吧。其实就是将一个大的迁移任务分为了一个个任务包。 putTreeVal-插入树结点123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778final TreeNode&lt;K,V&gt; putTreeVal(int h, K k, V v) &#123; Class&lt;?&gt; kc = null; boolean searched = false; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk; if (p == null) &#123; // 当前桶为空，则直接创建一个新的节点 first = root = new TreeNode&lt;K,V&gt;(h, k, v, null, null); break; &#125; else if ((ph = p.hash) &gt; h) // hash值大于当前key的，在左子树 dir = -1; else if (ph &lt; h) // hash值小于当前key的，在右子树 dir = 1; else if ((pk = p.key) == k || (pk != null &amp;&amp; k.equals(pk))) // 等于，则比较key是否相等 return p; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) &#123; // 如果hash值相等，那么就比较下是否是String或者实现了Comparable接口 // 如果等出现二次碰撞，则左右子树都搜索 if (!searched) &#123; TreeNode&lt;K,V&gt; q, ch; searched = true; // 找到对应的节点 if (((ch = p.left) != null &amp;&amp; (q = ch.findTreeNode(h, k, kc)) != null) || ((ch = p.right) != null &amp;&amp; (q = ch.findTreeNode(h, k, kc)) != null)) // 找到直接返回即可 return q; &#125; // 假如没有找到，则根据类名、System.identityHashCode比较来确定到底放在左右哪边 dir = tieBreakOrder(k, pk); &#125; TreeNode&lt;K,V&gt; xp = p; // 根据比较的大小dir来确定插入左子树还是右子树 if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; TreeNode&lt;K,V&gt; x, f = first; first = x = new TreeNode&lt;K,V&gt;(h, k, v, f, xp); if (f != null) f.prev = x; if (dir &lt;= 0) // &lt;=0 左子树 xp.left = x; else // &gt;0 右子树 xp.right = x; if (!xp.red) x.red = true; else &#123; // 加锁，调整平衡 lockRoot(); try &#123; root = balanceInsertion(root, x); &#125; finally &#123; unlockRoot(); &#125; &#125; break; &#125; &#125; assert checkInvariants(root); return null;&#125;// 多次冲突碰撞之后，就用此来决定谁大谁小，以区分在左还是在右子树上static int tieBreakOrder(Object a, Object b) &#123; int d; if (a == null || b == null || (d = a.getClass().getName(). compareTo(b.getClass().getName())) == 0) d = (System.identityHashCode(a) &lt;= System.identityHashCode(b) ? -1 : 1); return d;&#125; get操作123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; // 判断头结点是否就是我们需要的节点 if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; // 如果头结点的 hash 小于 0，说明 正在扩容，或者该位置是红黑树 else if (eh &lt; 0) // 参考 ForwardingNode.find(int h, Object k) 和 TreeBin.find(int h, Object k) return (p = e.find(h, key)) != null ? p.val : null; // 遍历链表 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; 计算 hash 值; 根据 hash 值找到数组对应位置: (n - 1) &amp; h; 根据该位置处结点性质进行相应查找 如果该位置为 null，那么直接返回 null 就可以了; 如果该位置处的节点刚好就是我们需要的，返回该节点的值即可; 如果该位置节点的 hash 值小于 0，说明正在扩容，或者是红黑树; 如果以上 3 条都不满足，那就是链表，进行遍历比对即可;","tags":"java"},{"title":"Linux-awk用法","url":"/posts/ed2e0218.html","text":"工作原理 读输入文件之前执行的代码段（由BEGIN关键字标识）。 主循环执行输入文件的代码段。 读输入文件之后的代码段（由END关键字标识）。 命令结构1awk &apos;BEGIN&#123; commands &#125; pattern&#123; commands &#125; END&#123; commands &#125;&apos; 工作流程 1、通过关键字 BEGIN 执行 BEGIN 块的内容，即 BEGIN 后花括号 {} 的内容。2、完成 BEGIN 块的执行，开始执行body块。3、读入有 \\n 换行符分割的记录。4、将记录按指定的域分隔符划分域，填充域，$0 则表示所有域(即一行内容)，$1 表示第一个域，$n 表示第 n 个域。5、依次执行各 BODY 块，pattern 部分匹配该行内容成功后，才会执行 awk-commands 的内容。6、循环读取并执行各行直到文件结束，完成body块执行。7、开始 END 块执行，END 块可以输出最终结果。 开始块（BEGIN）开始块的语法格式如下： 1BEGIN &#123;awk-commands&#125; 开始块就是在程序启动的时候执行的代码部分，并且它在整个过程中只执行一次。 一般情况下，我们可以在开始块中初始化一些变量。 BEGIN 是 AWK 的关键字，因此它必须是大写的。 注意：开始块部分是可选的，你的程序可以没有开始块部分。 主体块（BODY）主体部分的语法格式如下： 1/pattern/ &#123;awk-commands&#125; 对于每一个输入的行都会执行一次主体部分的命令。 默认情况下，对于输入的每一行，AWK 都会执行命令。但是，我们可以将其限定在指定的模式中。 注意：在主体块部分没有关键字存在。 结束块（END）结束块的语法格式如下： 1END &#123;awk-commands&#125; 结束块是在程序结束时执行的代码。 END 也是 AWK 的关键字，它也必须大写。 与开始块相似，结束块也是可选的。 命令形式1awk [-F|-f|-v] ‘BEGIN&#123;&#125; //&#123;command1; command2&#125; END&#123;&#125;’ file [-F|-f|-v] 大参数，-F指定分隔符，-f调用脚本，-v定义变量 var=value &#39; &#39; 引用代码块 BEGIN 初始化代码块，在对每一行进行处理之前，初始化代码，主要是引用全局变量，设置FS分隔符 // 匹配代码块，可以是字符串或正则表达式 {} 命令代码块，包含一条或多条命令 ； 多条命令使用分号分隔 END 结尾代码块，在对每一行进行处理之后再执行的代码块，主要是进行最终计算或输出结尾摘要信息 特殊要点： 12345678910111213141516171819202122232425262728293031323334353637383940414243$0 表示整个当前行$1 每行第一个字段NF 字段数量变量NR 每行的记录号，多文件记录递增FNR 与NR类似，不过多文件记录不递增，每个文件都从1开始\\t 制表符\\n 换行符FS BEGIN时定义分隔符RS 输入的记录分隔符， 默认为换行符(即文本是按一行一行输入)~ 匹配，与==相比不是精确比较!~ 不匹配，不精确比较== 等于，必须全部相等，精确比较!= 不等于，精确比较&amp;&amp; 逻辑与|| 逻辑或+ 匹配时表示1个或1个以上/[0-9][0-9]+/ 两个或两个以上数字/[0-9][0-9]*/ 一个或一个以上数字FILENAME 文件名OFS 输出字段分隔符， 默认也是空格，可以改为制表符等ORS 输出的记录分隔符，默认为换行符,即处理结果也是一行一行输出到屏幕-F&apos;[:#/]&apos; 定义三个分隔符 测试命令： 1awk &apos;BEGIN&#123;FS=&quot;&quot;&#125;&#123;for(i=1;i&lt;=NF;i++) &#123;if (i==NF)&#123;print $i&#125;else &#123;printf $i&#125;;system(&quot;sleep 0.03&quot;)&#125;&#125;&apos; /etc/fstab awk显示文件中的内容awk显示passwd中的内容，并且设置只显示前面5条信息。 awk将passwd中的内容以冒号为分隔，并取出第1，3，6位的数据 awk将passwd中的内容以冒号为分隔，并取出第1，3，6位的数据，并用采用tab键作为分隔符 awk以冒号为分隔符，显示一行中有多少字段 awk将每一行最后的一个字段显示出来 awk在每一行前面输出行号 awk显示第几行的数据 统计日志文件中每小时的请求次数1awk -F: &apos;&#123;a[$2]++&#125;END&#123;for(i in a)&#123;split(i,t);print i&quot; 至&quot;,t[1]&quot;:&quot;t[2]+59,&quot; 访问 &quot;a[i] &quot; 次&quot; | &quot;sort -t: -k1n -k2n&quot;&#125;&#125;&apos; xxx.xxxx.com_access.log-20190512 统计日志文件中每小时指定请求开头的请求次数1grep &quot;2019-05-13T23&quot; xxxx.xxxx.com_access.log-20190512|grep &quot;/pppppp&quot;|wc -l 查java进程ID1ps -ef|grep java |grep -v java |awk &apos;&#123;print $2&#125;&apos; 条件语句IF语句IF 条件语句语法格式如下： 12if (condition) action 也可以使用花括号来执行一组操作： 12345678if (condition)&#123; action-1 action-1 . . action-n&#125; 以下实例用来判断数字是奇数还是偶数： 1awk &apos;BEGIN &#123;num = 10; if (num % 2 == 0) printf &quot;%d 是偶数\\n&quot;, num &#125;&apos; IF - ELSE 语句IF - ELSE 条件语句语法格式如下： 1234if (condition) action-1else action-2 在条件语句 condition 为 true 时只需 action-1，否则执行 action-2。 12345awk &apos;BEGIN &#123; num = 11; if (num % 2 == 0) printf &quot;%d 是偶数\\n&quot;, num; else printf &quot;%d 是奇数\\n&quot;, num &#125;&apos; IF - ELSE - IF可以创建多个 IF - ELSE 格式的判断语句来实现多个条件的判断： 123456789awk &apos;BEGIN &#123;a=30;if (a==10) print &quot;a = 10&quot;;else if (a == 20) print &quot;a = 20&quot;;else if (a == 30) print &quot;a = 30&quot;;&#125;&apos; 循环语句For循环For 循环的语法如下： 12for (initialisation; condition; increment/decrement) action for 语句首先执行初始化动作( initialisation )，然后再检查条件( condition )。 如果条件为真，则执行动作( action )，然后执行递增( increment )或者递减( decrement )操作。 只要条件为 true 循环就会一直执行。每次循环结束都会进条件检查，若条件为 false 则结束循环。 下面的例子使用 For 循环输出数字 1 至 5： 1awk &apos;BEGIN &#123; for (i = 1; i &lt;= 5; ++i) print i &#125;&apos; While循环While 循环的语法如下： 12while (condition) action While 循环首先检查条件 condition 是否为 true ，若条件为 true 则执行动作 action。此过程一直重复直到条件 condition 为 flase 才停止。 下面是使用 While 循环输出数字 1 到 5 的例子： 1awk &apos;BEGIN &#123;i = 1; while (i &lt; 6) &#123; print i; ++i &#125; &#125;&apos; Break 终止循环在下面的示例子中，当计算的和大于 50 的时候使用 break 结束循环： 12345awk &apos;BEGIN &#123; sum = 0; for (i = 0; i &lt; 20; ++i) &#123; sum += i; if (sum &gt; 50) break; else print &quot;Sum =&quot;, sum &#125; &#125;&apos; Continue 结束本次循环进入下次循环 Continue 语句用于在循环体内部结束本次循环，从而直接进入下一次循环迭代。 下面的例子输出 1 到 20 之间的偶数： 1awk &apos;BEGIN &#123;for (i = 1; i &lt;= 20; ++i) &#123;if (i % 2 == 0) print i ; else continue&#125; &#125;&apos; Exit 结束程序 该函数接受一个整数作为参数表示 AWK 进程结束状态。 如果没有提供该参数，其默认状态为 0。 下面例子中当和大于 50 时结束 AWK 程序。 12345awk &apos;BEGIN &#123; sum = 0; for (i = 0; i &lt; 20; ++i) &#123; sum += i; if (sum &gt; 50) exit(10); else print &quot;Sum =&quot;, sum &#125; &#125;&apos;","tags":"linux"},{"title":"设计模式-外观模式","url":"/posts/6f592ef9.html","text":"模式定义外观模式，又称为门面模式，是一种使用频率非常高的结构型设计模式，是迪米特法则的一种具体实现，它通过引入一个外观角色来简化客户端与子系统之间的交互，为复杂的子系统调用提供一个统一的入口，降低子系统与客户端的耦合度，且客户端调用非常方便。如下图： 举个例子：如网站导航 主要作用 实现客户类与子系统类的松耦合； 降低原有系统的复杂度； 提高了客户端使用的便捷性，使得客户端无须关心子系统的工作细节，通过外观角色即可调用相关功能。 UML类图 角色 外观角色（Facade）：也称 门面角色，系统对外的统一接口； 子系统角色（SubSystem）：可以同时有一个或多个 SubSystem。每个 SubSytem 都不是一个单独的类，而是一个类的集合。SubSystem 并不知道 Facade 的存在，对于 SubSystem 而言，Facade 只是另一个客户端而已（即 Facade 对 SubSystem 透明）。 外观模式的目的不是给予子系统添加新的功能接口，而是为了让外部减少与子系统内多个模块的交互，松散耦合，从而让外部能够更简单地使用子系统。 外观模式的本质是：封装交互，简化调用。 模式优点 降低了客户类与子系统类的耦合度，实现了子系统与客户之间的松耦合关系； 只是提供了一个访问子系统的统一入口，并不影响用户直接使用子系统类； 减少了与子系统的关联对象，实现了子系统与客户之间的松耦合关系，松耦合使得子系统的组件变化不会影响到它的客户。 外观模式对客户屏蔽了子系统组件，从而简化了接口，减少了客户处理的对象数目并使子系统的使用更加简单。 引入外观角色之后，用户只需要与外观角色交互； 用户与子系统之间的复杂逻辑关系由外观角色来实现。 降低原有系统的复杂度和系统中的编译依赖性，并简化了系统在不同平台之间的移植过程。因为编译一个子系统一般不需要编译所有其他的子系统。一个子系统的修改对其他子系统没有任何影响，而且子系统内部变化也不会影响到外观对象。 模式缺点 不能很好地限制客户端直接使用子系统类，如果对客户端访问子系统类做太多的限制则减少了可变性和灵活性。 在不引入抽象外观类的情况下，增加新的子系统可能需要修改外观类或客户端的源代码，违背了“开闭原则”。 适用场景 为一个复杂的模块或子系统提供一个简洁的供外界访问的接口； 希望提高子系统的独立性时； 预防代码污染：当子系统由于不可避免的暂时原因导致可能存在 bug 或性能相关问题时，可以通过 外观模式 提供一个高层接口，隔离客户端与子系统的直接交互，方便后续问题修改； 在层次化结构中，可以使用外观模式定义系统中每一层的入口，层与层之间不直接产生联系，而通过外观类建立联系，降低层之间的耦合度。 使用步骤创建外观角色1234567891011121314151617181920212223242526272829303132333435package main.java.com.study.designPatterns.facade.demoOne;/** * @author: whb * @description: 外观角色Facade */public class Facade &#123; /** * 子系统A */ private SubSystemA a = new SubSystemA(); /** * 子系统B */ private SubSystemB b = new SubSystemB(); /** * 子系统C */ private SubSystemC c = new SubSystemC(); // 对外接口 public void doA() &#123; this.a.doA(); &#125; // 对外接口 public void doB() &#123; this.b.doB(); &#125; // 对外接口 public void doC() &#123; this.c.doC(); &#125;&#125; 创建子系统123456789101112131415161718192021222324252627282930313233343536package main.java.com.study.designPatterns.facade.demoOne;/** * @author: whb * @description: 子系统A */public class SubSystemA &#123; public void doA() &#123; System.out.println(\"处理A系统的业务...\"); &#125;&#125;package main.java.com.study.designPatterns.facade.demoOne;/** * @author: whb * @description: 子系统B */public class SubSystemB &#123; public void doB() &#123; System.out.println(\"处理B系统的业务...\"); &#125;&#125;package main.java.com.study.designPatterns.facade.demoOne;/** * @author: whb * @description: 子系统C */public class SubSystemC &#123; public void doC() &#123; System.out.println(\"处理C系统的业务...\"); &#125;&#125; 测试类1234567891011121314package main.java.com.study.designPatterns.facade.demoOne;/** * @author: whb * @description: 客户端调用 */public class Client &#123; public static void main(String[] args) &#123; Facade facade = new Facade(); facade.doA(); facade.doB(); facade.doC(); &#125;&#125; 与适配模式的区别 外观模式的实现核心主要是——由外观类去保存各个子系统的引用，实现由一个统一的外观类去包装多个子系统类，然而客户端只需要引用这个外观类，然后由外观类来调用各个子系统中的方法。 这样的实现方式非常类似适配器模式，然而外观模式与适配器模式不同的是：适配器模式是将一个对象包装起来以改变其接口，而外观是将一群对象 ”包装“起来以简化其接口。它们的意图是不一样的，适配器是将接口转换为不同接口，而外观模式是提供一个统一的接口来简化接口。","tags":"java 设计模式"},{"title":"计算机网络基础学习","url":"/posts/b2437d15.html","text":"计算机网络体系结构体系介绍计算机网络体系结构分为3种：OSI体系结构、TCP / IP体系结构、五层体系结构 低三层为通信子网，负责数据传输； 高三层为资源子网，相当于计算机系统，完成数据处理； 传输层承上启下； TCP/IP体系结构详介 OSI体系结构详介 TCP 协议定义Transmission Control Protocol，即 传输控制协议，属于传输层通信协议，基于TCP的应用层协议有HTTP、SMTP、FTP、Telnet 和 POP3。 特点 面向连接：使用TCP传输数据前，必须先建立TCP连接；传输完成后再释放连接。 全双工通信：建立TCP连接后，通信双方都能发送数据。 可靠：通过TCP连接传送数据：不丢失、无差错、不重复、按序到达。 面向字节流：数据以流的形式进行传输。 报文段格式 报文段 = 首部 + 数据 2部分 下面分别对其中的字段进行介绍： 源端口和目的端口：各占2个字节，这两个值加上IP首部中的源端IP地址和目的端IP地址唯一确定一个TCP连接。有时一个IP地址和一个端口号也称为socket（插口）。序号：占4个字节，是本报文段所发送的数据项目组第一个字节的序号。在TCP传送的数据流中，每一个字节都有一个序号。例如，一报文段的序号为300，而且数据共100字节，则下一个报文段的序号就是400；序号是32bit的无符号数，序号到达2^32-1后从0开始。（注：如何防止从0开始后序号相同的问题）确认序号：占4字节，是期望收到对方下次发送的数据的第一个字节的序号，也就是期望收到的下一个报文段的首部中的序号；确认序号应该是上次已成功收到数据字节序号+1。只有ACK标志为1时，确认序号才有效。数据偏移：占4比特，表示数据开始的地方离TCP段的起始处有多远。实际上就是TCP段首部的长度。由于首部长度不固定，因此数据偏移字段是必要的。数据偏移以32位为长度单位，也就是4个字节，因此TCP首部的最大长度是60个字节。即偏移最大为15个长度单位=1532位=154字节。保留： 6比特，供以后应用，现在置为0。6个标志位比特：URG：当URG=1时，注解此报文应尽快传送，而不要按本来的列队次序来传送。与“紧急指针”字段共同应用，紧急指针指出在本报文段中的紧急数据的最后一个字节的序号，使接管方可以知道紧急数据共有多长；ACK：只有当ACK=1时，确认序号字段才有效；PSH：当PSH=1时，接收方应该尽快将本报文段立即传送给其应用层；RST：当RST=1时，表示出现连接错误，必须释放连接，然后再重建传输连接。复位比特还用来拒绝一个不法的报文段或拒绝打开一个连接；SYN：SYN=1,ACK=0时表示请求建立一个连接，携带SYN标志的TCP报文段为同步报文段；FIN：发端完成发送任务。窗口：TCP通过滑动窗口的概念来进行流量控制。设想在发送端发送数据的速度很快而接收端接收速度却很慢的情况下，为了保证数据不丢失，显然需要进行流量控制， 协调好通信双方的工作节奏。所谓滑动窗口，可以理解成接收端所能提供的缓冲区大小。TCP利用一个滑动的窗口来告诉发送端对它所发送的数据能提供多大的缓冲区。窗口大小为字节数，起始于确认序号字段指明的值（这个值是接收端正期望接收的字节）。窗口大小是一个16bit字段，因而窗口大小最大为65535字节。检验和：检验和覆盖了整个TCP报文段：TCP首部和数据。这是一个强制性的字段，一定是由发端计算和存储，并由收端进行验证。紧急指针：只有当URG标志置1时紧急指针才有效。紧急指针是一个正的偏移量，和序号字段中的值相加表示紧急数据最后一个字节的序号。 建立连接-三次握手 过程说明： 客户端向服务器发出连接请求报文，这时报文首部中的同部位SYN=1，同时选择一个初始序列号 Seq=X ，此时，TCP客户端进程进入了 SYN-SENT（同步已发送状态）状态。TCP规定，SYN报文段（SYN=1的报文段）不能携带数据，但需要消耗掉一个序号。 TCP服务器收到请求报文后，如果同意连接，则发出确认报文。确认报文中应该 ACK=1，SYN=1，确认号是Ack=X+1，同时也要为自己初始化一个序列号 Seq=Y，此时，TCP服务器进程进入了SYN-RCVD（同步收到）状态。这个报文也不能携带数据，但是同样要消耗一个序号。 TCP客户进程收到确认后，还要向服务器给出确认。确认报文的ACK=1，Ack=Y+1，自己的序列号Seq=X+1，此时，TCP连接建立，客户端进入ESTABLISHED（已建立连接）状态。TCP规定，ACK报文段可以携带数据，但是如果不携带数据则不消耗序号。 当服务器收到客户端的确认后也进入ESTABLISHED状态，此后双方就可以开始通信了。 为什么TCP建立连接需三次握手 首先要知道信道是不可靠的，但是要建立可靠的连接发送可靠的数据，也就是数据传输是需要可靠的。在这个时候三次握手是一个理论上的最小值，并不是说是tcp协议要求的，而是为了满足在不可靠的信道上传输可靠的数据所要求的。 在《计算机网络》一书中其中有提到，三次握手的目的是“为了防止已经失效的连接请求报文段突然又传到服务端，因而产生错误”这种情况是：一端(client)A发出去的第一个连接请求报文并没有丢失，而是因为某些未知的原因在某个网络节点上发生滞留，导致延迟到连接释放以后的某个时间才到达另一端(server)B。本来这是一个早已失效的报文段，但是B收到此失效的报文之后，会误认为是A再次发出的一个新的连接请求，于是B端就向A又发出确认报文，表示同意建立连接。如果不采用“三次握手”，那么只要B端发出确认报文就会认为新的连接已经建立了，但是A端并没有发出建立连接的请求，因此不会去向B端发送数据，B端没有收到数据就会一直等待，这样B端就会白白浪费掉很多资源。如果采用“三次握手”的话就不会出现这种情况，B端收到一个过时失效的报文段之后，向A端发出确认，此时A并没有要求建立连接，所以就不会向B端发送确认，这个时候B端也能够知道连接没有建立。 释放连接-四次挥手 过程说明： 客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。 服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。 客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。 服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。 客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。 服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。 为什么TCP释放连接需要四次挥手 为了保证客户端发送的最后1个连接释放确认报文能到达服务器，从而使得服务器能正常释放连接。关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了，但未必你所有的数据都发送给对方了，所以你不必马上关闭SOCKET，也即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。 防止上文提到的早已失效的连接请求报文出现在本连接中。客户端发送了最后1个连接释放请求确认报文后，再经过2MSL时间，则可使本连接持续时间内所产生的所有报文段都从网络中消失。即在下1个新的连接中就不会出现早已失效的连接请求报文。 释放连接时为什么TIME-WAIT状态必须等待2MSL时间首先说下什么是MSL:MSL是Maximum Segment Lifetime英文的缩写，中文可以译为“报文最大生存时间”，他是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。 第一，为了保证A发送的最后一个ACK报文能够到达B。这个ACK报文段有可能丢失，因而使处在LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认。B会超时重传这个FIN+ACK报文段，而A就能在2MSL时间内收到这个重传的FIN+ACK报文段，重置时间等待计时器（2MSL）。如果A在TIME-WAIT状态不等待一段时间，而是在发送完ACK报文段后就立即释放连接，就无法收到B重传的FIN+ACK报文段，因而也不会再发送一次确认报文段。这样，B就无法按照正常的步骤进入CLOSED状态。 第二，A在发送完ACK报文段后，再经过2MSL时间，就可以使本连接持续的时间所产生的所有报文段都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求的报文段。 客户端突然挂掉了怎么办正常连接时，客户端突然挂掉了，如果没有措施处理这种情况，那么就会出现客户端和服务器端出现长时期的空闲。 解决办法是在服务器端设置保活计时器，每当服务器收到客户端的消息，就将计时器复位。超时时间通常设置为2小时。若服务器超过2小时没收到客户的信息，他就发送探测报文段。若发送了10个探测报文段，每一个相隔75秒，还没有响应就认为客户端出了故障，因而终止该连接。 滑动窗口协议基础概念发送窗口：任意时刻，发送方维持的一组连续的、允许发送帧的帧序号；用于对发送方进行流量控制； 接收窗口：任意时刻，接收方维持的一组连续的、允许接收帧的帧序号；用于控制可接收哪些数据帧、不可接收哪些数据帧，接收方只有当收到数据帧的序号落入接收窗口内才允许将该数据帧收下，否则一律丢弃。 工作原理发送端 每收到一个确认帧，发送窗口就向前滑动一个帧的距离。 当发送窗口内无可发送的帧时（即窗口内的帧全部是已发送但未收到确认的帧），发送方就会停止发送，直到收到接收方发送的确认帧使窗口移动，窗口内有可以发送的帧，之后才开始继续发送。 接收端 当收到数据帧后，将窗口向前移动一个位置，并发回确认帧，若收到的数据帧落在接收窗口之外，则一律丢弃。 重要特性 只有接收窗口向前滑动、接收方发送了确认帧时，发送窗口才有可能（只有发送方收到确认帧才是一定）向前滑动。 停止-等待协议、后退N帧协议 &amp; 选择重传协议只是在发送窗口大小和接收窗口大小上有所差别： 停止等待协议：发送窗口大小=1，接收窗口大小=1；即 单帧滑动窗口 等于 停止-等待协议 后退N帧协议：发送窗口大小&gt;1，接收窗口大小=1。 选择重传协议：发送窗口大小&gt;1，接收窗口大小&gt;1。 当接收窗口的大小为1时，可保证帧有序接收。 数据链路层的滑动窗口协议中，窗口的大小在传输过程中是固定的（注意要与TCP的滑动窗口协议区别）。 自动重传请求协议ARQ定义Auto Repeat reQuest，传输出现差错时，接收方自动请求发送方重传出错的数据。 作用保证信道的数据传输无差错。 机制 确认机制发送方每发送一帧，要等到接收方的应答信号后才能发送下一帧；接收方每接收一帧，都要反馈一个应答信号，表示可接收下一帧；若接收方不反馈应答信号，则发送方必须一直等待。 超时重传机制发送方在发送某个数据帧后就开启计时器；在一定时间内若没得到发送的数据帧的确认帧，则重新方法该数据帧，直到发送成功为止。 类型 停等式ARQ（Stop-and-Wait） 后退N帧ARQ（Go-Back-N） 选择重传ARQ（Selective Repeat） 停等式ARQ（Stop-and-Wait） 原理： （单帧滑动窗口）停止 - 等待协议 + 超时重传，即 ：发送窗口大小=1、接收窗口大小=1 具体描述： 发送方每发送一帧，要等到接收方的应答信号后才能发送下一帧； 接收方每接收一帧，都要反馈一个应答信号，表示可接下一帧； 若接收方不反馈应答信号，则发送方必须一直等待。 后退N帧协议 原理： 多帧滑动窗口 + 累计确认 + 后退N帧 + 超时重传，即 ：发送窗口大小&gt;1、接收窗口大小=1 具体描述： 发送方：采用多帧滑动窗口的原理，可连续发送多个数据帧 而不需等待对方确认 接收方：采用 累计确认 &amp; 后退N帧的原理，只允许按顺序接收帧。 累计确认 收到多个数据分组后，只需对按序到达的最后1个分组发送确认而不必对收到的每个分组逐个发送确认即可表示到该分组为止的所有分组都已正确收到。 优点：实现简答；数据丢失不必重传。 缺点：不能向发送方反映出接收方已正确收到所有分组信息。 后退N帧 退回来重传已发送过的N个分组。保证按序接收数据帧。 后退N帧协议的接口窗口长度 = 1，若采用n个比特对帧编号，则其发送窗口WT应满足1≤WT≤2n-1;若发送窗口尺寸大于2n-1，则会造成接收方无法分辨新帧和旧帧。 选择重传ARQ（Selective Repeat） 原理： 多帧滑动窗口 + 累计确认 + 后退N帧 + 超时重传，即 ：发送窗口大小&gt;1、接收窗口大小&gt;1 优缺点： 优点：因连续发送数据帧而提高了信道的利用率；缺点：重传时又必须把原来已经传送正确的数据帧进行重传（仅因为这些数据帧前面有一个数据帧出了错），将导致传送效率降低。 TCP超时重传在发送某一个数据以后就开启一个计时器，在一定时间内如果没有得到发送的数据报的ACK报文，那么就重新发送数据，直到发送成功为止。 影响超时重传机制协议效率的一个关键参数是重传超时时间（RTO，Retransmission TimeOut）。RTO的值被设置过大过小都会对协议造成不利影响。（1）RTO设长了，重发就慢，没有效率，性能差。（2）RTO设短了，重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。 连接往返时间（RTT，Round Trip Time），指发送端从发送TCP包开始到接收它的立即响应所消耗的时间。 RTO理论上最好是网络 RTT 时间，但又受制于网络距离与瞬态时延变化，所以实际上使用自适应的动态算法（例如 Jacobson 算法和 Karn 算法等）来确定超时时间。 TCP流量控制TCP流量控制主要是针对接收端的处理速度不如发送端发送速度快的问题，消除发送方使接收方缓存溢出的可能性。 TCP流量控制主要使用滑动窗口协议，滑动窗口是接受数据端使用的窗口大小，用来告诉发送端接收端的缓存大小，以此可以控制发送端发送数据的大小，从而达到流量控制的目的。 接收端通过TCP首部的窗口大小字段反馈当前可接收的字节数。 对于发送端的数据缓冲区有这些量： LastByteSent是目前发送的最后1字节的数据编号； LastByteAckd是目前接收到确认的最后1字节的数据编号； LastByteRcvd：接收端从网络接收的最后一个字节序号； LastByteRead：上层应用程序接收的最后一个字节序号； Rcvwin是窗口大小。 鉴于每次发送方都是收到ACK之后滑动窗口继续发送，发送到LastByteSent这个位置，LastByteSent-LastByteAckd也就是这次发送数据的多少，那么只要满足：LastByteSent–LastByteAckd&lt;=RcvWin(接收端空闲窗口大小) 就会保证不会溢出了。 那么接收端RcvWin怎么算呢？假设接收端缓冲区大小为RcvBuffer,那么LastByteRcvd–LastByteRead就是已经接受但是还没有传递给上层的数据。所以空闲区域RcvWin= RcvBuffer-(LastByteRcvd–LastByteRead)。 TCP拥塞控制TCP发送方可能因为IP网络的拥塞而被遏制，TCP拥塞控制就是为了解决这个问题（注意和TCP流量控制的区别）。TCP拥塞控制的几种方法：慢启动，拥塞避免，快重传和快恢复。在了解这几种方法之前，先了解下拥塞窗口、慢开始算法、拥塞避免算法。 拥塞窗口定义发送方维持一个叫做拥塞窗口 cwnd的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态变化。发送方的让自己的发送窗口=min(cwnd，接受端接收窗口大小）。 发送方控制拥塞窗口的原则只要网络没有出现拥塞，拥塞窗口就增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。 慢开始算法当主机开始发送数据时，如果立即将大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。因此，较好的方法是 先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。 通常在刚刚开始发送报文段时，先把拥塞窗口 cwnd 设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口 cwnd ，可以使分组注入到网络的速率更加合理。 每经过一个传输轮次，拥塞窗口 cwnd 就加倍。一个传输轮次所经历的时间其实就是往返时间RTT。不过“传输轮次”更加强调：把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。 慢开始的“慢”并不是指cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置cwnd=1，使得发送方在开始时只发送一个报文段（目的是试探一下网络的拥塞情况），然后再逐渐增大cwnd。 为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量。慢开始门限ssthresh的用法如下： 当 cwnd &lt; ssthresh 时，使用上述的慢开始算法。 当 cwnd &gt; ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。 当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法。 拥塞避免算法让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口cwnd按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。 拥塞避免并不可避免拥塞，只是将拥塞窗口按现行规律缓慢增长，使得网络比较不容易出现拥塞。 慢开始和拥塞避免算法的实现举例无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送 方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生 拥塞的路由器有足够时间把队列中积压的分组处理完毕。 如下图，用具体数值说明了上述拥塞控制的过程。现在发送窗口的大小和拥塞窗口一样大。 过程说明： 当TCP连接进行初始化时，把拥塞窗口cwnd置为1。为了便于理解，图中的窗口单位不使用字节而使用报文段的个数。慢开始门限的初始值设置为16个报文段，即 ssthresh= 16 。在执行慢开始算法时，拥塞窗口 cwnd 的初始值为1。以后发送方每收到一个对新报文段的确认ACK，就把拥塞窗口值加1，然后开始下一轮的传输（图中横坐标为传输轮次）。因此拥塞窗口cwnd 随着传输轮次按指数规律增长。当拥塞窗口cwnd增长到慢开始门限值ssthresh时（即当cwnd=16时），就改为执行拥塞控制算法，拥塞窗口按线性规律增长。假定拥塞窗口的数值增长到24时，网络出现超时（这很可能就是网络发生拥塞了）。更新后的ssthresh值变为12（即变为出现超时时的拥塞窗口数值 24的一半），拥塞窗口再重新设置为1，并执行慢开始算法。当cwnd=ssthresh=12时改为执行拥塞避免算法，拥塞窗口按线性规律增长，每经过 一个往返时间增加一个MSS的大小。强调：“拥塞避免”并非指完全能够避免了拥塞。利用以上的措施要完全避免网络拥塞还是不可能的。“拥塞避免”是说在拥塞避免阶段将拥塞窗口控制为按线性规律增长，使网络比较不容易出现拥塞。 快重传原理 接收方：每收到一个失序的报文段后 就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方），而不要等到自己发送数据时才进行捎带确认。 发送方：只要一连收到3个重复确认就立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器到期。 作用由于发送方尽早重传未被确认的报文段，因此采用快重传后可以使整个网络吞吐量提高约20%。 示例 快恢复与快重传配合使用的还有快恢复算法，其主要有以下两个要点： 当发送方连续收到接收方发来的三个重复确认时，就执行“乘法减小”算法，把慢开始门限减半（这个减半指的是变成发生阻塞时的阻塞窗口大小的一半），这是为了预防网络发生拥塞。（注意：接下来不执行慢开始算法） 由于发送方现在认为网络很可能没有发生拥塞，因此现在不执行慢开始算法，而是把cwnd(拥塞窗口)值设置为慢开始门限减半后的值，然后开始执行拥塞避免算法，使拥塞窗口缓慢的线性增大。 注：由于跳过了拥塞窗口（cwnd）从1起始的慢开始过程，所以称为：快恢复。 此处网络不会发生网络拥塞，因若拥塞，则不会收到多个重复确认报文。 示例如下图： TCP四种计时器TCP中有四种计时器（Timer），分别为： 重传计时器：Retransmission Timer 坚持计时器：Persistent Timer 保活计时器：Keeplive Timer 时间等待计时器：Timer_Wait Timer 重传计时器TCP是可以保证数据可靠传输的。怎么保证呢？带确认的重传机制。 在滑动窗口协议中，接收窗口会在连续收到的包序列中的最后一个包向接收端发送一个ACK，当网络拥堵的时候，发送端的数据包和接收端的ACK包都有可能丢失。 TCP为了保证数据可靠传输，就规定在重传的“时间片”到了以后，如果还没有收到对方的ACK，就重发此包，以避免陷入无限等待中。 当TCP发送报文段时，就创建该特定报文的重传计时器。可能发生两种情况：1）若在计时器截止时间到之前收到了对此特定报文段的确认，则撤销此计时器。2）若在收到了对此特定报文段的确认之前计时器截止时间到，则重传此报文段，并将计时器复位。 坚持计时器 专门对付零窗口通知而设立的。 先来考虑一下情景：发送端向接收端发送数据包知道接收窗口填满了，然后接收窗口告诉发送方接收窗口填满了停止发送数据。此时的状态称为“零窗口”状态，发送端和接收端窗口大小均为0.直到接受TCP发送确认并宣布一个非零的窗口大小。但这个确认会丢失。我们知道TCP中，对确认是不需要发送确认的。若确认丢失了，接受TCP并不知道，而是会认为他已经完成了任务，并等待着发送TCP接着会发送更多的报文段。但发送TCP由于没有收到确认，就等待对方发送确认来通知窗口大小。双方的TCP都在永远的等待着对方。要打开这种死锁，TCP为每一个链接使用一个持久计时器。当发送TCP收到窗口大小为0的确认时，就坚持启动计时器。当坚持计时器期限到时，发送TCP就发送一个特殊的报文段，叫做探测报文。这个报文段只有一个字节的数据。他有一个序号，但他的序号永远不需要确认；甚至在计算机对其他部分的数据的确认时该序号也被忽略。探测报文段提醒接受TCP：确认已丢失，必须重传。坚持计时器的值设置为重传时间的数值。但是，若没有收到从接收端来的响应，则需发送另一个探测报文段，并将坚持计时器的值加倍和复位。发送端继续发送探测报文段，将坚持计时器设定的值加倍和复位，直到这个值增大到门限值（通常是60秒）为止。在这以后，发送端每隔60秒就发送一个探测报文，直到窗口重新打开。 保活计时器 保活计时器使用在某些实现中，用来防止在两个TCP之间的连接出现长时间的空闲。 假定客户打开了到服务器的连接，传送了一些数据，然后就保持静默了。也许这个客户出故障了。在这种情况下，这个连接将永远的处于打开状态。 要解决这种问题，在大多数的实现中都是使服务器设置保活计时器。每当服务器收到客户的信息，就将计时器复位。通常设置为两小时。 若服务器过了两小时还没有收到客户的信息，他就发送探测报文段。若发送了10个探测报文段（每一个间隔75秒）还没有响应，就假定客户端出了故障，因而就终止了该连接。 这种连接的断开当然不会使用四次握手，而是直接硬性的中断和客户端的TCP连接。 时间等待计时器 时间等待计时器是在四次挥手手的时候使用的。即在释放连接的最终阶段，客户端还要等待2MSL（MSL=maxinum segment lifetime最长报文生存时间，2MSL就是两倍的MSL）才能真正的关闭连接。 UDP协议定义User Datagram Protocol，即 用户数据报协议，属于 传输层通信协议。基于UDP的应用层协议有 TFTP、SNMP 与 DNS。 特点 无连接：使用UDP传输数据前，不需要建立UDP连接，就像写信，写好信交给邮局，其余不需要管。 不可靠：UDP的数据包发送后，不管其是否会到达接收方，故可能出现丢包现象。 面向报文：数据以数据报文(包)的形式传输，UDP数据报文长度无限制，都一次性发送，不像TCP会拆分。 无拥塞控制：由于是不可靠传输，即不管是否到达接收方，故不需拥塞控制。 报文段格式 伪首部：计算检验和（不向下传送，也不向上递交）。 源端口：需要对方回信时使用，如果不需要则设为全0。 目的端口：终点交付报文时用到。 长度：UDP用户数据报的长度，最小值是8（仅有首部）。 检验和：检测UDP用户数据报在传输中是否有错，若有错则丢弃。 TCP、UDP的区别 HTTP协议定义HyperText Transfer Protocol，超文本传输协议，规定了应用进程之间的通信准则，属于应用层协议。 特点 无连接，即交换HTTP报文前，不需要建立HTTP连接。 无状态，即数据传输过程中不保存任何历史状态信息，该特性简化了服务器的设计，使服务器更容易支持大量并发的HTTP请求。 传输格式简单，即请求时只需传送请求方法和路径。 传输可靠性高，采用TCP作为运输层协议。 兼容性好，支持B/S、C/S模式。 灵活性高，HTTP允许传输任意类型的数据对象。 工作方式HTTP协议采用请求/响应的工作方式，具体工作流程如下： HTTP报文HTTP报文分为：请求报文、响应报文。 请求报文HTTP的请求报文由请求行、请求头、请求体组成。如下图： 请求行请求行 = 请求方法 + 请求路径 + 协议版本用于声明 请求方法 、主机域名、资源路径 、协议版本。 各部分组成介绍如下图： 请求头主要用于声明客户端、服务器/报文的部分信息。采用header(字段名):value(值)的方式。 请求和响应报文的通用Header 名称 作用 Content-Type 请求体/响应体的类型，如：text/plain、application/json Accept 说明接收的类型，可以多个值，用，（半角逗号）分开 Content-Length 请求体/响应体的长度，单位字节 Content-Encoding 请求体/响应体的编码格式，如gzip,deflate Accept-Encoding 告知对方我方接受的Content-Encoding ETag 给当前资源的标识，和Last-Modified、If-None-Match、If-Modified-Since 配合，用于缓存控制 Cache-Control 取值为一般为no-cache或max-age=Xx，XX为个整数，表示该资源缓存有效期（秒) 常见的请求Header 名称 作用 Authorization 用于设置身份认证信息 User-Agent 用户标识，如：OS和浏览器的类型和版本 If-Modified-Since 值为上一次服务器返回的Last-Modified值，用于确认某个资源是否被更改过，没有更改过（304）就从缓存中读取 If-None-Match 值为上一次服务器返回的ETag值，一般会和If-Modified-Since一起出现 Cookie 已有的Cookie Referer 表示请求引用自哪个地址，比如你从页面A跳转到页面B时，值为页面A的地址 Host 请求的主机和端口号 请求体主要用于存放需发送给服务器的数据信息。 使用方式共3种，如下图： 响应报文HTTP响应报文包括：状态行、响应头、响应体。结构如下图： 状态行状态行 = 协议版本 + 状态码 + 状态信息组成 主要用于声明协议版本、状态码、状态码描述。 各部分组成具体介绍如下： 响应头主要用于声明客户端、服务器/报文的部分信息。采用header(字段名):value(值)的方式。 常见响应Header 名称 作用 Date 服务器的日期 Last-Modified 该资源最后被修改时间 Transfer-Encoding 取值为一般为chunked，出现在Content-Length不能确定的情况下，表示服务器不知道响应版体的数据大小，一般同时还会出现Content-Encoding 响应头 Set-Cookie 设置Cookie Location 重定向到另一个URL，如输入浏览器就输入baidu.com回车，会自动跳到https://www.baidu.com，就是通过这个响应头控制的 Server 后台服务器 响应体主要用于存放需返回给客户端的数据信息。使用方式同请求报文的请求体。 HTTP1.1 与 HTTP1.0的区别Http1.1 比 Http1.0 多了以下优点： 引入持久连接，即 在同一个TCP的连接中可传送多个HTTP请求 &amp; 响应； 多个请求 &amp; 响应可同时进行、可重叠； 引入更加多的请求头 &amp; 响应头； 其他知识浏览器中输入URL到页面返回的全过程总共分为7个步骤，流程如下图： 第一步：域名解析 浏览器查找浏览器缓存，如果有域名对应的IP地址则返回，如果没有继续查找。 浏览器查看本机的host文件，如果有域名对应的IP地址则返回，如果没有继续查找。 然后是路由器缓存，路由器一般有自己的缓存，如果有域名对应的IP地址则返回，如果没有继续查找。 接着是对本地DNS服务器进行递归查询，看是否有域名对应的IP。主机向本地域名服务器的查询一般都是采用递归查询。所谓递归查询就是如果主机所询问的本地域名服务器不知道被查询域名的IP地址，那么本地域名服务器就以DNS客户的身份，向其他根域名服务器继续发出查询请求报文，而不是让该主机自己进行下一步查询。（本地域名服务器地址是通过DHPC协议获取地址，DHPC是负责分配IP地址的） 本地域名服务器采用迭代查询，它先向一个根域名服务器查询。本地域名服务器向根域名服务器的查询一般都是采用迭代查询。所谓迭代查询就是当根域名服务器收到本地域名服务器发出的查询请求报文后，要么告诉本地域名服务器下一步应该查询哪一个域名服务器，然后本地服务器自己进行后续的查询。（而不是替代本地服务器进行后续查询）。 根域名服务器告诉本地域名服务器，下一次应查询的顶级域名服务器dns.com的IP地址。 本地域名服务器向顶级域名服务器dns.com进行查询。 顶级域名服务器dns.com告诉本地域名服务器，下一次应查询的权限域名服务器dns.baidu.com的IP地址。 本地域名服务器向权限域名服务器dns.baidu.com进行查询。 权限域名服务器dns.baidu.com告诉本地域名服务器，所查询的主机www.baidu.com的IP地址。 本地域名服务器最后把查询结果告诉主机。 第二步：建立TCP连接，三次握手 第三步：Web浏览器向Web服务端发送HTTP请求报文 第四步：服务器响应HTTP请求 第五步：浏览器解析HTML代码，并请求HTML代码中的资源（JS，CSS，图片）（这是自动向服务器请求下载的） 第六步：浏览器对页面进行渲染呈现给客户 第七步：断开TCP连接，四次挥手 IP地址(IPV4)定义连接在Internet中的每一台主机（或 路由器）的全球唯一的标识符。 组成IP地址 = 32位 = 网络号 + 主机号；即IP地址::={&lt;网络号&gt;，&lt;主机号&gt;} 网络号：标志主机（或路由器）所连接到的网络。一个网络号在整个因特网范围内必须是唯一的。 主机号：标志该主机（或路由器）。一个主机号在它面前的网络号所指明的网络范围必须是唯一的。 不同类型的IP地址，其主机号 &amp; 网络号所占字节数不同；故：一个IP地址在整个网络范围内是唯一的。 分类传统的IP地址是分类的地址，分为A，B，C，D，E五类，区别在于网络号 &amp; 主机号占的字节数不同。 特别注意：在各类IP地址中，有一些IP地址用于特殊用途，不能用于做主机IP地址 Cookie与Session","tags":"计算机基础"},{"title":"JVM类加载机制","url":"/posts/de06556f.html","text":"类加载时机类的生命周期一个类从加载进内存到卸载出内存为止，一共经历7个阶段： 加载——&gt;验证——&gt;准备——&gt;解析——&gt;初始化——&gt;使用——&gt;卸载 其中，类加载包括5个阶段： 加载——&gt;验证——&gt;准备——&gt;解析——&gt;初始化 在类加载的过程中，以下3个过程称为连接： 验证——&gt;准备——&gt;解析 因此，JVM的类加载过程也可以概括为3个过程： 加载——&gt;连接——&gt;初始化 C/C++在运行前需要完成预处理、编译、汇编、链接；而在Java中，类加载(加载、连接、初始化)是在程序运行期间完成的。在程序运行期间进行类加载会稍微增加程序的开销，但随之会带来更大的好处——提高程序的灵活性。Java语言的灵活性体现在它可以在运行期间动态扩展，所谓动态扩展就是在运行期间动态加载和动态连接。 类加载的时机类加载过程中每个步骤的顺序类加载的过程包括：加载、连接、初始化，连接又分为：验证、准备、解析，所以说类加载一共分为5步：加载、验证、准备、解析、初始化。 其中加载、验证、准备、初始化的开始顺序是依次进行的，这些步骤开始之后的过程可能会有重叠。 而解析过程会发生在初始化过程中。 类加载过程中“初始化”开始的时机JVM规范中只定义了类加载过程中初始化过程开始的时机，加载、连接过程都应该在初始化之前开始(解析除外)，这些过程具体在何时开始，JVM规范并没有定义，不同的虚拟机可以根据具体的需求自定义。 初始化开始的时机： 在运行过程中遇到如下字节码指令时，如果类尚未初始化，那就要进行初始化：new、getstatic、putstatic、invokestatic。这四个指令对应的Java代码场景是： 通过new创建对象； 读取、设置一个类的静态成员变量(不包括final修饰的静态变量)； 调用一个类的静态成员函数。 使用java.lang.reflect进行反射调用的时候，如果类没有初始化，那就需要初始化； 当初始化一个类的时候，若其父类尚未初始化，那就先要让其父类初始化，然后再初始化本类； 当虚拟机启动时，虚拟机会首先初始化带有main方法的类，即主类； 当使用 JDK 1.7 的动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果 REF_getStatic、REF_putStatic、REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需先触发其初始化。 主动引用 与 被动引用 JVM规范中要求在程序运行过程中，“当且仅当”出现上述4个条件之一的情况才会初始化一个类。如果间接满足上述初始化条件是不会初始化类的。其中，直接满足上述初始化条件的情况叫做主动引用；间接满足上述初始化过程的情况叫做被动引用。那么，只有当程序在运行过程中满足主动引用的时候才会初始化一个类，若满足被动引用就不会初始化一个类。 被动引用的场景示例示例一12345678910111213141516public class Fu&#123; public static String name = \"类初始化的时机\"; static&#123; System.out.println(\"父类被初始化！\"); &#125;&#125;public class Zi&#123; static&#123; System.out.println(\"子类被初始化！\"); &#125;&#125;public static void main(String[] args)&#123; System.out.println(Zi.name);&#125; 输出结果： 12父类被初始化！ 类初始化的时机 原因分析： 本示例看似满足初始化时机的第一条：当要获取某一个类的静态成员变量的时候如果该类尚未初始化，则对该类进行初始化。但由于这个静态成员变量属于Fu类，Zi类只是间接调用Fu类中的静态成员变量，因此Zi类调用name属性属于间接引用，而Fu类调用name属性属于直接引用，由于JVM只初始化直接引用的类，因此只有Fu类被初始化。 示例二12345public class Test&#123; public static void main(String[] args)&#123; Fu[] arr = new Fu[10]; &#125;&#125; 输出结果： 并没有输出“父类被初始化！” 原因分析： 这个过程看似满足初始化时机的第一条：遇到new创建对象时若类没被初始化，则初始化该类。但现在通过new要创建的是一个数组对象，而非Fu类对象，因此也属于间接引用，不会初始化Fu类。 示例三123456789101112public class Fu&#123; public static final String name = \"类初始化的时机\"; static&#123; System.out.println(\"父类被初始化！\"); &#125;&#125;public class Son&#123; public static void main(String[] args)&#123; System.out.println(Fu.name); &#125;&#125; 输出结果： 类初始化的时机 原因分析： 本示例看似满足类初始化时机的第一个条件：获取一个类静态成员变量的时候若类尚未初始化则初始化类。但是，Fu类的静态成员变量被final修饰，它已经是一个常量。被final修饰的常量在Java代码编译的过程中就会被放入它被引用的class文件的常量池中(这里是A的常量池)。所以程序在运行期间如果需要调用这个常量，直接去当前类的常量池中取，而不需要初始化这个类。 接口的初始化接口和类都需要初始化，接口和类的初始化过程基本一样，不同点在于：类初始化时，如果发现父类尚未被初始化，则先要初始化父类，然后再初始化自己；但接口初始化时，并不要求父接口已经全部初始化，只有程序在运行过程中用到当父接口中的东西时才初始化父接口。 类加载的过程加载注意：“加载”是“类加载”过程的第一步，千万不要混淆。 加载的过程在加载过程中，JVM主要做3件事情： 通过一个类的全限定名来获取这个类的二进制字节流，即class文件： 在程序运行过程中，当要访问一个类时，若发现这个类尚未被加载，并满足类初始化时机的条件时，就根据要被初始化的这个类的全限定名找到该类的二进制字节流，开始加载过程。 将二进制字节流的存储结构转化为特定的数据结构，存储在方法区中； 在内存中创建一个java.lang.Class类型的对象： 接下来程序在运行过程中所有对该类的访问都通过这个类对象，也就是这个Class类型的类对象是提供给外界访问该类的接口。 从哪里加载JVM规范对于加载过程给予了较大的宽松度。一般二进制字节流都从已经编译好的本地class文件中读取，此外还可以从以下地方读取： 从压缩包中读取，如：Jar、War、Ear等。 从其它文件中动态生成，如：从JSP文件中生成Class类。 从数据库中读取，将二进制字节流存储至数据库中，然后在加载时从数据库中读取。有些中间件会这么做，用来实现代码在集群间分发。 从网络中获取，从网络中获取二进制字节流。典型就是Applet。 类 和 数组加载过程的区别数组也有类型，称为“数组类型”。如：String[] str = new String[10]; 这个数组的数组类型是Ljava.lang.String，而String只是这个数组中元素的类型。 当程序在运行过程中遇到new关键字创建一个数组时，由JVM直接创建数组类，再由类加载器创建数组中的元素类。 而普通类的加载由类加载器完成。既可以使用系统提供的引导类加载器，也可以使用用户自定义的类加载器。 加载过程的注意点 JVM规范并未给出类在方法区中存放的数据结构类完成加载后，二进制字节流就以特定的数据结构存储在方法区中，但存储的数据结构是由虚拟机自己定义的，JVM规范并没有指定。 JVM规范并没有指定Class对象存放的位置在二进制字节流以特定格式存储在方法区后，JVM会创建一个java.lang.Class类型的对象，作为本类的外部接口。既然是对象就应该存放在堆内存中，不过JVM规范并没有给出限制，不同的虚拟机根据自己的需求存放这个对象。HotSpot将Class对象存放在方法区。 加载阶段和连接阶段是交叉的通过前文可知，类加载过程中每个步骤的开始顺序都有严格限制，但每个步骤的结束顺序没有限制。也就是说，类加载过程中，必须按照如下顺序开始：加载、连接、初始化，但结束顺序无所谓，因此由于每个步骤处理时间的长短不一就会导致有些步骤会出现交叉。 验证验证阶段比较耗时，它非常重要但不一定必要，如果所运行的代码已经被反复使用和验证过，那么可以使用-Xverify:none参数关闭，以缩短类加载时间。 验证的目的验证是为了保证二进制字节流中的信息符合虚拟机规范，并没有安全问题。 为什么需要验证虽然Java语言是一门安全的语言，它能确保程序猿无法访问数组边界以外的内存、避免让一个对象转换成任意类型、避免跳转到不存在的代码行，如果出现这些情况，编译无法通过。也就是说，Java语言的安全性是通过编译器来保证的。 但是编译器和虚拟机是两个独立的东西，虚拟机只认二进制字节流，它不会管所获得的二进制字节流是哪来的，当然，如果是编译器给它的，那么就相对安全，但如果是从其它途径获得的，那么无法确保该二进制字节流是安全的。通过上文可知，虚拟机规范中没有限制二进制字节流的来源，那么任意来源的二进制字节流虚拟机都能接受，为了防止字节流中有安全问题，因此需要验证！ 验证的过程 文件格式验证 是否以魔数 0xCAFEBABE 开头 主、次版本号是否在当前虚拟机处理范围之内 常量池的常量是否有不被支持常量的类型（检查常量 tag 标志） 指向常量的各种索引值中是否有指向不存在的常量或不符合类型的常量 CONSTANT_Utf8_info 型的常量中是否有不符合 UTF8 编码的数据 Class 文件中各个部分集文件本身是否有被删除的附加的其他信息 …… 这个阶段主要验证输入的二进制字节流是否符合class文件结构的规范。二进制字节流只有通过了本阶段的验证，才会被允许存入到方法区中。本验证阶段是基于二进制字节流的，而后面的三个验证阶段都是在方法区中进行，并基于类特定的数据结构的。 通过上文可知，加载开始前，二进制字节流还没进方法区，而加载完成后，二进制字节流已经存入方法区。而在文件格式验证前，二进制字节流尚未进入方法区，文件格式验证通过之后才进入方法区。也就是说，加载开始后，立即启动了文件格式验证，本阶段验证通过后，二进制字节流被转换成特定数据结构存储至方法区中，继而开始下阶段的验证和创建Class对象等操作。这个过程印证了：加载和验证是交叉进行的。 元数据验证 这个类是否有父类（除 java.lang.Object 之外） 这个类的父类是否继承了不允许被继承的类（final 修饰的类） 如果这个类不是抽象类，是否实现了其父类或接口之中要求实现的所有方法 类中的字段、方法是否与父类产生矛盾（覆盖父类 final 字段、出现不符合规范的重载） 本阶段对方法区中的字节码描述信息进行语义分析，确保其符合Java语法规范。 字节码验证 保证任意时刻操作数栈的数据类型与指令代码序列都鞥配合工作（不会出现按照 long 类型读一个 int 型数据） 保证跳转指令不会跳转到方法体以外的字节码指令上 保证方法体中的类型转换是有效的（子类对象赋值给父类数据类型是安全的，反过来不合法的） …… 这是整个验证过程中最复杂的一个阶段，主要目的是通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。这个阶段对类的方法体进行校验分析，保证校验类的方法在运行时不会做出危害虚拟机安全的事件。 符号引用验证 符号引用中通过字符创描述的全限定名是否能找到对应的类 在指定类中是否存在符方法的字段描述符以及简单名称所描述的方法和字段 符号引用中的类、字段、方法的访问性（private、protected、public、default）是否可被当前类访问 …… 本阶段验证发生在解析阶段，确保解析能正常执行。如果无法通过符号引用验证将抛出一个 java.lang.IncompatibleClass.ChangeError 异常的子类。如 java.lang.IllegalAccessError、java.lang.NoSuchFieldError、java.lang.NoSuchMethodError 等。 准备准备阶段完成两件事情： 为已经在方法区中的类中的静态成员变量分配内存类的静态成员变量也存储在方法区中。 为静态成员变量设置初始值初始值为0、false、null等。 数据类型的零值: 数据类型 零值 byte (byte) 0 short (short) 0 int 0 long 0L float 0.0f double 0.0d char ‘\\u0000’ boolean false reference null 示例1： 1public static String name = \"测试类加载\"; 在准备阶段，JVM会在方法区中为name分配内存空间，并赋上初始值null。给name赋上”测试类加载”是在初始化阶段完成的。 示例2: 1public static final String name = \"测试类加载\"; 被final修饰的常量如果有初始值，那么在编译阶段就会将初始值存入constantValue属性中，在准备阶段就将constantValue的值赋给该字段。 解析解析阶段是虚拟机将常量池中的符号引用替换为直接引用的过程。 初始化初始化阶段就是执行类构造器clinit()的过程。clinit()方法由编译器自动产生，收集类中static{}代码块中的类变量赋值语句和类中静态成员变量的赋值语句。在准备阶段，类中静态成员变量已经完成了默认初始化，而在初始化阶段，clinit()方法对静态成员变量进行显示初始化。 初始化过程的注意点 clinit()方法中静态成员变量的赋值顺序是根据Java代码中成员变量的出现的顺序决定的。 静态代码块能访问出现在静态代码块之前的静态成员变量，无法访问出现在静态代码块之后的成员变量。 静态代码块能给出现在静态代码块之后的静态成员变量赋值。 构造函数init()需要显示调用父类构造函数，而类的构造函数clinit()不需要调用父类的类构造函数，因为虚拟机会确保子类的clinit()方法执行前已经执行了父类的clinit()方法。 如果一个类/接口中没有静态代码块，也没有静态成员变量的赋值操作，那么编译器就不会生成clinit()方法。 接口也需要通过clinit()方法为接口中定义的静态成员变量显示初始化。 接口中不能使用静态代码块。 接口在执行clinit()方法前，虚拟机不会确保其父接口的clinit()方法被执行，只有当父接口中的静态成员变量被使用到时才会执行父接口的clinit()方法。 虚拟机会给clinit()方法加锁，因此当多条线程同时执行某一个类的clinit()方法时，只有一个方法会被执行，其它的方法都被阻塞。并且，只要有一个clinit()方法执行完，其它的clinit()方法就不会再被执行。因此，在同一个类加载器下，同一个类只会被初始化一次。 类加载器java.lang.ClassLoader类的基本职责就是根据一个指定的类的名称，找到或者生成其对应的字节码，然后从这些字节代码中定义出一个 Java 类，即 java.lang.Class类的一个实例。除此之外，ClassLoader还负责加载 Java 应用所需的资源，如图像文件和配置文件等。为了完成加载类的这个职责，ClassLoader提供了一系列的方法: getParent() 返回该类加载器的父类加载器。 loadClass(String name) 加载名称为 name的类，返回的结果是 java.lang.Class类的实例。 findClass(String name) 查找名称为 name的类，返回的结果是 java.lang.Class类的实例。 findLoadedClass(String name) 查找名称为 name的已经被加载过的类，返回的结果是 java.lang.Class类的实例。 defineClass(String name, byte[] b, int off, int len) 把字节数组 b中的内容转换成 Java 类，返回的结果是java.lang.Class类的实例。这个方法被声明为 final的。 resolveClass(Class) 类加载器种类JVM提供如下四种类加载器： 启动类加载器负责加载Java_Home\\lib中的class文件。 扩展类加载器负责加载Java_Home\\lib\\ext目录下的class文件。 应用程序类加载器负责加载用户classpath下的class文件。 自定义类加载器 类加载的内存分布情况引导类加载器(Bootstrap ClassLoader）加载系统类后，JVM内存会呈现如下格局： 引导类加载器将类信息加载到方法区中，以特定方式组织，对于某一个特定的类而言，在方法区中它应该有：运行时常量池、类型信息、字段信息、方法信息、类加载器的引用，对应class实例的引用等信息。 类加载器的引用,由于这些类是由引导类加载器(Bootstrap Classloader)进行加载的，而引导类加载器是有C++语言实现的，所以是无法访问的，故而该引用为NULL。 对应class实例的引用，类加载器在加载类信息放到方法区中后，会创建一个对应的Class 类型的实例放到堆(Heap)中, 作为开发人员访问方法区中类定义的入口和切入点。 双亲委派模型工作过程如果一个类加载器收到了加载类的请求，它首先将请求交由父类加载器加载；若父类加载器加载失败，当前类加载器才会自己加载类。 作用像java.lang.Object这些存放在rt.jar中的类，无论使用哪个类加载器加载，最终都会委派给最顶端的启动类加载器加载，从而使得不同加载器加载的Object类都是同一个。 原理双亲委派模型的代码在java.lang.ClassLoader类中的loadClass函数中实现，其逻辑如下： （1）首先检查类是否被加载；（2）若未加载，则调用父类加载器的loadClass方法；（3）若该方法抛出ClassNotFoundException异常，则表示父类加载器无法加载，则当前类加载器调用findClass加载类；（4）若父类加载器可以加载，则直接返回Class对象； 加载类的过程类在加载过程中类加载器会首先委托给其它类加载器来尝试加载某个类。 这就意味着真正完成类的加载工作的类加载器和启动这个加载过程的类加载器，有可能不是同一个。 真正完成类的加载工作是通过调用 defineClass来实现的；而启动类的加载过程是通过调用 loadClass来实现的。 前者称为一个类的定义加载器（defining loader），后者称为初始加载器（initiating loader）。 在 Java 虚拟机判断两个类是否相同的时候，使用的是类的定义加载器。也就是说，哪个类加载器启动类的加载过程并不重要，重要的是最终定义这个类的加载器。 两种类加载器的关联之处在于：一个类的定义加载器是它引用的其它类的初始加载器。如类 com.example.Outer引用了类 com.example.Inner，则由类 com.example.Outer的定义加载器负责启动类 com.example.Inner的加载过程。方法 loadClass()抛出的是 java.lang.ClassNotFoundException异常；方法 defineClass()抛出的是 java.lang.NoClassDefFoundError异常。 类加载器在成功加载某个类之后，会把得到的 java.lang.Class类的实例缓存起来。下次再请求加载该类的时候，类加载器会直接使用缓存的类的实例，而不会尝试再次加载。也就是说，对于一个类加载器实例来说，相同全名的类只加载一次，即 loadClass方法不会被重复调用。 ClassNotFoundException当应用程序试图使用以下方法通过字符串名加载类时，抛出该异常： Class 类中的 forName 方法。 ClassLoader 类中的 findSystemClass 方法。 ClassLoader 类中的 loadClass 方法。 但是没有找到具有指定名称的类的定义。从 1.4 版本开始，此异常已经更新，以符合通用的异常链机制。 在构造时提供并通过 getException() 方法访问的“加载类时引发的可选异常”，现在被称为原因，它可以通过 Throwable.getCause() 方法以及与上面提到的“遗留方法”来访问。 NoClassDefFoundError当 Java 虚拟机或 ClassLoader 实例试图在类的定义中加载（作为通常方法调用的一部分或者作为使用 new 表达式创建的新实例的一部分），但无法找到该类的定义时，抛出此异常。 引起NoClassDefFoundError的三种情况： JAR重复引入，版本不一致导至 打程序版本时，没有把关联类打出去（这种情况一般是） java.lang.nosuchmethoderror 还有一种情况是A引用B时，B初始化失败时也会导致以上的错误出现。","tags":"java jvm"},{"title":"设计模式-装饰器模式","url":"/posts/4f101877.html","text":"模式定义装饰者模式(Decorator Pattern)：动态地给一个对象增加一些额外的职责，增加对象功能来说，装饰模式比生成子类实现更为灵活。装饰模式是一种对象结构型模式。 模式原理让装饰器实现被包装类（Concrete Component）相同的接口（Component）（使得装饰器与被扩展类类型一致），并在构造函数中传入该接口（Component）对象，然后就可以在接口需要实现的方法中在被包装类对象的现有功能上添加新功能了。 模式角色 抽象组件（Component）：可以是一个接口或者抽象类，其充当被装饰类的原始对象，规定了被装饰对象的行为； 具体组件（ConcreteComponent）：实现/继承 Component 的一个具体对象，也即 被装饰对象； 抽象装饰器（Decorator）：通用的装饰 ConcreteComponent 的装饰器，其内部必然有一个属性指向 Component抽象组件；其实现一般是一个抽象类，主要是为了让其子类按照其构造形式传入一个 Component抽象组件，这是强制的通用行为（当然，如果系统中装饰逻辑单一，并不需要实现许多装饰器，那么我们可以直接省略该类，而直接实现一个 具体装饰器（ConcreteDecorator） 即可）； 具体装饰器（ConcreteDecorator）：Decorator 的具体实现类，理论上，每个 ConcreteDecorator 都扩展了 Component 对象的一种功能； 装饰模式 角色分配符合设计模式 里氏替换原则，依赖倒置原则，从而使得其具备很强的扩展性，最终满足 开闭原则。 UML类图 模式优点 对于扩展一个对象的功能，装饰模式比继承更加灵活性，不会导致类的个数急剧增加。 可以通过一种动态的方式来扩展一个对象的功能，通过配置文件可以在运行时选择不同的具体装饰类，从而实现不同的行为。 可以对一个对象进行多次装饰，通过使用不同的具体装饰类以及这些装饰类的排列组合，可以创造出很多不同行为的组合，得到功能更为强大的对象。 具体组件类与具体装饰类可以独立变化，用户可以根据需要增加新的具体构件类和具体装饰类，原有类库代码无须改变，符合 “开闭原则”。 模式缺点 使用装饰模式进行系统设计时将产生很多小对象，这些对象的区别在于它们之间相互连接的方式有所不同，而不是它们的类或者属性值有所不同，大量小对象的产生势必会占用更多的系统资源，在一定程序上影响程序的性能。 装饰模式提供了一种比继承更加灵活机动的解决方案，但同时也意味着比继承更加易于出错，排错也很困难，对于多次装饰的对象，调试时寻找错误可能需要逐级排查，较为繁琐。 应用场景 需要扩展一个类的功能，或给一个类增加附加功能； 需要动态地给一个对象增加功能，且这些功能可以再动态地撤销； 需要为一批的兄弟类进行改装或加装功能； 应用示例示例背景所谓人靠衣装马靠鞍，假设现在要为男人增加穿衣服的功能（穿裤子、穿内衣、穿外套）。 分析以 装饰模式 的角度来看待上述例子，「人」属于 Component 角色；「男人」 属于 ConcreteComponent 角色，因此，「男人」 是被装饰对象；「穿衣服」 是功能扩展，属于 Decorator 角色；而「穿裤子」，「穿内衣」，「穿外套」 是3个具体功能扩展，均属于 ConcreteDecorator 角色； 使用步骤抽象组件(Component)123456789101112package main.java.com.study.designPatterns.decorator.demoOne;/** * @author: whb * @description: 定义人--抽象组件（Component） */public interface IPerson &#123; /** * 穿衣服 */ void dress();&#125; 具体组件(ConcreteComponent)12345678910111213package main.java.com.study.designPatterns.decorator.demoOne;/** * @author: whb * @description: 定义男人--具体组件（ConcreteComponent），即被修饰者 */public class Man implements IPerson &#123; @Override public void dress() &#123; System.out.println(\"穿了内裤！\"); &#125;&#125; 抽象装饰器(Decorator)12345678910111213141516171819202122package main.java.com.study.designPatterns.decorator.demoOne;/** * @author: whb * @description: 定义衣服--抽象装饰器（Decorator），接收一个具体的Component，本身也是一个Component */public abstract class ClothesDecorator implements IPerson &#123; protected IPerson mPerson; /** * 构造方法：强制子类构造器必须传入一个IPerson */ public ClothesDecorator(IPerson person) &#123; this.mPerson = person; &#125; @Override public void dress() &#123; this.mPerson.dress(); &#125;&#125; 具体装饰器(ConcreteDecorator)TrousersDecorator123456789101112131415161718192021222324252627282930package main.java.com.study.designPatterns.decorator.demoOne;/** * @author: whb * @description: 裤子装饰器-具体装饰器（ConcreteDecorator） */public class TrousersDecorator extends ClothesDecorator &#123; /** * 构造方法：强制子类构造器必须传入一个IPerson * * @param person */ public TrousersDecorator(IPerson person) &#123; super(person); &#125; @Override public void dress() &#123; super.dress(); this.dressTrousers(); &#125; /** * 穿裤子 */ private void dressTrousers() &#123; System.out.println(\"穿上裤子了！\"); &#125;&#125; UnderClothesDecorator123456789101112131415161718192021222324252627282930package main.java.com.study.designPatterns.decorator.demoOne;/** * @author: whb * @description: 内衣装饰器 */public class UnderClothesDecorator extends ClothesDecorator &#123; /** * 构造方法：强制子类构造器必须传入一个IPerson * * @param person */ public UnderClothesDecorator(IPerson person) &#123; super(person); &#125; @Override public void dress() &#123; super.dress(); this.dressUnderClothes(); &#125; /** * 穿内衣 */ private void dressUnderClothes() &#123; System.out.println(\"穿上内衣了！\"); &#125;&#125; OvercoatDecorator123456789101112131415161718192021222324252627282930package main.java.com.study.designPatterns.decorator.demoOne;/** * @author: whb * @description: 外套装饰器 */public class OvercoatDecorator extends ClothesDecorator &#123; /** * 构造方法：强制子类构造器必须传入一个IPerson * * @param person */ public OvercoatDecorator(IPerson person) &#123; super(person); &#125; @Override public void dress() &#123; super.dress(); this.dressOvercoat(); &#125; /** * 穿外套 */ private void dressOvercoat() &#123; System.out.println(\"穿上外套了！\"); &#125;&#125; 客户端调用12345678910111213141516171819202122232425262728package main.java.com.study.designPatterns.decorator.demoOne;/** * @author: whb * @description: 客户端调用 */public class Client &#123; public static void main(String[] args) &#123; IPerson person = new Man(); person.dress(); System.out.println(\"----------------------\"); System.out.println(\"增加裤子装饰器\"); person = new TrousersDecorator(person); person.dress(); System.out.println(\"----------------------\"); System.out.println(\"再增加内衣装饰器\"); person = new UnderClothesDecorator(person); person.dress(); System.out.println(\"----------------------\"); System.out.println(\"再增加外套装饰器\"); person = new OvercoatDecorator(person); person.dress(); &#125;&#125; 上面代码中客户是为new Man()这个IPerson一件一件的进行衣服试穿，太浪费时间了，完全可以使用装饰器嵌套（因为装饰器接收一个IPerson，而自己同时也是一个IPerson，因此完全支持嵌套）模式，这样一次性就穿完，代码如下： 123456789101112package main.java.com.study.designPatterns.decorator.demoOne;/** * @author: whb * @description: 装饰器嵌套 */public class Client2 &#123; public static void main(String[] args) &#123; IPerson person = new OvercoatDecorator(new UnderClothesDecorator(new TrousersDecorator(new Man()))); person.dress(); &#125;&#125;","tags":"java 设计模式"},{"title":"设计模式-建造者模式","url":"/posts/2a48474d.html","text":"模式定义建造者模式(Builder Pattern)：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。建造者模式是一种对象创建型模式。 建造者模式一步一步创建一个复杂的对象，它允许用户只通过指定复杂对象的类型和内容就可以构建它们，用户不需要知道内部的具体构建细节。 主要作用 降低创建复杂对象的复杂度； 隔离了创建对象的构建过程 &amp; 表示。 UML类图 角色 抽象建造者（Builder）：主要用于规范产品Product对象的各个组成部分，并提供一个返回完整产品的接口，在该接口中一般声明两类方法，一类方法是buildPartX()，它们用于创建复杂对象的各个部件；另一类方法是getResult()，它们用于返回复杂对象。Builder既可以是抽象类，也可以是接口。 具体建造者（Concrete Builder）：实现 抽象建造者 规定的各个方法，返回一个组建好的具体产品。 产品（Product）：它是被构建的复杂对象，包含多个组成部件，具体建造者创建该产品的内部表示并定义它的装配过程。 导演者（Director）：又称指挥者，它负责安排复杂对象的建造次序，指挥者与抽象建造者之间存在关联关系，可以在其construct()建造方法中调用建造者对象的部件构造与装配方法，完成复杂对象的建造。客户端一般只需要与指挥者进行交互，在客户端确定具体建造者的类型，并实例化具体建造者对象（也可以通过配置文件和反射机制），然后通过指挥者类的构造函数或者Setter方法将该对象传入指挥者类中。 总结： 建造者模式 最终返回一个具体的构建复杂的产品； 系统中产品可能只有一种类型或多种类型，但对某些产品族来说，它们具备相同的行为，因此对这些共性行为进行抽象，抽离出 抽象建造者（Builder）； 而对这些行为的具体构建过程，则交由 具体建造者（Concrete Builder） 负责，不同的 具体建造者 会构建出不同表示的产品； 而具体要构建出哪种产品，由 导演者（Director） 决定。导演者 会选择不同的 具体建造者，指导它构建出产品。 模式优点 在建造者模式中，客户端不必知道产品内部组成的细节，将产品本身与产品的创建过程解耦，使得相同的创建过程可以创建不同的产品对象。 每一个具体建造者都相对独立，而与其他的具体建造者无关，因此可以很方便地替换具体建造者或增加新的具体建造者，用户使用不同的具体建造者即可得到不同的产品对象。由于指挥者类针对抽象建造者编程，增加新的具体建造者无须修改原有类库的代码，系统扩展方便，符合 “开闭原则”。 可以更加精细地控制产品的创建过程。将复杂产品的创建步骤分解在不同的方法中，使得创建过程更加清晰，也更方便使用程序来控制创建过程。 模式缺点 建造者模式所创建的产品一般具有较多的共同点，其组成部分相似；如果产品之间的差异性很大，则不适合使用建造者模式，因此其使用范围受到一定的限制。 如果产品的内部变化复杂，可能会导致需要定义很多具体建造者类来实现这种变化，导致系统变得很庞大。 适用场景 需要生成的产品对象有复杂的内部结构，这些产品对象通常包含多个成员属性。 需要生成的产品对象的属性相互依赖，需要指定其生成顺序。 对象的创建过程独立于创建该对象的类。在建造者模式中通过引入了指挥者类，将创建过程封装在指挥者类中，而不在建造者类和客户类中。 隔离复杂对象的创建和使用，并使得相同的创建过程可以创建不同的产品。 模式示例以工厂制造电脑为例。 产品角色123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105package main.java.com.study.designPatterns.builder.demoOne;/** * @author: whb * @description: 产品角色--电脑 */public class Computer &#123; /** * 品牌 */ private String brand; /** * cpu */ private String cpu; /** * 主板 */ private String mainBoard; /** * 硬盘 */ private String hardDisk; /** * 显卡 */ private String displayCard; /** * 电源 */ private String power; /** * 内存 */ private String memory; public String getBrand() &#123; return brand; &#125; public void setBrand(String brand) &#123; this.brand = brand; &#125; public String getCpu() &#123; return cpu; &#125; public void setCpu(String cpu) &#123; this.cpu = cpu; &#125; public String getMainBoard() &#123; return mainBoard; &#125; public void setMainBoard(String mainBoard) &#123; this.mainBoard = mainBoard; &#125; public String getHardDisk() &#123; return hardDisk; &#125; public void setHardDisk(String hardDisk) &#123; this.hardDisk = hardDisk; &#125; public String getDisplayCard() &#123; return displayCard; &#125; public void setDisplayCard(String displayCard) &#123; this.displayCard = displayCard; &#125; public String getPower() &#123; return power; &#125; public void setPower(String power) &#123; this.power = power; &#125; public String getMemory() &#123; return memory; &#125; public void setMemory(String memory) &#123; this.memory = memory; &#125; @Override public String toString() &#123; return \"Computer&#123;\" + \"brand='\" + brand + '\\'' + \", cpu='\" + cpu + '\\'' + \", mainBoard='\" + mainBoard + '\\'' + \", hardDisk='\" + hardDisk + '\\'' + \", displayCard='\" + displayCard + '\\'' + \", power='\" + power + '\\'' + \", memory='\" + memory + '\\'' + '&#125;'; &#125;&#125; 抽象建造者1234567891011121314151617181920212223242526272829303132333435package main.java.com.study.designPatterns.builder.demoOne;/** * @author: whb * @description: 抽象建造者 */public abstract class Builder &#123; /** * 产品角色 */ protected Computer computer = new Computer(); public abstract void buildBrand(); public abstract void buildCPU(); public abstract void buildMainBoard(); public abstract void buildHardDisk(); public abstract void buildDisplayCard(); public abstract void buildPower(); public abstract void buildMemory(); /** * 制造电脑 * * @return */ public Computer createComputer() &#123; return computer; &#125;&#125; 具体建造者12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package main.java.com.study.designPatterns.builder.demoOne;/** * @author: whb * @description: 具体建造者--戴尔 */public class DellComputerBuilder extends Builder &#123; @Override public void buildBrand() &#123; computer.setBrand(\"戴尔电脑\"); &#125; @Override public void buildCPU() &#123; computer.setCpu(\"i5-8300H 四核\"); &#125; @Override public void buildMainBoard() &#123; computer.setMainBoard(\"戴尔主板\"); &#125; @Override public void buildHardDisk() &#123; computer.setHardDisk(\"1T + 128GB SSD\"); &#125; @Override public void buildDisplayCard() &#123; computer.setDisplayCard(\"GTX1060 独立6GB\"); &#125; @Override public void buildPower() &#123; computer.setPower(\"4芯 锂离子电池 180W AC适配器\"); &#125; @Override public void buildMemory() &#123; computer.setMemory(\"4G + 4G\"); &#125;&#125;package main.java.com.study.designPatterns.builder.demoOne;/** * @author: whb * @description: 具体建造者--华硕电脑 */public class ASUSComputerBuilder extends Builder &#123; @Override public void buildBrand() &#123; computer.setBrand(\"华硕电脑\"); &#125; @Override public void buildCPU() &#123; computer.setCpu(\"Intel 第8代 酷睿\"); &#125; @Override public void buildMainBoard() &#123; computer.setMainBoard(\"华硕主板\"); &#125; @Override public void buildHardDisk() &#123; computer.setHardDisk(\"256GB SSD\"); &#125; @Override public void buildDisplayCard() &#123; computer.setDisplayCard(\"MX150 独立2GB\"); &#125; @Override public void buildPower() &#123; computer.setPower(\"3芯 锂离子电池 65W AC适配器\"); &#125; @Override public void buildMemory() &#123; computer.setMemory(\"1 x SO-DIMM 8GB\"); &#125;&#125; 测试类12345678910111213141516171819202122232425262728package main.java.com.study.designPatterns.builder.demoOne;/** * @author: whb * @description: 测试类 */public class TestBuilder &#123; public static void main(String[] args) &#123; ComputerDirector director = new ComputerDirector(); //华硕电脑 Builder asusBuilder = new ASUSComputerBuilder(); Computer asusComputer = director.construct(asusBuilder); System.out.println(asusComputer.toString()); //戴尔电脑--通过反射机制创建具体建造者 try &#123; Class clazz = Class.forName(\"main.java.com.study.designPatterns.builder.demoOne.DellComputerBuilder\"); Builder dellBuilder = (DellComputerBuilder) clazz.newInstance(); Computer dellComputer = director.construct(dellBuilder); System.out.println(dellComputer.toString()); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; catch (InstantiationException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 建造者模式与工厂模式的区别建造者模式 与 工厂模式 的唯一区别就在于 构建复杂对象，这其实是它们的本质区别。而从表现形式上看，建造者模式 比 工厂模式 多了一个 导演者（Director）的角色。如果忽略 导演者，那么 建造者模式 与 工厂模式 几乎是一样的。 从上文 建造者模式 UML 类图中可以看到，导演者 是负责沟通 客户 与 具体建造者 的桥梁，也就是说，导演者 解耦了 客户 与 具体建造者。因为 具体建造者 属于细节实现，是底层模块，业务经常变换，不稳定；而 客户 属于上层模块，是业务逻辑部分，相对稳定；如果不设置 导演者 作为中间人，直接把 具体建造者 嵌入到业务逻辑（客户）中，会导致当业务改变（产品改变）时，需要更换 具体建造者，侵入了业务逻辑（客户）代码，不符合设计模式的迪米特法则。 而 工厂模式 之所以没有 导演者 这个角色，是因为 工厂 本身就担当了该角色。因为 导演者 最终的作用就是提供一个组装好的对象给到 客户，与 工厂 的作用一致。只是由于 工厂 生产的都是简单对象，因此 工厂 直接提供给 客户 就行了；而 建造者模式 提供的是复杂对象，需要专门的构建过程，因此借助 导演者 去沟通 具体的建造者 构建出相应的复杂对象，然后由 导演者 返回给 客户。","tags":"java 设计模式"},{"title":"JDK动态代理","url":"/posts/dfdc2005.html","text":"代理模式实现方式介绍什么是代理模式日常生活中我们经常会碰到代理模式，例如我们找房产中介帮我们找房子，找婚姻中介帮我们介绍对象，找保洁帮我们打理房间等。在无形中运用到了代理模式。 为什么要使用代理？运用代理可以使我们的生活更加便利，有了代理，我们不需要自己去找房子，不需要自己去找对象，不需要自己去打理房间。当然，你也可以选择一切都自己来干，但是存在前提条件，一是你是否都具备这样的资源和能力来做这些事情，二是你是否愿意花费这么多精力和时间来做这些事情。总之，代理模式使我们各专其事，我们可以将时间消耗在美好的事情上，而不用天天被一些琐事所羁绊。 代理模式有哪些实现？Java中的代理有静态代理和动态代理，下面分别用一个简单的例子来介绍一下静态代理和动态代理代码实现。 静态代理代理接口12345678910111213package main.java.com.study.designPatterns.proxy.staticProxy;/** * @author: whb * @description: 代理接口 */public interface UserDao &#123; /** * 保存 */ void save();&#125; 目标对象12345678910111213package main.java.com.study.designPatterns.proxy.staticProxy;/** * @author: whb * @description: 目标对象 */public class UserDaoImpl implements UserDao &#123; @Override public void save() &#123; System.out.println(\"正在保存用户...\"); &#125;&#125; 代理对象1234567891011121314151617181920212223242526272829303132package main.java.com.study.designPatterns.proxy.staticProxy;/** * @author: whb * @description: 代理对象 */public class TransactionHandler implements UserDao &#123; /** * 目标代理对象 */ private UserDaoImpl target; /** * 构造代理对象时传入目标对象 * * @param target */ public TransactionHandler(UserDaoImpl target) &#123; this.target = target; &#125; @Override public void save() &#123; //调用目标方法前的处理 System.out.println(\"开启事务控制...\"); //调用目标对象的方法 target.save(); //调用目标方法后的处理 System.out.println(\"关闭事务控制...\"); &#125;&#125; 测试调用123456789101112131415161718package main.java.com.study.designPatterns.proxy.staticProxy;/** * @author: whb * @description: 测试静态代理 */public class TestStaticProxy &#123; public static void main(String[] args) &#123; //新建目标对象 UserDaoImpl target = new UserDaoImpl(); //创建代理对象, 并使用接口对其进行引用 UserDao userDao = new TransactionHandler(target); //针对接口进行调用 userDao.save(); &#125;&#125; 测试结果123开启事务控制...正在保存用户...关闭事务控制... 总结静态代理实现简单也容易理解，但是静态代理不能使一个代理类反复作用于多个目标对象，代理对象直接持有目标对象的引用，这导致代理对象和目标对象类型紧密耦合了在一起。如果UserDao接口下还有另一个实现类也需要进行事务控制，那么就要重新写一个代理类，这样就会产生许多重复的模版代码，不能达到代码复用的目的。而动态代理就可以很好的解决这样的问题。 动态代理代理接口12345678910111213package main.java.com.study.designPatterns.proxy.JdkProxy;/** * @author: whb * @date: 2019/9/4 9:50 * @description: 代理接口 */public interface UserDao &#123; /** * 保存用户 */ void save();&#125; 目标对象1234567891011121314package main.java.com.study.designPatterns.proxy.JdkProxy;/** * @author: whb * @date: 2019/9/4 9:51 * @description: 目标对象 */public class UserDaoImpl implements UserDao &#123; @Override public void save() &#123; System.out.println(\"保存用户信息...\"); &#125;&#125; 代理对象123456789101112131415161718192021222324252627282930313233343536package main.java.com.study.designPatterns.proxy.JdkProxy;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;/** * @author: whb * @description: 代理对象 */public class TransactionHandler implements InvocationHandler &#123; /** * 需要代理的目标对象，这里设计为可以为任意对象添加事务控制, 所以将目标对象声明为Object */ private Object target; /** * 构造TransactionHandler时传入目标对象 * * @param target */ public TransactionHandler(Object target) &#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //调用目标方法前的处理 System.out.println(\"开启事务控制...\"); //调用目标对象的方法 Object result = method.invoke(target, args); //调用目标方法后的处理 System.out.println(\"关闭事务控制...\"); //放回方法调用结果 return result; &#125;&#125; 测试类123456789101112131415161718192021222324package main.java.com.study.designPatterns.proxy.JdkProxy;import java.lang.reflect.Proxy;/** * @author: whb * @description: 测试JDK动态代理 */public class TestJdkProxy &#123; public static void main(String[] args) &#123; //新建目标对象 Object target = new UserDaoImpl(); //创建事务处理器 TransactionHandler handler = new TransactionHandler(target); //生成代理类并使用接口对其进行引用 UserDao userDao = (UserDao) Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), handler); //针对接口进行方法调用 userDao.save(); &#125;&#125; 测试结果123开启事务控制...保存用户信息...关闭事务控制... 总结之前发现静态代理会产生许多重复代码，不能很好的进行代码复用，而动态代理能够很好的解决这个问题，代理类TransactionHandler实现了InvocationHandler接口，并且它持有的目标对象类型是Object，因此事务控制代理类TransactionHandler能够代理任意的对象，为任意的对象添加事务控制的逻辑。因此动态代理才真正的将代码中横向切面的逻辑剥离了出来，起到代码复用的目的。 但是动态代理也有缺点，一是它的实现比静态代理更加复杂也不好理解；二是它存在一定的限制，例如它要求需要代理的对象必须实现了某个接口；三是它不够灵活，动态代理会为接口中的声明的所有方法添加上相同的代理逻辑。 JDK动态代理的底层实现Proxy分析在动态代理的测试类TestJdkProxy中使用了Proxy类的静态方法newProxyInstance方法去生成一个代理类，这个静态方法接收三个参数，分别是目标类的类加载器，目标类实现的接口集合，InvocationHandler实例，最后返回一个Object类型的代理类。先从该方法开始，看看代理类是怎样一步一步造出来的。 newProxyInstance方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * 返回指定接口的代理类的实例，该接口将方法调用分发给指定的调用处理程序。这个静态方法有三个参数： * @param ClassLoader loader，指定当前目标对象使用类加载器 * @param Class&lt;?&gt;[ ] interfaces，目标对象实现的接口的类型,使用泛型方式确认类型 * @param InvocationHandler h，事件处理,执行目标对象的方法时,会触发事件处理器的方法,会把当前执行目标对象的方法作为参数传入 */public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; //验证传入的InvocationHandler不能为空 Objects.requireNonNull(h); //复制代理类实现的所有接口 final Class&lt;?&gt;[] intfs = interfaces.clone(); //获取安全管理器 final SecurityManager sm = System.getSecurityManager(); //进行一些权限检验 if (sm != null) &#123; checkProxyAccess(Reflection.getCallerClass(), loader, intfs); &#125; /* * 该方法先从缓存获取代理类, 如果没有再去生成一个代理类 */ Class&lt;?&gt; cl = getProxyClass0(loader, intfs); /* * 使用指定的调用处理程序调用其构造函数. */ try &#123; //进行一些权限检验 if (sm != null) &#123; checkNewProxyPermission(Reflection.getCallerClass(), cl); &#125; //获取参数类型是InvocationHandler.class的代理类构造器 final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; //如果代理类是不可访问的, 就使用特权将它的构造器设置为可访问 if (!Modifier.isPublic(cl.getModifiers())) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; cons.setAccessible(true); return null; &#125; &#125;); &#125; //所有代理类都继承自Proxy, 因此这里会调用Proxy的构造器将InvocationHandler引用传入去构造一个代理类的实例 return cons.newInstance(new Object[]&#123;h&#125;); &#125; catch (IllegalAccessException|InstantiationException e) &#123; throw new InternalError(e.toString(), e); &#125; catch (InvocationTargetException e) &#123; Throwable t = e.getCause(); if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else &#123; throw new InternalError(t.toString(), t); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString(), e); &#125;&#125; newProxyInstance方法首先是对参数进行一些权限校验，之后通过调用getProxyClass0方法生成了代理类的类对象，然后获取参数类型是InvocationHandler.class的代理类构造器。检验构造器是否可以访问，最后传入InvocationHandler实例的引用去构造出一个代理类实例，InvocationHandler实例的引用其实是Proxy持有着，因为生成的代理类默认继承自Proxy，所以最后会调用Proxy的构造器将引用传入。 getProxyClass0方法下面看下getProxyClass0这个方法，看看代理类的Class对象是怎样来的。 123456789101112/** * 生成一个代理类。必须调用checkProxyAccess方法，在调用这个方法之前需要检查权限。 */ private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; //目标类实现的接口不能大于65535 if (interfaces.length &gt; 65535) &#123; throw new IllegalArgumentException(\"interface limit exceeded\"); &#125; //如果由给定的装载机定义的代理类实现给定的接口存在，这将会返回缓存；否则，它将通过ProxyClassFactory创建代理类。 return proxyClassCache.get(loader, interfaces);&#125; getProxyClass0方法内部没有多少内容，首先是检查目标代理类实现的接口不能大于65535这个数，之后是通过类加载器和接口集合去缓存里面获取，如果能找到代理类就直接返回，否则就会调用ProxyClassFactory这个工厂去生成一个代理类。 ProxyClassFactory工厂类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485//代理类生成工厂private static final class ProxyClassFactory implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; &#123; //代理类名称前缀 private static final String proxyClassNamePrefix = \"$Proxy\"; //用原子类来生成代理类的序号, 以此来确定唯一的代理类 private static final AtomicLong nextUniqueNumber = new AtomicLong(); @Override public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt;[] interfaces) &#123; Map&lt;Class&lt;?&gt;, Boolean&gt; interfaceSet = new IdentityHashMap&lt;&gt;(interfaces.length); for (Class&lt;?&gt; intf : interfaces) &#123; //这里遍历interfaces数组进行验证, 主要做三件事情 /* * 1.intf是否可以由指定的类加载进行加载 */ Class&lt;?&gt; interfaceClass = null; try &#123; interfaceClass = Class.forName(intf.getName(), false, loader); &#125; catch (ClassNotFoundException e) &#123; &#125; if (interfaceClass != intf) &#123; throw new IllegalArgumentException( intf + \" is not visible from class loader\"); &#125; /* * 2.intf是否是一个接口 */ if (!interfaceClass.isInterface()) &#123; throw new IllegalArgumentException( interfaceClass.getName() + \" is not an interface\"); &#125; /* * 3.intf在数组中是否有重复 */ if (interfaceSet.put(interfaceClass, Boolean.TRUE) != null) &#123; throw new IllegalArgumentException( \"repeated interface: \" + interfaceClass.getName()); &#125; &#125; //生成代理类的包名 String proxyPkg = null; //生成代理类的访问标志, 默认是public final的 int accessFlags = Modifier.PUBLIC | Modifier.FINAL; for (Class&lt;?&gt; intf : interfaces) &#123; //获取接口的访问标志 int flags = intf.getModifiers(); //如果接口的访问标志不是public, 那么生成代理类的包名和接口包名相同 if (!Modifier.isPublic(flags)) &#123; //生成的代理类的访问标志设置为final accessFlags = Modifier.FINAL; //获取接口全限定名, 例如：java.util.Collection String name = intf.getName(); int n = name.lastIndexOf('.'); //剪裁后得到包名:java.util String pkg = ((n == -1) ? \"\" : name.substring(0, n + 1)); //生成的代理类的包名和接口包名是一样的 if (proxyPkg == null) &#123; proxyPkg = pkg; &#125; else if (!pkg.equals(proxyPkg)) &#123; //代理类如果实现不同包的接口, 并且接口都不是public的, 那么就会在这里报错 throw new IllegalArgumentException( \"non-public interfaces from different packages\"); &#125; &#125; &#125; //如果接口访问标志都是public的话, 那生成的代理类都放到默认的包下：com.sun.proxy if (proxyPkg == null) &#123; proxyPkg = ReflectUtil.PROXY_PACKAGE + \".\"; &#125; //生成代理类的序号 long num = nextUniqueNumber.getAndIncrement(); //生成代理类的全限定名, 包名+前缀+序号, 例如：com.sun.proxy.$Proxy0 String proxyName = proxyPkg + proxyClassNamePrefix + num; //这里是核心, 用ProxyGenerator来生成字节码, 该类放在sun.misc包下 byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces, accessFlags); try &#123; //根据二进制文件生成相应的Class实例 return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); &#125; catch (ClassFormatError e) &#123; throw new IllegalArgumentException(e.toString()); &#125; &#125;&#125; 该工厂的apply方法会被调用用来生成代理类的Class对象，由于代码的注释比较详细，只挑关键点进行阐述。 在代码中可以看到JDK生成的代理类的类名是“$Proxy”+序号。 如果接口是public的，代理类默认是public final的，并且生成的代理类默认放到com.sun.proxy这个包下。 如果接口是非public的，那么代理类也是非public的，并且生成的代理类会放在对应接口所在的包下。 如果接口是非public的，并且这些接口不在同一个包下，那么就会报错。 WeakCache缓存的实现机制Proxy内部用到了缓存机制，如果根据提供的类加载器和接口数组能在缓存中找到代理类就直接返回该代理类，否则会调用ProxyClassFactory工厂去生成代理类。这里用到的缓存是二级缓存，它的一级缓存key是根据类加载器生成的，二级缓存key是根据接口数组生成的。具体的内部机制直接上代码详细解释。 1234567891011121314151617//Reference引用队列private final ReferenceQueue&lt;K&gt; refQueue = new ReferenceQueue&lt;&gt;();//缓存的底层实现, key为一级缓存, value为二级缓存。 为了支持null, map的key类型设置为Objectprivate final ConcurrentMap&lt;Object, ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt;&gt; map = new ConcurrentHashMap&lt;&gt;();//reverseMap记录了所有代理类生成器是否可用, 这是为了实现缓存的过期机制private final ConcurrentMap&lt;Supplier&lt;V&gt;, Boolean&gt; reverseMap = new ConcurrentHashMap&lt;&gt;();//生成二级缓存key的工厂, 这里传入的是KeyFactoryprivate final BiFunction&lt;K, P, ?&gt; subKeyFactory;//生成二级缓存value的工厂, 这里传入的是ProxyClassFactoryprivate final BiFunction&lt;K, P, V&gt; valueFactory;//构造器, 传入生成二级缓存key的工厂和生成二级缓存value的工厂public WeakCache(BiFunction&lt;K, P, ?&gt; subKeyFactory, BiFunction&lt;K, P, V&gt; valueFactory) &#123; this.subKeyFactory = Objects.requireNonNull(subKeyFactory); this.valueFactory = Objects.requireNonNull(valueFactory);&#125; 首先看一下WeakCache的成员变量和构造器，WeakCache缓存的内部实现是通过ConcurrentMap来完成的，成员变量map就是二级缓存的底层实现，reverseMap是为了实现缓存的过期机制，subKeyFactory是二级缓存key的生成工厂，通过构造器传入，这里传入的值是Proxy类的KeyFactory，valueFactory是二级缓存value的生成工厂，通过构造器传入，这里传入的是Proxy类的ProxyClassFactory。接下来看一下WeakCache的get方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public V get(K key, P parameter) &#123; //这里要求实现的接口不能为空 Objects.requireNonNull(parameter); //清除过期的缓存 expungeStaleEntries(); //将ClassLoader包装成CacheKey, 作为一级缓存的key Object cacheKey = CacheKey.valueOf(key, refQueue); //获取得到二级缓存 ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; valuesMap = map.get(cacheKey); //如果根据ClassLoader没有获取到对应的值 if (valuesMap == null) &#123; //以CAS方式放入, 如果不存在则放入，否则返回原先的值 ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; oldValuesMap = map.putIfAbsent(cacheKey, valuesMap = new ConcurrentHashMap&lt;&gt;()); //如果oldValuesMap有值, 说明放入失败 if (oldValuesMap != null) &#123; valuesMap = oldValuesMap; &#125; &#125; //根据代理类实现的接口数组来生成二级缓存key, 分为key0, key1, key2, keyx Object subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter)); //这里通过subKey获取到二级缓存的值 Supplier&lt;V&gt; supplier = valuesMap.get(subKey); Factory factory = null; //这个循环提供了轮询机制, 如果条件为假就继续重试直到条件为真为止 while (true) &#123; //如果通过subKey取出来的值不为空 if (supplier != null) &#123; //在这里supplier可能是一个Factory也可能会是一个CacheValue //在这里不作判断, 而是在Supplier实现类的get方法里面进行验证 V value = supplier.get(); if (value != null) &#123; return value; &#125; &#125; if (factory == null) &#123; //新建一个Factory实例作为subKey对应的值 factory = new Factory(key, parameter, subKey, valuesMap); &#125; if (supplier == null) &#123; //到这里表明subKey没有对应的值, 就将factory作为subKey的值放入 supplier = valuesMap.putIfAbsent(subKey, factory); if (supplier == null) &#123; //到这里表明成功将factory放入缓存 supplier = factory; &#125; //否则, 可能期间有其他线程修改了值, 那么就不再继续给subKey赋值, 而是取出来直接用 &#125; else &#123; //期间可能其他线程修改了值, 那么就将原先的值替换 if (valuesMap.replace(subKey, supplier, factory)) &#123; //成功将factory替换成新的值 supplier = factory; &#125; else &#123; //替换失败, 继续使用原先的值 supplier = valuesMap.get(subKey); &#125; &#125; &#125;&#125; WeakCache的get方法并没有用锁进行同步，那它是怎样实现线程安全的呢？ 因为它的所有会进行修改的成员变量都使用了ConcurrentMap，这个类是线程安全的。因此它将自身的线程安全委托给了ConcurrentMap， get方法尽可能的将同步代码块缩小，这样可以有效提高WeakCache的性能。 ClassLoader作为了一级缓存的key，这样可以首先根据ClassLoader筛选一遍，因为不同ClassLoader加载的类是不同的。 然后它用接口数组来生成二级缓存的key，这里它进行了一些优化，因为大部分类都是实现了一个或两个接口，所以二级缓存key分为key0，key1，key2，keyX。key0到key2分别表示实现了0到2个接口，keyX表示实现了3个或以上的接口，事实上大部分都只会用到key1和key2。这些key的生成工厂是在Proxy类中，通过WeakCache的构造器将key工厂传入。这里的二级缓存的值是一个Factory实例，最终代理类的值是通过Factory这个工厂来获得的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152private final class Factory implements Supplier&lt;V&gt; &#123; //一级缓存key, 根据ClassLoader生成 private final K key; //代理类实现的接口数组 private final P parameter; //二级缓存key, 根据接口数组生成 private final Object subKey; //二级缓存 private final ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; valuesMap; Factory(K key, P parameter, Object subKey, ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; valuesMap) &#123; this.key = key; this.parameter = parameter; this.subKey = subKey; this.valuesMap = valuesMap; &#125; @Override public synchronized V get() &#123; //这里再一次去二级缓存里面获取Supplier, 用来验证是否是Factory本身 Supplier&lt;V&gt; supplier = valuesMap.get(subKey); if (supplier != this) &#123; //在这里验证supplier是否是Factory实例本身, 如果不则返回null让调用者继续轮询重试 //期间supplier可能替换成了CacheValue, 或者由于生成代理类失败被从二级缓存中移除了 return null; &#125; V value = null; try &#123; //委托valueFactory去生成代理类, 这里会通过传入的ProxyClassFactory去生成代理类 value = Objects.requireNonNull(valueFactory.apply(key, parameter)); &#125; finally &#123; //如果生成代理类失败, 就将这个二级缓存删除 if (value == null) &#123; valuesMap.remove(subKey, this); &#125; &#125; //只有value的值不为空才能到达这里 assert value != null; //使用弱引用包装生成的代理类 CacheValue&lt;V&gt; cacheValue = new CacheValue&lt;&gt;(value); //将包装后的cacheValue放入二级缓存中, 这个操作必须成功, 否则就报错 if (valuesMap.replace(subKey, this, cacheValue)) &#123; //将cacheValue成功放入二级缓存后, 再对它进行标记 reverseMap.put(cacheValue, Boolean.TRUE); &#125; else &#123; throw new AssertionError(\"Should not reach here\"); &#125; //最后返回没有被弱引用包装的代理类 return value; &#125;&#125; 再看看Factory这个内部工厂类，可以看到它的get方法是使用synchronized关键字进行了同步。进行get方法后首先会去验证subKey对应的suppiler是否是工厂本身，如果不是就返回null，而WeakCache的get方法会继续进行重试。如果确实是工厂本身，那么就会委托ProxyClassFactory生成代理类，ProxyClassFactory是在构造WeakCache的时候传入的。所以这里解释了为什么最后会调用到Proxy的ProxyClassFactory这个内部工厂来生成代理类。生成代理类后使用弱引用进行包装并放入reverseMap中，最后会返回原装的代理类。 ProxyGenerator生成代理类的字节码文件通过前面的分析，知道了代理类是通过Proxy类的ProxyClassFactory工厂生成的，这个工厂类会去调用ProxyGenerator类的generateProxyClass()方法来生成代理类的字节码。ProxyGenerator这个类存放在sun.misc包下，该类的generateProxyClass()静态方法的核心内容就是去调用generateClassFile()实例方法来生成Class文件。接下来看看generateClassFile()这个方法内部做了些什么。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128private byte[] generateClassFile() &#123; //第一步, 将所有的方法组装成ProxyMethod对象 //首先为代理类生成toString, hashCode, equals等代理方法 this.addProxyMethod(hashCodeMethod, Object.class); this.addProxyMethod(equalsMethod, Object.class); this.addProxyMethod(toStringMethod, Object.class); //获取接口类 Class[] var1 = this.interfaces; int var2 = var1.length; int var3; Class var4; //遍历每一个接口的每一个方法, 并且为其生成ProxyMethod对象 for(var3 = 0; var3 &lt; var2; ++var3) &#123; var4 = var1[var3]; Method[] var5 = var4.getMethods(); int var6 = var5.length; for(int var7 = 0; var7 &lt; var6; ++var7) &#123; Method var8 = var5[var7]; this.addProxyMethod(var8, var4); &#125; &#125; //对于具有相同签名的代理方法, 检验方法的返回值是否兼容 Iterator var11 = this.proxyMethods.values().iterator(); List var12; while(var11.hasNext()) &#123; var12 = (List)var11.next(); checkReturnTypes(var12); &#125; //第二步, 组装要生成的class文件的所有的字段信息和方法信息 Iterator var15; try &#123; //添加构造器方法 this.methods.add(this.generateConstructor()); var11 = this.proxyMethods.values().iterator(); //遍历缓存中的代理方法 while(var11.hasNext()) &#123; var12 = (List)var11.next(); var15 = var12.iterator(); while(var15.hasNext()) &#123; ProxyGenerator.ProxyMethod var16 = (ProxyGenerator.ProxyMethod)var15.next(); //添加代理类的静态字段, 例如:private static Method m1; this.fields.add(new ProxyGenerator.FieldInfo(var16.methodFieldName, \"Ljava/lang/reflect/Method;\", 10)); //添加代理类的代理方法 this.methods.add(var16.generateMethod()); &#125; &#125; //添加代理类的静态字段初始化方法 this.methods.add(this.generateStaticInitializer()); &#125; catch (IOException var10) &#123; throw new InternalError(\"unexpected I/O Exception\", var10); &#125; //验证方法和字段集合不能大于65535 if (this.methods.size() &gt; 65535) &#123; throw new IllegalArgumentException(\"method limit exceeded\"); &#125; else if (this.fields.size() &gt; 65535) &#123; throw new IllegalArgumentException(\"field limit exceeded\"); &#125; else &#123; //第三步, 写入最终的class文件 //验证常量池中存在代理类的全限定名 this.cp.getClass(dotToSlash(this.className)); //验证常量池中存在代理类父类的全限定名, 父类名为:\"java/lang/reflect/Proxy\" this.cp.getClass(\"java/lang/reflect/Proxy\"); var1 = this.interfaces; var2 = var1.length; //验证常量池存在代理类接口的全限定名 for(var3 = 0; var3 &lt; var2; ++var3) &#123; var4 = var1[var3]; this.cp.getClass(dotToSlash(var4.getName())); &#125; //接下来要开始写入文件了,设置常量池只读 this.cp.setReadOnly(); ByteArrayOutputStream var13 = new ByteArrayOutputStream(); DataOutputStream var14 = new DataOutputStream(var13); try &#123; //1.写入魔数 var14.writeInt(-889275714); //2.写入次版本号 var14.writeShort(0); //3.写入主版本号 var14.writeShort(49); //4.写入常量池 this.cp.write(var14); //5.写入访问修饰符 var14.writeShort(this.accessFlags); //6.写入类索引 var14.writeShort(this.cp.getClass(dotToSlash(this.className))); //7.写入父类索引, 生成的代理类都继承自Proxy var14.writeShort(this.cp.getClass(\"java/lang/reflect/Proxy\")); //8.写入接口计数值 var14.writeShort(this.interfaces.length); Class[] var17 = this.interfaces; int var18 = var17.length; //9.写入接口集合 for(int var19 = 0; var19 &lt; var18; ++var19) &#123; Class var22 = var17[var19]; var14.writeShort(this.cp.getClass(dotToSlash(var22.getName()))); &#125; //10.写入字段计数值 var14.writeShort(this.fields.size()); var15 = this.fields.iterator(); //11.写入字段集合 while(var15.hasNext()) &#123; ProxyGenerator.FieldInfo var20 = (ProxyGenerator.FieldInfo)var15.next(); var20.write(var14); &#125; //12.写入方法计数值 var14.writeShort(this.methods.size()); var15 = this.methods.iterator(); //13.写入方法集合 while(var15.hasNext()) &#123; ProxyGenerator.MethodInfo var21 = (ProxyGenerator.MethodInfo)var15.next(); var21.write(var14); &#125; //14.写入属性计数值, 代理类class文件没有属性所以为0 var14.writeShort(0); //转换成二进制数组输出 return var13.toByteArray(); &#125; catch (IOException var9) &#123; throw new InternalError(\"unexpected I/O Exception\", var9); &#125; &#125;&#125; 可以看到generateClassFile()方法是按照Class文件结构进行动态拼接的。那什么是Class文件呢？ 我们平时编写的Java文件是以.java结尾的，在编写好了之后通过编译器进行编译会生成.class文件，这个.class文件就是Class文件。Java程序的执行只依赖于Class文件，和Java文件是没有关系的。这个Class文件描述了一个类的信息，当我们需要使用到一个类时，Java虚拟机就会提前去加载这个类的Class文件并进行初始化和相关的检验工作，Java虚拟机能够保证在你使用到这个类之前就会完成这些工作，我们只需要安心的去使用它就好了，而不必关心Java虚拟机是怎样加载它的。当然，Class文件并不一定非得通过编译Java文件而来，你甚至可以直接通过文本编辑器来编写Class文件。在这里，JDK动态代理就是通过程序来动态生成Class文件的。 生成Class文件主要分为三步： 第一步：收集所有要生成的代理方法，将其包装成ProxyMethod对象并注册到Map集合中。 第二步：收集所有要为Class文件生成的字段信息和方法信息。 第三步：完成了上面的工作后，开始组装Class文件。 一个类的核心部分就是它的字段和方法。重点聚焦第二步，看看它为代理类生成了哪些字段和方法。在第二步中，按顺序做了下面四件事。 为代理类生成一个带参构造器，传入InvocationHandler实例的引用并调用父类的带参构造器。 遍历代理方法Map集合，为每个代理方法生成对应的Method类型静态域，并将其添加到fields集合中。 遍历代理方法Map集合，为每个代理方法生成对应的MethodInfo对象，并将其添加到methods集合中。 为代理类生成静态初始化方法，该静态初始化方法主要是将每个代理方法的引用赋值给对应的静态字段。 通过以上分析，可以大致知道JDK动态代理最终会生成如下结构的代理类： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class Proxy0 extends Proxy implements UserDao &#123; //第一步, 生成构造器 protected Proxy0(InvocationHandler h) &#123; super(h); &#125; //第二步, 生成静态域 private static Method m1; //hashCode方法 private static Method m2; //equals方法 private static Method m3; //toString方法 private static Method m4; //... //第三步, 生成代理方法 @Override public int hashCode() &#123; try &#123; return (int) h.invoke(this, m1, null); &#125; catch (Throwable e) &#123; throw new UndeclaredThrowableException(e); &#125; &#125; @Override public boolean equals(Object obj) &#123; try &#123; Object[] args = new Object[] &#123;obj&#125;; return (boolean) h.invoke(this, m2, args); &#125; catch (Throwable e) &#123; throw new UndeclaredThrowableException(e); &#125; &#125; @Override public String toString() &#123; try &#123; return (String) h.invoke(this, m3, null); &#125; catch (Throwable e) &#123; throw new UndeclaredThrowableException(e); &#125; &#125; @Override public void save(User user) &#123; try &#123; //构造参数数组, 如果有多个参数往后面添加就行了 Object[] args = new Object[] &#123;user&#125;; h.invoke(this, m4, args); &#125; catch (Throwable e) &#123; throw new UndeclaredThrowableException(e); &#125; &#125; //第四步, 生成静态初始化方法 static &#123; try &#123; Class c1 = Class.forName(Object.class.getName()); Class c2 = Class.forName(UserDao.class.getName()); m1 = c1.getMethod(\"hashCode\", null); m2 = c1.getMethod(\"equals\", new Class[]&#123;Object.class&#125;); m3 = c1.getMethod(\"toString\", null); m4 = c2.getMethod(\"save\", new Class[]&#123;User.class&#125;); //... &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 经过层层分析，深入探究JDK源码，还原动态生成的代理类的本来面目，明白了以下几点： 代理类默认继承Porxy类，因为Java中只支持单继承，所以JDK动态代理只能去实现接口。 代理方法都会去调用InvocationHandler的invoke()方法，因此需要重写InvocationHandler的invoke()方法。 调用invoke()方法时会传入代理实例本身，目标方法和目标方法参数。解释了invoke()方法的参数是怎样来的。","tags":"java 设计模式"},{"title":"Java中try...catch...finally语句中含有return语句的执行情况","url":"/posts/65251ffc.html","text":"首先看几个示例。 示例一（try中有return，finally中没有return）： 12345678910111213141516171819202122232425262728package main.java.com.study.tryCatchFinally;/** * @author: whb * @description: try中有return，finally中没有return */public class DemoOne &#123; public static void main(String[] args) &#123; System.out.println(test()); &#125; private static int test() &#123; int num = 10; try &#123; System.out.println(\"try...\"); return num += 100; &#125; catch (Exception e) &#123; System.out.println(\"catch...\"); &#125; finally &#123; if (num &gt; 50) &#123; System.out.println(\"num &gt; 50 : \" + num); &#125; System.out.println(\"finally...\"); &#125; return num; &#125;&#125; 输出结果： 1234try...num &gt; 50 : 110finally...110 分析： 显然“return num += 100”被拆分成了“num = num+100”和“return num”两个语句，线执行try中的“num = num+100”语句，将其保存起来，在try中的”return num“执行前，先将finally中的语句执行完，而后再将110返回。 示例二（try和finally中均有return）： 1234567891011121314151617181920212223242526272829package main.java.com.study.tryCatchFinally;/** * @author: whb * @description: try和finally中均有return */public class DemoTwo &#123; public static void main(String[] args) &#123; System.out.println(testTwo()); &#125; private static int testTwo() &#123; int num = 10; try &#123; System.out.println(\"try...\"); return num += 100; &#125; catch (Exception e) &#123; System.out.println(\"catch error...\"); &#125; finally &#123; if (num &gt; 50) &#123; System.out.println(\"num &gt; 50 : \" + num); &#125; System.out.println(\"finally...\"); num = 100; return num; &#125; &#125;&#125; 输出结果： 1234try...num &gt; 50 : 110finally...100 分析： try中的return语句同样被拆分了，finally中的return语句先于try中的return语句执行，因而try中的return被”覆盖“掉了，不再执行。 示例三（finally中改变返回值num）： 1234567891011121314151617181920212223242526272829package main.java.com.study.tryCatchFinally;/** * @author: whb * @description: finally中改变返回值num */public class DemoThree &#123; public static void main(String[] args) &#123; System.out.println(testThree()); &#125; private static int testThree() &#123; int num = 10; try &#123; System.out.println(\"try...\"); return num; &#125; catch (Exception e) &#123; System.out.println(\"catch error...\"); &#125; finally &#123; if (num &gt; 20) &#123; System.out.println(\"num &gt; 20 : \" + num); &#125; System.out.println(\"finally\"); num = 100; &#125; return num; &#125;&#125; 输出结果： 123try...finally10 分析： 虽然在finally中改变了返回值num，但因为finally中没有return该num的值，因此在执行完finally中的语句后，testThree()函数会得到try中返回的num的值，而try中的num的值依然是程序进入finally代码块前保留下来的值，因此得到的返回值为10。 示例四（将num的值包装在Num类中）： 12345678910111213141516171819202122232425262728293031package main.java.com.study.tryCatchFinally;/** * @author: whb * @description: 将num的值包装在Num类中 */public class DemoFour &#123; public static void main(String[] args) &#123; System.out.println(test().num); &#125; private static Num test() &#123; Num number = new Num(); try &#123; System.out.println(\"try\"); return number; &#125; catch (Exception e) &#123; System.out.println(\"error\"); &#125; finally &#123; if (number.num &gt; 20) &#123; System.out.println(\"number.num &gt; 20 : \" + number.num); &#125; System.out.println(\"finally\"); number.num = 100; &#125; return number; &#125;&#125;class Num &#123; public int num = 10;&#125; 输出结果： 123tryfinally100 分析： 从结果中可以看出，同样是在finally中改变了返回值num的值，在示例三中，并没有被try中的return返回（test（）方法得到的不是100），但在这里却被try中的return语句返回了。 对于含有return语句的情况，这里我们可以简单地总结如下： try语句在返回前，将其他所有的操作执行完，保留好要返回的值，而后转入执行finally中的语句，而后分为以下三种情况： 情况一：如果finally中有return语句，则会将try中的return语句”覆盖“掉，直接执行finally中的return语句，得到返回值，这样便无法得到try之前保留好的返回值。 情况二：如果finally中没有return语句，也没有改变要返回值，则执行完finally中的语句后，会接着执行try中的return语句，返回之前保留的值。 情况三：如果finally中没有return语句，但是改变了要返回的值，这里有点类似与引用传递和值传递的区别，分以下两种情况： 1）如果return的数据是基本数据类型或文本字符串，则在finally中对该基本数据的改变不起作用，try中的return语句依然会返回进入finally块之前保留的值。 2）如果return的数据是引用数据类型，而在finally中对该引用数据类型的属性值的改变起作用，try中的return语句返回的就是在finally中改变后的该属性的值。","tags":"java"},{"title":"JVM原理","url":"/posts/6f6b6cd5.html","text":"Java内存模型Java程序执行流程日常Java的基本开发模式是，我们写的所有java程序都保存在*.java的文件中，即我们的源代码，这些源代码必须经过javac.exe命令将其编译成*.class文件，而后利用java.exe命令在JVM进程中解释执行。整个过程如下图： 实际上，当JVM将所需要的 .class 文件加载到 JVM 进程之中，在这个过程需要一个类加载器（ClassLoad),类加载器的好处在于：可以随定指定 *.class 文件所在的路径。 JVM：java虚拟机，所有的程序都要求运行在JVM上，是因为考虑到了可移植性问题 ，但如果真正去执行程序，无法离开操作系统的支持。 在 java 中可以使用 native 实现 本地 C 函数的调用，Native Interface，但是这些都是属于程序的辅助手段，而真正的程序运行都在“运行时数据区”之中。 程序计数器什么是程序计数器程序计数器是一块较小的内存空间，可以把它看作当前线程正在执行的字节码的行号指示器。也就是说，程序计数器里面记录的是当前线程正在执行的那一条字节码指令的地址。注：但是，如果当前线程正在执行的是一个本地方法，那么此时程序计数器为空。 程序计数器的作用程序计数器有两个作用： 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 程序计数器的特点 是一块较小的存储空间 线程私有。每条线程都有一个程序计数器。 是唯一一个不会出现OutOfMemoryError的内存区域。 生命周期随着线程的创建而创建，随着线程的结束而死亡。 Java虚拟机栈(JVM Stack)什么是Java虚拟机栈Java虚拟机栈是描述Java方法运行过程的内存模型。Java虚拟机栈会为每一个即将运行的Java方法创建一块叫做“栈帧”的区域，这块区域用于存储该方法在运行过程中所需要的一些信息。 在JVM 中用栈帧（Stack Frame）来定义栈的数据，每一个栈帧表示每个可能执行的方法。 而栈帧中则包含了：局部变量表，操作数栈，指向运行时常量池的引用，方法返回地址和动态链接。局部变量表（Local Variables）:方法的局部变量或形参，其以变量槽（solt）为最小单位，只允许保存32为长度的变量，如果超过32位则会开辟两个连续的solt(64位长度，long和double)；操作数栈（Operand Stack）：表达式计算在栈中完成；指向当前方法所属的类的运行时常量池的引用（Reference to runtime constant pool）：引用其他类的常量或者使用String 池中的字符串；方法返回地址（Return Address）：方法执行完后需要返回调用此方法的位置，所以需要再栈帧中保存方法返回地址； Java虚拟机栈的特点 局部变量表的创建是在方法被执行的时候，随着栈帧的创建而创建。而且，局部变量表的大小在编译时期就确定下来了，在创建的时候只需分配事先规定好的大小即可。此外，在方法运行的过程中局部变量表的大小是不会发生改变的。 Java虚拟机栈会出现两种异常：StackOverFlowError和OutOfMemoryError。a) StackOverFlowError：若Java虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前Java虚拟机栈的最大深度的时候，就抛出StackOverFlowError异常。b) OutOfMemoryError：若Java虚拟机栈的内存大小允许动态扩展，且当线程请求栈时内存用完了，无法再动态扩展了，此时抛出OutOfMemoryError异常。 Java虚拟机栈也是线程私有的，每个线程都有各自的Java虚拟机栈，而且随着线程的创建而创建，随着线程的死亡而死亡。 注：StackOverFlowError和OutOfMemoryError的异同？StackOverFlowError表示当前线程申请的栈超过了事先定好的栈的最大深度，但内存空间可能还有很多。 解决这种问题可以适当加大栈的深度（增加栈空间大小），也就是把 -Xss 的值设置大一些，但一般情况下是代码问题的可能性较大而OutOfMemoryError是指当线程申请栈时发现栈已经满了，而且内存也全都用光了。 解决这种问题可以适当减小栈的深度，也就是把 -Xss 的值设置小一些，每个线程占用的空间小了，总空间一定就能容纳更多的线程，但是操作系统对一个进程的线程数有限制，经验值在 3000~5000 左右。在 jdk1.5 之前 -Xss 默认是 256k，jdk1.5 之后默认是 1M，这个选项对系统影响还是蛮大的，设置时要根据实际情况，谨慎操作。 本地方法栈什么是本地方法栈本地方法栈和Java虚拟机栈实现的功能类似，只不过本地方法栈是本地方法运行的内存模型。本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。方法执行完毕后相应的栈帧也会出栈并释放内存空间。也会抛出StackOverFlowError和OutOfMemoryError异常。 堆什么是堆堆是用来存放对象的内存空间。 几乎所有的对象都存储在堆中。 堆的特点 线程共享，整个Java虚拟机只有一个堆，所有的线程都访问同一个堆。而程序计数器、Java虚拟机栈、本地方法栈都是一个线程对应一个的。 在虚拟机启动时创建 垃圾回收的主要场所。 可以进一步细分为：新生代、老年代。新生代又可被分为：Eden、From Survior、To Survior。不同的区域存放具有不同生命周期的对象。这样可以根据不同的区域使用不同的垃圾回收算法，从而更具有针对性，更高效。 堆的大小既可以固定也可以扩展，但主流的虚拟机堆的大小是可扩展的，因此当线程请求分配内存，但堆已满，且内存已满无法再扩展时，就抛出OutOfMemoryError。 方法区什么是方法区Java虚拟机规范中定义方法区是堆的一个逻辑部分。方法区中存放已经被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等。 方法区的特点 线程共享方法区是堆的一个逻辑部分，因此和堆一样，都是线程共享的。整个虚拟机中只有一个方法区。 永久代方法区中的信息一般需要长期存在，而且它又是堆的逻辑分区，因此用堆的划分方法，我们把方法区称为永久代。 内存回收效率低方法区的信息一般需要长期存在，回收一遍内存之后可能只有少量信息无效。对方法区的内存回收的主要目标是：对常量池的回收 和 对类的卸载。 Java虚拟机规范对方法区的要求比较宽松。和堆一样，允许固定大小，也允许可扩展的大小，还允许不实现垃圾回收。 什么是运行时常量池方法区中存放三种数据：类信息、常量、静态变量、即时编译器编译后的代码。其中常量存储在运行时常量池中。jdk1,6常量池放在方法区，jdk1.7常量池放在堆内存，jdk1.8放在元空间里面，和堆相独立。我们一般在一个类中通过public static final来声明一个常量。这个类被编译后便生成Class文件，这个类的所有信息都存储在这个class文件中。当这个类被Java虚拟机加载后，class文件中的常量就存放在方法区的运行时常量池中。而且在运行期间，可以向常量池中添加新的常量。如：String类的intern()方法就能在运行期间向常量池中添加字符串常量。当运行时常量池中的某些常量没有被对象引用，同时也没有被变量引用，那么就需要垃圾收集器回收。 直接内存直接内存是除Java虚拟机之外的内存，但也有可能被Java使用。在NIO中引入了一种基于通道和缓冲的IO方式。它可以通过调用本地方法直接分配Java虚拟机之外的内存，然后通过一个存储在Java堆中的DirectByteBuffer对象直接操作该内存，而无需先将外面内存中的数据复制到堆中再操作，从而提升了数据操作的效率。直接内存的大小不受Java虚拟机控制，但既然是内存，当内存不足时就会抛出OOM异常。 Java对象访问模式对象的创建过程当虚拟机遇到一条含有new的指令时，会进行一系列对象创建的操作： 检查常量池中是否有即将要创建的这个对象所属的类的符号引用； 若常量池中没有这个类的符号引用，说明这个类还没有被定义！抛出ClassNotFoundException； 若常量池中有这个类的符号引用，则进行下一步工作； 进而检查这个符号引用所代表的类是否已经被JVM加载； 若该类还没有被加载，就找该类的class文件，并加载进方法区； 若该类已经被JVM加载，则准备为对象分配内存； 根据方法区中该类的信息确定该类所需的内存大小；一个对象所需的内存大小是在这个对象所属类被定义完就能确定的！且一个类所生产的所有对象的内存大小是一样的！JVM在一个类被加载进方法区的时候就知道该类生产的每一个对象所需要的内存大小。 从堆中划分一块对应大小的内存空间给新的对象；分配堆中内存有两种方式： 指针碰撞 如果JVM的垃圾收集器采用复制算法或标记-整理算法，那么堆中空闲内存是完整的区域，并且空闲内存和已使用内存之间由一个指针标记。那么当为一个对象分配内存时，只需移动指针即可。因此，这种在完整空闲区域上通过移动指针来分配内存的方式就叫做“指针碰撞”。 空闲列表 如果JVM的垃圾收集器采用标记-清除算法，那么堆中空闲区域和已使用区域交错，因此需要用一张“空闲列表”来记录堆中哪些区域是空闲区域，从而在创建对象的时候根据这张“空闲列表”找到空闲区域，并分配内存。 综上所述：JVM究竟采用哪种内存分配方法，取决于它使用了何种垃圾收集器。 为对象中的成员变量赋上初始值(默认初始化)； 设置对象头中的信息； 调用对象的构造函数进行初始化 此时，整个对象的创建过程就完成了。 对象的内存模型一个对象从逻辑角度看，它由成员变量和成员函数构成，从物理角度来看，对象是存储在堆中的一串二进制数，这串二进制数的组织结构如下。 对象在内存中分为三个部分： 对象头 实例数据 对齐补充 对象头包含两部分，第一部分用于存储对象自身的运行时数据，如哈希码、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等，32 位虚拟机占 32 bit，64 位虚拟机占 64 bit。官方称为 ‘Mark Word’。 第二部分是类型指针，即对象指向它的类的元数据指针，虚拟机通过这个指针确定这个对象是哪个类的实例。 另外，如果是 Java 数组，对象头中还必须有一块用于记录数组长度的数据，因为普通对象可以通过 Java 对象元数据确定大小，而数组对象不可以。 实例数据实例数据部分就是成员变量的值，其中包含父类的成员变量和本类的成员变量。 对齐补充用于确保对象的总长度为8字节的整数倍。HotSpot要求对象的总长度必须是8字节的整数倍。由于对象头一定是8字节的整数倍，但实例数据部分的长度是任意的，因此需要对齐补充字段确保整个对象的总长度为8的整数倍。 访问对象的过程我们知道，引用类型的变量中存放的是一个地址，那么根据地址类型的不同，对象有不同的访问方式： 句柄访问方式堆中需要有一块叫做“句柄池”的内存空间，用于存放所有对象的地址和所有对象所属类的类信息。引用类型的变量存放的是该对象在句柄池中的地址。访问对象时，首先需要通过引用类型的变量找到该对象的句柄，然后根据句柄中对象的地址再访问对象。 这种模式的准确度很高，但过程较为繁琐，而java中是没有句柄的，所以，java中直接利用的对象保存模式，也就是说堆内存中，不需要保存句柄，而直接保存具体的对象。就相当于省略了句柄到对象之间的查找。而后这个对象可以直接进行Java方法区的调用。 直接指针访问方式引用类型的变量直接存放对象的地址，从而不需要句柄池，通过引用能够直接访问对象。 但对象所在的内存空间中需要额外的策略存储对象所属的类信息的地址。 比较HotSpot采用直接指针方式访问对象，因为它只需一次寻址操作，从而性能比句柄访问方式快一倍。但它需要额外的策略存储对象在方法区中类信息的地址。 垃圾收集策略程序计数器、Java虚拟机栈、本地方法栈都是线程私有的，也就是每条线程都拥有这三块区域，而且会随着线程的创建而创建，线程的结束而销毁。那么，垃圾收集器在何时清扫这三块区域的问题就解决了。 此外，Java虚拟机栈、本地方法栈中的栈帧会随着方法的开始而入栈，方法的结束而出栈，并且每个栈帧中的本地变量表都是在类被加载的时候就确定的。因此以上三个区域的垃圾收集工作具有确定性，垃圾收集器能够清楚地知道何时清扫这三块区域中的哪些数据。 然而，堆和方法区中的内存清理工作就没那么容易了。堆和方法区所有线程共享，并且都在JVM启动时创建，一直得运行到JVM停止时。因此它们没办法根据线程的创建而创建、线程的结束而释放。 堆中存放JVM运行期间的所有对象，虽然每个对象的内存大小在加载该对象所属类的时候就确定了，但究竟创建多少个对象只有在程序运行期间才能确定。方法区中存放类信息、静态成员变量、常量。类的加载是在程序运行过程中，当需要创建这个类的对象时才会加载这个类。因此，JVM究竟要加载多少个类也需要在程序运行期间确定。因此，堆和方法区的内存回收具有不确定性，因此垃圾收集器在回收堆和方法区内存的时候花了一些心思。 堆内存的回收如何判定哪些对象需要回收在对堆进行对象回收之前，首先要判断哪些是无效对象。我们知道，一个对象不被任何对象或变量引用，那么就是无效对象，需要被回收。一般有两种判别方式： 引用计数法每个对象都有一个计数器，当这个对象被一个变量或另一个对象引用一次，该计数器加一；若该引用失效则计数器减一。当计数器为0时，就认为该对象是无效对象。引用计数法虽然简单，但存在一个严重的问题，它无法解决循环引用的问题。（比如对象A引用对象B，同时，对象B也引用对象A，造成循环引用） 可达性分析法所有和GC Roots直接或间接关联的对象都是有效对象，和GC Roots没有关联的对象就是无效对象。 GC Roots是指： Java虚拟机栈所引用的对象(栈帧中局部变量表中引用类型的变量所引用的对象) 方法区中静态属性引用的对象 方法区中常量所引用的对象 本地方法栈所引用的对象 注意：GC Roots并不包括堆中对象所引用的对象！这样就不会出现循环引用。 回收无效对象的过程当JVM筛选出失效的对象之后，并不是立即清除，而是再给对象一次重生的机会，具体过程如下： 判断该对象是否覆盖了finalize()方法 若已覆盖该方法，并该对象的finalize()方法还没有被执行过，那么就会将finalize()扔到F-Queue队列中； 若未覆盖该方法，则直接释放对象内存。 执行F-Queue队列中的finalize()方法虚拟机会以较低的优先级执行这些finalize()方法们，也不会确保所有的finalize()方法都会执行结束。如果finalize()方法中出现耗时操作，虚拟机就直接停止执行，将该对象清除。 对象重生或死亡如果在执行finalize()方法时，将this赋给了某一个引用，那么该对象就重生了。如果没有，那么就会被垃圾收集器清除。 注意： 强烈不建议使用finalize()函数进行任何操作！如果需要释放资源，请使用try-finally。 因为finalize()不确定性大，开销大，无法保证顺利执行。 方法区的内存回收如果使用复制算法实现堆的内存回收，堆就会被分为新生代和老年代，新生代中的对象“朝生夕死”，每次垃圾回收都会清除掉大量的对象；而老年代中的对象生命较长，每次垃圾回收只有少量的对象被清除掉。 由于方法区中存放生命周期较长的类信息、常量、静态变量，因此方法区就像是堆的老年代，每次垃圾收集的只有少量的垃圾被清除掉。 方法区中主要清除两种垃圾： 废弃常量 废弃的类 如何清除废弃常量清除废弃的常量和清除对象类似，只要常量池中的常量不被任何变量或对象引用，那么这些常量就会被清除掉。 如何清除废弃的类清除废弃类的条件较为苛刻： 该类的所有对象都已被清除 该类的java.lang.Class对象没有被任何对象或变量引用只要一个类被虚拟机加载进方法区，那么在堆中就会有一个代表该类的对象：java.lang.Class。这个对象在类被加载进方法区的时候创建，在方法区中该类被删除时清除。 加载该类的ClassLoader已经被回收 垃圾收集算法标记-清除算法首先利用刚才介绍的方法判断需要清除哪些数据，并给它们做上标记；然后清除被标记的数据。这种算法标记和清除过程效率都很低，而且清除完后存在大量碎片空间，导致无法存储大对象，降低了空间利用率。 复制算法将内存分成两份，只将数据存储在其中一块上。当需要回收垃圾时，也是首先标记出废弃的数据，然后将有用的数据复制到另一块内存上，最后将第一块内存全部清除。 分析： 这种算法避免了碎片空间，但内存被缩小了一半。而且每次都需要将有用的数据全部复制到另一片内存上去，效率不高。 解决空间利用率问题： 在新生代中，由于大量的对象都是“朝生夕死”，也就是一次垃圾收集后只有少量对象存活，因此可以将内存划分成三块：Eden、Survior1、Survior2，内存大小分别是8:1:1。分配内存时，只使用Eden和一块Survior1。当发现Eden+Survior1的内存即将满时，JVM会发起一次MinorGC，清除掉废弃的对象，并将所有存活下来的对象复制到另一块Survior2中。那么，接下来就使用Survior2+Eden进行内存分配。 通过这种方式，只需要浪费10%的内存空间即可实现带有压缩功能的垃圾收集方法，避免了内存碎片的问题。 但是，当一个对象要申请内存空间时，发现Eden+Survior中剩下的空间无法放置该对象，此时需要进行Minor GC，如果MinorGC过后空闲出来的内存空间仍然无法放置该对象，那么此时就需要将对象转移到老年代中，这种方式叫做“分配担保”。 “分配担保”策略详解 当垃圾收集器准备要在新生代发起一次MinorGC时，首先会检查“老年代中最大的连续空闲区域的大小 是否大于 新生代中所有对象的大小？”，也就是老年代中目前能够将新生代中所有对象全部装下？若老年代能够装下新生代中所有的对象，那么此时进行MinorGC没有任何风险，然后就进行MinorGC。若老年代无法装下新生代中所有的对象，那么此时进行MinorGC是有风险的，垃圾收集器会进行一次预测：根据以往MinorGC过后存活对象的平均数来预测这次MinorGC后存活对象的平均数。如果以往存活对象的平均数小于当前老年代最大的连续空闲空间，那么就进行MinorGC，虽然此次MinorGC是有风险的。如果以往存活对象的平均数大于当前老年代最大的连续空闲空间，那么就对老年代进行一次Full GC，通过清除老年代中废弃数据来扩大老年代空闲空间，以便给新生代作担保。这个过程就是分配担保。 标记-整理算法在回收垃圾前，首先将所有废弃的对象做上标记，然后将所有未被标记的对象移到一边，最后清空另一边区域即可。 分析： 它是一种老年代的垃圾收集算法。老年代中的对象一般寿命比较长，因此每次垃圾回收会有大量对象存活，因此如果选用“复制”算法，每次需要复制大量存活的对象，会导致效率很低。而且，在新生代中使用“复制”算法，当Eden+Survior中都装不下某个对象时，可以使用老年代的内存进行“分配担保”，而如果在老年代使用该算法，那么在老年代中如果出现Eden+Survior装不下某个对象时，没有其他区域给他作分配担保。因此，老年代中一般使用“标记-整理”算法。 分代收集算法将内存划分为老年代和新生代。老年代中存放寿命较长的对象，新生代中存放“朝生夕死”的对象。然后在不同的区域使用不同的垃圾收集算法。 垃圾回收流程对于整个GC流程里，最需要处理的就是年轻代和老年代的内存清理操作，而元空间（永久代）都不在GC范围内； 当现在有一个新的对象产生，那么对象一定需要内存空间，于是现在就需要为该对象进行内存空间的申请。 首先会判断伊甸园区是否有内存空间，如果此时有内存空间，则将新对象保存在伊甸园区； 但如果伊甸园区的内存空间不足，那么会自动执行一个 Minor GC 操作，将伊甸园区无用的内存空间进行清理，当清理之后会继续判断伊甸园区的内存空间是否充足？充足则将新的对象进行空间分配； 如果执行了 Minor GC 之后发现伊甸园区的内存依然不足，那么这个时候会进行存货区判断，如果存活区有剩余空间，则将伊甸园区的部分对象保存在存活区，那么随后继续判断伊甸园区的内存空间是否充足，如何内存充足，则在伊甸园区进行空间分配； 如果此时存活区也已经没有内存空间了，则开始判断老年区，如果此时老年区的空间充足，则将存活区中的活跃对象保存在老年代，而后存活区就会存现有空余空间，随后，伊甸园区将活跃对象保存在存活区之中，而后在伊甸园区里为新对象开辟内存空间； 如果这个时候老年代也满了，那么这个时候将产生 Major GC(Full GC)，进行老年代的内存清理； 如果老年代执行了 Full GC 之后，依然无法进行对象的保存，就会产生 OOM()异常“OutOfMemoryError”。 Java中引用的种类Java中根据生命周期的长短，将引用分为4类。 强引用我们平时所使用的引用就是强引用。A a = new A();也就是通过关键字new创建的对象所关联的引用就是强引用。只要强引用存在，该对象永远也不会被回收。 软引用只有当堆即将发生OOM异常时，JVM才会回收软引用所指向的对象。软引用通过SoftReference类实现。软引用的生命周期比强引用短一些。 弱引用只要垃圾收集器运行，软引用所指向的对象就会被回收。弱引用通过WeakReference类实现。弱引用的生命周期比软引用短。 虚引用虚引用也叫幽灵引用，它和没有引用没有区别，无法通过虚引用访问对象的任何属性或函数。一个对象关联虚引用唯一的作用就是在该对象被垃圾收集器回收之前会受到一条系统通知。虚引用通过PhantomReference类来实现。 对象内存分配策略Java所承诺的自动内存管理主要是针对对象内存的回收和对象内存的分配。 在Java虚拟机的五块内存空间中，程序计数器、Java虚拟机栈、本地方法栈内存的分配和回收都具有确定性，一般在编译阶段就能确定需要分配的内存大小，并且由于都是线程私有，因此它们的内存空间都随着线程的创建而创建，线程的结束而回收。也就是这三个区域的内存分配和回收都具有确定性，垃圾回收器不需要在这里花费太大的精力。 而Java虚拟机中的方法区因为是用来存储类信息、常量、静态变量，这些数据的变动性较小，因此不是Java内存管理重点需要关注的区域。 而对于堆，所有线程共享，所有的对象都需要在堆中创建和回收。虽然每个对象的大小在类加载的时候就能确定，但对象的数量只有在程序运行期间才能确定，因此堆中内存的分配具有较大的不确定性。此外，对象的生命周期长短不一，因此需要针对不同生命周期的对象采用不同的内存回收算法，增加了内存回收的复杂性。 综上所述：Java自动内存管理最核心的功能是堆内存中对象的分配与回收。 对象优先在Eden区中分配目前主流的垃圾收集器都会采用分代回收算法，因此需要将堆内存分为新生代和老年代。 在新生代中为了防止内存碎片问题，因此垃圾收集器一般都选用“复制”算法。因此，堆内存的新生代被进一步分为：Eden区＋Survior1区＋Survior2区。 每次创建对象时，首先会在Eden区中分配。若Eden区已满，则在Survior1区中分配。若Eden区＋Survior1区剩余内存太少，导致对象无法放入该区域时，就会启用“分配担保”，将当前Eden区＋Survior1区中的对象转移到老年代中，然后再将新对象存入Eden区。 大对象直接进入老年代所谓“大对象”就是指一个占用大量连续存储空间的对象，如数组。 当发现一个大对象在Eden区＋Survior1区中存不下的时候就需要分配担保机制把当前Eden区＋Survior1区的所有对象都复制到老年代中去。我们知道，一个大对象能够存入Eden区＋Survior1区的概率比较小，发生分配担保的概率比较大，而分配担保需要涉及到大量的复制，就会造成效率低下。因此，对于大对象我们直接把他放到老年代中去，从而就能避免大量的复制操作。那么，什么样的对象才是“大对象”呢？ 通过-XX:PretrnureSizeThreshold参数设置大对象该参数用于设置大小超过该参数的对象被认为是“大对象”，直接进入老年代。注意：该参数只对Serial和ParNew收集器有效 生命周期较长的对象进入老年代老年代用于存储生命周期较长的对象，那么如何判断一个对象的年龄呢？ 新生代中的每个对象都有一个年龄计数器，当新生代发生一次MinorGC后，存活下来的对象的年龄就加一，当年龄超过一定值时，就将超过该值的所有对象转移到老年代中去。 使用-XXMaxTenuringThreshold设置新生代的最大年龄,设置该参数后，只要超过该参数的新生代对象都会被转移到老年代中去。 相同年龄的对象内存超过Survior内存一半的对象进入老年代如果当前新生代的Survior中，年龄相同的对象的内存空间总和超过了Survior内存空间的一半，那么所有年龄相同的对象和超过该年龄的对象都被转移到老年代中去。无需等到对象的年龄超过MaxTenuringThreshold才被转移到老年代中去。 HotSpot垃圾收集器 说明：如果两个收集器之间存在连线说明他们之间可以搭配使用。 新生代垃圾收集器Serial垃圾收集器 单线程只开启一条GC线程进行垃圾回收，并且在垃圾回收过程中停止一切用户线程，从而用户的请求或图形化界面会出现卡顿。 适合客户端应用一般客户端应用所需内存较小，不会创建太多的对象，而且堆内存不大，因此垃圾回收时间比较短，即使在这段时间停止一切用户线程，用户也不会感受到明显的停顿，因此本垃圾收集器适合客户端应用。 简单高效由于Serial收集器只有一条GC线程，因此避免了线程切换的开销，从而简单高效。 采用“复制”算法 ParNew垃圾收集器ParNew是Serial的多线程版本。 多线程并行执行ParNew由多条GC线程并行地进行垃圾清理。但清理过程仍然需要停止一切用户线程。但由于有多条GC线程同时清理，清理速度比Serial有一定的提升。 适合多CPU的服务器环境由于使用了多线程，因此适合CPU较多的服务器环境。 与Serial性能对比ParNew和Serial唯一的区别就是使用了多线程进行垃圾回收，在多CPU的环境下性能比Serial会有一定程度的提升；但线程切换需要额外的开销，因此在单CPU环境中表现不如Serial。 采用“复制”算法 追求“降低停顿时间”和Serial相比，ParNew使用多线程的目的就是缩短垃圾收集时间，从而减少用户线程被停顿的时间。 并行(Parallel)：指多条垃圾收集线程并行工作，此时用户线程处于等待状态。 并发(Concurrent)：指用户线程和垃圾回收线程同时执行(不一定是并行，有可能是交叉执行)，用户进程在运行，而垃圾回收线程在另一个 CPU 上运行。 Parallel Scavenge垃圾收集器Parallel Scavenge和ParNew一样都是多线程、新生代收集器，都使用“复制”算法进行垃圾回收。但它们有个巨大的不同点：ParNew收集器追求降低用户线程的停顿时间，因此适合交互式应用；而Parallel Scavenge追求CPU吞吐量，能够在较短的时间内完成指定任务，因此适合没有交互的后台计算。 什么是“吞吐量”？吞吐量是指用户线程运行时间占CPU总时间的比例。CPU总时间包括：用户线程运行时间 和 GC线程运行的时间。因此，吞吐量越高表示用户线程运行时间越长，从而用户线程能够被快速处理完。 降低停顿时间的两种方式 在多CPU环境中使用多条GC线程，从而垃圾回收的时间减少，从而用户线程停顿的时间也减少； 实现GC线程与用户线程并发执行。所谓并发，就是用户线程与GC线程交替执行，从而每次停顿的时间会减少，用户感受到的停顿感降低，但线程之间不断切换意味着需要额外的开销，从而垃圾回收和用户线程的总时间将会延长。 Parallel Scavenge提供的参数 设置“吞吐量”：通过参数-XX:GCTimeRadio设置垃圾回收时间占总CPU时间的百分比。 设置“停顿时间”：通过参数-XX:MaxGCPauseMillis设置垃圾处理过程最久停顿时间。Parallel Scavenge会根据这个值的大小确定新生代的大小。如果这个值越小，新生代就会越小，从而收集器就能以较短的时间进行一次回收。但新生代变小后，回收的频率就会提高，因此要合理控制这个值。 启用自适应调节策略：通过命令-XX:+UseAdaptiveSizePolicy就能开启自适应策略。我们只要设置好堆的大小和MaxGCPauseMillis或GCTimeRadio，收集器会自动调整新生代的大小、Eden和Survior的比例、对象进入老年代的年龄，以最大程度上接近我们设置的MaxGCPauseMillis或GCTimeRadio。 老年代垃圾收集器Serial Old垃圾收集器Serial Old收集器是Serial的老年代版本，它们都是单线程收集器，也就是垃圾收集时只启动一条GC线程，因此都适合客户端应用。 它们唯一的区别就是Serial Old工作在老年代，使用“标记-整理”算法；而Serial工作在新生代，使用“复制”算法。 Parallel Old垃圾收集器Parallel Old收集器是Parallel Scavenge的老年代版本，一般它们搭配使用，追求CPU吞吐量。它们在垃圾收集时都是由多条GC线程并行执行，并停止一切用户线程。因此，由于在垃圾清理过程中没有使垃圾收集和用户线程并行执行，因此它们是追求吞吐量的垃圾收集器。 CMS垃圾收集器CMS收集器是一款追求停顿时间的老年代收集器，它在垃圾收集时使得用户线程和GC线程并行执行，因此在垃圾收集过程中用户也不会感受到明显的卡顿。但用户线程和GC线程之间不停地切换会有额外的开销，因此垃圾回收总时间就会被延长。 回收过程 初始标记停止一切用户线程，仅使用一条初始标记线程对所有与GC ROOTS直接关联的对象进行标记。速度很快。 并发标记使用多条并发标记线程并行执行，并与用户线程并发执行。此过程进行可达性分析，标记出所有废弃的对象。速度很慢。 重新标记停止一切用户线程，并使用多条重新标记线程并行执行，将刚才并发标记过程中新出现的废弃对象标记出来。这个过程的运行时间介于初始标记和并发标记之间。 并发清除只使用一条并发清除线程，和用户线程们并发执行，清除刚才标记的对象。这个过程非常耗时。 CMS的缺点 吞吐量低由于CMS在垃圾收集过程使用用户线程和GC线程并行执行，从而线程切换会有额外开销，因此CPU吞吐量就不如在垃圾收集过程中停止一切用户线程的方式来的高。 无法处理浮动垃圾，导致频繁Full GC由于垃圾清除过程中，用户线程和GC线程并发执行，也就是用户线程仍在执行，那么在执行过程中会产生垃圾，这些垃圾称为“浮动垃圾”。如果CMS在垃圾清理过程中，用户线程需要在老年代中分配内存时发现空间不足时，就需要再次发起Full GC，而此时CMS正在进行清除工作，因此此时只能由Serial Old临时对老年代进行一次Full GC。 使用“标记-清除”算法产生碎片空间由于CMS使用了“标记-清除”算法， 因此清除之后会产生大量的碎片空间，不利于空间利用率。不过CMS提供了应对策略： 开启-XX:+UseCMSCompactAtFullCollection开启该参数后，每次FullGC完成后都会进行一次内存压缩整理，将零散在各处的对象整理到一块儿。但每次都整理效率不高，因此提供了以下参数。 设置参数-XX:CMSFullGCsBeforeCompaction本参数告诉CMS，经过了N次Full GC过后再进行一次内存整理。 通用垃圾收集器–G1垃圾收集器G1的特点 追求停顿时间 多线程GC 面向服务端应用 标记-整理和复制算法合并不会产生碎片内存。 可对整个堆进行垃圾回收 可预测停顿时间 G1的内存模型G1垃圾收集器没有新生代和老年代的概念了，而是将堆划分为一块块独立的Region。当要进行垃圾收集时，首先估计每个Region中的垃圾数量，每次都从垃圾回收价值最大的Region开始回收，因此可以获得最大的回收效率。 Remembered Set一个对象和它内部所引用的对象可能不在同一个Region中，那么当垃圾回收时，是否需要扫描整个堆内存才能完整地进行一次可达性分析？ 当然不是，每个Region都有一个Remembered Set，用于记录本区域中所有对象引用的对象所在的区域，从而在进行可达性分析时，只要在GC ROOTs中再加上Remembered Set即可防止对所有堆内存的遍历。 G1垃圾收集过程 初始标记标记与GC ROOTS直接关联的对象，停止所有用户线程，只启动一条初始标记线程，这个过程很快。 并发标记进行全面的可达性分析，开启一条并发标记线程与用户线程并行执行。这个过程比较长。 最终标记标记出并发标记过程中用户线程新产生的垃圾。停止所有用户线程，并使用多条最终标记线程并行执行。 筛选回收回收废弃的对象。此时也需要停止一切用户线程，并使用多条筛选回收线程并行执行。 Class文件结构什么是JVM的“无关性”Java具有平台无关性，也就是任何操作系统都能运行Java代码。之所以能实现这一点，是因为Java运行在虚拟机之上，不同的操作系统都拥有各自的Java虚拟机，因此Java能实现“一次编写，处处运行”。 而JVM不仅具有平台无关性，还具有语言无关性。平台无关性是指不同操作系统都有各自的JVM，而语言无关性是指Java虚拟机能运行除Java以外的代码！ 这听起来非常惊人，但JVM对能运行的语言是有严格要求的。首先来了解下Java代码的运行过程。 Java源代码首先需要使用Javac编译器编译成class文件，然后启动JVM执行class文件，从而程序开始运行。也就是JVM只认识class文件，它并不管何种语言生成了class文件，只要class文件符合JVM的规范就能运行。因此目前已经有Scala、JRuby、Jython等语言能够在JVM上运行。它们有各自的语法规则，不过它们的编译器都能将各自的源码编译成符合JVM规范的class文件，从而能够借助JVM运行它们。 Class文件基本组织结构class文件是二进制文件，它的内容具有严格的规范，文件中没有任何空格，全是连续的0/1。class文件中的所有内容被分为两种类型：无符号数 和 表。 无符号数它表示class文件中的值，这些值没有任何类型，但有不同的长度。根据这些值长度的不同分为：u1、u2、u4、u8，分别代表1字节的无符号数、2字节的无符号数、4字节的无符号数、8字节的无符号数。 表class文件中所有数据(即无符号数)要么单独存在，要么由多个无符号数组成二维表。即class文件中的数据要么是单个值，要么是二维表。 魔数(magic)所有的由Java编译器编译而成的class文件的前4个字节都是“0xCAFEBABE”它的作用在于：当JVM在尝试加载某个文件到内存中来的时候，会首先判断此class文件有没有JVM认为可以接受的“签名”，即JVM会首先读取文件的前4个字节，判断该4个字节是否是“0xCAFEBABE”，如果是，则JVM会认为可以将此文件当作class文件来加载并使用。 版本号(minor_version,major_version)紧接着魔数的4个字节是版本号。它表示本class中使用的是哪个版本的JDK。主版本号和次版本号在class文件中各占两个字节，副版本号占用第5、6两个字节，而主版本号则占用第7，8两个字节。JDK1.0的主版本号为45，以后的每个新主版本都会在原先版本的基础上加1。若现在使用的是JDK1.7编译出来的class文件，则相应的主版本号应该是51,对应的7，8个字节的十六进制的值应该是 0x33。 一个 JVM实例只能支持特定范围内的主版本号 （Mi 至Mj） 和 0 至特定范围内 （0 至 m） 的副版本号。假设一个 Class 文件的格式版本号为 V， 仅当Mi.0 ≤ v ≤ Mj.m成立时，这个 Class 文件才可以被此 Java 虚拟机支持。不同版本的 Java 虚拟机实现支持的版本号也不同，高版本号的 Java 虚拟机实现可以支持低版本号的 Class 文件，反之则不成立。 JVM在加载class文件的时候，会读取出主版本号，然后比较这个class文件的主版本号和JVM本身的版本号，如果JVM本身的版本号 &lt; class文件的版本号，JVM会认为加载不了这个class文件，会抛出我们经常见到的&quot;java.lang.UnsupportedClassVersionError: Bad version number in .class file &quot; Error 错误；反之，JVM会认为可以加载此class文件，继续加载此class文件。 常量池(constant_pool)什么是常量池紧接着版本号之后的就是常量池。常量池中存放两种类型的常量： 字面值常量字面值常量即我们在程序中定义的字符串、被final修饰的值。 符号引用符号引用就是我们定义的各种名字： 类和接口的全限定名 字段的名字 和 描述符 方法的名字 和 描述符 常量池的特点 常量池长度不固定常量池的大小是不固定的，因此常量池开头放置一个u2类型的无符号数，用来存储当前常量池的容量。JVM根据这个值就知道常量池的头尾来。注：这个值是从1开始的，若为5表示池中有4个常量。 常量池中的常量由而为表来表示常量池开头有个常量池容量计数器，接下来就全是一个个常量了，只不过常量都是由一张张二维表构成，除了记录常量的值以外，还记录当前常量的相关信息。 常量池是class文件的资源仓库 常量池是与本class中其它部分关联最多的部分 常量池是class文件中空间占用最大的部分之一 常量池中常量的类型刚才介绍了，常量池中的常量大体上分为：字面值常量 和 符号引用。在此基础上，根据常量的数据类型不同，又可以被细分为14种常量类型。这14种常量类型都有各自的二维表示结构。每种常量类型的头1个字节都是tag，用于表示当前常量属于14种类型中的哪一个。 以CONSTANT_Class_info常量为例，它的二维表示结构如下： 类型 名称 数量 u1 tag 1 u2 length 1 tag表示当前常量的类型(当前常量为CONSTANT_Class_info，因此tag的值应为7，表示一个类或接口的全限定名)；name_index表示这个类或接口全限定名的位置。它的值表示指向常量池的第几个常量。它会指向一个CONSTANT_Utf8_info类型的常量，它的二维表结构如下： 类型 名称 数量 u1 tag 1 u2 length 1 u1 bytes length CONSTANT_Utf8_info表示字符串常量；tag表示当前常量的类型，这里应该是1；length表示这个字符串的长度；bytes为这个字符串的内容(采用缩略的UTF8编码) 为什么Java中定义的类、变量名字必须小于64K类、接口、变量等名字都属于符号引用，它们都存储在常量池中。而不管哪种符号引用，它们的名字都由CONSTANT_Utf8_info类型的常量表示，这种类型的常量使用u2存储字符串的长度。由于2字节最多能表示65535个数，因此这些名字的最大长度最多只能是64K。 访问标志(access_flags)在常量池之后是2字节的访问标志。访问标志是用来表示这个class文件是类还是接口、是否被public修饰、是否被abstract修饰、是否被final修饰等。由于这些标志都由是/否表示，因此可以用0/1表示。访问标志为2字节，可以表示16位标志，但JVM目前只定义了8种，未定义的直接写0. 类索引(this_class)类索引，this_class的值必须是对constant_pool表中项目的一个有效索引值。constant_pool表在这个索引处的项必须为CONSTANT_Class_info 类型常量，表示这个 Class 文件所定义的类或接口。 父类索引(super_class)父类索引，对于类来说，super_class 的值必须为 0 或者是对constant_pool 表中项目的一个有效索引值。如果它的值不为 0，那 constant_pool 表在这个索引处的项必须为CONSTANT_Class_info 类型常量，表示这个 Class 文件所定义的类的直接父类。当前类的直接父类，以及它所有间接父类的access_flag 中都不能带有ACC_FINAL 标记。对于接口来说，它的Class文件的super_class项的值必须是对constant_pool表中项目的一个有效索引值。constant_pool表在这个索引处的项必须为代表 java.lang.Object 的 CONSTANT_Class_info 类型常量 。如果 Class 文件的 super_class的值为 0，那这个Class文件只可能是定义的是java.lang.Object类，只有它是唯一没有父类的类。 接口计数器(interfaces_count)接口计数器，interfaces_count的值表示当前类或接口的直接父接口数量。 接口信息数据区(interfaces[interfaces_count])接口表，interfaces[]数组中的每个成员的值必须是一个对constant_pool表中项目的一个有效索引值， 它的长度为 interfaces_count。每个成员 interfaces[i] 必须为 CONSTANT_Class_info类型常量，其中 0 ≤ i &lt;interfaces_count。在interfaces[]数组中，成员所表示的接口顺序和对应的源代码中给定的接口顺序（从左至右）一样，即interfaces[0]对应的是源代码中最左边的接口。 字段表的集合什么是字段表集合字段表集合用于存储本类所涉及到的成员变量，包括实例变量和类变量，但不包括方法中的局部变量。每一个字段表只表示一个成员变量，本类中所有的成员变量构成了字段表集合。 描述一个字段的信息包括：字段的作用域（public、protected、private）、实例变量与否（static）、可变性（final）、并发可见性（volatile）、可否被序列化（transient）、字段数据类型（基本数据类型、对象、数组）、字段名称。而字段叫什么名字，字段被定义为什么数据类型，这些都是无法固定的，只能引用常量池中的常量来描述。 字段表结构的定义 类型 名称 数量 u2 access_flags 1 u2 name_index 1 u2 descriptor_index 1 u2 attributes_count 1 attribute_info attributes attributes_count access_flags字段的访问标志。在Java中，每个成员变量都有一系列的修饰符，和上述class文件的访问标志的作用一样，只不过成员变量的访问标志与类的访问标志稍有区别。 name_index本字段名字的索引。指向一个CONSTANT_Class_info类型的常量，这里面存储了本字段的名字等信息。 descriptor_index描述符。用于描述本字段在Java中的数据类型等信息(下面详细介绍) attributes_count属性表集合的长度。 attributes属性表集合。到descriptor_index为止是字段表的固定信息，光有上述信息可能无法完整地描述一个字段，因此用属性表集合来存放额外的信息，比如一个字段的值。 什么是描述符成员变量(包括静态成员变量和实例变量) 和 方法都有各自的描述符。对于字段而言，描述符用于描述字段的数据类型；对于方法而言，描述符用于描述字段的数据类型、参数列表、返回值。 在描述符中，基本数据类型用大写字母表示，对象类型用“L对象类型的全限定名”表示，数组用“数组类型的全限定名”表示。描述方法时，将参数根据上述规则放在()中，()右侧按照上述方法放置返回值。而且，参数之间无需任何符号。 字段表集合的注意点 一个class文件的字段表集合中不能出现从父类/接口继承而来字段； 一个class文件的字段表集合中可能会出现程序猿没有定义的字段如编译器会自动地在内部类的class文件的字段表集合中添加外部类对象的成员变量，供内部类访问外部类。 Java中只要两个字段名字相同就无法通过编译。但在JVM规范中，允许两个字段的名字相同但描述符不同的情况，并且认为它们是两个不同的字段。 方法表的集合在class文件中，所有的方法以二维表的形式存储，每张表来表示一个函数，一个类中的所有方法构成方法表的集合。方法表的结构和字段表的结构一致，只不过访问标志和属性表集合的可选项有所不同。 方法表的属性表集合中有一张Code属性表，用于存储当前方法经编译器编译过后的字节码指令。 方法表集合的注意点 如果本class没有重写父类的方法，那么本class文件的方法表集合中是不会出现父类/父接口的方法表； 本class的方法表集合可能出现程序猿没有定义的方法编译器在编译时会在class文件的方法表集合中加入类构造器和实例构造器。 重载一个方法需要有相同的简单名称和不同的特征签名。JVM的特征签名和Java的特征签名有所不同： Java特征签名：方法参数在常量池中的字段符号引用的集合 JVM特征签名：方法参数＋返回值 属性表属性计数器(attributes_count)属性计数器，attributes_count的值表示当前 Class 文件attributes表的成员个数。attributes表中每一项都是一个attribute_info 结构的数据项。 属性信息数据区(attributes[attributes_count])属性表，attributes 表的每个项的值必须是attribute_info结构。 在Java 7 规范里，Class文件结构中的attributes表的项包括下列定义的属性： InnerClasses 、 EnclosingMethod 、 Synthetic 、Signature、SourceFile，SourceDebugExtension 、Deprecated、RuntimeVisibleAnnotations 、RuntimeInvisibleAnnotations以及BootstrapMethods属性。 对于支持 Class 文件格式版本号为 49.0 或更高的 Java 虚拟机实现，必须正确识别并读取attributes表中的Signature、RuntimeVisibleAnnotations和RuntimeInvisibleAnnotations属性。对于支持Class文件格式版本号为 51.0 或更高的 Java 虚拟机实现，必须正确识别并读取 attributes表中的BootstrapMethods属性。Java 7 规范 要求任一 Java 虚拟机实现可以自动忽略 Class 文件的 attributes表中的若干 （甚至全部） 它不可识别的属性项。任何本规范未定义的属性不能影响Class文件的语义，只能提供附加的描述信息 。 根据上述的叙述，我们可以将class的文件组织结构概括成以下面这个结构体：","tags":"java jvm"},{"title":"Linux - 常用命令","url":"/posts/cb6839f2.html","text":"命令的基本格式[root@localhost~] root为用户名（#超级用户 $普通用户） localhost主机名命令的基本格式： 1命令[选项][参数] 查询目录的内容命令格式： 1ls [选项][文件或目录] 选项： -a 所有文件,包括隐藏文件。 -l 查看详情,包含文件的确切大小，拥有该文件的人员，有权查看该文件，以及何时进行上次修改。 -d 查看目录属性 -h 显示文件大小 文件处理 建立目录 mkdir -p[目录名]-p表示递归创建文件夹 切换目录 cd [目录]简化操作： 1234cd ~ 进入当前用户目录cd - 上次目录cd .. 进入上一级目录pwd 查看当前目录所在位置 删除目录 12rmdir [目录] 删除所有文件rm -rf [目录] 删除目录所有文件 复制目录 cp [选项] [原文件目录] [目标目录] 选项： -r复制目录 -p连文件属性一起复制 -a 相当于-pdr 剪切、改名 mv [原文件目录] [目标文件目录] 1mv filename1 filename2 filename1 文件的源路径，filename2 是目标路径。 常见目录作用 123456789101112131415/ 根目录/bin 命令保存目录/boot 启动目录/dev 设备文件命令/etc 配置文件保存目录/home 家目录/lib 系统库保存命令/mnt 系统挂载目录 创建或更新文件 1touch filename cat 它可以在UNIX或Linux下用于以下目的。 在屏幕上显示文本文件 复制文本文件 合并文本文件 创建新的文本文件 123cat filenamecat file1 file2 cat file1 file2 &gt; newcombinedfile more 显示文件的第一部分（用空格移动并键入q以退出）。 1more filename head 输出文件的前10行。 1head filename tail 输出最后10行文件。用于-f在文件增长时输出附加数据。 1tail filename diff 比较文件，并列出他们的差异。 1diff filename1 filename2 lpr 打印文件。 1lpr filename 文件搜索 locate locate [文件名] 在系统数据库中查找文件。新建的文件，要执行updatedb操作之后才能搜到。 命令搜索 whereis [选项] [命令名] 或者 which [选项][命令名] 选项： -b 只查找可执行文件 -m 只查找帮助文件 说明：whereis使用系统自动构建的数据库来搜索可执行文件，源文件和手册页面。 which在环境变量PATH指定的目录中搜索可执行文件。此命令将打印可执行文件的完整路径。 文件搜索 find [搜索范围][选项][条件] 举例： 在根目录下查找名为install.log文件find / -name install.log 忽略大小写查找文件find /root -inname install.log find /var/log -mtime +10 其中-mtime 文件修改时间 -atime 文件访问时间 -ctime 改变文件属性时间 +10 10天前 10 10天 -10 10天内 查找文件大于20M的文件find /etc -size +20M 文本操作 awk awk 是处理文本文件最有用的命令。它一行一行地在整个文件上运行。默认情况下，它使用空格分隔字段。awk命令最常用的语法是: 1awk &apos;/search_pattern/ &#123; action_to_take_if_pattern_matches; &#125;&apos; file_to_parse 以/etc/passwd文件包含的示例数据为例： 12345root:x:0:0:root:/root:/usr/bin/zshdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologinsys:x:3:3:sys:/dev:/usr/sbin/nologinsync:x:4:65534:sync:/bin:/bin/sync 现在从这个文件只获取用户名。 -F指定要基于哪个分隔字段。在我们的例子中 { print $1 } 意味着打印出第一个匹配字段。 1awk -F&apos;:&apos; &apos;&#123; print $1 &#125;&apos; /etc/passwd 运行上述命令后，将获得以下输出。 12345rootdaemonbinsyssync grep 查找文件内的文本。可以使用 grep 搜索与一个或多个正则表达式匹配的文本行，并仅输出匹配的行。 1grep pattern filename 示例： 1234$ grep admin /etc/passwd_kadmin_admin:*:218:-2:Kerberos Admin Service:/var/empty:/usr/bin/false_kadmin_changepw:*:219:-2:Kerberos Change Password Service:/var/empty:/usr/bin/false_krb_kadmin:*:231:-2:Open Directory Kerberos Admin Service:/var/empty:/usr/bin/false 还可以通过使用-i选项强制grep忽略单词大小写。-r可用于搜索指定目录下的所有文件，例如： 1$ grep -r admin /etc/ -w 只搜索单词。 wc 统计一个文件中有多少行，多少单词和多少字符。 1wc filename 示例： 12$ wc demo.txt7459 15915 398400 demo.txt 7459 是行数, 15915 是单词数， 398400 是字符数. sed 用于过滤和转换文本的流编辑器。 example.txt文件内容如下： 1Hello This is a Test 1 2 3 4 用连字符替换所有空格 1sed &apos;s/ /-/g&apos; example.txt 结果如下： 1Hello-This-is-a-Test-1-2-3-4 使用”d”替换所有的数字 1sed &apos;s/[0-9]/d/g&apos; example.txt 结果如下： 1Hello This is a Test d d d d sort 排序文本文件的行 example.txt文件内容如下： 1234567fbcgaed 排序example.txt 1sort example.txt 结果如下： 1234567abcdefg 随机化一个排序的example.txt 1sort example.txt | sort -R 结果如下： 1234567bfacdge uniq报告或省略重复的行 example.txt文件内容如下： 12345678aababcdc 只显示example.txt的唯一行（首先你需要排序，否则看不到重叠） 1sort example.txt | uniq 结果如下： 1234abcd 显示每行的唯一项，并告诉我找到了多少个实例 1sort example.txt | uniq -c 结果如下： 12343 a2 b2 c1 d cut从每行文件中删除部分。 example.txt文件内容如下： 1red riding hood went to the park to play 显示第2,7和9栏的空格作为分隔符 1cut -d &quot; &quot; -f2,7,9 example.txt 结果如下： 1riding park play echo 显示一行文字 显示 “Hello World” 1echo Hello World 结果如下： 1Hello World 用字母之间的换行显示 “Hello World” 1echo -ne &quot;Hello\\nWorld\\n&quot; 结果如下： 12HelloWorld fmt简单的最佳文本格式化程序 example.txt内容如下： 1Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. 将example.txt的行输出为20个字符的宽度 1234567891011121314151617181920cat example.txt | fmt -w 20Lorem ipsumdolor sit amet,consetetursadipscing elitr,sed diam nonumyeirmod temporinvidunt ut laboreet dolore magnaaliquyam erat, seddiam voluptua. Atvero eos etaccusam et justoduo dolores et earebum. Stet clitakasd gubergren,no sea takimatasanctus est Loremipsum dolor sitamet. tr 翻译或删除字符 example.txt文件内容如下： 1Hello World Foo Bar Baz! 把所有小写字母变成为大写 1cat example.txt | tr &apos;a-z&apos; &apos;A-Z&apos; 结果如下： 1HELLO WORLD FOO BAR BAZ! 把所有的空格变成换行符 1cat example.txt | tr &apos; &apos; &apos;\\n&apos; 结果如下： 12345HelloWorldFooBarBaz! nl 显示文件的行数 example.txt内容如下： 12345678910111213141516171819Lorem ipsumdolor sit amet,consetetursadipscing elitr,sed diam nonumyeirmod temporinvidunt ut laboreet dolore magnaaliquyam erat, seddiam voluptua. Atvero eos etaccusam et justoduo dolores et earebum. Stet clitakasd gubergren,no sea takimatasanctus est Loremipsum dolor sitamet. 带行号显示 example.txt 1nl -s&quot;. &quot; example.txt 结果如下： 1234567891011121314151617181920212223242526 1. Lorem ipsum 2. dolor sit amet, 3. consetetur 4. sadipscing elitr, 5. sed diam nonumy 6. eirmod tempor 7. invidunt ut labore 8. et dolore magna 9. aliquyam erat, sed 10. diam voluptua. At 11. vero eos et 12. accusam et justo 13. duo dolores et ea 14. rebum. Stet clita 15. kasd gubergren, 16. no sea takimata 17. sanctus est Lorem 18. ipsum dolor sit 19. amet.``` 12. `egrep`打印匹配模式的行 - 扩展表达式（别名为：&apos;grep -E&apos;）`example.txt`文件内容如下： Lorem ipsumdolor sit amet,consetetursadipscing elitr,sed diam nonumyeirmod temporinvidunt ut laboreet dolore magnaaliquyam erat, seddiam voluptua. Atvero eos etaccusam et justoduo dolores et earebum. Stet clitakasd gubergren,no sea takimatasanctus est Loremipsum dolor sitamet. 12&gt;在其中显示“Lorem”或“dolor”的行 egrep ‘(Lorem|dolor)’ example.txtorgrep -E ‘(Lorem|dolor)’ example.txt 12结果如下： Lorem ipsumdolor sit amet,et dolore magnaduo dolores et easanctus est Loremipsum dolor sit 12345613. `fgrep`打印匹配模式到的行 - FIXED模式匹配（别名为：&apos;grep -F&apos;）`example.txt`文件内容如下： Lorem ipsumdolor sit amet,consetetursadipscing elitr,sed diam nonumyeirmod temporfoo (Lorem|dolor)invidunt ut laboreet dolore magnaaliquyam erat, seddiam voluptua. Atvero eos etaccusam et justoduo dolores et earebum. Stet clitakasd gubergren,no sea takimatasanctus est Loremipsum dolor sitamet. 12&gt;在example.txt中找到具体的字符串&apos;（Lorem | doloar）&apos; fgrep ‘(Lorem|dolor)’ example.txtorgrep -F ‘(Lorem|dolor)’ example.txt 12结果如下： foo (Lorem|dolor) 123456789101112131415#### 压缩与解压缩常见压缩格式：.zip 、 .gz 、 .bz2、 .tar.gz 、 .tar.bz21. zip格式**压缩文件**`zip [压缩文件名][原文件]`**压缩目录**`zip -r [压缩文件名][原文件]`举例： touch jp/cangls touch jp/longls zip -r jp.zip jp 1234567891011121314151617181920212223242526**解压：**`unzip [压缩文件名]`**压缩为gz格式，原文件不保留**`gzip [原文件]`2. gz格式**压缩.gz格式，原文件保留**`gzip -c 原文件 &gt; 压缩文件`**压缩目录：**`gzip -r 目录`**解压：**`guzip [文件]``guzip -r [目录]`**查看gzip压缩文件，而不需要gunzip它** gzcat filename 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859603. tar**打包**`tar -cvf 打包文件名 原文件`**解压**`tar -xvf jp.tar`4. tar.gz**打包**`tar -zcvf 压缩包名.tar.gz 原文件`**解压**`tar -zxvf 压缩包名.tar.gz`#### 关机、重启`shutdown [选项][时间]`**选项：**+ -c 取消前一个关机命令+ -h 关机+ -r 重启+ init 6 重启+ init 0 关机+ logout 退出登陆#### 查看用户信息`w`、`who`、`last`、`lastlog`#### 输出重定向`命令&gt;文件` 以覆盖的方式，把正确的命令输出到指定文件`命令&gt;&gt;文件` 以追加的方式，把正确的命令输出到指定文件、`错误命令 2&gt; 文件` 以覆盖的方式把错误的命令覆盖到指定文件`错误命令 2&gt;&gt; 文件` 以追击的方式把错误的命令覆盖到指定文件`命令&gt;&gt;文件 2&gt;&amp;1` 同时追加正确命令和错误命令到 指定文件`命令 &gt;&gt;文件1 2&gt;&gt;文件2` 把正确的命令输出到文件1错误的文件2#### 网络相关1. ifconfig查看ip举个例子： ifconfig&gt;&gt; ip.log cat ip.log``` 查看网络状态 netstat [选项] 选项： -t: 列出tcp 协议端口 -u: 列出upd协议端口 -n ip地址个端口号 -l 列出监听状态的 -a 所有 查看路由列表 netstat -rn 或者 route -n 查看某域名与自己的电脑的网络状态 ping www.baidu.com vi编辑器vi的升级版是vim vim的操作模式 commond mode 命令模式 inser tmode 编辑模式 lastline mode 底行模式 模式切换 i 进入编辑模式 esc 进入命令行模式 命令模式 vim [文件] 进入文件或者创建文件（文件不存在的情况下） vim + [文件名] 进入文件尾部 vim +/[字符串] [文件名] 光标定位到文件第一次出现该字符串的位置 底行模式 :w 保存 :q退出 :! 强制 :15 定位的第15行 /[字符串] 光标位置向后搜索该字符串 ?[字符串] 光标位置向前搜索该字符串 dd删除光标所在行 ctr+f 向下翻页 ctr+b 向上翻页 常用操作快捷键ctr+c 终止当前命令 ctr+l 清屏 相当于 clear ctr+a 光标移到行首 ctr+e 光标移到行尾 ctr+u 把光标所在位置删除到行首 ctr+z 把命令放入后台 ctr+r 在历史命令中搜索","tags":"linux"},{"title":"Java - CompletableFuture","url":"/posts/cad2f756.html","text":"CompletableFuture是Java8中对Future的增强。实现CompletionStage接口(40余个方法)，大多数方法多数应用在函数式编程中，并且支持流式调用。 简单实现： 123456789101112131415161718192021222324252627282930public class CompletableFutureTest implements Runnable &#123; CompletableFuture&lt;Integer&gt; completableFuture = null; public CompletableFutureTest(CompletableFuture&lt;Integer&gt; completableFuture) &#123; this.completableFuture = completableFuture; &#125; @Override public void run() &#123; int result = 0; try &#123; result = completableFuture.get() * completableFuture.get(); &#125; catch (Exception e) &#123; &#125; System.out.println(result); &#125; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; final CompletableFuture&lt;Integer&gt; future = new CompletableFuture&lt;&gt;(); new Thread(new CompletableFutureTest(future)).start(); //模拟长时间的计算过程 Thread.sleep(1000); //告知完成结果 future.complete(60); &#125;&#125; Future最令人诟病的就是要等待，要自己去检查任务是否完成了，在Future中，任务完成的时间是不可控的。而CompletableFuture的最大改进在于，任务完成的时间也开放了出来。 CompletableFuture的异步执行： 12345678910111213141516public static Integer calc(Integer param) &#123; try &#123; //模拟长时间的执行 Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#125; return param * param;&#125;public static void main(String[] args) throws InterruptedException, ExecutionException &#123; //异步调用 final CompletableFuture&lt;Integer&gt; future2 = CompletableFuture.supplyAsync(() -&gt; calc(50)); System.out.println(future2.get());&#125; CompletableFuture的流式调用： 1234567891011121314151617181920public static Integer calc(Integer param) &#123; try &#123; //模拟长时间的执行 Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#125; return param * param;&#125;public static void main(String[] args) throws InterruptedException, ExecutionException &#123; //流式调用 CompletableFuture&lt;Void&gt; future3 = CompletableFuture.supplyAsync(() -&gt; calc(40)) .thenApply((i) -&gt; Integer.toString(i)) .thenApply((str) -&gt; \"\\\"\" + str + \"\\\"\") .thenAccept(System.out::println); future3.get();&#125; 组合多个CompletableFuture： 123456789101112public static Integer calc2(Integer param) &#123; return param / 2;&#125;public static void main(String[] args) throws InterruptedException, ExecutionException &#123; //组合多个CompletableFuture CompletableFuture&lt;Void&gt; future4 = CompletableFuture.supplyAsync(() -&gt; calc2(100)) .thenCompose((i) -&gt; CompletableFuture.supplyAsync(() -&gt; calc2(i))) .thenApply((str) -&gt; \"\\\"\" + str + \"\\\"\") .thenAccept(System.out::println); future4.get();&#125; CompletableFuture跟性能上关系不大，更多的是为了支持函数式编程，在功能上的增强。当然开放了完成时间的设置是一大亮点。 演示的完整代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package main.java.com.study.completableFuture;import java.util.concurrent.CompletableFuture;import java.util.concurrent.ExecutionException;/** * @author: whb * @description: 增强版Future测试类 */public class CompletableFutureTest implements Runnable &#123; CompletableFuture&lt;Integer&gt; completableFuture = null; public CompletableFutureTest(CompletableFuture&lt;Integer&gt; completableFuture) &#123; this.completableFuture = completableFuture; &#125; @Override public void run() &#123; int result = 0; try &#123; result = completableFuture.get() * completableFuture.get(); &#125; catch (Exception e) &#123; &#125; System.out.println(result); &#125; public static Integer calc(Integer param) &#123; try &#123; //模拟长时间的执行 Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#125; return param * param; &#125; public static Integer calc2(Integer param) &#123; return param / 2; &#125; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; final CompletableFuture&lt;Integer&gt; future = new CompletableFuture&lt;&gt;(); new Thread(new CompletableFutureTest(future)).start(); //模拟长时间的计算过程 Thread.sleep(1000); //告知完成结果 future.complete(60); //异步调用 final CompletableFuture&lt;Integer&gt; future2 = CompletableFuture.supplyAsync(() -&gt; calc(50)); System.out.println(future2.get()); //流式调用 CompletableFuture&lt;Void&gt; future3 = CompletableFuture.supplyAsync(() -&gt; calc(40)) .thenApply((i) -&gt; Integer.toString(i)) .thenApply((str) -&gt; \"\\\"\" + str + \"\\\"\") .thenAccept(System.out::println); future3.get(); //组合多个CompletableFuture CompletableFuture&lt;Void&gt; future4 = CompletableFuture.supplyAsync(() -&gt; calc2(100)) .thenCompose((i) -&gt; CompletableFuture.supplyAsync(() -&gt; calc2(i))) .thenApply((str) -&gt; \"\\\"\" + str + \"\\\"\") .thenAccept(System.out::println); future4.get(); &#125;&#125;","tags":"java"},{"title":"Java多线程-12之-Callable、Future、FutureTask","url":"/posts/75995567.html","text":"概述从Java 1.5开始，开始提供了Callable和Future，通过它们可以在任务执行完毕之后得到任务执行结果。 对比Runnable和Callbale Runnable是在java.lang.Runnable包下面，没有返回值，而Callable是在java.util.concurrent包下面（说明Callable是为并发编程做准备的）可以有返回值。 Callable不能使用Thread来直接执行，一般情况下面使用ExecutorService中的submit方法类执行，Runnable使用ExecutorService的execute来执行。 Runnable接口里面有一个run()方法，无返回值；Callable接口里面有一个call()，有返回值，可以抛出异常。 FutureFuture就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果。必要时可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果。 在Future接口中声明了5个方法，依次解释每个方法的作用： cancel方法用来取消任务，如果取消任务成功则返回true，如果取消任务失败则返回false。参数mayInterruptIfRunning表示是否允许取消正在执行却没有执行完毕的任务，如果设置true，则表示可以取消正在执行过程中的任务。如果任务已经完成，则无论mayInterruptIfRunning为true还是false，此方法肯定返回false，即如果取消已经完成的任务会返回false；如果任务正在执行，若mayInterruptIfRunning设置为true，则返回true，若mayInterruptIfRunning设置为false，则返回false；如果任务还没有执行，则无论mayInterruptIfRunning为true还是false，肯定返回true。 isCancelled方法表示任务是否被取消成功，如果在任务正常完成前被取消成功，则返回 true。 isDone方法表示任务是否已经完成，若任务完成，则返回true； get()方法用来获取执行结果，这个方法会产生阻塞，会一直等到任务执行完毕才返回； get(long timeout, TimeUnit unit)用来获取执行结果，如果在指定时间内，还没获取到结果，就直接返回null。 也就是说Future提供了三种功能： 1）判断任务是否完成； 2）能够中断任务； 3）能够获取任务执行结果。 因为Future只是一个接口，所以是无法直接用来创建对象使用的，因此就有了FutureTask。 FutureTask先来看一下FutureTask的实现： 1public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; FutureTask类实现了RunnableFuture接口，看一下RunnableFuture接口的实现： 123public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; void run();&#125; 可以看出RunnableFuture继承了Runnable接口和Future接口，而FutureTask实现了RunnableFuture接口。所以它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值。 FutureTask提供了2个构造器： 1234public FutureTask(Callable&lt;V&gt; callable) &#123;&#125;public FutureTask(Runnable runnable, V result) &#123;&#125; 事实上，FutureTask是Future接口的一个唯一实现类。 使用示例使用Callable+Future获取执行结果1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package main.java.com.study.thread;import java.util.concurrent.*;/** * @author: whb * @description: 使用Callable+Future获取执行结果 */public class TestCallableFuture &#123; public static void main(String[] args) &#123; ExecutorService executor = Executors.newCachedThreadPool(); Task task = new Task(); Future&lt;Integer&gt; result = executor.submit(task); executor.shutdown(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; System.out.println(\"主线程在执行任务\"); try &#123; System.out.println(\"task运行结果\" + result.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; System.out.println(\"所有任务执行完毕\"); &#125;&#125;class Task implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; System.out.println(\"子线程在进行计算\"); Thread.sleep(3000); int sum = 0; for (int i = 0; i &lt; 100; i++) &#123; sum += i; &#125; return sum; &#125;&#125; 执行结果： 1234子线程在进行计算主线程在执行任务task运行结果4950所有任务执行完毕 使用Callable+FutureTask获取执行结果123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package main.java.com.study.thread;import java.util.concurrent.*;/** * @author: whb * @description: 使用Callable+FutureTask获取执行结果 */public class TestCallableFutureTask &#123; public static void main(String[] args) &#123; //第一种方式 ExecutorService executor = Executors.newCachedThreadPool(); Task2 task = new Task2(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(task); executor.submit(futureTask); executor.shutdown(); //第二种方式，注意这种方式和第一种方式效果是类似的，只不过一个使用的是ExecutorService，一个使用的是Thread /*Task task = new Task(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(task); Thread thread = new Thread(futureTask); thread.start();*/ try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; System.out.println(\"主线程在执行任务\"); try &#123; System.out.println(\"task运行结果\" + futureTask.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; System.out.println(\"所有任务执行完毕\"); &#125;&#125;class Task2 implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; System.out.println(\"子线程在进行计算\"); Thread.sleep(3000); int sum = 0; for (int i = 0; i &lt; 100; i++) sum += i; return sum; &#125;&#125; 执行结果： 1234子线程在进行计算主线程在执行任务task运行结果4950所有任务执行完毕 如果为了可取消性而使用 Future 但又不提供可用的结果，则可以声明 Future&lt;?&gt; 形式类型、并返回 null 作为底层任务的结果。","tags":"java 多线程"},{"title":"Java多线程-11之-生产者消费者模型","url":"/posts/4189fc6.html","text":"生产者/消费者模型生产/消费者问题是个非常典型的多线程问题，涉及到的对象包括“生产者”、“消费者”、“仓库”和“产品”。他们之间的关系如下： 生产者仅仅在仓储未满时候生产，仓满则停止生产。 消费者仅仅在仓储有产品时候才能消费，仓空则等待。 当消费者发现仓储没产品可消费时候会通知生产者生产。 生产者在生产出可消费产品时候，应该通知等待的消费者去消费。 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140package main.java.com.study.thread;/** * @author: whb * @description: 生产者消费者模型测试 */public class ProducerConsumerDemo &#123; public static void main(String[] args) &#123; Depot mDepot = new Depot(100); Producer mPro = new Producer(mDepot); Customer mCus = new Customer(mDepot); mPro.produce(60); mPro.produce(120); mCus.consume(90); mCus.consume(150); mPro.produce(110); &#125;&#125;/** * 仓库 */class Depot &#123; /** * 仓库的容量 */ private int capacity; /** * 仓库的实际数量 */ private int size; public Depot(int capacity) &#123; this.capacity = capacity; this.size = 0; &#125; /** * 生产 * * @param val */ public synchronized void produce(int val) &#123; try &#123; // left 表示“想要生产的数量”(有可能生产量太多，需多此生产) int left = val; while (left &gt; 0) &#123; // 库存已满时，等待“消费者”消费产品。 while (size &gt;= capacity) &#123; wait(); &#125; // 获取“实际生产的数量”(即库存中新增的数量) // 如果“库存”+“想要生产的数量”&gt;“总的容量”，则“实际增量”=“总的容量”-“当前容量”。(此时填满仓库) // 否则“实际增量”=“想要生产的数量” int inc = (size + left) &gt; capacity ? (capacity - size) : left; size += inc; left -= inc; System.out.printf(\"%s produce(%3d) --&gt; left=%3d, inc=%3d, size=%3d\\n\", Thread.currentThread().getName(), val, left, inc, size); // 通知“消费者”可以消费了。 notifyAll(); &#125; &#125; catch (InterruptedException e) &#123; &#125; &#125; /** * 消费 * * @param val */ public synchronized void consume(int val) &#123; try &#123; // left 表示“客户要消费数量”(有可能消费量太大，库存不够，需多此消费) int left = val; while (left &gt; 0) &#123; // 库存为0时，等待“生产者”生产产品。 while (size &lt;= 0) &#123; wait(); &#125; // 获取“实际消费的数量”(即库存中实际减少的数量) // 如果“库存”&lt;“客户要消费的数量”，则“实际消费量”=“库存”； // 否则，“实际消费量”=“客户要消费的数量”。 int dec = (size &lt; left) ? size : left; size -= dec; left -= dec; System.out.printf(\"%s consume(%3d) &lt;-- left=%3d, dec=%3d, size=%3d\\n\", Thread.currentThread().getName(), val, left, dec, size); notifyAll(); &#125; &#125; catch (InterruptedException e) &#123; &#125; &#125; @Override public String toString() &#123; return \"capacity:\" + capacity + \", actual size:\" + size; &#125;&#125;/** * 生产者 */class Producer &#123; private Depot depot; public Producer(Depot depot) &#123; this.depot = depot; &#125; /** * 消费产品：新建一个线程向仓库中生产产品。 * * @param val */ public void produce(final int val) &#123; new Thread(() -&gt; depot.produce(val)).start(); &#125;&#125;/** * 消费者 */class Customer &#123; private Depot depot; public Customer(Depot depot) &#123; this.depot = depot; &#125; /** * 消费产品：新建一个线程从仓库中消费产品。 * * @param val */ public void consume(final int val) &#123; new Thread(() -&gt; depot.consume(val)).start(); &#125;&#125; 说明： Producer是“生产者”类，它与“仓库(depot)”关联。当调用“生产者”的produce()方法时，它会新建一个线程并向“仓库”中生产产品。 Customer是“消费者”类，它与“仓库(depot)”关联。当调用“消费者”的consume()方法时，它会新建一个线程并消费“仓库”中的产品。 Depot是“仓库”类，仓库中记录“仓库的容量(capacity)”以及“仓库中当前产品数目(size)”。 “仓库”类的生产方法produce()和消费方法consume()方法都是synchronized方法，进入synchronized方法体，意味着这个线程获取到了该“仓库”对象的同步锁。这也就是说，同一时间，生产者和消费者线程只能有一个能运行。通过同步锁，实现了对“残酷”的互斥访问。对于生产方法produce()而言：当仓库满时，生产者线程等待，需要等待消费者消费产品之后，生产线程才能生产；生产者线程生产完产品之后，会通过notifyAll()唤醒同步锁上的所有线程，包括“消费者线程”，即我们所说的“通知消费者进行消费”。对于消费方法consume()而言：当仓库为空时，消费者线程等待，需要等待生产者生产产品之后，消费者线程才能消费；消费者线程消费完产品之后，会通过notifyAll()唤醒同步锁上的所有线程，包括“生产者线程”，即我们所说的“通知生产者进行生产”。 (某一次)运行结果： Thread-0 produce( 60) --&gt; left= 0, inc= 60, size= 60 Thread-4 produce(110) --&gt; left= 70, inc= 40, size=100 Thread-3 consume(150) &lt;-- left= 50, dec=100, size= 0 Thread-1 produce(120) --&gt; left= 20, inc=100, size=100 Thread-2 consume( 90) &lt;-- left= 0, dec= 90, size= 10 Thread-3 consume(150) &lt;-- left= 40, dec= 10, size= 0 Thread-4 produce(110) --&gt; left= 0, inc= 70, size= 70 Thread-3 consume(150) &lt;-- left= 0, dec= 40, size= 30 Thread-1 produce(120) --&gt; left= 0, inc= 20, size= 50","tags":"java 多线程"},{"title":"设计模式-模板方法模式","url":"/posts/2d3dc485.html","text":"模式定义定义一个操作中算法的框架，而将一些步骤延迟到子类中。模板方法模式使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。模板方法模式是一种基于继承的代码复用技术，它是一种类行为型模式。 主要作用当完成一个操作具有固定的流程时，由抽象固定流程步骤，具体步骤交给子类进行具体实现（固定的流程，不同的实现）。 UML类图 角色 AbstractClass（抽象类）：在抽象类中定义了一系列基本操作(PrimitiveOperations)，这些基本操作可以是具体的，也可以是抽象的，每一个基本操作对应算法的一个步骤，在其子类中可以重定义或实现这些步骤。同时，在抽象类中实现了一个模板方法(Template Method)，用于定义一个算法的框架，模板方法不仅可以调用在抽象类中实现的基本方法，也可以调用在抽象类的子类中实现的基本方法，还可以调用其他对象中的方法。 ConcreteClass（具体子类）：它是抽象类的子类，用于实现在父类中声明的抽象基本操作以完成子类特定算法的步骤，也可以覆盖在父类中已经实现的具体基本操作。 模式原理一个模板方法是定义在抽象类中的、把基本操作方法组合在一起形成一个总算法或一个总行为的方法。这个模板方法定义在抽象类中，并由子类不加以修改地完全继承下来。模板方法是一个具体方法，它给出了一个顶层逻辑框架，而逻辑的组成步骤在抽象类中可以是具体方法，也可以是抽象方法。 基本方法是实现算法各个步骤的方法，是模板方法的组成部分。基本方法又可以分为三种：抽象方法(Abstract Method)、具体方法(Concrete Method)和钩子方法(Hook Method)。 抽象方法：一个抽象方法由抽象类声明、由其具体子类实现。 具体方法：一个具体方法由一个抽象类或具体类声明并实现，其子类可以进行覆盖也可以直接继承。 钩子方法：可以与一些具体步骤 “挂钩” ，以实现在不同条件下执行模板方法中的不同步骤。 模式优点 提高代码复用性：将相同部分的代码放在抽象的父类中。 提高了拓展性：将不同的代码放入不同的子类中，通过对子类的扩展增加新的行为。 实现了反向控制：通过一个父类调用其子类的操作，通过对子类的扩展增加新的行为，实现了反向控制，符合“单一职责”和“开闭原则” 模式缺点 引入了抽象类，每一个不同的实现都需要一个子类来实现，导致类的个数增加，从而增加了系统实现的复杂度。 适用场景 一次性实现一个算法的不变部分，并将可变的行为留给子类来实现。 各子类中公共的行为应被提取出来并集中到一个公共父类中以避免代码重复。 需要通过子类来决定父类算法中某个步骤是否执行，实现子类对父类的反向控制。 使用步骤抽象模板类12345678910111213141516171819202122232425262728package main.java.com.study.designPatterns.templateMethod.demoOne;/** * @author: whb * @description: 抽象模板类，定义了一套算法框架/流程； */public abstract class AbstractClass &#123; protected void step1() &#123; System.out.println(\"AbstractClass:step1\"); &#125; protected void step2() &#123; System.out.println(\"AbstractClass:step2\"); &#125; protected void step3() &#123; System.out.println(\"AbstractClass:step3\"); &#125; /** * 固定算法，声明为final方法，避免子类覆写 */ public final void templateMehthod() &#123; this.step1(); this.step2(); this.step3(); &#125;&#125; 具体实现类12345678910111213141516171819202122232425package main.java.com.study.designPatterns.templateMethod.demoOne;/** * @author: whb * @description: 具体实现类A */public class ConcreteClassA extends AbstractClass &#123; @Override protected void step1() &#123; System.out.println(\"ConcreateClassA:step1\"); &#125;&#125;package main.java.com.study.designPatterns.templateMethod.demoOne;/** * @author: whb * @description: 具体实现类B */public class ConcreteClassB extends AbstractClass &#123; @Override protected void step2() &#123; System.out.println(\"ConcreateClassB:step2\"); &#125;&#125; 客户端调用1234567891011121314package main.java.com.study.designPatterns.templateMethod.demoOne;/** * @author: whb * @description: 测试类 */public class Client &#123; public static void main(String[] args) &#123; AbstractClass abc = new ConcreteClassA(); abc.templateMehthod(); abc = new ConcreteClassB(); abc.templateMehthod(); &#125;&#125;","tags":"java 设计模式"},{"title":"数据库锁机制及事务隔离级别","url":"/posts/57a9974a.html","text":"前言用T1代表一个数据库执行请求，T2代表另一个请求，也可以理解为T1为一个线程，T2 为另一个线程。T3,T4以此类推。 锁的种类共享锁(Shared lock) 例1： 12T1: select * from table (请想象它需要执行1个小时之久，后面的sql语句请都这么想象）T2: update table set column1=&apos;hello&apos; 过程： T1运行 （加共享锁)T2运行If T1 还没执行完 T2等……else 锁被释放 T2执行endif T2之所以要等，是因为T2在执行update前，试图对table表加一个排他锁，而数据库规定同一资源上不能同时共存共享锁和排他锁。所以T2必须等T1执行完，释放了共享锁，才能加上排他锁，然后才能开始执行update语句。 例2： 12T1: select * from tableT2: select * from table 这里T2不用等待T1执行完，而是可以马上执行。 分析： T1运行，则table被加锁，比如叫lockA，T2运行，再对table加一个共享锁，比如叫lockB。两个锁是可以同时存在于同一资源上的（比如同一个表上）。这被称为共享锁与共享锁兼容。这意味着共享锁不阻止其它session同时读资源，但阻止其它session update 例3： 123T1: select * from tableT2: select * from tableT3: update table set column1=&apos;hello&apos; 这次，T2不用等T1运行完就能运行，T3却要等T1和T2都运行完才能运行。 因为T3必须等T1和T2的共享锁全部释放才能进行加排他锁然后执行update操作。 例4：（死锁的发生） 12345678T1:begin transelect * from table (holdlock) (holdlock意思是加共享锁，直到事物结束才释放)update table set column1=&apos;hello&apos;T2:begin transelect * from table(holdlock)update table set column1=&apos;world&apos; 假设T1和T2同时达到select，T1对table加共享锁，T2也对加共享锁，当T1的select执行完，准备执行update时，根据锁机制，T1的共享锁需要升级到排他锁才能执行接下来的update.在升级排他锁前，必须等table上的其它共享锁释放，但因为holdlock这样的共享锁只有等事务结束后才释放，所以因为T2的共享锁不释放而导致T1等(等T2释放共享锁，自己好升级成排他锁），同理，也因为T1的共享锁不释放而导致T2等。死锁产生了。 例5： 123456T1:begin tranupdate table set column1=&apos;hello&apos; where id=10T2:begin tranupdate table set column1=&apos;world&apos; where id=20 这种语句虽然最为常见，很多人觉得它有机会产生死锁，但实际上要看情况，如果id是主键上面有索引，那么T1会一下子找到该条记录(id=10的记录），然后对该条记录加排他锁，T2，同样，一下子通过索引定位到记录，然后对id=20的记录加排他锁，这样T1和T2各更新各的，互不影响。T2也不需要等。 但如果id是普通的一列，没有索引。那么当T1对id=10这一行加排他锁后，T2为了找到id=20，需要对全表扫描，那么就会预先对表加上共享锁或更新锁或排他锁(依赖于数据库执行策略和方式，比如第一次执行和第二次执行数据库执行策略就会不同）。但因为T1已经为一条记录加了排他锁，导致T2的全表扫描进行不下去，就导致T2等待。 死锁怎么解决呢？一种办法是，如下： 例6： 12345678T1:begin transelect * from table(xlock) (xlock意思是直接对表加排他锁)update table set column1=&apos;hello&apos;T2:begin transelect * from table(xlock)update table set column1=&apos;world&apos; 当T1的select 执行时，直接对表加上了排他锁，T2在执行select时，就需要等T1事务完全执行完才能执行。排除了死锁发生。但当第三个user过来想执行一个查询语句时，也因为排他锁的存在而不得不等待，第四个、第五个user也会因此而等待。在大并发情况下，让大家等待显得性能就太友好了，所以，这里引入了更新锁。 更新锁(Update lock) 为解决死锁，引入更新锁。 例7： 12345678T1:begin transelect * from table(updlock) (加更新锁)update table set column1=&apos;hello&apos;T2:begin transelect * from table(updlock)update table set column1=&apos;world&apos; 更新锁的意思是：“我现在只想读，你们别人也可以读，但我将来可能会做更新操作，我已经获取了从共享锁（用来读）到排他锁（用来更新）的资格”。一个事物只能有一个更新锁获此资格。 T1执行select，加更新锁。 T2运行，准备加更新锁，但发现已经有一个更新锁在那儿了，只好等。 当后来有user3、user4…需要查询table表中的数据时，并不会因为T1的select在执行就被阻塞，照样能查询，相比起例6，这提高了效率。 例8： 123T1: select * from table(updlock) (加更新锁）T2: select * from table(updlock) (等待，直到T1释放更新锁，因为同一时间不能在同一资源上有两个更新锁）T3: select * from table (加共享锁，但不用等updlock释放，就可以读） 这个例子是说明：共享锁和更新锁可以同时在同一个资源上。这被称为共享锁和更新锁是兼容的。 排他锁（独占锁，Exclusive Locks) 其它事务既不能读，又不能改排他锁锁定的资源。 例9： 12345678T1:beginselect * from table(updlock) (加更新锁）update table set column1=&apos;hello&apos; (重点：这里T1做update时，不需要等T2释放什么，而是直接把更新锁升级为排他锁，然后执行update)T2:beginselect * from table (T1加的更新锁不影响T2读取）update table set column1=&apos;world&apos; (T2的update需要等T1的update做完才能执行) 第一种情况：T1先达，T2紧接到达；在这种情况中，T1先对表加更新锁，T2对表加共享锁，假设T2的select先执行完，准备执行update，发现已有更新锁存在，T2等。T1这时才执行完select，准备执行update，更新锁升级为排他锁，然后执行update，执行完成，事务结束，释放锁，T2才轮到执行update。 第二种情况：T2先达，T1紧接达；在这种情况，T2先对表加共享锁，T1到达后，T1对表加更新锁，假设T2 select先结束，准备update，发现已有更新锁，则等待，后面步骤就跟第一种情况一样了。 这个例子是说明：排他锁与更新锁是不兼容的，它们不能同时加在同一资源上。 例10： 12T1: update table set column1=&apos;hello&apos; where id&lt;1000T2: update table set column1=&apos;world&apos; where id&gt;1000 假设T1先达，T2随后至，这个过程中T1会对id&lt;1000的记录施加排他锁.但不会阻塞T2的update。 例11：(假设id都是自增长且连续的） 12T1: update table set column1=&apos;hello&apos; where id&lt;1000T2: update table set column1=&apos;world&apos; where id&gt;900 如同例10，T1先达，T2立刻也到，T1加的排他锁会阻塞T2的update。 意向锁(Intent Locks)意向锁就是说在屋（比如代表一个表）门口设置一个标识，说明屋子里有人（比如代表某些记录）被锁住了。另一个人想知道屋子里是否有人被锁，不用进屋子里一个个去查，直接看门口标识就行了。 当一个表中的某一行被加上排他锁后，该表就不能再被加表锁。数据库程序如何知道该表不能被加表锁？一种方式是逐条的判断该表的每一条记录是否已经有排他锁，另一种方式是直接在表这一层级检查表本身是否有意向锁，不需要逐条判断。显然后者效率高。 例12： 1234T1: begin transelect * from table (xlock) where id=10 --意思是对id=10这一行强加排他锁T2: begin transelect * from table (tablock) --意思是要加表级锁 假设T1先执行，T2后执行，T2执行时，欲加表锁，为判断是否可以加表锁，数据库系统要逐条判断table表每行记录是否已有排他锁，如果发现其中一行已经有排他锁了，就不允许再加表锁了。只是这样逐条判断效率太低了。 实际上，数据库系统不是这样工作的。当T1的select执行时，系统对表table的id=10的这一行加了排他锁，还同时悄悄的对整个表加了意向排他锁(IX)，当T2执行表锁时，只需要看到这个表已经有意向排他锁存在，就直接等待，而不需要逐条检查资源了。 例13： 1234T1: begin tranupdate table set column1=&apos;hello&apos; where id=1T2: begin tranupdate table set column1=&apos;world&apos; where id=1 这个例子和上面的例子实际效果相同，T1执行，系统同时对行加排他锁、对页加意向排他锁、对表加意向排他锁。 计划锁(Schema Locks) 例14： 1alter table .... (加schema locks，称之为Schema modification (Sch-M) locks DDL语句都会加Sch-M锁，该锁不允许任何其它session连接该表。连都连不了这个表了，当然更不用说想对该表执行什么sql语句了。 例15： 用jdbc向数据库发送了一条新的sql语句，数据库要先对之进行编译，在编译期间，也会加锁，称之为：Schema stability (Sch-S) locks。 1select * from tableA 编译这条语句过程中，其它session可以对表tableA做任何操作(update,delete，加排他锁等等），但不能做DDL(比如alter table)操作。 Bulk Update Locks 主要在批量导数据时用（比如用类似于oracle中的imp/exp的bcp命令）。 何时加锁 例16： 12345T1: begin tranupdate table set column1=&apos;hello&apos; where id=1T2: SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED -- 事务隔离级别为允许脏读select * from table where id=1 这里，T2的select可以查出结果。如果事务隔离级别不设为脏读，则T2会等T1事务执行完才能读出结果。 数据库如何自动加锁的？ 1) T1执行，数据库自动加排他锁2) T2执行，数据库发现事务隔离级别允许脏读，便不加共享锁。不加共享锁，则不会与已有的排他锁冲突，所以可以脏读。 例17： 123T1: begin tranupdate table set column1=&apos;hello&apos; where id=1T2: select * from table where id=1 –未指定隔离级别，则使用系统默认隔离级别，它不允许脏读 如果事务级别不设为脏读，则：1) T1执行，数据库自动加排他锁2) T2执行，数据库发现事务隔离级别不允许脏读，便准备为此次select过程加共享锁，但发现加不上，因为已经有排他锁了，所以就等到T1执行完，释放了排他锁，T2才加上了共享锁，然后开始读…. 锁的粒度锁的粒度就是指锁的生效范围，就是说是行锁，还是页锁，还是整表锁. 锁的粒度同样既可以由数据库自动管理，也可以通过手工指定hint来管理。 例18： 12T1: select * from table (paglock)T2: update table set column1=&apos;hello&apos; where id&gt;10 T1执行时，会先对第一页加锁，读完第一页后，释放锁，再对第二页加锁，依此类推。假设前10行记录恰好是一页(当然，一般不可能一页只有10行记录），那么T1执行到第一页查询时，并不会阻塞T2的更新。 例19： 12T1: select * from table (rowlock)T2: update table set column1=&apos;hello&apos; where id=10 T1执行时，对每行加共享锁，读取，然后释放，再对下一行加锁;T2执行时，会对id=10的那一行试图加锁，只要该行没有被T1加上行锁，T2就可以顺利执行update操作。 例20： 12T1: select * from table (tablock)T2: update table set column1=&apos;hello&apos; where id = 10 T1执行，对整个表加共享锁. T1必须完全查询完，T2才可以允许加锁，并开始更新。 锁与事务隔离级别的优先级 手工指定的锁优先。 例21： 1234567T1: SET TRANSACTION ISOLATION LEVEL SERIALIZABLEBEGIN TRANSACTIONSELECT * FROM table (NOLOCK)T2: update table set column1=&apos;hello&apos; where id=10 T1是事务隔离级别为最高级，串行锁，数据库系统本应对后面的select语句自动加表级锁，但因为手工指定了NOLOCK，所以该select语句不会加任何锁，所以T2也就不会有任何阻塞。 数据库其他锁及其区别 holdlock 对表加共享锁，且事务（commit/rollback）不完成，共享锁不释放。 tablock 对表加共享锁，只要statement不完成，共享锁不释放。 tablock 例22： 123456T1:begin transelect * from table (tablock)T2:begin tranupdate table set column1=&apos;hello&apos; where id = 10 T1执行完select，就会释放共享锁，然后T2就可以执行update。 holdlock 例23： 123456T1:begin transelect * from table (holdlock)T2:begin tranupdate table set column1=&apos;hello&apos; where id = 10 T1执行完select，共享锁仍然不会释放，仍然会被hold(持有），T2也因此必须等待而不能update. 当T1最后执行了commit或rollback说明这一个事务结束了，T2才取得执行权。 TABLOCKX 对表加排他锁 例24： 1T1: select * from table(tablockx) (强行加排他锁） 其它session就无法对这个表进行读和更新了，除非T1执行完了，就会自动释放排他锁。 例25： 12T1: begin transelect * from table(tablockx) 单单select执行完还不行，必须整个事务完成（commit或rollback后）才会释放排他锁。 xlock 加排他锁 例26： 1select * from table(xlock paglock) 对page加排他锁 xlock还可这么用： 1select * from table(xlock tablock) 效果等同于 1select * from table(tablockx) 锁的超时等待SET LOCK_TIMEOUT 4000 用来设置锁等待时间，单位是毫秒，4000意味着等待4秒可以用select @@LOCK_TIMEOUT查看当前session的锁超时设置。-1 意味着永远等待。 例27： 1234T1: begin tranudpate table set column1=&apos;hello&apos; where id = 10T2: set lock_timeout 4000select * from table wehre id = 10 T2执行时，会等待T1释放排他锁，等了4秒钟，如果T1还没有释放排他锁，T2就会抛出异常： Lock request time out period exceeded。 事务隔离级别SQL标准规定了四个隔离水平： READ_UNCOMMITTED（读未提交） ：事务中的修改，即使没有提交，其他事务也可以看得到，会导致“脏读”、“幻读”和“不可重复读”。READ_COMMITTED（读已提交）：大多数主流数据库的默认事务等级，保证了一个事务不会读到另一个并行事务已修改但未提交的数据，避免了“脏读”，但不能避免“幻读”和“不可重复读”。该级别适用于大多数系统，如Oracle、SQLServer等。REPETABLE_READ（重复读） ：保证了一个事务不会修改已经由另一个事务读取但未提交（回滚）的数据。避免了“脏读”和“不可重复读”的情况，但不能避免“幻读”。MySQL默认就是这种隔离级别。SERIALIZABLE（串行化）：最严格的级别，事务串行执行，资源消耗最大； 脏读 脏读发生在：当一个事务允许读取一个被其他事务改变但是未提交的状态时，这是因为并没有锁阻止读取。 如上图，第二个事务读取了一个并不一致的值。不一致的意思是，这个值是无效的，因为修改这个值的第一个事务已经回滚，也就是说，第一个事务修改了这个值，但是未提交确认，却被第二个事务读取，第一个事务又放弃修改，而第二个事务就得到一个脏数据。 不可重复读 反复读同一个数据却得到不同的结果，这是因为在反复几次读取的过程中，数据被修改了，这就导致我们使用了stale数据，这可以通过一个共享读锁来避免。这是隔离级别READ_COMMITTED会导致可重复读的原因。设置共享读锁也就是隔离级别提高到REPETABLE_READ。 幻读 当第二个事务插入一行记录，而正好之前第一个事务查询了应该包含这个新纪录的数据，那么这个查询事务的结果里肯定没有包含这个刚刚新插入的数据，这时幻影读发生了，通过变化锁和predicate locking避免。 总结不可重复读和幻读的区别是：前者是指读到了已经提交的事务的更改数据（update或delete），后者是指读到了其他已经提交事务的新增数据（insert）。 对于这两种问题解决采用不同的办法，防止读到更改数据，只需对操作的数据添加行级锁，防止操作中的数据发生变化； 防止读到新增数据，往往需要添加表级锁，将整张表锁定，防止新增数据（oracle采用多版本数据的方式实现）。 READ_COMMITED 是比较正确的选择，因为SERIALIZABLE虽然能在不同事务发生时避免stale数据，也就是避免上述丢失刚刚修改的数据，但是性能是最低的，因为是一种最大化的串行。","tags":"数据库"},{"title":"Java多线程-10之-线程优先级和守护线程","url":"/posts/fc4de834.html","text":"线程优先级java 中的线程优先级的范围是1～10，默认的优先级是5。“高优先级线程”会优先于“低优先级线程”执行。 java 中有两种线程：用户线程和守护线程。可以通过isDaemon()方法来区别它们：如果返回false，则说明该线程是“用户线程”；否则就是“守护线程”。用户线程一般用户执行用户级任务，而守护线程也就是“后台线程”，一般用来执行后台任务。需要注意的是：Java虚拟机在“用户线程”都结束后会后退出。 JDK 中关于线程优先级和守护线程的介绍如下： 1234567Every thread has a priority. Threads with higher priority are executed in preference to threads with lower priority. Each thread may or may not also be marked as a daemon. When code running in some thread creates a new Thread object, the new thread has its priority initially set equal to the priority of the creating thread, and is a daemon thread if and only if the creating thread is a daemon.When a Java Virtual Machine starts up, there is usually a single non-daemon thread (which typically calls the method named main of some designated class). The Java Virtual Machine continues to execute threads until either of the following occurs:The exit method of class Runtime has been called and the security manager has permitted the exit operation to take place.All threads that are not daemon threads have died, either by returning from the call to the run method or by throwing an exception that propagates beyond the run method. Marks this thread as either a daemon thread or a user thread. The Java Virtual Machine exits when the only threads running are all daemon threads. 大致意思是： 1234567每个线程都有一个优先级。“高优先级线程”会优先于“低优先级线程”执行。每个线程都可以被标记为一个守护进程或非守护进程。在一些运行的主线程中创建新的子线程时，子线程的优先级被设置为等于“创建它的主线程的优先级”，当且仅当“创建它的主线程是守护线程”时“子线程才会是守护线程”。当Java虚拟机启动时，通常有一个单一的非守护线程（该线程通过是通过main()方法启动）。JVM会一直运行直到下面的任意一个条件发生，JVM就会终止运行：(01) 调用了exit()方法，并且exit()有权限被正常执行。(02) 所有的“非守护线程”都死了(即JVM中仅仅只有“守护线程”)。每一个线程都被标记为“守护线程”或“用户线程”。当只有守护线程运行时，JVM会自动退出。 线程优先级的示例12345678910111213141516171819202122232425262728293031323334353637383940package main.java.com.study.thread.priority;/** * @author: whb * @description: 线程优先级测试 */public class PriorityDemo &#123; public static void main(String[] args) &#123; System.out.println(Thread.currentThread().getName() + \"(\" + Thread.currentThread().getPriority() + \")\"); // 新建线程t1 Thread t1 = new MyThread(\"t1\"); // 新建线程t2 Thread t2 = new MyThread(\"t2\"); // 设置t1的优先级为1 t1.setPriority(1); // 设置t2的优先级为10 t2.setPriority(10); // 启动t1 t1.start(); // 启动t2 t2.start(); &#125;&#125;class MyThread extends Thread &#123; public MyThread(String name) &#123; super(name); &#125; @Override public void run() &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(Thread.currentThread().getName() + \"(\" + Thread.currentThread().getPriority() + \")\" + \", loop \" + i); &#125; &#125;&#125;; 运行结果： 1234567891011main(5)t1(1), loop 0t2(10), loop 0t1(1), loop 1t1(1), loop 2t1(1), loop 3t2(10), loop 1t1(1), loop 4t2(10), loop 2t2(10), loop 3t2(10), loop 4 结果说明： 主线程main的优先级是5。 t1的优先级被设为1，而t2的优先级被设为10。cpu在执行t1和t2的时候，根据时间片轮循调度，所以能够并发执行。 守护线程的示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package main.java.com.study.thread.priority;/** * @author: whb * @description: 守护线程示例 */public class DaemonDemo &#123; public static void main(String[] args) &#123; System.out.println(Thread.currentThread().getName() + \"(isDaemon=\" + Thread.currentThread().isDaemon() + \")\"); // 新建线程t1 Thread t1 = new MyThread2(\"t1\"); // 新建线程t2 Thread t2 = new MyDaemon(\"t2\"); // 设置t2为守护线程 t2.setDaemon(true); // 启动t1 t1.start(); // 启动t2 t2.start(); &#125;&#125;class MyThread2 extends Thread &#123; public MyThread2(String name) &#123; super(name); &#125; @Override public void run() &#123; try &#123; for (int i = 0; i &lt; 5; i++) &#123; Thread.sleep(3); System.out.println(this.getName() + \"(isDaemon=\" + this.isDaemon() + \")\" + \", loop \" + i); &#125; &#125; catch (InterruptedException e) &#123; &#125; &#125;&#125;;class MyDaemon extends Thread &#123; public MyDaemon(String name) &#123; super(name); &#125; @Override public void run() &#123; try &#123; for (int i = 0; i &lt; 10000; i++) &#123; Thread.sleep(1); System.out.println(this.getName() + \"(isDaemon=\" + this.isDaemon() + \")\" + \", loop \" + i); &#125; &#125; catch (InterruptedException e) &#123; &#125; &#125;&#125; 运行结果： 12345678910111213141516main(isDaemon=false)t2(isDaemon=true), loop 0t2(isDaemon=true), loop 1t1(isDaemon=false), loop 0t2(isDaemon=true), loop 2t1(isDaemon=false), loop 1t2(isDaemon=true), loop 3t2(isDaemon=true), loop 4t1(isDaemon=false), loop 2t2(isDaemon=true), loop 5t2(isDaemon=true), loop 6t2(isDaemon=true), loop 7t1(isDaemon=false), loop 3t2(isDaemon=true), loop 8t2(isDaemon=true), loop 9t1(isDaemon=false), loop 4 结果说明： 主线程main是用户线程，它创建的子线程t1也是用户线程。 t2是守护线程。在“主线程main”和“子线程t1”(它们都是用户线程)执行完毕，只剩t2这个守护线程的时候，JVM自动退出。","tags":"java 多线程"},{"title":"Java多线程-09之-线程中断和终止方式","url":"/posts/bafe248a.html","text":"interrupt()说明关于interrupt()，java的djk文档描述如下：http://docs.oracle.com/javase/7/docs/api/ Interrupts this thread.Unless the current thread is interrupting itself, which is always permitted, the checkAccess method of this thread is invoked, which may cause a SecurityException to be thrown. If this thread is blocked in an invocation of the wait(), wait(long), or wait(long, int) methods of the Object class, or of the join(), join(long), join(long, int), sleep(long), or sleep(long, int), methods of this class, then its interrupt status will be cleared and it will receive an InterruptedException. If this thread is blocked in an I/O operation upon an interruptible channel then the channel will be closed, the thread’s interrupt status will be set, and the thread will receive a ClosedByInterruptException. If this thread is blocked in a Selector then the thread’s interrupt status will be set and it will return immediately from the selection operation, possibly with a non-zero value, just as if the selector’s wakeup method were invoked. If none of the previous conditions hold then this thread’s interrupt status will be set. Interrupting a thread that is not alive need not have any effect. 大致意思是： interrupt()的作用是中断本线程。本线程中断自己是被允许的；其它线程调用本线程的interrupt()方法时，会通过checkAccess()检查权限。这有可能抛出SecurityException异常。如果本线程是处于阻塞状态：调用线程的wait(), wait(long)或wait(long, int)会让它进入等待(阻塞)状态，或者调用线程的join(), join(long), join(long, int), sleep(long), sleep(long, int)也会让它进入阻塞状态。若线程在阻塞状态时，调用了它的interrupt()方法，那么它的“中断状态”会被清除并且会收到一个InterruptedException异常。例如，线程通过wait()进入阻塞状态，此时通过interrupt()中断该线程；调用interrupt()会立即将线程的中断标记设为“true”，但是由于线程处于阻塞状态，所以该“中断标记”会立即被清除为“false”，同时，会产生一个InterruptedException的异常。如果线程被阻塞在一个Selector选择器中，那么通过interrupt()中断它时；线程的中断标记会被设置为true，并且它会立即从选择操作中返回。如果不属于前面所说的情况，那么通过interrupt()中断线程时，它的中断标记会被设置为“true”。中断一个“已终止的线程”不会产生任何操作。 终止线程的方式终止处于“阻塞状态”的线程通常，我们通过“中断”方式终止处于“阻塞状态”的线程。当线程由于被调用了sleep(), wait(), join()等方法而进入阻塞状态；若此时调用线程的interrupt()将线程的中断标记设为true。由于处于阻塞状态，中断标记会被清除，同时产生一个InterruptedException异常。将InterruptedException放在适当的为止就能终止线程，形式如下： 12345678910@Overridepublic void run() &#123; try &#123; while (true) &#123; // 执行任务... &#125; &#125; catch (InterruptedException ie) &#123; // 由于产生InterruptedException异常，退出while(true)循环，线程终止！ &#125;&#125; 说明： 在while(true)中不断的执行任务，当线程处于阻塞状态时，调用线程的interrupt()产生InterruptedException中断。中断的捕获在while(true)之外，这样就退出了while(true)循环！ 注意： 对InterruptedException的捕获务一般放在while(true)循环体的外面，这样，在产生异常时就退出了while(true)循环。否则，InterruptedException在while(true)循环体之内，就需要额外的添加退出处理。 形式如下： 123456789101112@Overridepublic void run() &#123; while (true) &#123; try &#123; // 执行任务... &#125; catch (InterruptedException ie) &#123; // InterruptedException在while(true)循环体内。 // 当线程产生了InterruptedException异常时，while(true)仍能继续运行！需要手动退出 break; &#125; &#125;&#125; 说明： 上面的InterruptedException异常的捕获在whle(true)之内。当产生InterruptedException异常时，被catch处理之外，仍然在while(true)循环体内；要退出while(true)循环体，需要额外的执行退出while(true)的操作。 终止处于“运行状态”的线程通常，我们通过“标记”方式终止处于“运行状态”的线程。其中，包括“中断标记”和“额外添加标记”。 通过“中断标记”终止线程形式如下： 123456@Overridepublic void run() &#123; while (!isInterrupted()) &#123; // 执行任务... &#125;&#125; 说明： isInterrupted()是判断线程的中断标记是不是为true。当线程处于运行状态，并且我们需要终止它时；可以调用线程的interrupt()方法，使用线程的中断标记为true，即isInterrupted()会返回true。此时，就会退出while循环。 注意：interrupt()并不会终止处于“运行状态”的线程！它会将线程的中断标记设为true。 通过“额外添加标记”形式如下： 1234567891011private volatile boolean flag= true;protected void stopTask() &#123; flag = false;&#125;@Overridepublic void run() &#123; while (flag) &#123; // 执行任务... &#125;&#125; 说明： 线程中有一个flag标记，它的默认值是true；并且我们提供stopTask()来设置flag标记。当我们需要终止该线程时，调用该线程的stopTask()方法就可以让线程退出while循环。 注意：将flag定义为volatile类型，是为了保证flag的可见性。即其它线程通过stopTask()修改了flag之后，本线程能看到修改后的flag的值。 综合线程处于“阻塞状态”和“运行状态”的终止方式，比较 通用的终止线程的形式 如下： 1234567891011@Overridepublic void run() &#123; try &#123; // 1. isInterrupted()保证，只要中断标记为true就终止线程。 while (!isInterrupted()) &#123; // 执行任务... &#125; &#125; catch (InterruptedException ie) &#123; // 2. InterruptedException异常保证，当InterruptedException异常产生时，线程被终止。 &#125;&#125; 终止线程的示例首先定义线程对象MyThread 1234567891011121314151617181920212223242526package main.java.com.study.thread.interrupt;/** * @author: whb * @description: 线程对象 */public class MyThread extends Thread &#123; public MyThread(String name) &#123; super(name); &#125; @Override public void run() &#123; int i = 0; while (!isInterrupted()) &#123; try &#123; Thread.sleep(100); &#125; catch (InterruptedException ie) &#123; System.out.println(Thread.currentThread().getName() + \" (\" + this.getState() + \") catch InterruptedException.\"); &#125; i++; System.out.println(Thread.currentThread().getName() + \" (\" + this.getState() + \") loop \" + i); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930package main.java.com.study.thread.interrupt;/** * @author: whb * @description: 线程终止示例1 */public class Demo1 &#123; public static void main(String[] args) &#123; try &#123; // 新建“线程t1” Thread t1 = new MyThread(\"t1\"); System.out.println(t1.getName() + \" (\" + t1.getState() + \") is new.\"); t1.start(); // 启动“线程t1” System.out.println(t1.getName() + \" (\" + t1.getState() + \") is started.\"); // 主线程休眠300ms，然后主线程给t1发“中断”指令。 Thread.sleep(300); t1.interrupt(); System.out.println(t1.getName() + \" (\" + t1.getState() + \") is interrupted.\"); // 主线程休眠300ms，然后查看t1的状态。 Thread.sleep(300); System.out.println(t1.getName() + \" (\" + t1.getState() + \") is interrupted now.\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 运行结果： 1234567t1 (NEW) is new.t1 (RUNNABLE) is started.t1 (RUNNABLE) loop 1t1 (RUNNABLE) loop 2t1 (TIMED_WAITING) is interrupted.t1 (RUNNABLE) catch InterruptedException.t1 (TERMINATED) is interrupted now. 结果说明： 主线程main中通过new MyThread(“t1”)创建线程t1，之后通过t1.start()启动线程t1。 t1启动之后，会不断的检查它的中断标记，如果中断标记为“false”；则休眠100ms。 t1休眠之后，会切换到主线程main；主线程再次运行时，会执行t1.interrupt()中断线程t1。t1收到中断指令之后，会将t1的中断标记设置“false”，而且会抛出InterruptedException异常。在t1的run()方法中，是在循环体while之外捕获的异常；因此循环被终止。 对上面的代码进行小小的修改，将run()方法中捕获InterruptedException异常的代码块移到while循环体内。 12345678910111213141516171819202122232425262728293031package main.java.com.study.thread.interrupt;/** * @author: whb * @description: 线程终止示例2 */public class Demo2 &#123; public static void main(String[] args) &#123; try &#123; // 新建“线程t1” Thread t1 = new MyThread(\"t1\"); System.out.println(t1.getName() + \" (\" + t1.getState() + \") is new.\"); // 启动“线程t1” t1.start(); System.out.println(t1.getName() + \" (\" + t1.getState() + \") is started.\"); // 主线程休眠300ms，然后主线程给t1发“中断”指令。 Thread.sleep(300); t1.interrupt(); System.out.println(t1.getName() + \" (\" + t1.getState() + \") is interrupted.\"); // 主线程休眠300ms，然后查看t1的状态。 Thread.sleep(300); System.out.println(t1.getName() + \" (\" + t1.getState() + \") is interrupted now.\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 运行结果： 123456789101112131415t1 (NEW) is new.t1 (RUNNABLE) is started.t1 (RUNNABLE) loop 1t1 (RUNNABLE) loop 2t1 (TIMED_WAITING) is interrupted.t1 (RUNNABLE) catch InterruptedException.t1 (RUNNABLE) loop 3t1 (RUNNABLE) loop 4t1 (RUNNABLE) loop 5t1 (TIMED_WAITING) is interrupted now.t1 (RUNNABLE) loop 6t1 (RUNNABLE) loop 7t1 (RUNNABLE) loop 8t1 (RUNNABLE) loop 9... 结果说明： 程序进入了死循环！ 为什么会这样呢？这是因为，t1在“等待(阻塞)状态”时，被interrupt()中断；此时，会清除中断标记「即isInterrupted()会返回false」，而且会抛出InterruptedException异常「该异常在while循环体内被捕获」。因此，t1理所当然的会进入死循环了。 解决该问题，需要在捕获异常时，额外的进行退出while循环的处理。例如，在MyThread的catch(InterruptedException)中添加break 或 return就能解决该问题。 下面是通过“额外添加标记”的方式终止“状态状态”的线程的示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package main.java.com.study.thread.interrupt;/** * @author: whb * @description: 线程终止示例3 */public class Demo3 &#123; public static void main(String[] args) &#123; try &#123; // 新建“线程t1” TestThread t1 = new TestThread(\"t1\"); System.out.println(t1.getName() + \" (\" + t1.getState() + \") is new.\"); t1.start(); // 启动“线程t1” System.out.println(t1.getName() + \" (\" + t1.getState() + \") is started.\"); // 主线程休眠300ms，然后主线程给t1发“中断”指令。 Thread.sleep(300); t1.stopTask(); System.out.println(t1.getName() + \" (\" + t1.getState() + \") is interrupted.\"); // 主线程休眠300ms，然后查看t1的状态。 Thread.sleep(300); System.out.println(t1.getName() + \" (\" + t1.getState() + \") is interrupted now.\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;class TestThread extends Thread &#123; private volatile boolean flag = true; public void stopTask() &#123; flag = false; &#125; public TestThread(String name) &#123; super(name); &#125; @Override public void run() &#123; synchronized (this) &#123; try &#123; int i = 0; while (flag) &#123; Thread.sleep(100); i++; System.out.println(Thread.currentThread().getName() + \" (\" + this.getState() + \") loop \" + i); &#125; &#125; catch (InterruptedException ie) &#123; System.out.println(Thread.currentThread().getName() + \" (\" + this.getState() + \") catch InterruptedException.\"); &#125; &#125; &#125;&#125; 运行结果： 1234567t1 (NEW) is new.t1 (RUNNABLE) is started.t1 (RUNNABLE) loop 1t1 (RUNNABLE) loop 2t1 (TIMED_WAITING) is interrupted.t1 (RUNNABLE) loop 3t1 (TERMINATED) is interrupted now. interrupted() 和 isInterrupted()的区别interrupted() 和 isInterrupted()都能够用于检测对象的“中断标记”。区别是，interrupted()除了返回中断标记之外，它还会清除中断标记(即将中断标记设为false)；而isInterrupted()仅仅返回中断标记。","tags":"java 多线程"},{"title":"Java内存模型-内容总结","url":"/posts/c0ec3ded.html","text":"处理器内存模型顺序一致性内存模型是一个理论参考模型，JMM 和处理器内存模型在设计时通常会把顺序一致性内存模型作为参照。JMM 和处理器内存模型在设计时会对顺序一致性模型做一些放松，因为如果完全按照顺序一致性模型来实现处理器和 JMM，那么很多的处理器和编译器优化都要被禁止，这对执行性能将会有很大的影响。 根据对不同类型读 / 写操作组合的执行顺序的放松，可以把常见处理器的内存模型划分为下面几种类型： 放松程序中写 - 读操作的顺序，由此产生了 total store ordering 内存模型（简称为 TSO）。 在前面 1 的基础上，继续放松程序中写 - 写操作的顺序，由此产生了 partial store order 内存模型（简称为 PSO）。 在前面 1 和 2 的基础上，继续放松程序中读 - 写和读 - 读操作的顺序，由此产生了 relaxed memory order 内存模型（简称为 RMO）和 PowerPC 内存模型。 注意，这里处理器对读 / 写操作的放松，是以两个操作之间不存在数据依赖性为前提的（因为处理器要遵守 as-if-serial 语义，处理器不会对存在数据依赖性的两个内存操作做重排序）。 常见处理器内存模型的细节特征： 内存模型名称 对应的处理器 Store-Load重排序 Store-Store重排序 Load-Load和Load-Store重排序 可以更早读取到其他处理器的写 可以更早读取到当前处理器的写 TSO sparc-TSO X64 Y Y PSO sparc-PSO Y Y Y RMO ia64 Y Y Y Y PowerPC PowerPC Y Y Y Y Y 在这个表格中，可以看到所有处理器内存模型都允许写 - 读重排序，原因：它们都使用了写缓存区，写缓存区可能导致写 - 读操作重排序。同时，可以看到这些处理器内存模型都允许更早读到当前处理器的写，原因同样是因为写缓存区：由于写缓存区仅对当前处理器可见，这个特性导致当前处理器可以比其他处理器先看到临时保存在自己的写缓存区中的写。 上面表格中的各种处理器内存模型，从上到下，模型由强变弱。越是追求性能的处理器，内存模型设计的会越弱。因为这些处理器希望内存模型对它们的束缚越少越好，这样它们就可以做尽可能多的优化来提高性能。 由于常见的处理器内存模型比 JMM 要弱，java 编译器在生成字节码时，会在执行指令序列的适当位置插入内存屏障来限制处理器的重排序。同时，由于各种处理器内存模型的强弱并不相同，为了在不同的处理器平台向程序员展示一个一致的内存模型，JMM 在不同的处理器中需要插入的内存屏障的数量和种类也不相同。下图展示了 JMM 在不同处理器内存模型中需要插入的内存屏障的示意图： 如上图所示，JMM 屏蔽了不同处理器内存模型的差异，它在不同的处理器平台之上为 java 程序员呈现了一个一致的内存模型。 JMM、处理器内存模型与顺序一致性内存模型之间的关系JMM 是一个语言级的内存模型，处理器内存模型是硬件级的内存模型，顺序一致性内存模型是一个理论参考模型。下面是语言内存模型，处理器内存模型和顺序一致性内存模型的强弱对比示意图： 从上图可以看出：常见的 4 种处理器内存模型比常用的 3 中语言内存模型要弱，处理器内存模型和语言内存模型都比顺序一致性内存模型要弱。同处理器内存模型一样，越是追求执行性能的语言，内存模型设计的会越弱。 JMM的设计从 JMM 设计者的角度来说，在设计 JMM 时，需要考虑两个关键因素： 程序员对内存模型的使用。程序员希望内存模型易于理解，易于编程。程序员希望基于一个强内存模型来编写代码。 编译器和处理器对内存模型的实现。编译器和处理器希望内存模型对它们的束缚越少越好，这样它们就可以做尽可能多的优化来提高性能。编译器和处理器希望实现一个弱内存模型。 由于这两个因素互相矛盾，所以 JSR-133 专家组在设计 JMM 时的核心目标就是找到一个好的平衡点：一方面要为程序员提供足够强的内存可见性保证；另一方面，对编译器和处理器的限制要尽可能的放松。 JSR-133 是如何实现这一目标的？答案是：happens-before规则。JMM 把 happens- before 要求禁止的重排序分为了下面两类： 会改变程序执行结果的重排序。不会改变程序执行结果的重排序。 JMM 对这两种不同性质的重排序，采取了不同的策略： 对于会改变程序执行结果的重排序，JMM 要求编译器和处理器必须禁止这种重排序。对于不会改变程序执行结果的重排序，JMM 对编译器和处理器不作要求（JMM 允许这种重排序） 下面是 JMM 的设计示意图： 从上图可以看出两点： JMM 向程序员提供的 happens- before 规则能满足程序员的需求。JMM 的 happens- before 规则不但简单易懂，而且也向程序员提供了足够强的内存可见性保证。JMM 对编译器和处理器的束缚已经尽可能的少。JMM 其实是在遵循一个基本原则：只要不改变程序的执行结果（指的是单线程程序和正确同步的多线程程序），编译器和处理器怎么优化都行。比如，如果编译器经过细致的分析后，认定一个锁只会被单个线程访问，那么这个锁可以被消除。再比如，如果编译器经过细致的分析后，认定一个 volatile 变量仅仅只会被单个线程访问，那么编译器可以把这个 volatile 变量当作一个普通变量来对待。这些优化既不会改变程序的执行结果，又能提高程序的执行效率。 JMM内存可见性保证Java 程序的内存可见性保证按程序类型可以分为下列三类： 单线程程序。单线程程序不会出现内存可见性问题。编译器，runtime 和处理器会共同确保单线程程序的执行结果与该程序在顺序一致性模型中的执行结果相同。 正确同步的多线程程序。正确同步的多线程程序的执行将具有顺序一致性（程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同）。这是 JMM 关注的重点，JMM 通过限制编译器和处理器的重排序来为程序员提供内存可见性保证。 未同步 / 未正确同步的多线程程序。JMM 为它们提供了最小安全性保障：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，null，false）。 下图展示了这三类程序在 JMM 中与在顺序一致性内存模型中的执行结果的异同： 只要多线程程序是正确同步的，JMM 保证该程序在任意的处理器平台上的执行结果，与该程序在顺序一致性内存模型中的执行结果一致。","tags":"java jmm"},{"title":"Java多线程-08之-线程Join","url":"/posts/38c1adea.html","text":"join()介绍join() 的作用：让“主线程”等待“子线程”结束之后才能继续运行。通过例子来理解： 123456789101112131415// 主线程public class Father extends Thread &#123; public void run() &#123; Son s = new Son(); s.start(); s.join(); ... &#125;&#125;// 子线程public class Son extends Thread &#123; public void run() &#123; ... &#125;&#125; 说明： 上面的有两个类Father(主线程类)和Son(子线程类)。因为Son是在Father中创建并启动的，所以，Father是主线程类，Son是子线程类。在Father主线程中，通过new Son()新建“子线程s”。接着通过s.start()启动“子线程s”，并且调用s.join()。在调用s.join()之后，Father主线程会一直等待，直到“子线程s”运行完毕；在“子线程s”运行完毕之后，Father主线程才能接着运行。 这也就是我们所说的“join()的作用，是让主线程会等待子线程结束之后才能继续运行”！ join()源码分析12345678910111213141516171819202122232425262728public final void join() throws InterruptedException &#123; join(0);&#125;public final synchronized void join(long millis)throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException(\"timeout value is negative\"); &#125; if (millis == 0) &#123; while (isAlive()) &#123; wait(0); &#125; &#125; else &#123; while (isAlive()) &#123; long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125;&#125; 说明： 从代码中，可以发现。当millis==0时，会进入while(isAlive())循环；即只要子线程是活的，主线程就不停的等待。根据上面解释join()作用时的代码来理解join()的用法！ 问题： 虽然s.join()被调用的地方是发生在“Father主线程”中，但是s.join()是通过“子线程s”去调用的join()。那么，join()方法中的isAlive()应该是判断“子线程s”是不是Alive状态；对应的wait(0)也应该是“让子线程s”等待才对。但如果是这样的话，s.join()的作用怎么可能是“让主线程等待，直到子线程s完成为止”呢，应该是让\"子线程等待才对(因为调用子线程对象s的wait方法嘛)\"？ 答案： wait()的作用是让“当前线程”等待，而这里的“当前线程”是指当前在CPU上运行的线程。所以，虽然是调用子线程的wait()方法，但是它是通过“主线程”去调用的；所以，休眠的是主线程，而不是“子线程”！ join()示例12345678910111213141516171819202122232425262728293031323334353637383940package main.java.com.study.thread.join;/** * @author: whb * @description: join() 的作用：让“主线程”等待“子线程”结束之后才能继续运行。 */public class JoinTest &#123; public static void main(String[] args) &#123; try &#123; // 新建“线程t1” ThreadA t1 = new ThreadA(\"t1\"); t1.start(); // 启动“线程t1” t1.join(); // 将“线程t1”加入到“主线程main”中，并且“主线程main()会等待它的完成” System.out.printf(\"%s finish\\n\", Thread.currentThread().getName()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; static class ThreadA extends Thread &#123; public ThreadA(String name) &#123; super(name); &#125; @Override public void run() &#123; System.out.printf(\"%s start\\n\", this.getName()); // 延时操作 for (int i = 0; i &lt; 1000000; i++) &#123; ; &#125; System.out.printf(\"%s finish\\n\", this.getName()); &#125; &#125;&#125; 运行结果： 123t1 startt1 finishmain finish 运行结果：(01) 在“主线程main”中通过 new ThreadA(“t1”) 新建“线程t1”。 接着，通过 t1.start() 启动“线程t1”，并执行t1.join()。(02) 执行t1.join()之后，“主线程main”会进入“阻塞状态”等待t1运行结束。“子线程t1”结束之后，会唤醒“主线程main”，“主线程”重新获取cpu执行权，继续运行。","tags":"java 多线程"},{"title":"Java内存模型-理解final","url":"/posts/5a0704df.html","text":"概述与锁和 volatile 相比较，对 final 域的读和写更像是普通的变量访问。对于 final 域，编译器和处理器要遵守两个重排序规则： 在构造函数内对一个 final 域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。 初次读一个包含 final 域的对象的引用，与随后初次读这个 final 域，这两个操作之间不能重排序。 示例代码： 1234567891011121314151617181920public class FinalExample &#123; int i; // 普通变量 final int j; //final 变量 static FinalExample obj; public void FinalExample () &#123; // 构造函数 i = 1; // 写普通域 j = 2; // 写 final 域 &#125; public static void writer () &#123; // 写线程 A 执行 obj = new FinalExample (); &#125; public static void reader () &#123; // 读线程 B 执行 FinalExample object = obj; // 读对象引用 int a = object.i; // 读普通域 int b = object.j; // 读 final 域 &#125;&#125; 这里假设一个线程 A 执行 writer () 方法，随后另一个线程 B 执行 reader () 方法。 写final域的重排序规则写 final 域的重排序规则禁止把 final 域的写重排序到构造函数之外。这个规则的实现包含下面 2 个方面： JMM 禁止编译器把 final 域的写重排序到构造函数之外。 编译器会在 final 域的写之后，构造函数 return 之前，插入一个 StoreStore 屏障。这个屏障禁止处理器把 final 域的写重排序到构造函数之外。 现在分析 writer () 方法：finalExample = new FinalExample ()。这行代码包含两个步骤： 构造一个 FinalExample 类型的对象； 把这个对象的引用赋值给引用变量 obj。 假设线程 B 读对象引用与读对象的成员域之间没有重排序，下图是一种可能的执行时序： 在上图中，写普通域的操作被编译器重排序到了构造函数之外，读线程 B 错误的读取了普通变量 i 初始化之前的值。而写 final 域的操作，被写 final 域的重排序规则“限定”在了构造函数之内，读线程 B 正确的读取了 final 变量初始化之后的值。 写 final 域的重排序规则可以确保：在对象引用为任意线程可见之前，对象的 final 域已经被正确初始化过了，而普通域不具有这个保障。以上图为例，在读线程 B“看到”对象引用 obj 时，很可能 obj 对象还没有构造完成（对普通域 i 的写操作被重排序到构造函数外，此时初始值 2 还没有写入普通域 i）。 读final域的重排序规则 在一个线程中，初次读对象引用与初次读该对象包含的 final 域，JMM 禁止处理器重排序这两个操作（这个规则仅仅针对处理器）。编译器会在读 final 域操作的前面插入一个 LoadLoad 屏障。 初次读对象引用与初次读该对象包含的 final 域，这两个操作之间存在间接依赖关系。由于编译器遵守间接依赖关系，因此编译器不会重排序这两个操作。大多数处理器也会遵守间接依赖，大多数处理器也不会重排序这两个操作。但有少数处理器允许对存在间接依赖关系的操作做重排序（比如 alpha 处理器），这个规则就是专门用来针对这种处理器。 reader() 方法包含三个操作： 初次读引用变量 obj; 初次读引用变量 obj 指向对象的普通域 j。 初次读引用变量 obj 指向对象的 final 域 i。 现在假设写线程 A 没有发生任何重排序，同时程序在不遵守间接依赖的处理器上执行，下面是一种可能的执行时序： 在上图中，读对象的普通域的操作被处理器重排序到读对象引用之前。读普通域时，该域还没有被写线程 A 写入，这是一个错误的读取操作。而读 final 域的重排序规则会把读对象 final 域的操作“限定”在读对象引用之后，此时该 final 域已经被 A 线程初始化过了，这是一个正确的读取操作。 读 final 域的重排序规则可以确保：在读一个对象的 final 域之前，一定会先读包含这个 final 域的对象的引用。在这个示例程序中，如果该引用不为 null，那么引用对象的 final 域一定已经被 A 线程初始化过了。 final域是引用类型1234567891011121314151617181920212223public class FinalReferenceExample &#123; final int[] intArray; //final 是引用类型 static FinalReferenceExample obj; public FinalReferenceExample () &#123; // 构造函数 intArray = new int[1]; //1 intArray[0] = 1; //2 &#125; public static void writerOne () &#123; // 写线程 A 执行 obj = new FinalReferenceExample (); //3 &#125; public static void writerTwo () &#123; // 写线程 B 执行 obj.intArray[0] = 2; //4 &#125; public static void reader () &#123; // 读线程 C 执行 if (obj != null) &#123; //5 int temp1 = obj.intArray[0]; //6 &#125; &#125;&#125; 这里 final 域为一个引用类型，它引用一个 int 型的数组对象。对于引用类型，写 final 域的重排序规则对编译器和处理器增加了如下约束： 在构造函数内对一个 final 引用的对象的成员域的写入，与随后在构造函数外把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。 对上面的示例程序，假设首先线程 A 执行 writerOne() 方法，执行完后线程 B 执行 writerTwo() 方法，执行完后线程 C 执行 reader () 方法。下面是一种可能的线程执行时序： 在上图中，1 是对 final 域的写入，2 是对这个 final 域引用的对象的成员域的写入，3 是把被构造的对象的引用赋值给某个引用变量。这里除了前面提到的 1 不能和 3 重排序外，2 和 3 也不能重排序。 JMM 可以确保读线程 C 至少能看到写线程 A 在构造函数中对 final 引用对象的成员域的写入。即 C 至少能看到数组下标 0 的值为 1。而写线程 B 对数组元素的写入，读线程 C 可能看的到，也可能看不到。JMM 不保证线程 B 的写入对读线程 C 可见，因为写线程 B 和读线程 C 之间存在数据竞争，此时的执行结果不可预知。 为什么final引用不能从构造函数内逸出写 final 域的重排序规则可以确保：在引用变量为任意线程可见之前，该引用变量指向的对象的 final 域已经在构造函数中被正确初始化过了。其实要得到这个效果，还需要一个保证：在构造函数内部，不能让这个被构造对象的引用为其他线程可见，也就是对象引用不能在构造函数中“逸出”。示例如下： 12345678910111213141516171819public class FinalReferenceEscapeExample &#123; final int i; static FinalReferenceEscapeExample obj; public FinalReferenceEscapeExample () &#123; i = 1; //1 写 final 域 obj = this; //2 this 引用在此“逸出” &#125; public static void writer() &#123; new FinalReferenceEscapeExample (); &#125; public static void reader &#123; if (obj != null) &#123; //3 int temp = obj.i; //4 &#125; &#125;&#125; 假设一个线程 A 执行 writer() 方法，另一个线程 B 执行 reader() 方法。这里的操作 2 使得对象还未完成构造前就为线程 B 可见。即使这里的操作 2 是构造函数的最后一步，且即使在程序中操作 2 排在操作 1 后面，执行 read() 方法的线程仍然可能无法看到 final 域被初始化后的值，因为这里的操作 1 和操作 2 之间可能被重排序。实际的执行时序可能如下图所示： 从上图可以看出：在构造函数返回前，被构造对象的引用不能为其他线程可见，因为此时的 final 域可能还没有被初始化。在构造函数返回后，任意线程都将保证能看到 final 域正确初始化之后的值。 JSR-133为什么要增强final语义在旧的 Java 内存模型中 ，最严重的一个缺陷就是线程可能看到 final 域的值会改变。比如，一个线程当前看到一个整形 final 域的值为 0（还未初始化之前的默认值），过一段时间之后这个线程再去读这个 final 域的值时，却发现值变为了 1（被某个线程初始化之后的值）。最常见的例子就是在旧的 Java 内存模型中，String 的值可能会改变。 为了修补这个漏洞，JSR-133 专家组增强了 final 的语义。通过为 final 域增加写和读重排序规则，可以为 java 程序员提供初始化安全保证：只要对象是正确构造的（被构造对象的引用在构造函数中没有“逸出”），那么不需要使用同步（指 lock 和 volatile 的使用），就可以保证任意线程都能看到这个 final 域在构造函数中被初始化之后的值。","tags":"java jmm"},{"title":"Java内存模型-理解锁","url":"/posts/a87ac669.html","text":"锁的happens-before关系锁是 java 并发编程中最重要的同步机制。锁除了让临界区互斥执行外，还可以让释放锁的线程向获取同一个锁的线程发送消息。 123456789101112class MonitorExample &#123; int a = 0; public synchronized void writer() &#123; //1 a++; //2 &#125; //3 public synchronized void reader() &#123; //4 int i = a; //5 …… &#125; //6&#125; 假设线程 A 执行 writer() 方法，随后线程 B 执行 reader() 方法。根据 happens before 规则，这个过程包含的 happens before 关系可以分为两类： 根据程序次序规则，1 happens before 2, 2 happens before 3; 4 happens before 5, 5 happens before 6。 根据监视器锁规则，3 happens before 4。 根据 happens before 的传递性，2 happens before 5。 上述 happens-before 关系图如下： 上图中，每一个箭头链接的两个节点，代表了一个 happens before 关系。黑色箭头表示程序顺序规则；橙色箭头表示监视器锁规则；蓝色箭头表示组合这些规则后提供的 happens before 保证。 上图表示在线程 A 释放了锁之后，随后线程 B 获取同一个锁。在上图中，2 happens before 5。因此，线程 A 在释放锁之前所有可见的共享变量，在线程 B 获取同一个锁之后，将立刻变得对 B 线程可见。 锁的内存语义 锁释放的内存语义 当线程释放锁时，JMM 会把该线程对应的本地内存中的共享变量刷新到主内存中。以上面的程序为例，A 线程释放锁后，共享数据的状态示意图如下： 锁获取的内存语义 当线程获取锁时，JMM 会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须要从主内存中去读取共享变量。下面是锁获取的状态示意图： 对比锁释放 - 获取的内存语义与 volatile 写 - 读的内存语义，可以看出：锁释放与 volatile 写有相同的内存语义；锁获取与 volatile 读有相同的内存语义。 锁内存语义的实现1234567891011121314151617181920212223class ReentrantLockExample &#123; int a = 0; ReentrantLock lock = new ReentrantLock(); public void writer() &#123; lock.lock(); // 获取锁 try &#123; a++; &#125; finally &#123; lock.unlock(); // 释放锁 &#125; &#125; public void reader () &#123; lock.lock(); // 获取锁 try &#123; int i = a; …… &#125; finally &#123; lock.unlock(); // 释放锁 &#125; &#125;&#125; 在 ReentrantLock 中，调用 lock() 方法获取锁；调用 unlock() 方法释放锁。 ReentrantLock 的实现依赖于 java 同步器框架 AbstractQueuedSynchronizer（简称 AQS）。AQS 使用一个整型的 volatile 变量（命名为 state）来维护同步状态，马上我们会看到，这个 volatile 变量是 ReentrantLock 内存语义实现的关键。 下面是 ReentrantLock 的类图（仅部分）： ReentrantLock 分为公平锁和非公平锁，首先分析公平锁。 使用公平锁时，加锁方法 lock() 的方法调用轨迹如下： ReentrantLock : lock() FairSync : lock() AbstractQueuedSynchronizer : acquire(int arg) ReentrantLock : tryAcquire(int acquires) 在第 4 步真正开始加锁，下面是该方法的源代码： 12345678910111213141516171819protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); // 获取锁的开始，首先读 volatile 变量 state if (c == 0) &#123; if (isFirst(current) &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false;&#125; 从上面源代码中我们可以看出，加锁方法首先读 volatile 变量 state。 在使用公平锁时，解锁方法 unlock() 的方法调用轨迹如下： ReentrantLock : unlock() AbstractQueuedSynchronizer : release(int arg) Sync : tryRelease(int releases) 在第 3 步真正开始释放锁，下面是该方法的源代码： 123456789101112protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); // 释放锁的最后，写 volatile 变量 state return free;&#125; 从上面的源代码我们可以看出，在释放锁的最后写 volatile 变量 state。 公平锁在释放锁的最后写 volatile 变量 state；在获取锁时首先读这个 volatile 变量。根据 volatile 的 happens-before 规则，释放锁的线程在写 volatile 变量之前可见的共享变量，在获取锁的线程读取同一个 volatile 变量后将立即变的对获取锁的线程可见。 现在分析非公平锁的内存语义的实现。 非公平锁的释放和公平锁完全一样，所以这里仅仅分析非公平锁的获取。 使用公平锁时，加锁方法 lock() 的方法调用轨迹如下： ReentrantLock : lock() NonfairSync : lock() AbstractQueuedSynchronizer : compareAndSetState(int expect, int update) 在第 3 步真正开始加锁，下面是该方法的源代码： 123protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; 该方法以原子操作的方式更新 state 变量，JDK 文档对该方法的说明如下：如果当前状态值等于预期值，则以原子方式将同步状态设置为给定的更新值。此操作具有 volatile 读和写的内存语义。 前文说过，编译器不会对 volatile 读与 volatile 读后面的任意内存操作重排序；编译器不会对 volatile 写与 volatile 写前面的任意内存操作重排序。组合这两个条件，意味着为了同时实现 volatile 读和 volatile 写的内存语义，编译器不能对 CAS 与 CAS 前面和后面的任意内存操作重排序。 对公平锁和非公平锁的内存语义做个总结： 公平锁和非公平锁释放时，最后都要写一个 volatile 变量 state。 公平锁获取时，首先会去读这个 volatile 变量。 非公平锁获取时，首先会用 CAS 更新这个 volatile 变量, 这个操作同时具有 volatile 读和 volatile 写的内存语义。 从对 ReentrantLock 的分析可以看出，锁释放 - 获取的内存语义的实现至少有下面两种方式： 利用 volatile 变量的写 - 读所具有的内存语义。利用 CAS 所附带的 volatile 读和 volatile 写的内存语义。 J.U.C包的实现由于 java 的 CAS 同时具有 volatile 读和 volatile 写的内存语义，因此 Java 线程之间的通信现在有了下面四种方式： A 线程写 volatile 变量，随后 B 线程读这个 volatile 变量。 A 线程写 volatile 变量，随后 B 线程用 CAS 更新这个 volatile 变量。 A 线程用 CAS 更新一个 volatile 变量，随后 B 线程用 CAS 更新这个 volatile 变量。 A 线程用 CAS 更新一个 volatile 变量，随后 B 线程读这个 volatile 变量。 Java 的 CAS 会使用现代处理器上提供的高效机器级别原子指令，这些原子指令以原子方式对内存执行读 - 改 - 写操作，这是在多处理器中实现同步的关键（从本质上来说，能够支持原子性读 - 改 - 写指令的计算机器，是顺序计算图灵机的异步等价机器，因此任何现代的多处理器都会去支持某种能对内存执行原子性读 - 改 - 写操作的原子指令）。同时，volatile 变量的读 / 写和 CAS 可以实现线程之间的通信。把这些特性整合在一起，就形成了整个 J.U.C 包得以实现的基石。如果仔细分析 J.U.C 包的源代码实现，会发现一个通用化的实现模式： 首先，声明共享变量为 volatile； 然后，使用 CAS 的原子条件更新来实现线程之间的同步； 同时，配合以 volatile 的读 / 写和 CAS 所具有的 volatile 读和写的内存语义来实现线程之间的通信。 AQS，非阻塞数据结构和原子变量类（java.util.concurrent.atomic 包中的类），这些 J.U.C 包中的基础类都是使用这种模式来实现的，而 J.U.C 包中的高层类又是依赖于这些基础类来实现的。从整体来看，J.U.C 包的实现示意图如下：","tags":"java jmm"},{"title":"Java内存模型-顺序一致性模型","url":"/posts/60b19e41.html","text":"顺序一致性保证当程序未正确同步时，就会存在数据竞争。java 内存模型规范对数据竞争的定义如下： 在一个线程中写一个变量，在另一个线程读同一个变量，而且写和读没有通过同步来排序。 当代码中包含数据竞争时，程序的执行往往产生违反直觉的结果。如果一个多线程程序能正确同步，这个程序将是一个没有数据竞争的程序。 JMM 对正确同步的多线程程序的内存一致性做了如下保证： 如果程序是正确同步的，程序的执行将具有顺序一致性（sequentially consistent）– 即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同。这里的同步是指广义上的同步，包括对常用同步原语（lock，volatile 和 final）的正确使用。 顺序一致性内存模型顺序一致性内存模型是理论参考模型，它为程序员提供了极强的内存可见性保证。顺序一致性内存模型有两大特性： 一个线程中的所有操作必须按照程序的顺序来执行。 （不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。顺序一致性内存模型为程序员提供的视图如下： 在概念上，顺序一致性模型有一个单一的全局内存，这个内存通过一个左右摆动的开关可以连接到任意一个线程。同时，每一个线程必须按程序的顺序来执行内存读 / 写操作。在任意时间点最多只能有一个线程可以连接到内存。当多个线程并发执行时，图中的开关装置能把所有线程的所有内存读 / 写操作串行化。 示例：假设有两个线程 A 和 B 并发执行。其中 A 线程有三个操作，它们在程序中的顺序是：A1-&gt;A2-&gt;A3。B 线程也有三个操作，它们在程序中的顺序是：B1-&gt;B2-&gt;B3。 假设这两个线程使用监视器来正确同步：A 线程的三个操作执行后释放监视器，随后 B 线程获取同一个监视器。那么程序在顺序一致性模型中的执行效果将如下图所示： 再假设这两个线程没有做同步，下面是这个未同步程序在顺序一致性模型中的执行示意图： 未同步程序在顺序一致性模型中虽然整体执行顺序是无序的，但所有线程都只能看到一个一致的整体执行顺序。以上图为例，线程 A 和 B 看到的执行顺序都是：B1-&gt;A1-&gt;A2-&gt;B2-&gt;A3-&gt;B3。之所以能得到这个保证是因为顺序一致性内存模型中的每个操作必须立即对任意线程可见。 但是，在 JMM 中就没有这个保证。未同步程序在 JMM 中不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致。比如，在当前线程把写过的数据缓存在本地内存中，且还没有刷新到主内存之前，这个写操作仅对当前线程可见；从其他线程的角度来观察，会认为这个写操作根本还没有被当前线程执行。只有当前线程把本地内存中写过的数据刷新到主内存之后，这个写操作才能对其他线程可见。在这种情况下，当前线程和其它线程看到的操作执行顺序将不一致。 同步程序的顺序一致性12345678910111213141516class SynchronizedExample &#123; int a = 0; boolean flag = false; public synchronized void writer() &#123; a = 1; flag = true; &#125; public synchronized void reader() &#123; if (flag) &#123; int i = a; …… &#125; &#125;&#125; 示例代码中，假设 A 线程执行 writer() 方法后，B 线程执行 reader() 方法。这是一个正确同步的多线程程序。根据 JMM 规范，该程序的执行结果将与该程序在顺序一致性模型中的执行结果相同。如下执行对比图：在顺序一致性模型中，所有操作完全按程序的顺序串行执行。而在 JMM 中，临界区内的代码可以重排序（但 JMM 不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。JMM 会在退出监视器和进入监视器这两个关键时间点做一些特别处理，使得线程在这两个时间点具有与顺序一致性模型相同的内存视图。虽然线程 A 在临界区内做了重排序，但由于监视器的互斥执行的特性，这里的线程 B 根本无法“观察”到线程 A 在临界区内的重排序。这种重排序既提高了执行效率，又没有改变程序的执行结果。 从这里可以看到 JMM 在具体实现上的基本方针：在不改变（正确同步的）程序执行结果的前提下，尽可能的为编译器和处理器的优化打开方便之门。 未同步程序的执行特性对于未同步或未正确同步的多线程程序，JMM 只提供最小安全性：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，null，false），JMM 保证线程读操作读取到的值不会无中生有（out of thin air）的冒出来。为了实现最小安全性，JVM 在堆上分配对象时，首先会清零内存空间，然后才会在上面分配对象（JVM 内部会同步这两个操作）。因此，在已清零的内存空间（pre-zeroed memory）分配对象时，域的默认初始化已经完成了。 JMM 不保证未同步程序的执行结果与该程序在顺序一致性模型中的执行结果一致。因为未同步程序在顺序一致性模型中执行时，整体上是无序的，其执行结果无法预知。保证未同步程序在两个模型中的执行结果一致毫无意义。 和顺序一致性模型一样，未同步程序在 JMM 中的执行时，整体上也是无序的，其执行结果也无法预知。同时，未同步程序在这两个模型中的执行特性有下面几个差异： 顺序一致性模型保证单线程内的操作会按程序的顺序执行，而 JMM 不保证单线程内的操作会按程序的顺序执行述。 顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而 JMM 不保证所有线程能看到一致的操作执行顺序。。 JMM 不保证对 64 位的 long 型和 double 型变量的读 / 写操作具有原子性，而顺序一致性模型保证对所有的内存读 / 写操作都具有原子性。","tags":"java jmm"},{"title":"Java内存模型-指令重排序","url":"/posts/60874885.html","text":"数据依赖性如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分下列三种类型： 名称 代码示例 说明 写后读 a = 1;b = a; 写一个变量之后，再读这个变量。 写后写 a = 1;a = 2; 写一个变量后，再写这个变量。 读后写 a = b;b = 1; 读一个变量之后，再写这个变量。 上面三种情况，只要重排序两个操作的执行顺序，程序的执行结果将会被改变。 编译器和处理器可能会对操作做重排序。编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。 注意，这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。 as-if-serial语义as-if-serial 语义是指：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器，runtime 和处理器都必须遵守 as-if-serial 语义。 为了遵守 as-if-serial 语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作可能被编译器和处理器重排序。如下计算圆面积的代码示例： 123double pi = 3.14; //Adouble r = 1.0; //Bdouble area = pi * r * r; //C 上面三个操作的数据依赖关系如下图所示： 如上图所示，A 和 C 之间存在数据依赖关系，同时 B 和 C 之间也存在数据依赖关系。因此在最终执行的指令序列中，C 不能被重排序到 A 和 B 的前面（C 排到 A 和 B 的前面，程序的结果将会被改变）。但 A 和 B 之间没有数据依赖关系，编译器和处理器可以重排序 A 和 B 之间的执行顺序。下图是该程序的两种执行顺序： as-if-serial 语义把单线程程序保护了起来，遵守 as-if-serial 语义的编译器，runtime 和处理器共同为编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的。as-if-serial 语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。 程序顺序规则根据 happens- before 的程序顺序规则，上面计算圆的面积的示例代码存在三个 happens- before 关系： A happens- before B； B happens- before C； A happens- before C；这里的第 3 个 happens- before 关系，是根据 happens- before 的传递性推导出来的。 这里 A happens- before B，但实际执行时 B 却可以排在 A 之前执行。根据happens-before规则，如果 A happens- before B，JMM 并不要求 A 一定要在 B 之前执行。JMM 仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。这里操作 A 的执行结果不需要对操作 B 可见；而且重排序操作 A 和操作 B 后的执行结果，与操作 A 和操作 B 按 happens- before 顺序执行的结果一致。在这种情况下，JMM 会认为这种重排序并不非法（not illegal），JMM 允许这种重排序。 在计算机中，软件技术和硬件技术有一个共同的目标：在不改变程序执行结果的前提下，尽可能的开发并行度。编译器和处理器遵从这一目标，从 happens- before 的定义我们可以看出，JMM 同样遵从这一目标。 重排序对多线程的影响12345678910111213141516class ReorderExample &#123; int a = 0; boolean flag = false; public void writer() &#123; a = 1; //1 flag = true; //2 &#125; Public void reader() &#123; if (flag) &#123; //3 int i = a * a; //4 …… &#125; &#125;&#125; flag 变量是个标记，用来标识变量 a 是否已被写入。这里假设有两个线程 A 和 B，A 首先执行 writer() 方法，随后 B 线程接着执行 reader() 方法。线程 B 在执行操作 4 时，能否看到线程 A 在操作 1 对共享变量 a 的写入？ 答案是：不一定能看到。 由于操作 1 和操作 2 没有数据依赖关系，编译器和处理器可以对这两个操作重排序；同样，操作 3 和操作 4 没有数据依赖关系，编译器和处理器也可以对这两个操作重排序。下面来看看，当操作 1 和操作 2 重排序时，可能会产生什么效果？如下图： 操作 1 和操作 2 做了重排序。程序执行时，线程 A 首先写标记变量 flag，随后线程 B 读这个变量。由于条件判断为真，线程 B 将读取变量 a。此时，变量 a 还根本没有被线程 A 写入，在这里多线程程序的语义被重排序破坏了！ ※注：红色的虚箭线表示错误的读操作，用绿色的虚箭线表示正确的读操作。 下面再看看，当操作 3 和操作 4 重排序时会产生什么效果（借助这个重排序，可以顺便说明控制依赖性）。如下图： 在程序中，操作 3 和操作 4 存在控制依赖关系。当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程 B 的处理器可以提前读取并计算 a*a，然后把计算结果临时保存到一个名为重排序缓冲（reorder buffer ROB）的硬件缓存中。当接下来操作 3 的条件判断为真时，就把该计算结果写入变量 i 中。 从图中我们可以看出，猜测执行实质上对操作 3 和 4 做了重排序。重排序在这里破坏了多线程程序的语义！ 在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是 as-if-serial 语义允许对存在控制依赖的操作做重排序的原因）；但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。","tags":"java jmm"},{"title":"设计模式-抽象工厂模式","url":"/posts/5a86ebac.html","text":"模式定义抽象工厂模式，即Abstract Factory Pattern，提供一个创建一系列相关或相互依赖对象的接口，而无须指定它们具体的类；具体的工厂负责实现具体的产品实例。 主要作用允许使用抽象的接口来创建一组相关产品，而不需要知道或关心实际生产出的具体产品是什么，这样就可以从具体产品中被解耦。 解决的问题解决工厂方法模式的缺点：每个工厂只能创建一类产品。 模式原理UML类图 模式组成 组成（角色） 关系 作用 抽象产品族（AbstractProduct） 抽象产品的父类 描述抽象产品的公共接口 抽象产品（Product） 具体产品的父类 描述具体产品的公共接口 具体产品（Concrete Product） 抽象产品的子类； 工厂类创建的目标类 描述生产的具体产品 抽象工厂（Creator） 具体工厂的父类 描述具体工厂的公共接口 具体工厂（Concrete Creator） 抽象工厂的子类； 被外界调用 描述具体工厂； 实现FactoryMethod工厂方法创建产品的实例 如何理解抽象产品族、抽象产品和具体产品的区别呢？请看下图： 使用步骤 创建抽象工厂类，定义具体工厂的公共接口； 创建抽象产品族类 ，定义抽象产品的公共接口； 创建抽象产品类 （继承抽象产品族类），定义具体产品的公共接口； 创建具体产品类（继承抽象产品类） &amp; 定义生产的具体产品； 创建具体工厂类（继承抽象工厂类），定义创建对应具体产品实例的方法； 客户端通过实例化具体的工厂类，并调用其创建不同目标产品的方法创建不同具体产品类的实例 模式优点 降低耦合抽象工厂模式将具体产品的创建延迟到具体工厂的子类中，这样将对象的创建封装起来，可以减少客户端与具体产品类之间的依赖，从而使系统耦合度低，这样更有利于后期的维护和扩展。 更符合开-闭原则新增一种产品类时，只需要增加相应的具体产品类和相应的工厂子类即可。 符合单一职责原则每个具体工厂类只负责创建对应的产品。 不使用静态工厂方法，可以形成基于继承的等级结构。 模式缺点抽象工厂模式很难支持新种类产品的变化。这是因为抽象工厂接口中已经确定了可以被创建的产品集合，如果需要添加新产品，此时就必须去修改抽象工厂的接口，这样就涉及到抽象工厂类的以及所有子类的改变，这样也就违背了“开放——封闭”原则。 应用场景 一个系统不要求依赖产品类实例如何被创建、组合和表达的表达，这点也是所有工厂模式应用的前提。 这个系统有多个系列产品，而系统中只消费其中某一系列产品。 系统要求提供一个产品类的库，所有产品以同样的接口出现，客户端不需要依赖具体实现。 模式示例示例背景背景：假设有两间塑料加工厂（A厂仅生产容器类产品；B厂仅生产模具类产品）；随着客户需求的变化，A厂所在地的客户需要也模具类产品，B厂所在地的客户也需要容器类产品；冲突：没有资源（资金+租位）在当地分别开设多一家注塑分厂解决方案：在原有的两家塑料厂里增设生产需求的功能，即A厂能生产容器+模具产品；B厂间能生产模具+容器产品。 抽象工厂类123456789101112131415161718192021package main.java.com.study.designPatterns.factory.abstracts.demoOne;/** * @author: whb * @description: 抽象工厂类，定义具体工厂的公共接口 */public abstract class Factory &#123; /** * 生产容器 * * @return */ public abstract AbstractProduct manufactureContainer(); /** * 生产模具 * * @return */ public abstract AbstractProduct manufactureMould();&#125; 抽象产品族类123456789101112package main.java.com.study.designPatterns.factory.abstracts.demoOne;/** * @author: whb * @description: 抽象产品族类 ，定义具体产品的公共接口； */public abstract class AbstractProduct &#123; /** * 展示产品 */ public abstract void show();&#125; 抽象产品类容器产品抽象类12345678910package main.java.com.study.designPatterns.factory.abstracts.demoOne;/** * @author: whb * @description: 抽象产品类--容器 ，定义具体产品的公共接口 */public abstract class ContainerProduct extends AbstractProduct &#123; @Override public abstract void show();&#125; 模具产品抽象类12345678910package main.java.com.study.designPatterns.factory.abstracts.demoOne;/** * @author: whb * @description: 抽象产品类--模具 ，定义具体产品的公共接口 */public abstract class MouldProduct extends AbstractProduct &#123; @Override public abstract void show();&#125; 具体产品类容器产品A类123456789101112package main.java.com.study.designPatterns.factory.abstracts.demoOne;/** * @author: whb * @description: 具体产品类--容器A（继承抽象产品类）， 定义生产的具体产品 */public class ContainerProductA extends ContainerProduct &#123; @Override public void show() &#123; System.out.println(\"生产出了容器产品A...\"); &#125;&#125; 容器产品B类123456789101112package main.java.com.study.designPatterns.factory.abstracts.demoOne;/** * @author: whb * @description: 具体产品类-容器B（继承抽象产品类）， 定义生产的具体产品 */public class ContainerProductB extends ContainerProduct &#123; @Override public void show() &#123; System.out.println(\"生产出了容器产品B...\"); &#125;&#125; 模具产品A类12345678910111213package main.java.com.study.designPatterns.factory.abstracts.demoOne;/** * @author: whb * @description: 具体产品类--模具A（继承抽象产品类）， 定义生产的具体产品 */public class MouldProductA extends MouldProduct &#123; @Override public void show() &#123; System.out.println(\"生产出了模具产品A...\"); &#125;&#125; 模具产品B类12345678910111213package main.java.com.study.designPatterns.factory.abstracts.demoOne;/** * @author: whb * @description: 具体产品类--模具B（继承抽象产品类）， 定义生产的具体产品 */public class MouldProductB extends MouldProduct &#123; @Override public void show() &#123; System.out.println(\"生产出了模具产品B...\"); &#125;&#125; 具体工厂类A厂 - 生产模具+容器产品12345678910111213141516171819package main.java.com.study.designPatterns.factory.abstracts.demoOne;/** * @author: whb * @description: 具体工厂类（继承抽象工厂类），定义创建对应具体产品实例的方法 * A厂 - 生产模具+容器产品 */public class FactoryA extends Factory &#123; @Override public AbstractProduct manufactureContainer() &#123; return new ContainerProductA(); &#125; @Override public AbstractProduct manufactureMould() &#123; return new MouldProductA(); &#125;&#125; B厂 - 生产模具+容器产品12345678910111213141516171819package main.java.com.study.designPatterns.factory.abstracts.demoOne;/** * @author: whb * @description: 具体工厂类（继承抽象工厂类），定义创建对应具体产品实例的方法 * B厂 - 生产模具+容器产品 */public class FactoryB extends Factory &#123; @Override public AbstractProduct manufactureContainer() &#123; return new ContainerProductB(); &#125; @Override public AbstractProduct manufactureMould() &#123; return new MouldProductB(); &#125;&#125; 客户端调用12345678910111213141516171819202122package main.java.com.study.designPatterns.factory.abstracts.demoOne;/** * @author: whb * @description: 客户端调用 */public class Client &#123; public static void main(String[] args) &#123; FactoryA mFactoryA = new FactoryA(); FactoryB mFactoryB = new FactoryB(); //A厂当地客户需要容器产品A mFactoryA.manufactureContainer().show(); //A厂当地客户需要模具产品A mFactoryA.manufactureMould().show(); //B厂当地客户需要容器产品B mFactoryB.manufactureContainer().show(); //B厂当地客户需要模具产品B mFactoryB.manufactureMould().show(); &#125;&#125;","tags":"java 设计模式"},{"title":"Java内存模型-理解Volatile","url":"/posts/e72020d.html","text":"volatile特性当声明共享变量为 volatile 后，对这个变量的读 / 写将会很特别。理解 volatile 特性的一个好方法是：把对 volatile 变量的单个读 / 写，看成是使用同一个监视器锁对这些单个读 / 写操作做了同步。如下示例代码： 12345678910111213141516class VolatileFeaturesExample &#123; volatile long vl = 0L; // 使用 volatile 声明 64 位的 long 型变量 public void set(long l) &#123; vl = l; // 单个 volatile 变量的写 &#125; public void getAndIncrement () &#123; vl++; // 复合（多个）volatile 变量的读 / 写 &#125; public long get() &#123; return vl; // 单个 volatile 变量的读 &#125;&#125; 假设有多个线程分别调用上面程序的三个方法，这个程序在语意上和下面程序等价： 1234567891011121314151617class VolatileFeaturesExample &#123; long vl = 0L; // 64 位的 long 型普通变量 public synchronized void set(long l) &#123; // 对单个的普通 变量的写用同一个监视器同步 vl = l; &#125; public void getAndIncrement () &#123; // 普通方法调用 long temp = get(); // 调用已同步的读方法 temp += 1L; // 普通写操作 set(temp); // 调用已同步的写方法 &#125; public synchronized long get() &#123; // 对单个的普通变量的读用同一个监视器同步 return vl; &#125;&#125; 如示例程序所示，对一个 volatile 变量的单个读 / 写操作，与对一个普通变量的读 / 写操作使用同一个监视器锁来同步，它们之间的执行效果相同。 监视器锁的 happens-before 规则保证释放监视器和获取监视器的两个线程之间的内存可见性，这意味着对一个 volatile 变量的读，总是能看到（任意线程）对这个 volatile 变量最后的写入。 监视器锁的语义决定了临界区代码的执行具有原子性。这意味着即使是 64 位的 long 型和 double 型变量，只要它是 volatile 变量，对该变量的读写就将具有原子性。如果是多个 volatile 操作或类似于 volatile++ 这种复合操作，这些操作整体上不具有原子性。 简而言之，volatile 变量自身具有下列特性： 可见性。对一个 volatile 变量的读，总是能看到（任意线程）对这个 volatile 变量最后的写入。 原子性：对任意单个 volatile 变量的读 / 写具有原子性，但类似于 volatile++ 这种复合操作不具有原子性。 volatile的happens-before关系从内存语义的角度来说，volatile 与监视器锁有相同的效果：volatile 写和监视器的释放有相同的内存语义；volatile 读与监视器的获取有相同的内存语义。 12345678910111213141516class VolatileExample &#123; int a = 0; volatile boolean flag = false; public void writer() &#123; a = 1; //1 flag = true; //2 &#125; public void reader() &#123; if (flag) &#123; //3 int i = a; //4 …… &#125; &#125;&#125; 假设线程 A 执行 writer() 方法之后，线程 B 执行 reader() 方法。根据 happens before 规则，这个过程建立的 happens before 关系可以分为两类： 根据程序次序规则，1 happens before 2; 3 happens before 4。 根据 volatile 规则，2 happens before 3。 根据 happens before 的传递性规则，1 happens before 4。 上述 happens before 关系的图形化表现形式如下： 在上图中，每一个箭头链接的两个节点，代表了一个 happens before 关系。黑色箭头表示程序顺序规则；橙色箭头表示 volatile 规则；蓝色箭头表示组合这些规则后提供的 happens before 保证。 这里 A 线程写一个 volatile 变量后，B 线程读同一个 volatile 变量。A 线程在写 volatile 变量之前所有可见的共享变量，在 B 线程读同一个 volatile 变量后，将立即变得对 B 线程可见。 volatile的内存语义 volatile 写的内存语义如下： 当写一个 volatile 变量时，JMM 会把该线程对应的本地内存中的共享变量刷新到主内存。 以上面示例程序为例，假设线程 A 首先执行 writer() 方法，随后线程 B 执行 reader() 方法，初始时两个线程的本地内存中的 flag 和 a 都是初始状态。下图是线程 A 执行 volatile 写后，共享变量的状态示意图： 如上图所示，线程 A 在写 flag 变量后，本地内存 A 中被线程 A 更新过的两个共享变量的值被刷新到主内存中。此时，本地内存 A 和主内存中的共享变量的值是一致的。 volatile 读的内存语义如下： 当读一个 volatile 变量时，JMM 会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。 下面是线程 B 读同一个 volatile 变量后，共享变量的状态示意图： 如上图所示，在读 flag 变量后，本地内存 B 已经被置为无效。此时，线程 B 必须从主内存中读取共享变量。线程 B 的读取操作将导致本地内存 B 与主内存中的共享变量的值也变成一致的了。 如果把 volatile 写和 volatile 读这两个步骤综合起来看的话，在读线程 B 读一个 volatile 变量后，写线程 A 在写这个 volatile 变量之前所有可见的共享变量的值都将立即变得对读线程 B 可见。 volatile内存语义实现重排序分为编译器重排序和处理器重排序。为了实现 volatile 内存语义，JMM 会分别限制这两种类型的重排序类型。下面是 JMM 针对编译器制定的 volatile 重排序规则表： 能否重排序 第二个操作 第一个操作 普通读 / 写 volatile 读 volatile 写 普通读 / 写 NO volatile 读 NO NO NO volatile 写 NO NO 从上表可以看出： 当第二个操作是 volatile 写时，不管第一个操作是什么，都不能重排序。这个规则确保 volatile 写之前的操作不会被编译器重排序到 volatile 写之后。 当第一个操作是 volatile 读时，不管第二个操作是什么，都不能重排序。这个规则确保 volatile 读之后的操作不会被编译器重排序到 volatile 读之前。 当第一个操作是 volatile 写，第二个操作是 volatile 读时，不能重排序。 为了实现 volatile 的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能，为此，JMM 采取保守策略。下面是基于保守策略的 JMM 内存屏障插入策略： 在每个 volatile 写操作的前面插入一个 StoreStore 屏障。 在每个 volatile 写操作的后面插入一个 StoreLoad 屏障。 在每个 volatile 读操作的后面插入一个 LoadLoad 屏障。 在每个 volatile 读操作的后面插入一个 LoadStore 屏障。 上述内存屏障插入策略非常保守，但它可以保证在任意处理器平台，任意的程序中都能得到正确的 volatile 内存语义。 下面是保守策略下，volatile 写插入内存屏障后生成的指令序列示意图： 上图中的 StoreStore 屏障可以保证在 volatile 写之前，其前面的所有普通写操作已经对任意处理器可见了。这是因为 StoreStore 屏障将保障上面所有的普通写在 volatile 写之前刷新到主内存。 这里比较有意思的是 volatile 写后面的 StoreLoad 屏障。这个屏障的作用是避免 volatile 写与后面可能有的 volatile 读 / 写操作重排序。因为编译器常常无法准确判断在一个 volatile 写的后面，是否需要插入一个 StoreLoad 屏障（比如，一个 volatile 写之后方法立即 return）。为了保证能正确实现 volatile 的内存语义，JMM 在这里采取了保守策略：在每个 volatile 写的后面或在每个 volatile 读的前面插入一个 StoreLoad 屏障。从整体执行效率的角度考虑，JMM 选择了在每个 volatile 写的后面插入一个 StoreLoad 屏障。因为 volatile 写 - 读内存语义的常见使用模式是：一个写线程写 volatile 变量，多个读线程读同一个 volatile 变量。当读线程的数量大大超过写线程时，选择在 volatile 写之后插入 StoreLoad 屏障将带来可观的执行效率的提升。从这里可以看到 JMM 在实现上的一个特点：首先确保正确性，然后再去追求执行效率。 下面是在保守策略下，volatile 读插入内存屏障后生成的指令序列示意图： 上图中的 LoadLoad 屏障用来禁止处理器把上面的 volatile 读与下面的普通读重排序。LoadStore 屏障用来禁止处理器把上面的 volatile 读与下面的普通写重排序。 上述 volatile 写和 volatile 读的内存屏障插入策略非常保守。在实际执行时，只要不改变 volatile 写 - 读的内存语义，编译器可以根据具体情况省略不必要的屏障。下面通过示例代码来说明： 123456789101112131415class VolatileBarrierExample &#123; int a; volatile int v1 = 1; volatile int v2 = 2; void readAndWrite() &#123; int i = v1; // 第一个 volatile 读 int j = v2; // 第二个 volatile 读 a = i + j; // 普通写 v1 = i + 1; // 第一个 volatile 写 v2 = j * 2; // 第二个 volatile 写 &#125; … // 其他方法 &#125; 针对 readAndWrite() 方法，编译器在生成字节码时可以做如下的优化： 注意，最后的 StoreLoad 屏障不能省略。因为第二个 volatile 写之后，方法立即 return。此时编译器可能无法准确断定后面是否会有 volatile 读或写，为了安全起见，编译器常常会在这里插入一个 StoreLoad 屏障。 上面的优化是针对任意处理器平台，由于不同的处理器有不同“松紧度”的处理器内存模型，内存屏障的插入还可以根据具体的处理器内存模型继续优化。以 x86 处理器为例，上图中除最后的 StoreLoad 屏障外，其它的屏障都会被省略。 前面保守策略下的 volatile 读和写，在 x86 处理器平台可以优化成： 前面提到过，x86 处理器仅会对写 - 读操作做重排序。X86 不会对读 - 读，读 - 写和写 - 写操作做重排序，因此在 x86 处理器中会省略掉这三种操作类型对应的内存屏障。在 x86 中，JMM 仅需在 volatile 写后面插入一个 StoreLoad 屏障即可正确实现 volatile 写 - 读的内存语义。这意味着在 x86 处理器中，volatile 写的开销比 volatile 读的开销会大很多（因为执行 StoreLoad 屏障开销会比较大）。 JSR-133 为什么要增强 volatile 的内存语义在 JSR-133 之前的旧 Java 内存模型中，虽然不允许 volatile 变量之间重排序，但旧的 Java 内存模型允许 volatile 变量与普通变量之间重排序。 因此在旧的内存模型中 ，volatile 的写 - 读没有监视器的释放 - 获所具有的内存语义。为了提供一种比监视器锁更轻量级的线程之间通信的机制，JSR-133 专家组决定增强 volatile 的内存语义：严格限制编译器和处理器对 volatile 变量与普通变量的重排序，确保 volatile 的写 - 读和监视器的释放 - 获取一样，具有相同的内存语义。从编译器重排序规则和处理器内存屏障插入策略来看，只要 volatile 变量与普通变量之间的重排序可能会破坏 volatile 的内存语意，这种重排序就会被编译器重排序规则和处理器内存屏障插入策略禁止。 由于 volatile 仅仅保证对单个 volatile 变量的读 / 写具有原子性，而监视器锁的互斥执行的特性可以确保对整个临界区代码的执行具有原子性。在功能上，监视器锁比 volatile 更强大；在可伸缩性和执行性能上，volatile 更有优势。如果想在程序中用 volatile 代替监视器锁，请一定谨慎。","tags":"java jmm"},{"title":"Java内存模型-基础学习","url":"/posts/d4946f29.html","text":"并发编程模型分类在并发编程中，需要处理两个关键问题：线程之间如何通信及线程之间如何同步（这里的线程是指并发执行的活动实体）。通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。 在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写 - 读内存中的公共状态来隐式进行通信。在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。 同步是指程序用于控制不同线程之间操作发生相对顺序的机制。在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。 Java 的并发采用的是共享内存模型，Java 线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。 Java内存模型的抽象Java 线程之间的通信由 Java 内存模型（简称为 JMM）控制，JMM 决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM 定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读 / 写共享变量的副本。本地内存是 JMM 的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。Java 内存模型的抽象示意图如下： 从上图来看，线程 A 与线程 B 之间如要通信的话，必须要经历2个步骤： 首先，线程 A 把本地内存 A 中更新过的共享变量刷新到主内存中去。 然后，线程 B 到主内存中去读取线程 A 之前已更新过的共享变量。 下面通过示意图来说明这两个步骤：如上图所示，本地内存 A 和 B 有主内存中共享变量 x 的副本。假设初始时，这三个内存中的 x 值都为 0。线程 A 在执行时，把更新后的 x 值（假设值为 1）临时存放在自己的本地内存 A 中。当线程 A 和线程 B 需要通信时，线程 A 首先会把自己本地内存中修改后的 x 值刷新到主内存中，此时主内存中的 x 值变为了 1。随后，线程 B 到主内存中去读取线程 A 更新后的 x 值，此时线程 B 的本地内存的 x 值也变为了 1。 从整体来看，这两个步骤实质上是线程 A 在向线程 B 发送消息，而且这个通信过程必须要经过主内存。JMM 通过控制主内存与每个线程的本地内存之间的交互，来为 java 程序员提供内存可见性保证。 指令重排序在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型： 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读 / 写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 上述的1属于编译器重排序，2 和 3属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编译器，JMM 的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM 的处理器重排序规则会要求 java 编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel 称之为 memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。 JMM 属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。 内存屏障指令现代的处理器使用写缓冲区来临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，可以减少对内存总线的占用。虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读 / 写操作的执行顺序，不一定与内存实际发生的读 / 写操作顺序一致！如下示例： ProcessorA ProcessorB a = 1; //A1x = b; //A2 b = 2; //B1y = a; //B2 初始状态：a = b = 0处理器允许得到结果：x = y = 0 假设处理器 A 和处理器 B 按程序的顺序并行执行内存访问，最终却可能得到 x = y = 0 的结果。具体的原因如下图所示： 这里处理器 A 和处理器 B 可以同时把共享变量写入自己的写缓冲区（A1，B1），然后从内存中读取另一个共享变量（A2，B2），最后才把自己写缓存区中保存的脏数据刷新到内存中（A3，B3）。当以这种时序执行时，程序就可以得到 x = y = 0 的结果。 从内存操作实际发生的顺序来看，直到处理器 A 执行 A3 来刷新自己的写缓存区，写操作 A1 才算真正执行了。虽然处理器 A 执行内存操作的顺序为：A1-&gt;A2，但内存操作实际发生的顺序却是：A2-&gt;A1。此时，处理器 A 的内存操作顺序被重排序了（处理器 B 的情况和处理器 A 一样）。 这里的关键是，由于写缓冲区仅对自己的处理器可见，它会导致处理器执行内存操作的顺序可能会与内存实际的操作执行顺序不一致。由于现代的处理器都会使用写缓冲区，因此现代的处理器都会允许对写 - 读操做重排序。 下面是常见处理器允许的重排序类型的列表： Load-Load Load-Store Store-Store Store-Load 数据依赖 sparc-TSO N N N Y N x86 N N N Y N ia64 N N N Y N PowerPC N N N Y N 上表单元格中的“N”表示处理器不允许两个操作重排序，“Y”表示允许重排序。常见的处理器都允许 Store-Load 重排序；常见的处理器都不允许对存在数据依赖的操作做重排序。sparc-TSO 和 x86 拥有相对较强的处理器内存模型，它们仅允许对写 - 读操作做重排序（因为它们都使用了写缓冲区）。 为了保证内存可见性，java 编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。JMM 把内存屏障指令分为下列四类： 屏障类型 指令示例 说明 LoadLoad Barriers Load1; LoadLoad; Load2 确保 Load1 数据的装载，之前于 Load2 及所有后续装载指令的装载。 StoreStore Barriers Store1; StoreStore; Store2 确保 Store1 数据对其他处理器可见（刷新到内存），之前于 Store2 及所有后续存储指令的存储。 LoadStore Barriers Load1; LoadStore; Store2 确保 Load1 数据装载，之前于 Store2 及所有后续的存储指令刷新到内存。 StoreLoad Barriers Store1; StoreLoad; Load2 确保 Store1 数据对其他处理器变得可见（指刷新到内存），之前于 Load2 及所有后续装载指令的装载。StoreLoad Barriers 会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令。 StoreLoad Barriers 是一个“全能型”的屏障，它同时具有其他三个屏障的效果。现代的多处理器大都支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（buffer fully flush）。 happens-before从 JDK5 开始，java 使用新的 JSR -133 内存模型，JSR-133 提出了 happens-before 的概念，通过这个概念来阐述操作之间的内存可见性。如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在 happens-before 关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。 与程序员密切相关的 happens-before 规则如下： 程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作。 监视器锁规则：对一个监视器锁的解锁，happens- before 于随后对这个监视器锁的加锁。 volatile 变量规则：对一个 volatile 域的写，happens- before 于任意后续对这个 volatile 域的读。 传递性：如果 A happens- before B，且 B happens- before C，那么 A happens- before C。 注意：两个操作之间具有 happens-before 关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before 仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。 如上图所示，一个 happens-before 规则通常对应于多个编译器重排序规则和处理器重排序规则。对于 java 程序员来说，happens-before 规则简单易懂，它避免程序员为了理解 JMM 提供的内存可见性保证而去学习复杂的重排序规则以及这些规则的具体实现。","tags":"java jmm"},{"title":"Java多线程-07之-线程休眠","url":"/posts/c0fad076.html","text":"sleep()介绍sleep() 的作用是让当前线程休眠，即当前线程会从“运行状态”进入到“休眠(阻塞)状态”。sleep()会指定休眠时间，线程休眠的时间会大于/等于该休眠时间；在线程重新被唤醒时，它会由“阻塞状态”变成“就绪状态”，从而等待cpu的调度执行。 sleep()示例123456789101112131415161718192021222324252627282930313233package main.java.com.study.thread.sleep;/** * @author: whb * @description: 线程休眠测试 */public class SleepTest &#123; public static void main(String[] args) &#123; ThreadA t1 = new ThreadA(\"t1\"); t1.start(); &#125;&#125;class ThreadA extends Thread &#123; public ThreadA(String name) &#123; super(name); &#125; @Override public synchronized void run() &#123; try &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.printf(\"%s: %d\\n\", this.getName(), i); // i能被4整除时，休眠100毫秒 if (i % 4 == 0) &#123; Thread.sleep(100); &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 运行结果： 12345678910t1: 0t1: 1t1: 2t1: 3t1: 4t1: 5t1: 6t1: 7t1: 8t1: 9 结果说明： 程序比较简单，在主线程main中启动线程t1。t1启动之后，当t1中的计算i能被4整除时，t1会通过Thread.sleep(100)休眠100毫秒。 sleep() 与 wait()的比较wait()的作用是让当前线程由“运行状态”进入“等待(阻塞)状态”的同时，也会释放同步锁。而sleep()的作用是也是让当前线程由“运行状态”进入到“休眠(阻塞)状态”。但是，wait()会释放对象的同步锁，而sleep()则不会释放锁。 下面通过示例演示sleep()是不会释放锁的。 123456789101112131415161718192021222324252627282930313233343536373839404142package main.java.com.study.thread.sleep;/** * @author: whb * @description: wait()的作用是让当前线程由“运行状态”进入“等待(阻塞)状态”的同时，也会释放同步锁。而sleep()的作用是也是让当前线程由“运行状态”进入到“休眠(阻塞)状态”。 * 但是，wait()会释放对象的同步锁，而sleep()则不会释放锁。 */public class SleepLockTest &#123; private static Object obj = new Object(); public static void main(String[] args) &#123; ThreadA t1 = new ThreadA(\"t1\"); ThreadA t2 = new ThreadA(\"t2\"); t1.start(); t2.start(); &#125; static class ThreadA extends Thread &#123; public ThreadA(String name) &#123; super(name); &#125; @Override public void run() &#123; // 获取obj对象的同步锁 synchronized (obj) &#123; try &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.printf(\"%s: %d\\n\", this.getName(), i); // i能被4整除时，休眠100毫秒 if (i % 4 == 0) &#123; Thread.sleep(100); &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 运行结果： 1234567891011121314151617181920t1: 0t1: 1t1: 2t1: 3t1: 4t1: 5t1: 6t1: 7t1: 8t1: 9t2: 0t2: 1t2: 2t2: 3t2: 4t2: 5t2: 6t2: 7t2: 8t2: 9 结果说明： 主线程main中启动了两个线程t1和t2。t1和t2在run()会引用同一个对象的同步锁，即synchronized(obj)。在t1运行过程中，虽然它会调用Thread.sleep(100)；但是，t2是不会获取cpu执行权的。因为，t1并没有释放“obj所持有的同步锁”！","tags":"java 多线程"},{"title":"设计模式-工厂方法模式","url":"/posts/89a20157.html","text":"模式定义工厂方法模式，又称工厂模式、多态工厂模式和虚拟构造器模式，通过定义工厂父类负责定义创建对象的公共接口，而子类则负责生成具体的对象。 主要作用将类的实例化（具体产品的创建）延迟到工厂类的子类（具体工厂）中完成，即由子类来决定应该实例化（创建）哪一个类。 解决的问题解决简单工厂模式一旦需要生产新产品就需要修改工厂类的方法逻辑，违背了“开放 - 关闭原则的缺点。之所以可以解决简单工厂的问题，是因为工厂方法模式把具体产品的创建推迟到工厂类的子类（具体工厂）中，此时工厂类不再负责所有产品的创建，而只是给出具体工厂必须实现的接口，这样工厂方法模式在添加新产品的时候就不修改工厂类逻辑而是添加新的工厂子类，符合开放封闭原则，克服了简单工厂模式中缺点 模式原理UML类图 模式组成 组成（角色） 关系 作用 抽象产品（Product） 具体产品的父类 描述具体产品的公共接口 具体产品（Concrete Product） 抽象产品的子类； 工厂类创建的目标类 描述生产的具体产品 抽象工厂（Creator） 具体工厂的父类 描述具体工厂的公共接口 具体工厂（Concrete Creator） 抽象工厂的子类； 被外界调用 描述具体工厂； 实现FactoryMethod工厂方法创建产品的实例 使用步骤 创建抽象工厂类，定义具体工厂的公共接口； 创建抽象产品类 ，定义具体产品的公共接口； 创建具体产品类（继承抽象产品类） &amp; 定义生产的具体产品； 创建具体工厂类（继承抽象工厂类），定义创建对应具体产品实例的方法； 外界通过调用具体工厂类的方法，从而创建不同具体产品类的实例。 模式优点 更符合开-闭原则，新增一种产品时，只需要增加相应的具体产品类和相应的工厂子类即可。 符合单一职责原则，每个具体工厂类只负责创建对应的产品。 不使用静态工厂方法，可以形成基于继承的等级结构。 模式缺点 添加新产品时，除了增加新产品类外，还要提供与之对应的具体工厂类，系统类的个数将成对增加，在一定程度上增加了系统的复杂度；同时，有更多的类需要编译和运行，会给系统带来一些额外的开销； 由于考虑到系统的可扩展性，需要引入抽象层，在客户端代码中均使用抽象层进行定义，增加了系统的抽象性和理解难度，且在实现时可能需要用到DOM、反射等技术，增加了系统的实现难度。 虽然保证了工厂方法内的对修改关闭，但对于使用工厂方法的类，如果要更换另外一种产品，仍然需要修改实例化的具体工厂类； 一个具体工厂只能创建一种具体产品。 应用场景 当一个类不知道它所需要的对象的类时在工厂方法模式中，客户端不需要知道具体产品类的类名，只需要知道所对应的工厂即可； 当一个类希望通过其子类来指定创建对象时在工厂方法模式中，对于抽象工厂类只需要提供一个创建产品的接口，而由其子类来确定具体要创建的对象，利用面向对象的多态性和里氏代换原则，在程序运行时，子类对象将覆盖父类对象，从而使得系统更容易扩展。 将创建对象的任务委托给多个工厂子类中的某一个，客户端在使用时可以无须关心是哪一个工厂子类创建产品子类，需要时再动态指定，可将具体工厂类的类名存储在配置文件或数据库中。 模式示例示例背景以塑料加工厂为例，目前加工厂仅生产A类产品，随着客户需求变化，客户需要生产B类产品；但是改变原有塑料加工厂的配置和变化非常困难，假设下一次客户需要再发生变化，再次改变将增加非常大的成本；所以通过置办塑料分厂B来生产B类产品。 抽象工厂类1234567891011121314package main.java.com.study.designPatterns.factory.method.demoOne;/** * @author: whb * @description: 抽象工厂类，定义具体工厂的公共接口 */public abstract class Factory &#123; /** * 生产产品 * * @return */ public abstract Product manuFacture();&#125; 抽象产品类12345678910111213package main.java.com.study.designPatterns.factory.method.demoOne;/** * @author: whb * @description: 抽象产品类，定义具体产品的公共接口 */public abstract class Product &#123; /** * 展示产品 */ public abstract void show();&#125; 具体产品类123456789101112131415161718192021222324252627package main.java.com.study.designPatterns.factory.method.demoOne;/** * @author: whb * @description: 具体产品类A（继承抽象产品类），定义生产的具体产品 */public class ProductA extends Product &#123; @Override public void show() &#123; System.out.println(\"生产了产品A\"); &#125;&#125;package main.java.com.study.designPatterns.factory.method.demoOne;/** * @author: whb * @description: 具体产品类B, 定义生产的具体产品 */public class ProductB extends Product &#123; @Override public void show() &#123; System.out.println(\"生产了产品B\"); &#125;&#125; 具体工厂类123456789101112131415161718192021222324252627package main.java.com.study.designPatterns.factory.method.demoOne;/** * @author: whb * @description: 具体工厂类A，定义创建具体产品的实例方法 */public class FactoryA extends Factory &#123; @Override public Product manuFacture() &#123; return new ProductA(); &#125;&#125;package main.java.com.study.designPatterns.factory.method.demoOne;/** * @author: whb * @description: 具体工厂类B，定义创建具体产品的实例方法 */public class FactoryB extends Factory &#123; @Override public Product manuFacture() &#123; return new ProductB(); &#125;&#125; 客户端调用1234567891011121314151617package main.java.com.study.designPatterns.factory.method.demoOne;/** * @author: whb * @description: 客户端调用 */public class Client &#123; public static void main(String[] args) &#123; //客户要产品A FactoryA factoryA = new FactoryA(); factoryA.manuFacture().show(); //客户要产品B FactoryB factoryB = new FactoryB(); factoryB.manuFacture().show(); &#125;&#125;","tags":"java 设计模式"},{"title":"设计模式-简单工厂模式","url":"/posts/aac06fee.html","text":"模式定义简单工厂模式(Simple Factory Pattern)：又称为静态工厂方法(Static Factory Method)模式，它属于类创建型模式。提供一个创建对象实例的功能，而无需关心其具体实现。被创建实例的类型可以是接口、抽象类，也可以是具体类。 解决的问题将“类实例化的操作”与“使用对象的操作”分开，让使用者不用知道具体参数就可以实例化出所需要的“产品”类，从而避免了在客户端代码中显式指定，实现了解耦。即使用者可直接消费产品而不需要知道其生产的细节。 适用的环境 工厂类创建的对象比较小，这样不会造成工厂方法中业务的逻辑过于复杂。 客户端只是知道传入工厂类的参数、对于如何去创建对象并不关心。客户端不需要去关心创建的细节，只需要明确需要的参数，而由工厂内部负责具体的类的创建。 模式原理模式组成 组成（角色） 关系 作用 抽象产品（Product） 具体产品的父类 描述产品的公共接口 具体产品（Concrete Product） 抽象产品的子类； 工厂类创建的目标类 描述生产的具体产品 工厂（Creator） 被外界调用 根据传入不同参数从而创建不同具体产品类的实例 UML类图 使用步骤 创建抽象产品类 &amp; 定义具体产品的公共接口； 创建具体产品类（继承抽象产品类） &amp; 定义生产的具体产品； 创建工厂类，通过创建静态方法根据传入不同参数从而创建不同具体产品类的实例； 外界通过调用工厂类的静态方法，传入不同参数从而创建不同具体产品类的实例 模式优点 责任分割：工厂类含有处理逻辑，决定何时去创建产品对象，客户端只是需要传递对应的参数，即可以完成产品的创建。 在一定程度上提高了系统的灵活性：可以通过引入配置文件的方法，在不去修改客户端代码的前提下，更换和增减新的产品。 模式缺点 工厂类集中了所有实例（产品）的创建逻辑，一旦这个工厂不能正常工作，整个系统都会受到影响。 违背“开放 - 关闭原则”，一旦添加新产品就不得不修改工厂类的逻辑，这样就会造成工厂逻辑过于复杂。 简单工厂模式由于使用了静态工厂方法，静态方法不能被继承和重写，会造成工厂角色无法形成基于继承的等级结构。 模式应用 JDK类库中广泛使用了简单工厂模式，如工具类java.text.DateFormat，它用于格式化一个本地日期或者时间。 123public final static DateFormat getDateInstance(); public final static DateFormat getDateInstance(int style); public final static DateFormat getDateInstance(int style,Locale locale); 获取不同加密算法的密钥生成器。 1KeyGenerator keyGen=KeyGenerator.getInstance(\"DESede\"); 模式示例以生产电脑为例，假设有一个电脑的代工生产商，它目前已经可以代工生产联想电脑，随着业务的拓展，这个代工生产商还要生产惠普和华硕的电脑，这样就需要用一个单独的类来专门生产电脑，这就用到了简单工厂模式。 抽象产品类创建一个电脑的抽象产品类，他有一个抽象方法用于启动电脑生产： 12345678910111213package main.java.com.study.designPatterns.simpleFactoryPattern.demoOne;/** * @author: whb * @description: 抽象产品类：电脑 */public abstract class Computer &#123; /** * 产品的抽象方法，由具体的产品去实现 */ public abstract void startProduce();&#125; 具体产品类接着创建各个品牌的电脑，他们都继承了他们的父类Computer，并实现了父类的startProduce方法： 联想电脑12345678910111213package main.java.com.study.designPatterns.simpleFactoryPattern.demoOne;/** * @author: whb * @description: 具体产品类：联想电脑 */public class LenovoComputer extends Computer &#123; @Override public void startProduce() &#123; System.out.println(\"联想电脑启动生产\"); &#125;&#125; 惠普电脑123456789101112package main.java.com.study.designPatterns.simpleFactoryPattern.demoOne;/** * @author: whb * @description: 具体产品类：惠普电脑 */public class HpComputer extends Computer &#123; @Override public void startProduce() &#123; System.out.println(\"惠普电脑启动生产\"); &#125;&#125; 华硕电脑123456789101112package main.java.com.study.designPatterns.simpleFactoryPattern.demoOne;/** * @author: whb * @description: 具体产品类：华硕电脑 */public class AsusComputer extends Computer&#123; @Override public void startProduce() &#123; System.out.println(\"华硕电脑启动生产\"); &#125;&#125; 工厂类接下来创建一个工厂类，它提供了一个静态方法createComputer用来生产电脑。你只需要传入你想生产的电脑的品牌，它就会实例化相应品牌的电脑对象： 123456789101112131415161718192021222324252627282930package main.java.com.study.designPatterns.simpleFactoryPattern.demoOne;/** * @author: whb * @description: 工厂类 */public class ComputerFactory &#123; /** * 生产电脑 * * @param type * @return */ public static Computer createComputer(String type) &#123; Computer computer = null; switch (type) &#123; case \"lenovo\": computer = new LenovoComputer(); break; case \"hp\": computer = new HpComputer(); break; case \"asus\": computer = new AsusComputer(); break; &#125; return computer; &#125;&#125; 客户端客户端调用工厂类，传入“asus”生产出华硕电脑并调用该电脑对象的startProduce方法： 1234567891011package main.java.com.study.designPatterns.simpleFactoryPattern.demoOne;/** * @author: whb * @description: 客户端 */public class Client &#123; public static void main(String[] args) &#123; ComputerFactory.createComputer(\"asus\").startProduce(); &#125;&#125;","tags":"java 设计模式"},{"title":"Java多线程-06之-线程让步","url":"/posts/a8d456e8.html","text":"yield()介绍 yield()的作用是让步。它能让当前线程由“运行状态”进入到“就绪状态”，从而让其它具有相同优先级的等待线程获取执行权；但是，并不能保证在当前线程调用yield()之后，其它具有相同优先级的线程就一定能获得执行权；也有可能是当前线程又进入到“运行状态”继续运行！ yield()示例12345678910111213141516171819202122232425262728293031package main.java.com.study.thread.yield;/** * @author: whb * @description: yield()的作用是让步。它能让当前线程由“运行状态”进入到“就绪状态”，从而让其它具有相同优先级的等待线程获取执行权；但是，并不能保证在当前线程调用yield()之后，其它具有相同优先级的线程就一定能获得执行权；也有可能是当前线程又进入到“运行状态”继续运行！ */public class YieldTest &#123; public static void main(String[] args) &#123; ThreadA t1 = new ThreadA(\"t1\"); ThreadA t2 = new ThreadA(\"t2\"); t1.start(); t2.start(); &#125;&#125;class ThreadA extends Thread &#123; public ThreadA(String name) &#123; super(name); &#125; @Override public synchronized void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.printf(\"%s [%d]:%d\\n\", this.getName(), this.getPriority(), i); // i整除4时，调用yield if (i % 4 == 0) &#123; Thread.yield(); &#125; &#125; &#125;&#125; (某一次的)运行结果: 1234567891011121314151617181920t1 [5]:0t2 [5]:0t1 [5]:1t1 [5]:2t1 [5]:3t1 [5]:4t1 [5]:5t1 [5]:6t1 [5]:7t1 [5]:8t1 [5]:9t2 [5]:1t2 [5]:2t2 [5]:3t2 [5]:4t2 [5]:5t2 [5]:6t2 [5]:7t2 [5]:8t2 [5]:9 结果说明： “线程t1”在能被4整数的时候，并没有切换到“线程t2”。这表明，yield()虽然可以让线程由“运行状态”进入到“就绪状态”；但是，它不一定会让其它线程获取CPU执行权(即，其它线程进入到“运行状态”)，即使这个“其它线程”与当前调用yield()的线程具有相同的优先级。 yield() 与 wait()的比较 wait()的作用是让当前线程由“运行状态”进入“等待(阻塞)状态”的同时，也会释放同步锁。而yield()的作用是让步，它也会让当前线程离开“运行状态”。它们的区别是：(01) wait()是让线程由“运行状态”进入到“等待(阻塞)状态”，而不yield()是让线程由“运行状态”进入到“就绪状态”。(02) wait()是会线程释放它所持有对象的同步锁，而yield()方法不会释放锁。 下面通过示例演示yield()是不会释放锁的。 123456789101112131415161718192021222324252627282930313233343536373839package main.java.com.study.thread.yield;/** * @author: whb * @description: wait()的作用是让当前线程由“运行状态”进入“等待(阻塞)状态”的同时，也会释放同步锁。而yield()的作用是让步，它也会让当前线程离开“运行状态”。它们的区别是： * (01) wait()是让线程由“运行状态”进入到“等待(阻塞)状态”，而不yield()是让线程由“运行状态”进入到“就绪状态”。 * (02) wait()是会线程释放它所持有对象的同步锁，而yield()方法不会释放锁。 */public class YieldLockTest &#123; private static Object obj = new Object(); public static void main(String[] args) &#123; ThreadA t1 = new ThreadA(\"t1\"); ThreadA t2 = new ThreadA(\"t2\"); t1.start(); t2.start(); &#125; static class ThreadA extends Thread &#123; public ThreadA(String name) &#123; super(name); &#125; @Override public void run() &#123; // 获取obj对象的同步锁 synchronized (obj) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.printf(\"%s [%d]:%d\\n\", this.getName(), this.getPriority(), i); // i整除4时，调用yield if (i % 4 == 0) &#123; Thread.yield(); &#125; &#125; &#125; &#125; &#125;&#125; (某一次)运行结果： 1234567891011121314151617181920t1 [5]:0t1 [5]:1t1 [5]:2t1 [5]:3t1 [5]:4t1 [5]:5t1 [5]:6t1 [5]:7t1 [5]:8t1 [5]:9t2 [5]:0t2 [5]:1t2 [5]:2t2 [5]:3t2 [5]:4t2 [5]:5t2 [5]:6t2 [5]:7t2 [5]:8t2 [5]:9 结果说明： 主线程main中启动了两个线程t1和t2。t1和t2在run()会引用同一个对象的同步锁，即synchronized(obj)。在t1运行过程中，虽然它会调用Thread.yield()；但是，t2是不会获取cpu执行权的。因为，t1并没有释放“obj所持有的同步锁”！","tags":"java 多线程"},{"title":"排序算法 - 梳排序","url":"/posts/9d531ce3.html","text":"基本思想梳排序和希尔排序很类似。希尔排序是在直接插入排序的基础上做的优化，而梳排序是在冒泡排序的基础上做的优化。也是像希尔排序一样，将待排序序列通过增量分为若干个子序列，然后对子序列进行一趟冒泡排序，一步步减小增量，直至增量为1。所以梳排序的最后一次排序是冒泡排序。梳排序增量是根据递减率减小的，递减率的设定影响着梳排序的效率，原作者以随机数作实验，得到最有效递减率为1.3的。因为编程中乘法比除法快，所以会取递减率的倒数与间距相乘，即0.8。其实当间距为1的时候，梳排序就是冒泡排序，而间距大于1的时候，梳排序的就是尽量把小的数字往前移动并保证此次间隔内的组是有序的。 举个例子：假设待数组[10 4 3 9 6 5 2 1 7 8] 待排数组长度为10,而10÷1.3=8,则比较10和7,4和8,并做交换。 交换后的结果为： [7 4 3 9 6 5 2 1 10 8] 第二次循环,更新间距为8÷1.3=6,比较7和2,4和1,3和10,9和8,7和2，4和1,9和8需要交换。 交换后的结果为： [2 1 3 8 6 5 7 4 10 9] 第三次循环,更新距离为4,比较2和6,1和5,3和7,8和4,6和10,5和9,8和4需要交换。 [2 1 3 4 6 5 7 8 10 9] 第四次循环,更新距离为3,比较2和4,1和6,3和5,4和7,6和8,5和10,7和9，不需要交换。 第五次循环,更新距离为2,比较2和3,1和4,3和6,4和5,6和7,5和8,7和10,8和9，不需要交换。 第六次循环，更新距离为1，为冒泡排序。 [1 2 3 4 5 6 7 8 9 10] 交换后排序结束,顺序输出即可得到[1 2 3 4 5 6 7 8 9 10]。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package main.java.com.study.sortingAalgorithm;import main.java.com.study.utils.CommonUtils;/** * @author: whb * @description: 梳排序 */public class CombSort &#123; /** * 梳排序 * * @param unsorted 待排序列 */ public static void combSort(int[] unsorted) &#123; int gap = unsorted.length; boolean swapped = true; while (gap &gt; 1 || swapped) &#123; if (gap &gt; 1) &#123; gap = (int) (gap / 1.3); &#125; int i = 0; swapped = false; while (i + gap &lt; unsorted.length) &#123; if (unsorted[i] &gt; unsorted[i + gap]) &#123; swap(unsorted, i, i + gap); swapped = true; &#125; i++; &#125; &#125; &#125; /** * 按从小到大的顺序交换数组 * * @param a 传入的数组 * @param b 传入的要交换的数b * @param c 传入的要交换的数c */ public static void swap(int[] a, int b, int c) &#123; if (b == c) &#123; return; &#125; int temp = a[b]; a[b] = a[c]; a[c] = temp; &#125; public static void main(String[] args) &#123; int[] unsorted = &#123;11, 95, 45, 15, 78, 84, 51, 24, 12&#125;; System.out.println(\"**************梳排序******************\"); System.out.println(\"排序前：\"); CommonUtils.display(unsorted); System.out.println(\"排序后：\"); combSort(unsorted); CommonUtils.display(unsorted); &#125;&#125; 测试结果","tags":"java 算法"},{"title":"排序算法 - 地精排序","url":"/posts/d703cb77.html","text":"基本思想号称最简单的排序算法,只有一层循环,默认情况下前进冒泡,一旦遇到冒泡的情况发生就往回冒,直到把这个数字放好为止。 举个例子：待排数组[6 2 4 1 5 9]。 先设计一个标识i=0然后从头开始判断,什么时候(i &lt; 6)不成立,什么时候排序结束。 [6 2 4 1 5 9] [0 1 2 3 4 5] 下具体的排序过程如下： [ i = 0 ]时啥也不干,先让i自增1,达到值为1才开始真正的比较。 交换前[6 2 4 1 5 9][ i = 0] 交换后[6 2 4 1 5 9][ i = 1] [ i = 1 ]比较6和2,发生交换,只要发生交换i就减1。 交换前[6 2 4 1 5 9][ i = 1] 交换后[2 6 4 1 5 9][ i = 0] [ i = 0 ]又成0了,啥也不干,自增变成1再说。 交换前[2 6 4 1 5 9][ i = 0] 交换后[2 6 4 1 5 9][ i = 1] [ i = 1 ]再比较2和6,不交换,只要不交换就自增1。 交换前[2 6 4 1 5 9][ i = 1] 交换后[2 6 4 1 5 9][ i = 2] [ i = 2 ]比较6和4,发生交换,只要交换就减1。 交换前[2 6 4 1 5 9][ i = 2] 交换后[2 4 6 1 5 9][ i = 1] [ i = 1 ]比较2和4,不交换,只要不交换就自增1。 交换前[2 4 6 1 5 9][ i = 1] 交换后[2 4 6 1 5 9][ i = 2] [ i = 2 ]比较4和6,不交换,只要不交换就自增1。 交换前[2 4 6 1 5 9][ i = 2] 交换后[2 4 6 1 5 9][ i = 3] [ i = 3 ]比较6和1,交换,只要交换就减1。 交换前[2 4 6 1 5 9][ i = 3] 交换后[2 4 1 6 5 9][ i = 2] [ i = 2 ]比较4和1,交换,只要交换就减1。 交换前[2 4 1 6 5 9][ i = 2] 交换后[2 1 4 6 5 9][ i = 1] [ i = 1 ]比较2和1,交换,只要交换就减1。 交换前[2 1 4 6 5 9][ i = 1] 交换后[1 2 4 6 5 9][ i = 0] [ i = 0 ]时啥也不干,先让i自增1,达到值为1才开始真正的比较。 交换前[1 2 4 6 5 9][ i = 0] 交换后[1 2 4 6 5 9][ i = 1] [ i = 1]比较1和2,不交换,只要不交换就自增1。 [ i = 2]比较2和4,不交换,只要不交换就自增1。 [ i = 3]比较4和6,不交换,只要不交换就自增1。 [ i = 4]比较6和5,交换,只要交换就减1。 交换前[1 2 4 6 5 9][ i = 4] 交换后[1 2 4 5 6 9][ i = 3] [ i = 3]比较4和5,不交换,只要不交换就自增1。 [ i = 4]比较5和6,不交换,只要不交换就自增1。 [ i = 5]比较6和9,不交换,只要不交换就自增1。 [ i = 6]表达式(i &lt; n)不成立,排序结束。 顺序输出结果即可:[ 1 2 4 5 6 9]。 代码12345678910111213141516171819202122232425262728293031323334package main.java.com.study.sortingAalgorithm;import main.java.com.study.utils.CommonUtils;/** * @author: whb * @description: 地精排序：号称最简单的排序算法,只有一层循环,默认情况下前进冒泡,一旦遇到冒泡的情况发生就往回冒,直到把这个数字放好为止。 */public class GnomeSort &#123; public static void gnomeSort(int[] unsorted) &#123; int i = 0; while (i &lt; unsorted.length) &#123; if (i == 0 || unsorted[i - 1] &lt;= unsorted[i]) &#123; i++; &#125; else &#123; int temp = unsorted[i]; unsorted[i] = unsorted[i - 1]; unsorted[i - 1] = temp; i--; &#125; &#125; &#125; public static void main(String[] args) &#123; int[] unsorted = &#123;6, 2, 4, 1, 5, 9&#125;; System.out.println(\"**************地精排序******************\"); System.out.println(\"排序前：\"); CommonUtils.display(unsorted); System.out.println(\"排序后：\"); gnomeSort(unsorted); CommonUtils.display(unsorted); &#125;&#125; 测试结果","tags":"java 算法"},{"title":"排序算法 - 鸡尾酒排序","url":"/posts/6d9204ec.html","text":"基本思想鸡尾酒排序基于冒泡排序,双向循环。 举个例子：给定待排数组[2 3 4 5 1] 第一趟过去时的每一步。 第一步迭代,2 &lt; 3不换 [2 3 4 5 1] 第二步迭代,3 &lt; 4不换 [2 3 4 5 1] 第三步迭代,4 &lt; 5不换 [2 3 4 5 1] 第四步迭代,5 &gt; 1交换 [2 3 4 1 5] 第一趟回来时的第一步,鸡尾酒一次到头后就回返回来,再到头后再过去,来回比,一个来回能排两个数字。 第五步迭代,1 &lt; 5不交换 [2 3 4 1 5] 第六步迭代,1 &lt; 4交换 [2 3 1 4 5] 第七步迭代,1 &lt; 3交换 [2 1 3 4 5] 第八步迭代,2 &gt; 1交换 [1 2 3 4 5] 排序完毕,顺序输出结果即可得[ 1 2 3 4 5]。 如何判断排序结束了? 假如一趟来回没有交换任何数字,则表示该数组已经有序了,可以设置了个变量表示有没有交换过。 代码12345678910111213141516171819202122232425262728293031323334353637383940414243package main.java.com.study.sortingAalgorithm;import main.java.com.study.utils.CommonUtils;/** * @author: whb * @description: 鸡尾酒排序 基于冒泡排序,双向循环 */public class CocktailSort &#123; public static void cocktailSort(int[] unsorted) &#123; boolean swapped = false; do &#123; for (int i = 0; i &lt; unsorted.length - 1; i++) &#123; if (unsorted[i] &gt; unsorted[i + 1]) &#123; int temp = unsorted[i]; unsorted[i] = unsorted[i + 1]; unsorted[i + 1] = temp; swapped = true; &#125; &#125; swapped = false; for (int j = unsorted.length - 1; j &gt; 0; j--) &#123; if (unsorted[j] &lt; unsorted[j - 1]) &#123; int temp = unsorted[j]; unsorted[j] = unsorted[j - 1]; unsorted[j - 1] = temp; swapped = true; &#125; &#125; &#125; while (swapped); &#125; public static void main(String[] args) &#123; int[] unsorted = &#123;6, 2, 4, 1, 5, 9&#125;; System.out.println(\"**************鸡尾酒排序******************\"); System.out.println(\"排序前：\"); CommonUtils.display(unsorted); System.out.println(\"排序后：\"); cocktailSort(unsorted); CommonUtils.display(unsorted); &#125;&#125; 测试结果","tags":"java 算法"},{"title":"排序算法 - 桶排序","url":"/posts/41e434a7.html","text":"基本思想是将阵列分到有限数量的桶子里。每个桶子再个别排序（有可能再使用别的排序算法或是以递回方式继续使用桶排序进行排序）。桶排序是鸽巢排序的一种归纳结果。当要被排序的阵列内的数值是均匀分配的时候，桶排序使用线性时间（Θ（n））。但桶排序并不是 比较排序，他不受到 O(n log n) 下限的影响。简单来说，就是把数据分组，放在一个个的桶中，然后对每个桶里面的在进行排序。 例如要对大小为[1..1000]范围内的n个整数A[1..n]排序。首先，可以把桶设为大小为10的范围，具体而言，设集合B[1]存储[1..10]的整数，集合B[2]存储(10..20]的整数，……集合B[i]存储((i-1)10, i10]的整数，i = 1,2,..100。总共有100个桶。然后，对A[1..n]从头到尾扫描一遍，把每个A[i]放入对应的桶B[j]中。再对这100个桶中每个桶里的数字排序，这时可用冒泡，选择，乃至快排，一般来说任何排序法都可以。最后，依次输出每个桶里面的数字，且每个桶中的数字从小到大输出，这样就得到所有数字排好序的一个序列了。假设有n个数字，有m个桶，如果数字是平均分布的，则每个桶里面平均有n/m个数字。如果对每个桶中的数字采用快速排序，那么整个算法的复杂度是O(n + m * n/m*log(n/m)) = O(n + nlogn - nlogm)从上式看出，当m接近n的时候，桶排序复杂度接近O(n)。 当然，以上复杂度的计算是基于输入的n个数字是平均分布这个假设的。这个假设是很强的 ，实际应用中效果并没有这么好。如果所有的数字都落在同一个桶中，那就退化成一般的排序了。 桶排序的缺点是：1）首先是空间复杂度比较高，需要的额外开销大。排序有两个数组的空间开销，一个存放待排序数组，一个就是所谓的桶，比如待排序值是从0到m-1，那就需要m个桶，这个桶数组就要至少m个空间。2）其次待排序的元素都要在一定的范围内等等。桶式排序是一种分配排序。分配排序的特点是不需要进行关键码的比较，但前提是要知道待排序列的一些具体情况。 例如待排数字[6 2 4 1 5 9] 准备10个空桶,最大数个空桶 [6 2 4 1 5 9] 待排数组 [0 0 0 0 0 0 0 0 0 0] 空桶 [0 1 2 3 4 5 6 7 8 9] 桶编号(实际不存在) 1,顺序从待排数组中取出数字,首先6被取出,然后把6入6号桶,这个过程类似这样:空桶[ 待排数组[ 0 ] ] = 待排数组[ 0 ] [6 2 4 1 5 9] 待排数组 [0 0 0 0 0 0 6 0 0 0] 空桶 [0 1 2 3 4 5 6 7 8 9] 桶编号(实际不存在) 2,顺序从待排数组中取出下一个数字,此时2被取出,将其放入2号桶,是几就放几号桶 [6 2 4 1 5 9] 待排数组 [0 0 2 0 0 0 6 0 0 0] 空桶 [0 1 2 3 4 5 6 7 8 9] 桶编号(实际不存在) 3,4,5,6省略,过程一样,全部入桶后变成下边这样 [6 2 4 1 5 9] 待排数组 [0 1 2 0 4 5 6 0 0 9] 空桶 [0 1 2 3 4 5 6 7 8 9] 桶编号(实际不存在) 0表示空桶,跳过,顺序取出即可:1 2 4 5 6 9 代码12345678910111213141516171819202122232425262728293031323334353637package main.java.com.study.sortingAalgorithm;import main.java.com.study.utils.CommonUtils;/** * @author: whb * @description: 桶排序 */public class BucketSort &#123; /** * 是将阵列分到有限数量的桶子里。每个桶子再个别排序（有可能再使用别的排序算法或是以递回方式继续使用桶排序进行排序）。 * 桶排序是鸽巢排序的一种归纳结果。当要被排序的阵列内的数值是均匀分配的时候，桶排序使用线性时间（Θ（n））。 * 但桶排序并不是 比较排序，他不受到 O(n log n) 下限的影响。简单来说，就是把数据分组，放在一个个的桶中，然后对每个桶里面的在进行排序。 */ public static int[] bucketSort(int[] unsorted, int maxNumber) &#123; int[] sorted = new int[maxNumber + 1]; for (int i = 0; i &lt; unsorted.length; i++) &#123; sorted[unsorted[i]] = unsorted[i]; &#125; return sorted; &#125; public static void main(String[] args) &#123; int[] unsorted = &#123;99, 65, 24, 47, 50, 88, 33, 66, 67, 31, 18&#125;; int[] sorted = bucketSort(unsorted, 99); System.out.println(\"**************桶排序******************\"); System.out.println(\"排序前：\"); CommonUtils.display(unsorted); System.out.println(\"排序后：\"); for (int tmp : sorted) &#123; if (tmp &gt; 0) &#123; System.out.print(tmp + \" \"); &#125; &#125; &#125;&#125; 测试结果","tags":"java 算法"},{"title":"Java多线程-05之-线程等待与唤醒","url":"/posts/f777650b.html","text":"wait(), notify(), notifyAll()等方法介绍在Object.java中，定义了wait(), notify()和notifyAll()等接口。wait()的作用是让当前线程进入等待状态，同时，wait()也会让当前线程释放它所持有的锁。而notify()和notifyAll()的作用，则是唤醒当前对象上的等待线程；notify()是唤醒单个线程，而notifyAll()是唤醒所有的线程。 Object类中关于等待/唤醒的API详细信息如下：notify() – 唤醒在此对象监视器上等待的单个线程。notifyAll() – 唤醒在此对象监视器上等待的所有线程。wait() – 让当前线程处于“等待(阻塞)状态”，“直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法”，当前线程被唤醒(进入“就绪状态”)。wait(long timeout) – 让当前线程处于“等待(阻塞)状态”，“直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者超过指定的时间量”，当前线程被唤醒(进入“就绪状态”)。wait(long timeout, int nanos) – 让当前线程处于“等待(阻塞)状态”，“直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者其他某个线程中断当前线程，或者已超过某个实际时间量”，当前线程被唤醒(进入“就绪状态”)。 wait()和notify()示例123456789101112131415161718192021222324252627282930313233343536373839404142434445package main.java.com.study.thread.waitNotify;/** * @author: whb * @description: wait()和notify()使用示例 */public class WaitTest &#123; public static void main(String[] args) &#123; ThreadA t1 = new ThreadA(\"t1\"); synchronized (t1) &#123; try &#123; // 启动“线程t1” System.out.println(Thread.currentThread().getName() + \" start t1\"); t1.start(); // 主线程等待t1通过notify()唤醒。 System.out.println(Thread.currentThread().getName() + \" wait()\"); t1.wait(); System.out.println(Thread.currentThread().getName() + \" continue\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;class ThreadA extends Thread &#123; public ThreadA(String name) &#123; super(name); &#125; @Override public void run() &#123; synchronized (this) &#123; System.out.println(Thread.currentThread().getName() + \" call notify()\"); // 唤醒当前的wait线程 notify(); &#125; &#125;&#125; 运行结果: 1234main start t1main wait()t1 call notify()main continue 结果说明： 如下图，说明了“主线程”和“线程t1”的流程。 (01) 注意，图中”主线程” 代表“主线程main”。”线程t1” 代表WaitTest中启动的“线程t1”。 而“锁” 代表“t1这个对象的同步锁”。(02) “主线程”通过 new ThreadA(“t1”) 新建“线程t1”。随后通过synchronized(t1)获取“t1对象的同步锁”。然后调用t1.start()启动“线程t1”。(03) “主线程”执行t1.wait() 释放“t1对象的锁”并且进入“等待(阻塞)状态”。等待t1对象上的线程通过notify() 或 notifyAll()将其唤醒。(04) “线程t1”运行之后，通过synchronized(this)获取“当前对象的锁”；接着调用notify()唤醒“当前对象上的等待线程”，也就是唤醒“主线程”。(05) “线程t1”运行完毕之后，释放“当前对象的锁”。紧接着，“主线程”获取“t1对象的锁”，然后接着运行。 对于上面的代码：t1.wait()应该是让“线程t1”等待；但是，为什么却是让“主线程main”等待了呢？ 在解答该问题前，先看看jdk文档中关于wait的一段介绍： Causes the current thread to wait until another thread invokes the notify() method or the notifyAll() method for this object. In other words, this method behaves exactly as if it simply performs the call wait(0). The current thread must own this object's monitor. The thread releases ownership of this monitor and waits until another thread notifies threads waiting on this object's monitor to wake up either through a call to the notify method or the notifyAll method. The thread then waits until it can re-obtain ownership of the monitor and resumes execution. 中文意思大概是： 引起“当前线程”等待，直到另外一个线程调用notify()或notifyAll()唤醒该线程。换句话说，这个方法和wait(0)的效果一样！(补充，对于wait(long millis)方法，当millis为0时，表示无限等待，直到被notify()或notifyAll()唤醒)。 “当前线程”在调用wait()时，必须拥有该对象的同步锁。该线程调用wait()之后，会释放该锁；然后一直等待直到“其它线程”调用对象的同步锁的notify()或notifyAll()方法。然后，该线程继续等待直到它重新获取“该对象的同步锁”，然后就可以接着运行。 注意：jdk的解释中，说wait()的作用是让“当前线程”等待，而“当前线程”是指正在cpu上运行的线程！ 这也意味着，虽然t1.wait()是通过“线程t1”调用的wait()方法，但是调用t1.wait()的地方是在“主线程main”中。而主线程必须是“当前线程”，也就是运行状态，才可以执行t1.wait()。所以，此时的“当前线程”是“主线程main”！因此，t1.wait()是让“主线程”等待，而不是“线程t1”！ wait(long timeout)和notify()wait(long timeout)会让当前线程处于“等待(阻塞)状态”，“直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者超过指定的时间量”，当前线程被唤醒(进入“就绪状态”)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445package main.java.com.study.thread.waitNotify;/** * @author: whb * @description: wait(long timeout)和notify()的使用示例 */public class WaitTimeoutTest &#123; public static void main(String[] args) &#123; ThreadB t1 = new ThreadB(\"t1\"); synchronized (t1) &#123; try &#123; // 启动“线程t1” System.out.println(Thread.currentThread().getName() + \" start t1\"); t1.start(); // 主线程等待t1通过notify()唤醒 或 notifyAll()唤醒，或超过3000ms延时；然后才被唤醒。 System.out.println(Thread.currentThread().getName() + \" call wait \"); t1.wait(3000); System.out.println(Thread.currentThread().getName() + \" continue\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;class ThreadB extends Thread &#123; public ThreadB(String name) &#123; super(name); &#125; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + \" run \"); // 死循环，不断运行。 while (true) &#123; ; &#125; &#125;&#125; 运行结果： 1234main start t1main call wait t1 run // 大约3秒之后...输出“main continue”main continue 结果说明： 如下图，说明了“主线程”和“线程t1”的流程。(01) 注意，图中”主线程” 代表WaitTimeoutTest主线程(即，线程main)。”线程t1” 代表WaitTest中启动的线程t1。 而“锁” 代表“t1这个对象的同步锁”。(02) 主线程main执行t1.start()启动“线程t1”。(03) 主线程main执行t1.wait(3000)，此时，主线程进入“阻塞状态”。需要“用于t1对象锁的线程通过notify() 或者 notifyAll()将其唤醒” 或者 “超时3000ms之后”，主线程main才进入到“就绪状态”，然后才可以运行。(04) “线程t1”运行之后，进入了死循环，一直不断的运行。(05) 超时3000ms之后，主线程main会进入到“就绪状态”，然后接着进入“运行状态”。 wait() 和 notifyAll()通过前面的示例，我们知道 notify() 可以唤醒在此对象监视器上等待的单个线程。下面，通过示例演示notifyAll()的用法；它的作用是唤醒在此对象监视器上等待的所有线程。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package main.java.com.study.thread.waitNotify;/** * @author: whb * @description: wait() 和 notifyAll()使用示例 */public class NotifyAllTest &#123; private static Object obj = new Object(); public static void main(String[] args) &#123; ThreadA t1 = new ThreadA(\"t1\"); ThreadA t2 = new ThreadA(\"t2\"); ThreadA t3 = new ThreadA(\"t3\"); t1.start(); t2.start(); t3.start(); try &#123; System.out.println(Thread.currentThread().getName() + \" sleep(3000)\"); Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (obj) &#123; // 主线程等待唤醒。 System.out.println(Thread.currentThread().getName() + \" notifyAll()\"); obj.notifyAll(); &#125; &#125; static class ThreadA extends Thread &#123; public ThreadA(String name) &#123; super(name); &#125; @Override public void run() &#123; synchronized (obj) &#123; try &#123; // 打印输出结果 System.out.println(Thread.currentThread().getName() + \" wait\"); // 唤醒当前的wait线程 obj.wait(); // 打印输出结果 System.out.println(Thread.currentThread().getName() + \" continue\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 运行结果： 12345678t1 waitmain sleep(3000)t3 waitt2 waitmain notifyAll()t2 continuet3 continuet1 continue 结果说明： (01) 主线程中新建并且启动了3个线程”t1”, “t2”和”t3”。(02) 主线程通过sleep(3000)休眠3秒。在主线程休眠3秒的过程中，我们假设”t1”, “t2”和”t3”这3个线程都运行了。以”t1”为例，当它运行的时候，它会执行obj.wait()等待其它线程通过notify()或额nofityAll()来唤醒它；相同的道理，”t2”和”t3”也会等待其它线程通过nofity()或nofityAll()来唤醒它们。(03) 主线程休眠3秒之后，接着运行。执行 obj.notifyAll() 唤醒obj上的等待线程，即唤醒”t1”, “t2”和”t3”这3个线程。 紧接着，主线程的synchronized(obj)运行完毕之后，主线程释放“obj锁”。这样，”t1”, “t2”和”t3”就可以获取“obj锁”而继续运行了！ 为什么notify(), wait()等函数定义在Object中，而不是Thread中Object中的wait(), notify()等函数，和synchronized一样，会对“对象的同步锁”进行操作。 wait()会使“当前线程”等待，因为线程进入等待状态，所以线程应该释放它锁持有的“同步锁”，否则其它线程获取不到该“同步锁”而无法运行！线程调用wait()之后，会释放它锁持有的“同步锁”；而且，等待线程可以被notify()或notifyAll()唤醒。那么问题来了：notify()是依据什么唤醒等待线程的？或者说，wait()等待线程和notify()之间是通过什么关联起来的？答案是：依据“对象的同步锁”。 负责唤醒等待线程的那个线程(称为“唤醒线程”)，它只有在获取“该对象的同步锁”(这里的同步锁必须和等待线程的同步锁是同一个)，并且调用notify()或notifyAll()方法之后，才能唤醒等待线程。虽然，等待线程被唤醒；但是，它不能立刻执行，因为唤醒线程还持有“该对象的同步锁”。必须等到唤醒线程释放了“对象的同步锁”之后，等待线程才能获取到“对象的同步锁”进而继续运行。 总之，notify(), wait()依赖于“同步锁”，而“同步锁”是对象锁持有，并且每个对象有且仅有一个！这就是为什么notify(), wait()等函数定义在Object类，而不是Thread类中的原因。","tags":"java 多线程"},{"title":"排序算法 - 耐心排序","url":"/posts/de5a6680.html","text":"基本思想耐心排序充分集合了桶排序和插入排序的优点，首先使用桶排序，排序之后每个桶中数据相对有序，这样再使用插入排序，简化了问题，速度变的更快。 建桶规则:如果没有桶,新建一个桶;如果不符合入桶规则那么新建一个桶。 入桶规则:只要比桶里最上边的数字小即可入桶,如果有多个桶可入,那么按照从左到右的顺序入桶即可。 举个例子：待排序数组[6 4 5 1 8 7 2 3] 第一步：因为此前还没有桶，则建立一个桶，我们命名为桶1,从上面取出第一个数字 6，然后将6放入到桶中。 第二步：我们使用第二个值4，然后遍历现有的桶，遍历的工程中先遇到桶1，我们发现桶1中最上面的元素是6,4比6大，则6下沉，有桶【4,6】。 第三步：我们使用第三个值5，然后遍历现有的桶，因为第一个桶第一个元素是4，比5小，所以重新开一个桶【5】，之后共有两个桶【4,5】【5】。 第四部：我们使用第四个值1，然后遍历现有的桶，因为第一个桶第一个元素是4，比1大，所以放到桶1【4,6】最前面，从而形成【1,4,6】【5】。 第五步：我们使用第五个元素，然后遍历现有的桶，第一个桶第一个元素是1，第二个桶第一个元素是5，都比8小，所以需要重新开一个桶【8】，此时共有桶【1,4,6】【5】【8】。 第六步：使用同样的方法，之后桶是【1,4,6】【5】【7，8】。 第七步：使用同样的方法，之后桶是【1,4,6】【2，5】【7，8】。 第八步：使用同样的方法，之后桶是【1,4,6】【2，5】【3，7，8】。 注意：遍历的数组，只跟各个桶的第一个元素做比较，这样保证各个桶元素有序。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package main.java.com.study.sortingAalgorithm;import main.java.com.study.utils.CommonUtils;import java.util.ArrayList;import java.util.List;/** * @author: whb * @description: 耐心排序 */public class PatienceSort &#123; public static int[] patienceSort(int[] unsorted) &#123; List new_list = new ArrayList(); for (int i = 0; i &lt; unsorted.length; i++) &#123; List bucket_list = new ArrayList(); if (i == 0) &#123; bucket_list.add(unsorted[i]); new_list.add(bucket_list); &#125; else &#123; boolean is_ok = false; for (int j = 0; j &lt; new_list.size(); j++) &#123; if (unsorted[i] &lt; (int) ((List) new_list.get(j)).get(0)) &#123; ((List) new_list.get(j)).add(0, unsorted[i]); is_ok = true; break; &#125; &#125; if (!is_ok) &#123; bucket_list.add(unsorted[i]); new_list.add(bucket_list); &#125; &#125; &#125; //多维数组变成单维数组 int[] ok_list = new int[unsorted.length]; int q = 0; for (int m = 0; m &lt; new_list.size(); m++) &#123; for (int n = 0; n &lt; ((List) new_list.get(m)).size(); n++) &#123; ok_list[q] = (int) ((List) new_list.get(m)).get(n); q++; &#125; &#125; //插入循环 //将数组的长度赋给n是为了防止每次for循环中判断时都调用length方法影响性能 int n = ok_list.length; //用于中转数据 int tmp; int j; //排序的次数 for (int i = 1; i &lt; n; i++) &#123; tmp = ok_list[i]; //取i前面的所有跟i位置元素进行比较，先比较i-1和i，如果i-1大于i，则互换位置，i-1和i-2比较，以此类推 for (j = i - 1; j &gt;= 0 &amp;&amp; ok_list[j] &gt; tmp; j--) &#123; ok_list[j + 1] = ok_list[j]; &#125; ok_list[j + 1] = tmp; &#125; return ok_list; &#125; public static void main(String[] args) &#123; int[] unsorted = &#123;6, 4, 5, 1, 8, 7, 2, 3&#125;; System.out.println(\"**************耐心排序******************\"); System.out.println(\"排序前：\"); CommonUtils.display(unsorted); System.out.println(\"排序后：\"); int[] sorted = patienceSort(unsorted); CommonUtils.display(sorted); &#125;&#125; 测试结果","tags":"java 算法"},{"title":"排序算法 - 计数排序","url":"/posts/4531d6c3.html","text":"基本思想计数排序是一种非基于比较的排序算法，其空间复杂度和时间复杂度均为O(n+k)，其中k是整数的范围。基于比较的排序算法时间复杂度最小是O(nlogn)的。该算法于1954年由 Harold H. Seward 提出。 计数排序的核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。 算法步骤 花O(n)的时间扫描一下整个序列 A，获取最小值 min 和最大值 max。 开辟一块新的空间创建新的数组 B，长度为 ( max - min + 1)。 数组 B 中 index 的元素记录的值是 A 中某元素出现的次数。 最后输出目标整数序列，具体的逻辑是遍历数组 B，输出相应元素以及对应的个数。 算法演示 算法演示说明 首先，扫描一下整个序列。 获得最小值为 2 ，最大值为 7。 新建数组包含 2~7 的元素。 再次扫描序列，将序列的值放置在新建数组中。 扫描数字 5，数组中 index 为 3 的值为 5，次数为 1。 扫描数字 3，数组中 index 为 1 的值为 3，次数为 1。 扫描数字 4，数组中 index 为 2 的值为 4，次数为 1。 扫描数字 7，数组中 index 为 5 的值为 7，次数为 1。 扫描数字 2，数组中 index 为 0 的值为 2，次数为 1。 扫描数字 4，数组中 index 为 2 的值为 4，次数为 2。 扫描数字 3，数组中 index 为 1 的值为 3，次数为 2。 按照这种节奏，扫描结束后，新建数组中存放了整个序列以及每个数字出现的次数。 最后输出目标整数序列。 输出数字 2，同时数组中 index 为 0 的值为 2 的元素次数变为 0。 输出数字 3，同时数组中 index 为 1 的值为 3 的元素次数变为 1。 同样的操作，整个序列就完全输出了。 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package main.java.com.study.sortingAalgorithm;import main.java.com.study.utils.CommonUtils;import java.util.Arrays;/** * @author: whb * @description: 计数排序 */public class CountingSort &#123; public static int[] countingSort(int[] unsorted) &#123; //开始声明桶,找到数组的最小值和最大值 int minNum = unsorted[0]; int maxNum = unsorted[0]; for (int i = 0; i &lt; unsorted.length; i++) &#123; if (unsorted[i] &lt; minNum) &#123; minNum = unsorted[i]; &#125; if (unsorted[i] &gt; maxNum) &#123; maxNum = unsorted[i]; &#125; &#125; System.out.println(\"最小数字为:\" + minNum); System.out.println(\"最大数字位:\" + maxNum); //找到最大最小值的之后,就开始声明有序桶,桶的初始位代表的值为minNum最大值为maxNum //数组的长度为(maxNum-minNum+1) int[] bucket = new int[(maxNum - minNum + 1)]; //声明了有序桶之后,开始对数字进行放桶操作 for (int j = 0; j &lt; unsorted.length; j++) &#123; //因为是找到了待排序数组的最小值minNum,所以,与数组数组比较的值应为(j+minNum) //如果遍历的值大小与数组代表的数字大小相等,则放入 //j次循环得到的数字是tempArray[j],则存储到下标为tempArray[j]+minNum的桶中 bucket[unsorted[j] - minNum] = bucket[unsorted[j] - minNum] + 1; &#125; //将得到的桶排序结果进行输出,输出的是桶排序的数组的下标 //可以声明新数组对该序列进行存储 int[] sorted = new int[unsorted.length]; int count = 0; for (int k = 0; k &lt; bucket.length; k++) &#123; if (bucket[k] != 0) &#123; //桶里装的值可能不是1,所以,在不等于一的时候,对桶里面的数字进行遍历存储 if (bucket[k] != 1) &#123; for (int z = 0; z &lt; bucket[k]; z++) &#123; sorted[count] = k + minNum; count++; &#125; &#125; else &#123; sorted[count] = k + minNum; count++; &#125; &#125; &#125; return sorted; &#125; public static void main(String[] args) &#123; //产生随机待排序列 int[] unsorted = new int[(int) (Math.random() * 11) + 5]; for (int i = 0; i &lt; unsorted.length; i++) &#123; unsorted[i] = (int) (Math.random() * 100); &#125; System.out.println(\"**************计数排序******************\"); System.out.println(\"排序前：\"); CommonUtils.display(unsorted); System.out.println(\"排序后：\"); int[] sorted = countingSort(unsorted); CommonUtils.display(sorted); &#125;&#125; 测试结果","tags":"java 算法"},{"title":"排序算法 - 鸽巢排序","url":"/posts/d7da214b.html","text":"基本思想鸽巢排序是桶排序的一种，顾名思义，就是一排鸽巢，看里面有几个鸽巢，然后遍历这些鸽巢，打印出来就好，排序之前得先知道区间和最大值。 比如有数组a = [2,7,5,9,8,8]，我们需要对这个数组进行排序，这是一个最大值不超过10的数组，那么我们定区间为0-10，定义一个下标0-10这样一个11位数组b,初始化值为0。然后遍历已知数组a，通过a的一项一项的值和我们定义的数组b的下标进行对应。 遍历开始： 取a[0]=2，然后操作b[2]=1 取a[1]=7，然后操作b[7]=1 取a[2]=5，然后操作b[5]=1 取a[3]=9，然后操作b[9]=1 取a[4]=8，然后操作b[8]=1 取a[5]=8，然后操作b[8]=2（注意了哦） 这样就对号入座了，之后遍历b，如果b中某个小标对应的值是多个，则遍历多次，把不是0的给打印出来，结果就是我们想要的了 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546package main.java.com.study.sortingAalgorithm;import main.java.com.study.utils.CommonUtils;/** * @author: whb * @description: 鸽巢排序 * 原理类似桶排序,同样需要一个很大的鸽巢[桶排序里管这个叫桶,名字无所谓] * 鸽巢其实就是数组,数组的索引位置就表示值,该索引位置的值表示出现次数,如果全部为1次或0次那就是桶排序 * 例如 * int[] pigeonHole = new int[100]; * pigeonHole[0]的值表示0的出现次数... * pigeonHole[1]的值表示1的出现次数... * pigeonHole[2]的值表示2的出现次数... */public class PigeonholeSort &#123; /** * 鸽巢排序 * * @param unsorted 待排序列 * @param maxNumber 最大数 * @return */ public static int[] pigeonholeSort(int[] unsorted, int maxNumber) &#123; int[] pogeonHole = new int[maxNumber + 1]; for (int item : unsorted) &#123; pogeonHole[item]++; &#125; return pogeonHole; &#125; public static void main(String[] args) &#123; int[] unsorted = &#123;99, 65, 24, 47, 47, 50, 99, 88, 66, 33, 66, 67, 31, 18, 24&#125;; System.out.println(\"**************鸽巢排序******************\"); System.out.println(\"排序前：\"); CommonUtils.display(unsorted); int[] sorted = pigeonholeSort(unsorted, 99); System.out.println(\"排序后：\"); for (int i = 0; i &lt; sorted.length; i++) &#123; for (int j = 0; j &lt; sorted[i]; j++) &#123; System.out.print(i + \" \"); &#125; &#125; &#125;&#125; 测试结果","tags":"java 算法"},{"title":"排序算法 - 基数排序","url":"/posts/ed3439ee.html","text":"基本思想基数排序过程无须比较关键字，而是通过“分配”和“收集”过程来实现排序。它们的时间复杂度可达到线性阶：O(n)。 实例扑克牌中52张牌，可按花色和面值分成两个字段，其大小关系为： 花色： 梅花&lt; 方块&lt; 红心&lt; 黑心 面值： 2 &lt; 3 &lt; 4 &lt; 5 &lt; 6 &lt; 7 &lt; 8 &lt; 9 &lt; 10 &lt; J &lt; Q &lt; K &lt; A若对扑克牌按花色、面值进行升序排序，得到如下序列： 即两张牌，若花色不同，不论面值怎样，花色低的那张牌小于花色高的，只有在同花色情况下，大小关系才由面值的大小确定。这就是多关键码排序。为得到排序结果，我们讨论两种排序方法。方法1：先对花色排序，将其分为4 个组，即梅花组、方块组、红心组、黑心组。再对每个组分别按面值进行排序，最后，将4 个组连接起来即可。方法2：先按13 个面值给出13 个编号组(2 号，3 号，…，A 号)，将牌按面值依次放入对应的编号组，分成13 堆。再按花色给出4 个编号组(梅花、方块、红心、黑心)，将2号组中牌取出分别放入对应花色组，再将3 号组中牌取出分别放入对应花色组，……，这样，4 个花色组中均按面值有序，然后，将4 个花色组依次连接起来即可。设n 个元素的待排序列包含d 个关键码{k1，k2，…，kd}，则称序列对关键码{k1，k2，…，kd}有序是指：对于序列中任两个记录r[i]和rj都满足下列有序关系： 其中k1 称为最主位关键码，kd 称为最次位关键码。 两种多关键码排序方法多关键码排序按照从最主位关键码到最次位关键码或从最次位到最主位关键码的顺序逐次排序，分两种方法： 最高位优先(Most Significant Digit first)法，简称MSD 法： 1）先按k1 排序分组，将序列分成若干子序列，同一组序列的记录中，关键码k1 相等。 2）再对各组按k2 排序分成子组，之后，对后面的关键码继续这样的排序分组，直到按最次位关键码kd 对各子组排序后。 3）再将各组连接起来，便得到一个有序序列。扑克牌按花色、面值排序中介绍的方法一即是MSD 法。 最低位优先(Least Significant Digit first)法，简称LSD 法： 1) 先从kd 开始排序，再对kd-1进行排序，依次重复，直到按k1排序分组分成最小的子序列后。 2) 最后将各个子序列连接起来，便可得到一个有序的序列, 扑克牌按花色、面值排序中介绍的方法二即是LSD 法。基于LSD方法的链式基数排序的基本思想 “多关键字排序”的思想实现“单关键字排序”。对数字型或字符型的单关键字，可以看作由多个数位或多个字符构成的多关键字，此时可以采用“分配-收集”的方法进行排序，这一过程称作基数排序法，其中每个数字或字符可能的取值个数称为基数。比如，扑克牌的花色基数为4，面值基数为13。在整理扑克牌时，既可以先按花色整理，也可以先按面值整理。按花色整理时，先按红、黑、方、花的顺序分成4摞（分配），再按此顺序再叠放在一起（收集），然后按面值的顺序分成13摞（分配），再按此顺序叠放在一起（收集），如此进行二次分配和收集即可将扑克牌排列有序。基数排序:是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。基数排序基于分别排序，分别收集，所以是稳定的。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130package main.java.com.study.sortingAalgorithm;import main.java.com.study.utils.CommonUtils;/** * @author: whb * @description: 基数排序：过程无须比较关键字，而是通过“分配”和“收集”过程来实现排序。 * 平均O(d(n+r)),最好O(d(n+r)),最坏O(d(n+r));空间复杂度O(n+r);稳定;较复杂 * d为位数,r为分配后链表的个数 */public class RadixSort &#123; /** * 基数排序 * * @param unsorted 待排数组 * @param max 最大几位数 */ public static void radixSort(int[] unsorted, int max) &#123; //count数组用来计数 int[] count = new int[unsorted.length]; //bucket用来当桶，放数据，取数据 int[] bucket = new int[unsorted.length]; //k表示第几位，1代表个位，2代表十位，3代表百位 for (int k = 1; k &lt;= max; k++) &#123; //把count置空，防止上次循环的数据影响 for (int i = 0; i &lt; unsorted.length; i++) &#123; count[i] = 0; &#125; //分别统计第k位是0,1,2,3,4,5,6,7,8,9的数量 //以下便称为桶 //即此循环用来统计每个桶中的数据的数量 for (int i = 0; i &lt; unsorted.length; i++) &#123; count[getFigure(unsorted[i], k)]++; &#125; //利用count[i]来确定放置数据的位置 for (int i = 1; i &lt; unsorted.length; i++) &#123; count[i] = count[i] + count[i - 1]; &#125; //执行完此循环之后的count[i]就是第i个桶右边界的位置 //利用循环把数据装入各个桶中，注意是从后往前装 for (int i = unsorted.length - 1; i &gt;= 0; i--) &#123; int j = getFigure(unsorted[i], k); bucket[count[j] - 1] = unsorted[i]; count[j]--; &#125; //将桶中的数据取出来，赋值给unsorted for (int i = 0, j = 0; i &lt; unsorted.length; i++, j++) &#123; unsorted[i] = bucket[j]; &#125; &#125; &#125; /** * 返回整型数num的第pos位是什么 * * @param num 整数num * @param pos pos=1表示个位，pos=2表示十位 * @return */ public static int getFigure(int num, int pos) &#123; int tmp = 1; for (int i = 0; i &lt; pos - 1; i++) &#123; tmp *= 10; &#125; return (num / tmp) % 10; &#125; /** * 二维数组的方式实现基数排序 * * @param unsorted 待排序列 * @param arr_x 最大数字不超过999999999...(array_x个9) * @param arr_y 最大位数 */ public static void radix_sort(int[] unsorted, int arr_x, int arr_y) &#123; for (int i = 0; i &lt; arr_x; i++) &#123; int[][] bucket = new int[arr_x][arr_y]; //分配 for (int item : unsorted) &#123; int temp = (item / (int) Math.pow(10, i)) % 10; for (int j = 0; j &lt; arr_y; j++) &#123; if (bucket[temp][j] == 0) &#123; bucket[temp][j] = item; break; &#125; &#125; &#125; //收集 for (int o = 0, x = 0; x &lt; arr_x; x++) &#123; for (int y = 0; y &lt; arr_y; y++) &#123; if (bucket[x][y] == 0) &#123; continue; &#125; unsorted[o++] = bucket[x][y]; &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; //定义待排整型数组 int[] arr = &#123;21, 56, 88, 195, 354, 1, 35, 12, 6, 7&#125;; System.out.println(\"**************基数排序******************\"); System.out.println(\"排序前：\"); CommonUtils.display(arr); //调用基数排序函数 radixSort(arr, 3); System.out.println(\"排序后：\"); //输出排序后的数组 CommonUtils.display(arr); System.out.println(\" \"); int[] unsorted = &#123;999999999, 65, 24, 47, 13, 50, 92, 88, 66, 33, 22445, 10001, 624159, 624158, 624155501&#125;; System.out.println(\"**************二维数组方式实现的基数排序******************\"); System.out.println(\"排序前：\"); CommonUtils.display(unsorted); radix_sort(unsorted, 10, 100); System.out.println(\"排序后：\"); for (int tmp : unsorted) &#123; if (tmp &gt; 0) &#123; System.out.print(tmp + \" \"); &#125; &#125; &#125;&#125; 测试结果","tags":"java 算法"},{"title":"哆啦A梦","url":"/posts/9a1a736f.html","text":"代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=\"utf-8\"/&gt; &lt;title&gt;哆啦A梦&lt;/title&gt; &lt;style&gt; body &#123; margin: 0; padding: 0; &#125; #doraemon &#123; background-color: #fff; display: block; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body onmousemove=\"zuobiao(event)\"&gt;&lt;canvas id=\"doraemon\" width=\"400\" height=\"600\"&gt;&lt;/canvas&gt;&lt;div id=\"put\" style=\"width: 50px\" height=\"20px\"&gt;&lt;/div&gt;&lt;script&gt; window.onload = function () &#123; var cxt = document.getElementById('doraemon').getContext('2d'); /* 头部*/ cxt.beginPath();//起始路径 cxt.lineWidth = 1;//线宽度为1 cxt.strokeStyle = '#000';//笔触的颜色 cxt.arc(200, 175, 175, 0.7 * Math.PI, 0.3 * Math.PI);//绘制弧，中心点（200，175），半径175 cxt.fillStyle = '#0bb0da';//设置填充时的颜色 cxt.fill();//填充颜色 cxt.stroke();//绘制路径 /*脸部*/ cxt.beginPath(); cxt.fillStyle = '#fff'; cxt.moveTo(110, 110);//将路径移到点（110，110），不创建线条 cxt.quadraticCurveTo(-10, 200, 120, 315);//创建二次贝塞尔曲线,控制点(-10,200),结束点(120,315) cxt.lineTo(280, 315);//添加一个新点，然后在画布中创建从（110，110）到（280，315）的线条 cxt.quadraticCurveTo(410, 210, 290, 110); cxt.lineTo(110, 110); cxt.fill(); cxt.stroke(); /*眼睛*/ cxt.beginPath(); cxt.lineWidth = 1; cxt.fillStyle = '#fff'; cxt.moveTo(110, 110); cxt.bezierCurveTo(110, 25, 200, 25, 200, 100);//创建三次贝塞尔曲线,控制点1(110,25),控制点2(200,25),结束点(200,100)，也就是画左上半椭圆 cxt.bezierCurveTo(200, 175, 110, 175, 110, 100);//画左下半椭圆 cxt.moveTo(200, 100); cxt.bezierCurveTo(200, 25, 290, 25, 290, 100); cxt.bezierCurveTo(290, 175, 200, 175, 200, 100); cxt.fill(); cxt.stroke(); /*右眼球*/ cxt.beginPath(); cxt.fillStyle = '#000'; cxt.arc(230, 130, 12, 0, 2 * Math.PI); cxt.fill(); cxt.stroke(); /*左眼球*/ cxt.beginPath(); cxt.fillStyle = '#000'; cxt.arc(170, 130, 12, 0, 2 * Math.PI); cxt.fill(); cxt.stroke(); /* 鼻子*/ cxt.beginPath(); cxt.arc(200, 165, 25, 0, 2 * Math.PI); cxt.fillStyle = '#d05823'; cxt.fill(); cxt.stroke(); /*胡须*/ //左胡须 cxt.beginPath(); cxt.moveTo(80, 175); cxt.lineTo(150, 195); cxt.moveTo(80, 200); cxt.lineTo(150, 205); cxt.moveTo(80, 225); cxt.lineTo(150, 215); //中部胡须 cxt.moveTo(200, 195); cxt.lineTo(200, 290); //右胡须 cxt.moveTo(250, 195); cxt.lineTo(320, 175); cxt.moveTo(250, 205); cxt.lineTo(320, 200); cxt.moveTo(250, 215); cxt.lineTo(320, 225); cxt.stroke(); /*嘴*/ cxt.moveTo(80, 240); cxt.quadraticCurveTo(200, 350, 320, 240); cxt.stroke(); /*围巾*/ cxt.beginPath(); cxt.moveTo(96, 316); cxt.lineTo(305, 316); cxt.lineTo(320, 316); cxt.arcTo(330, 316, 330, 326, 10);//在画布上创建介于两个切线之间的弧，起点坐标为(330,316),终点坐标为(330,326),半径为10 cxt.lineTo(330, 336); cxt.arcTo(330, 346, 305, 346, 10); cxt.lineTo(81, 346); cxt.arcTo(71, 346, 71, 336, 10); cxt.lineTo(71, 326); cxt.arcTo(71, 316, 81, 316, 10); cxt.lineTo(96, 316); cxt.fillStyle = '#b13209'; cxt.fill(); cxt.stroke(); /*下半身*/ cxt.beginPath(); cxt.fillStyle = '#0bb0da'; cxt.moveTo(80, 346); //左衣服 cxt.lineTo(26, 406); cxt.lineTo(65, 440); cxt.lineTo(85, 418); cxt.lineTo(85, 528); cxt.lineTo(185, 528); //右衣服 cxt.lineTo(315, 528); cxt.lineTo(315, 418); cxt.lineTo(337, 440); cxt.lineTo(374, 406); cxt.lineTo(320, 346); cxt.fill(); cxt.stroke(); /*手*/ //左手 cxt.beginPath(); cxt.fillStyle = '#fff'; cxt.arc(37, 433, 30, 0, 2 * Math.PI); cxt.fill(); cxt.stroke(); //右手 cxt.beginPath(); cxt.fillStyle = '#fff'; cxt.arc(363, 433, 30, 0, 2 * Math.PI); cxt.fill(); cxt.stroke(); /*肚*/ cxt.beginPath(); cxt.fillStyle = '#fff'; cxt.arc(200, 400, 91, 1.8 * Math.PI, 1.2 * Math.PI); cxt.fill(); cxt.stroke(); //小口袋 cxt.beginPath(); cxt.fillStyle = '#fff'; cxt.moveTo(130, 394); cxt.lineTo(270, 394); cxt.moveTo(130, 394); cxt.bezierCurveTo(130, 490, 270, 490, 270, 394); cxt.fill(); cxt.stroke(); /*两只脚的空隙*/ cxt.beginPath(); cxt.fillStyle = '#fff'; cxt.arc(200, 529, 20,Math.PI, 0); cxt.fill(); cxt.stroke(); /*脚*/ //左脚 cxt.beginPath(); cxt.fillStyle='#fff'; cxt.moveTo(180,528); cxt.lineTo(72,528); cxt.bezierCurveTo(52,528,52,558,72,558); cxt.lineTo(180,558); cxt.moveTo(180,558); cxt.bezierCurveTo(200,558,200,528,180,528); cxt.fill(); cxt.stroke(); //右脚 cxt.beginPath(); cxt.fillStyle='#fff'; cxt.moveTo(220,528); cxt.lineTo(328,528); cxt.bezierCurveTo(348,528,348,558,328,558); cxt.lineTo(220,558); cxt.moveTo(220,558); cxt.bezierCurveTo(200,558,200,528,220,528); cxt.fill(); cxt.stroke(); &#125;; //显示坐标 function zuobiao(event) &#123; var x = event.clientX; var y = event.clientY; var out = document.getElementById(\"put\"); out.innerHTML = \"x:\" + x + \" y:\" + y; &#125;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 效果","tags":"html js"},{"title":"排序算法 - 归并排序","url":"/posts/9bca323a.html","text":"基本思想归并（Merge）排序法是将两个（或两个以上）有序表合并成一个新的有序表，即把待排序序列分为若干个子序列，每个子序列是有序的。然后再把有序子序列合并为整体有序序列。 算法步骤 申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列 设定两个指针，最初位置分别为两个已经排序序列的起始位置 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置 重复步骤3直到某一指针到达序列尾 将另一序列剩下的所有元素直接复制到合并序列尾 算法流程图 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package main.java.com.study.sortingAalgorithm;import main.java.com.study.utils.CommonUtils;/** * @author: whb * @description: 归并排序 */public class MergeSort &#123; /** * 归并排序（Merge Sort）与快速排序思想类似：将待排序数据分成两部分，继续将两个子部分进行递归的归并排序；然后将已经有序的两个子部分进行合并，最终完成排序。 * 其时间复杂度与快速排序均为O(nlogn)，但是归并排序除了递归调用间接使用了辅助空间栈，还需要额外的O(n)空间进行临时存储。从此角度归并排序略逊于快速排序，但是归并排序是一种稳定的排序算法，快速排序则不然。 * 所谓稳定排序，表示对于具有相同值的多个元素，其间的先后顺序保持不变。对于基本数据类型而言，一个排序算法是否稳定，影响很小，但是对于结构体数组，稳定排序就十分重要。例如对于student结构体按照关键字score进行非降序排序： */ public static void mergeSort(int[] numArr, int[] tempArr, int head, int rear) &#123; if (head &lt; rear) &#123; //取分割位置 int middle = (head + rear) / 2; //递归划分列表的左序列 mergeSort(numArr, tempArr, head, middle); //递归划分列表的右序列 mergeSort(numArr, tempArr, middle + 1, rear); //列表的合并 merge(numArr, tempArr, head, middle + 1, rear); &#125; &#125; /** * 合并操作(列表的两两合并) * * @param numArr * @param tempArr * @param head * @param middle * @param rear */ public static void merge(int[] numArr, int[] tempArr, int head, int middle, int rear) &#123; //左指针尾 int headEnd = middle - 1; //右指针头 int rearStart = middle; //临时表的下标 int tempIndex = head; //列表合并后的长度 int tempLength = rear - head + 1; //先循环两个区间段都没有结束的情况 while ((headEnd &gt;= head) &amp;&amp; (rearStart &lt;= rear)) &#123; //如果发现右序列大，则将此数放入临时列表 if (numArr[head] &lt; numArr[rearStart]) &#123; tempArr[tempIndex++] = numArr[head++]; &#125; else &#123; tempArr[tempIndex++] = numArr[rearStart++]; &#125; &#125; //判断左序列是否结束 while (head &lt;= headEnd) &#123; tempArr[tempIndex++] = numArr[head++]; &#125; //判断右序列是否结束 while (rearStart &lt;= rear) &#123; tempArr[tempIndex++] = numArr[rearStart++]; &#125; //交换数据 for (int i = 0; i &lt; tempLength; i++) &#123; numArr[rear] = tempArr[rear]; rear--; &#125; &#125; public static void main(String[] args) &#123; int[] numArr = &#123;27, 11, 13, 45, 34, 22, 19, 8, 3, 99, 74, 55, 88, 66&#125;; System.out.println(\"**************归并排序******************\"); System.out.println(\"排序前：\"); CommonUtils.display(numArr); System.out.println(\"排序后：\"); mergeSort(numArr, new int[numArr.length], 0, numArr.length - 1); CommonUtils.display(numArr); &#125;&#125; CommonUtils工具类： 12345678910111213141516171819202122package main.java.com.study.utils;/** * @author: whb * @description: 工具类 */public class CommonUtils &#123; /** * 遍历打印 * * @param numArr */ public static void display(int[] numArr) &#123; if (numArr != null &amp;&amp; numArr.length &gt; 0) &#123; for (int num : numArr) &#123; System.out.print(num + \" \"); &#125; &#125; System.out.println(\"\"); &#125;&#125; 测试结果","tags":"java 算法"},{"title":"Java多线程-04之-synchronized关键字","url":"/posts/2965099a.html","text":"synchronized原理在java中，每一个对象有且仅有一个同步锁。这也意味着，同步锁是依赖于对象而存在。当我们调用某对象的synchronized方法时，就获取了该对象的同步锁。例如，synchronized(obj)就获取了“obj这个对象”的同步锁。不同线程对同步锁的访问是互斥的。也就是说，某时间点，对象的同步锁只能被一个线程获取到！通过同步锁，我们就能在多线程中，实现对“对象/方法”的互斥访问。例如，现在有两个线程A和线程B，它们都会访问“对象obj的同步锁”。假设，在某一时刻，线程A获取到“obj的同步锁”并在执行一些操作；而此时，线程B也企图获取“obj的同步锁” —— 线程B会获取失败，它必须等待，直到线程A释放了“该对象的同步锁”之后线程B才能获取到“obj的同步锁”从而才可以运行。 synchronized基本规则 1. 当一个线程访问“某对象”的“synchronized方法”或者“synchronized代码块”时，其他线程对“该对象”的该“synchronized方法”或者“synchronized代码块”的访问将被阻塞。 2. 当一个线程访问“某对象”的“synchronized方法”或者“synchronized代码块”时，其他线程仍然可以访问“该对象”的非同步代码块。 3. 当一个线程访问“某对象”的“synchronized方法”或者“synchronized代码块”时，其他线程对“该对象”的其他的“synchronized方法”或者“synchronized代码块”的访问将被阻塞。 第一条规则当一个线程访问“某对象”的“synchronized方法”或者“synchronized代码块”时，其他线程对“该对象”的该“synchronized方法”或者“synchronized代码块”的访问将被阻塞。 12345678910111213141516171819202122232425262728293031323334package main.java.com.study.thread.synchronizedDemo;/** * @author: whb * @description: 当一个线程访问“某对象”的“synchronized方法”或者“synchronized代码块”时，其他线程对“该对象”的该“synchronized方法”或者“synchronized代码块”的访问将被阻塞。 */public class Demo1_1 &#123; public static void main(String[] args) &#123; // 新建“Runnable对象” Runnable demo = new MyRunable(); // 新建“线程t1”, t1是基于demo这个Runnable对象 Thread t1 = new Thread(demo, \"t1\"); // 新建“线程t2”, t2是基于demo这个Runnable对象 Thread t2 = new Thread(demo, \"t2\"); t1.start(); // 启动“线程t1” t2.start(); // 启动“线程t2” &#125;&#125;class MyRunable implements Runnable &#123; @Override public void run() &#123; synchronized (this) &#123; try &#123; for (int i = 0; i &lt; 5; i++) &#123; // 休眠100ms Thread.sleep(100); System.out.println(Thread.currentThread().getName() + \" loop \" + i); &#125; &#125; catch (InterruptedException ie) &#123; &#125; &#125; &#125;&#125; 运行结果： 12345678910t1 loop 0t1 loop 1t1 loop 2t1 loop 3t1 loop 4t2 loop 0t2 loop 1t2 loop 2t2 loop 3t2 loop 4 结果说明： run()方法中存在“synchronized(this)代码块”，而且t1和t2都是基于”demo这个Runnable对象”创建的线程。这就意味着，我们可以将synchronized(this)中的this看作是“demo这个Runnable对象”；因此，线程t1和t2共享“demo对象的同步锁”。所以，当一个线程运行的时候，另外一个线程必须等待“运行线程”释放“demo的同步锁”之后才能运行。 接下来将上面的代码进行修改，然后再运行看看结果怎么样。修改后的源码如下： 12345678910111213141516171819202122232425262728293031323334353637package main.java.com.study.thread.synchronizedDemo;/** * @author: whb * @description: 当一个线程访问“某对象”的“synchronized方法”或者“synchronized代码块”时，其他线程对“该对象”的该“synchronized方法”或者“synchronized代码块”的访问将被阻塞。 */public class Demo1_2 &#123; public static void main(String[] args) &#123; // 新建“线程t1” Thread t1 = new MyThread(\"t1\"); // 新建“线程t2” Thread t2 = new MyThread(\"t2\"); t1.start(); // 启动“线程t1” t2.start(); // 启动“线程t2” &#125;&#125;class MyThread extends Thread &#123; public MyThread(String name) &#123; super(name); &#125; @Override public void run() &#123; synchronized (this) &#123; try &#123; for (int i = 0; i &lt; 5; i++) &#123; // 休眠100ms Thread.sleep(100); System.out.println(Thread.currentThread().getName() + \" loop \" + i); &#125; &#125; catch (InterruptedException ie) &#123; &#125; &#125; &#125;&#125; 代码说明： 比较Demo1_2 和 Demo1_1后发现，Demo1_2中的MyThread类是直接继承于Thread，而且t1和t2都是MyThread子线程。在“Demo1_2的run()方法”也调用了synchronized(this)，正如“Demo1_1的run()方法”也调用了synchronized(this)一样！那么，Demo1_2的执行流程是不是和Demo1_1一样呢？ 运行结果： 12345678910t1 loop 0t2 loop 0t1 loop 1t2 loop 1t1 loop 2t2 loop 2t1 loop 3t2 loop 3t1 loop 4t2 loop 4 结果说明： synchronized(this)中的this是指“当前的类对象”，即synchronized(this)所在的类对应的当前对象。它的作用是获取“当前对象的同步锁”。对于Demo1_2中，synchronized(this)中的this代表的是MyThread对象，而t1和t2是两个不同的MyThread对象，因此t1和t2在执行synchronized(this)时，获取的是不同对象的同步锁。对于Demo1_1对而言，synchronized(this)中的this代表的是MyRunable对象；t1和t2共同一个MyRunable对象，因此，一个线程获取了对象的同步锁，会造成另外一个线程等待。 第二条规则当一个线程访问“某对象”的“synchronized方法”或者“synchronized代码块”时，其他线程仍然可以访问“该对象”的非同步代码块。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package main.java.com.study.thread.synchronizedDemo;/** * @author: whb * @description: 当一个线程访问“某对象”的“synchronized方法”或者“synchronized代码块”时，其他线程仍然可以访问“该对象”的非同步代码块。 */public class Demo2 &#123; public static void main(String[] args) &#123; final Count count = new Count(); // 新建t1, t1会调用“count对象”的synMethod()方法 Thread t1 = new Thread( new Runnable() &#123; @Override public void run() &#123; count.synMethod(); &#125; &#125;, \"t1\"); // 新建t2, t2会调用“count对象”的nonSynMethod()方法 Thread t2 = new Thread( new Runnable() &#123; @Override public void run() &#123; count.nonSynMethod(); &#125; &#125;, \"t2\"); t1.start(); // 启动t1 t2.start(); // 启动t2 &#125;&#125;class Count &#123; /** * 含有synchronized同步块的方法 */ public void synMethod() &#123; synchronized (this) &#123; try &#123; for (int i = 0; i &lt; 5; i++) &#123; // 休眠100ms Thread.sleep(100); System.out.println(Thread.currentThread().getName() + \" synMethod loop \" + i); &#125; &#125; catch (InterruptedException ie) &#123; &#125; &#125; &#125; /** * 非同步的方法 */ public void nonSynMethod() &#123; try &#123; for (int i = 0; i &lt; 5; i++) &#123; Thread.sleep(100); System.out.println(Thread.currentThread().getName() + \" nonSynMethod loop \" + i); &#125; &#125; catch (InterruptedException ie) &#123; &#125; &#125;&#125; 运行结果： 12345678910t1 synMethod loop 0t2 nonSynMethod loop 0t1 synMethod loop 1t2 nonSynMethod loop 1t1 synMethod loop 2t2 nonSynMethod loop 2t1 synMethod loop 3t2 nonSynMethod loop 3t1 synMethod loop 4t2 nonSynMethod loop 4 结果说明： 主线程中新建了两个子线程t1和t2。t1会调用count对象的synMethod()方法，该方法内含有同步块；而t2则会调用count对象的nonSynMethod()方法，该方法不是同步方法。t1运行时，虽然调用synchronized(this)获取“count的同步锁”；但是并没有造成t2的阻塞，因为t2没有用到“count”同步锁。 第三条规则当一个线程访问“某对象”的“synchronized方法”或者“synchronized代码块”时，其他线程对“该对象”的其他的“synchronized方法”或者“synchronized代码块”的访问将被阻塞。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package main.java.com.study.thread.synchronizedDemo;/** * @author: whb * @description: 当一个线程访问“某对象”的“synchronized方法”或者“synchronized代码块”时，其他线程对“该对象”的其他的“synchronized方法”或者“synchronized代码块”的访问将被阻塞。 */public class Demo3 &#123; public static void main(String[] args) &#123; final Count2 count = new Count2(); // 新建t1, t1会调用“count对象”的synMethod()方法 Thread t1 = new Thread( new Runnable() &#123; @Override public void run() &#123; count.synMethod(); &#125; &#125;, \"t1\"); // 新建t2, t2会调用“count对象”的nonSynMethod()方法 Thread t2 = new Thread( new Runnable() &#123; @Override public void run() &#123; count.nonSynMethod(); &#125; &#125;, \"t2\"); t1.start(); // 启动t1 t2.start(); // 启动t2 &#125;&#125;class Count2 &#123; /** * 含有synchronized同步块的方法 */ public void synMethod() &#123; synchronized (this) &#123; try &#123; for (int i = 0; i &lt; 5; i++) &#123; // 休眠100ms Thread.sleep(100); System.out.println(Thread.currentThread().getName() + \" synMethod loop \" + i); &#125; &#125; catch (InterruptedException ie) &#123; &#125; &#125; &#125; /** * 也包含synchronized同步块的方法 */ public void nonSynMethod() &#123; synchronized (this) &#123; try &#123; for (int i = 0; i &lt; 5; i++) &#123; Thread.sleep(100); System.out.println(Thread.currentThread().getName() + \" nonSynMethod loop \" + i); &#125; &#125; catch (InterruptedException ie) &#123; &#125; &#125; &#125;&#125; 运行结果： 12345678910t1 synMethod loop 0t1 synMethod loop 1t1 synMethod loop 2t1 synMethod loop 3t1 synMethod loop 4t2 nonSynMethod loop 0t2 nonSynMethod loop 1t2 nonSynMethod loop 2t2 nonSynMethod loop 3t2 nonSynMethod loop 4 结果说明： 主线程中新建了两个子线程t1和t2。t1和t2运行时都调用synchronized(this)，这个this是Count对象(count)，而t1和t2共用count。因此，在t1运行时，t2会被阻塞，等待t1运行释放“count对象的同步锁”，t2才能运行。 synchronized方法 和 synchronized代码块“synchronized方法”是用synchronized修饰方法，而 “synchronized代码块”则是用synchronized修饰代码块。 synchronized方法示例: 123public synchronized void foo1() &#123; System.out.println(\"synchronized methoed\");&#125; synchronized代码块示例： 12345public void foo2() &#123; synchronized (this) &#123; System.out.println(\"synchronized methoed\"); &#125;&#125; synchronized代码块中的this是指当前对象。也可以将this替换成其他对象，例如将this替换成obj，则foo2()在执行synchronized(obj)时就获取的是obj的同步锁。 synchronized代码块可以更精确的控制冲突限制访问区域，有时候表现更高效率。下面通过一个示例来演示： 123456789101112131415161718192021222324252627282930313233343536373839404142package main.java.com.study.thread.synchronizedDemo;/** * @author: whb * @description: synchronized代码块可以更精确的控制冲突限制访问区域，有时候表现更高效率。 */public class Demo4 &#123; public synchronized void synMethod() &#123; for (int i = 0; i &lt; 1000000; i++) &#123; ; &#125; &#125; public void synBlock() &#123; synchronized (this) &#123; for (int i = 0; i &lt; 1000000; i++) &#123; ; &#125; &#125; &#125; public static void main(String[] args) &#123; Demo4 demo = new Demo4(); long start, diff; // 获取当前时间(millis) start = System.currentTimeMillis(); // 调用“synchronized方法” demo.synMethod(); // 获取“时间差值” diff = System.currentTimeMillis() - start; System.out.println(\"synMethod() : \" + diff); // 获取当前时间(millis) start = System.currentTimeMillis(); // 调用“synchronized方法块” demo.synBlock(); // 获取“时间差值” diff = System.currentTimeMillis() - start; System.out.println(\"synBlock() : \" + diff); &#125;&#125; (某一次)执行结果： 12synMethod() : 11synBlock() : 3 实例锁 和 全局锁实例锁 – 锁在某一个实例对象上。如果该类是单例，那么该锁也具有全局锁的概念。 实例锁对应的就是synchronized关键字。 全局锁 – 该锁针对的是类，无论实例多少个对象，那么线程都共享该锁。 全局锁对应的就是static synchronized（或者是锁在该类的class或者classloader对象上）。 关于“实例锁”和“全局锁”有一个很形象的例子： 123456pulbic class Something &#123; public synchronized void isSyncA()&#123;&#125; public synchronized void isSyncB()&#123;&#125; public static synchronized void cSyncA()&#123;&#125; public static synchronized void cSyncB()&#123;&#125;&#125; 假设，Something有两个实例x和y。分析下面4组表达式获取的锁的情况。(01) x.isSyncA()与x.isSyncB()(02) x.isSyncA()与y.isSyncA()(03) x.cSyncA()与y.cSyncB()(04) x.isSyncA()与Something.cSyncA() 下面通过四个示例演示进行分析。首先定义Something对象。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package main.java.com.study.thread.synchronizedDemo;/** * @author: whb * @description: Something对象 */public class Something &#123; public synchronized void isSyncA() &#123; try &#123; for (int i = 0; i &lt; 5; i++) &#123; Thread.sleep(100); System.out.println(Thread.currentThread().getName() + \" : isSyncA\"); &#125; &#125; catch (InterruptedException ie) &#123; &#125; &#125; public synchronized void isSyncB() &#123; try &#123; for (int i = 0; i &lt; 5; i++) &#123; Thread.sleep(100); System.out.println(Thread.currentThread().getName() + \" : isSyncB\"); &#125; &#125; catch (InterruptedException ie) &#123; &#125; &#125; public static synchronized void cSyncA() &#123; try &#123; for (int i = 0; i &lt; 5; i++) &#123; Thread.sleep(100); System.out.println(Thread.currentThread().getName() + \" : cSyncA\"); &#125; &#125; catch (InterruptedException ie) &#123; &#125; &#125; public static synchronized void cSyncB() &#123; try &#123; for (int i = 0; i &lt; 5; i++) &#123; Thread.sleep(100); System.out.println(Thread.currentThread().getName() + \" : cSyncB\"); &#125; &#125; catch (InterruptedException ie) &#123; &#125; &#125;&#125; (01) 不能被同时访问。因为isSyncA()和isSyncB()都是访问同一个对象(对象x)的同步锁！ 123456789101112131415161718192021222324252627282930313233package main.java.com.study.thread.synchronizedDemo;/** * @author: whb * @description: 实例锁和全局锁分析示例1 * 不能被同时访问。因为isSyncA()和isSyncB()都是访问同一个对象(对象x)的同步锁！ */public class LockTest1 &#123; Something x = new Something(); Something y = new Something(); /** * 比较(01) x.isSyncA()与x.isSyncB() */ private void test1() &#123; // 新建t11, t11会调用 x.isSyncA() Thread t11 = new Thread( () -&gt; x.isSyncA(), \"t11\"); // 新建t12, t12会调用 x.isSyncB() Thread t12 = new Thread( () -&gt; x.isSyncB(), \"t12\"); t11.start(); // 启动t11 t12.start(); // 启动t12 &#125; public static void main(String[] args) &#123; LockTest1 demo = new LockTest1(); demo.test1(); &#125;&#125; 运行结果： 12345678910t11 : isSyncAt11 : isSyncAt11 : isSyncAt11 : isSyncAt11 : isSyncAt12 : isSyncBt12 : isSyncBt12 : isSyncBt12 : isSyncBt12 : isSyncB (02) 可以同时被访问。因为访问的不是同一个对象的同步锁，x.isSyncA()访问的是x的同步锁，而y.isSyncA()访问的是y的同步锁。 1234567891011121314151617181920212223242526272829303132333435package main.java.com.study.thread.synchronizedDemo;/** * @author: whb * @description: 实例锁和全局锁示例2 * 可以同时被访问。因为访问的不是同一个对象的同步锁，x.isSyncA()访问的是x的同步锁，而y.isSyncA()访问的是y的同步锁。 */public class LockTest2 &#123; Something x = new Something(); Something y = new Something(); /** * 比较(02) x.isSyncA()与y.isSyncA() */ private void test2() &#123; // 新建t21, t21会调用 x.isSyncA() Thread t21 = new Thread( () -&gt; x.isSyncA(), \"t21\"); // 新建t22, t22会调用 x.isSyncB() Thread t22 = new Thread( () -&gt; y.isSyncA(), \"t22\"); t21.start(); // 启动t21 t22.start(); // 启动t22 &#125; public static void main(String[] args) &#123; LockTest2 demo = new LockTest2(); demo.test2(); &#125;&#125; 运行结果： 12345678910t21 : isSyncAt22 : isSyncAt21 : isSyncAt22 : isSyncAt21 : isSyncAt22 : isSyncAt21 : isSyncAt22 : isSyncAt21 : isSyncAt22 : isSyncA (03) 不能被同时访问。因为cSyncA()和cSyncB()都是static类型，x.cSyncA()相当于Something.isSyncA()，y.cSyncB()相当于Something.isSyncB()，因此它们共用一个同步锁，不能被同时反问。 1234567891011121314151617181920212223242526272829303132333435package main.java.com.study.thread.synchronizedDemo;/** * @author: whb * @description: 实例锁和全局锁示例3 * 不能被同时访问。因为cSyncA()和cSyncB()都是static类型，x.cSyncA()相当于Something.isSyncA()，y.cSyncB()相当于Something.isSyncB()，因此它们共用一个同步锁，不能被同时反问。 */public class LockTest3 &#123; Something x = new Something(); Something y = new Something(); /** * 比较(03) x.cSyncA()与y.cSyncB() */ private void test3() &#123; // 新建t31, t31会调用 x.isSyncA() Thread t31 = new Thread( () -&gt; x.cSyncA(), \"t31\"); // 新建t32, t32会调用 x.isSyncB() Thread t32 = new Thread( () -&gt; y.cSyncB(), \"t32\"); t31.start(); // 启动t31 t32.start(); // 启动t32 &#125; public static void main(String[] args) &#123; LockTest3 demo = new LockTest3(); demo.test3(); &#125;&#125; 运行结果： 12345678910t31 : cSyncAt31 : cSyncAt31 : cSyncAt31 : cSyncAt31 : cSyncAt32 : cSyncBt32 : cSyncBt32 : cSyncBt32 : cSyncBt32 : cSyncB (04) 可以被同时访问。因为isSyncA()是实例方法，x.isSyncA()使用的是对象x的锁；而cSyncA()是静态方法，Something.cSyncA()可以理解对使用的是“类的锁”。因此，它们是可以被同时访问的。 1234567891011121314151617181920212223242526272829303132333435package main.java.com.study.thread.synchronizedDemo;/** * @author: whb * @description: 实例锁和全局锁示例4 * 可以被同时访问。因为isSyncA()是实例方法，x.isSyncA()使用的是对象x的锁；而cSyncA()是静态方法，Something.cSyncA()可以理解对使用的是“类的锁”。因此，它们是可以被同时访问的。 */public class LockTest4 &#123; Something x = new Something(); Something y = new Something(); /** * 比较(04) x.isSyncA()与Something.cSyncA() */ private void test4() &#123; // 新建t41, t41会调用 x.isSyncA() Thread t41 = new Thread( () -&gt; x.isSyncA(), \"t41\"); // 新建t42, t42会调用 x.isSyncB() Thread t42 = new Thread( () -&gt; Something.cSyncA(), \"t42\"); t41.start(); // 启动t41 t42.start(); // 启动t42 &#125; public static void main(String[] args) &#123; LockTest4 demo = new LockTest4(); demo.test4(); &#125;&#125; 运行结果： 12345678910t41 : isSyncAt42 : cSyncAt41 : isSyncAt42 : cSyncAt41 : isSyncAt42 : cSyncAt41 : isSyncAt42 : cSyncAt41 : isSyncAt42 : cSyncA","tags":"java 多线程"},{"title":"排序算法 - 奇偶排序","url":"/posts/185015d0.html","text":"基本思想基本思路是奇数列排一趟序,偶数列排一趟序,再奇数排,再偶数排,直到全部有序。 举个例子：待排数组[6 2 4 1 5 9] 第一次比较奇数列,奇数列与它的邻居偶数列比较,如6和2比,4和1比,5和9比。 [6 2 4 1 5 9] 交换后变成 [2 6 1 4 5 9] 第二次比较偶数列,即6和1比,5和5比。 [2 6 1 4 5 9] 交换后变成 [2 1 6 4 5 9] 第三趟又是奇数列,选择的是2,6,5分别与它们的邻居列比较。 [2 1 6 4 5 9] 交换后 [1 2 4 6 5 9] 第四趟偶数列。 [1 2 4 6 5 9] 一次交换 [1 2 4 5 6 9] 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package main.java.com.study.sortingAalgorithm;import main.java.com.study.utils.CommonUtils;/** * @author: whb * @description: 奇偶排序：基本思路是奇数列排一趟序,偶数列排一趟序,再奇数排,再偶数排,直到全部有序 */public class OddEventSort &#123; public static void oddEventSort(int[] unsorted) &#123; int temp; for (int i = unsorted.length - 1; i &gt; unsorted.length / 2 - 1; i--) &#123; //奇数排序 for (int j = 1; j &lt;= i; j += 2) &#123; if (j == unsorted.length - 1) &#123; break; &#125; if (unsorted[j] &gt; unsorted[j + 1]) &#123; temp = unsorted[j]; unsorted[j] = unsorted[j + 1]; unsorted[j + 1] = temp; &#125; &#125; //偶数排序 for (int j = 0; j &lt;= i; j += 2) &#123; if (j == unsorted.length - 1) &#123; break; &#125; if (unsorted[j] &gt; unsorted[j + 1]) &#123; temp = unsorted[j]; unsorted[j] = unsorted[j + 1]; unsorted[j + 1] = temp; &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; int[] unsorted = new int[]&#123;12, 33, 45, 33, 13, 55, 34, 7, 6&#125;; System.out.println(\"**************奇偶排序******************\"); System.out.println(\"排序前：\"); CommonUtils.display(unsorted); System.out.println(\"排序后：\"); oddEventSort(unsorted); CommonUtils.display(unsorted); &#125;&#125; 测试结果","tags":"java 算法"},{"title":"Git学习之~常用命令","url":"/posts/db6149c7.html","text":"git config –global user.name “你的名字” 让你全部的Git仓库绑定你的名字 git config –global user.email “你的邮箱” 让你全部的Git仓库绑定你的邮箱 git init 初始化你的仓库 git add . 把工作区的文件全部提交到暂存区 git add .// 把工作区的文件提交到暂存区 git commit -m “xxx” 把暂存区的所有文件提交到仓库区，暂存区空空荡荡 git remote add origin https://github.com/name/name_cangku.git 把本地仓库与远程仓库连接起来 git push -u origin master 把仓库区的主分支master提交到远程仓库里 git push -u origin &lt;其他分支&gt; 把其他分支提交到远程仓库 git status查看当前仓库的状态 git diff 查看文件修改的具体内容 git log 显示从最近到最远的提交历史 git clone + 仓库地址下载克隆文件 git reset –hard + 版本号 回溯版本，版本号在commit的时候与master跟随在一起 git reflog 显示命令历史 git checkout – 撤销命令，用版本库里的文件替换掉工作区的文件。我觉得就像是Git世界的ctrl + z git rm 删除版本库的文件 git branch 查看当前所有分支 git branch &lt;分支名字&gt; 创建分支 git checkout &lt;分支名字&gt; 切换到分支 git merge &lt;分支名字&gt; 合并分支 git branch -d &lt;分支名字&gt; 删除分支,有可能会删除失败，因为Git会保护没有被合并的分支 git branch -D + &lt;分支名字&gt; 强行删除，丢弃没被合并的分支 git log –graph 查看分支合并图 git merge –no-ff &lt;分支名字&gt; 合并分支的时候禁用Fast forward模式,因为这个模式会丢失分支历史信息 git stash 当有其他任务插进来时，把当前工作现场“存储”起来,以后恢复后继续工作 git stash list 查看你刚刚“存放”起来的工作去哪里了 git stash apply 恢复却不删除stash内容 git stash drop 删除stash内容 git stash pop 恢复的同时把stash内容也删了 git remote 查看远程库的信息，会显示origin，远程仓库默认名称为origin git remote -v 显示更详细的信息 git pull 把最新的提交从远程仓库中抓取下来，在本地合并,和git push相反 git rebase 把分叉的提交历史“整理”成一条直线，看上去更直观 git tag 查看所有标签，可以知道历史版本的tag git tag 打标签，默认为HEAD。比如git tag v1.0 git tag &lt;版本号&gt; 把版本号打上标签，版本号就是commit时，跟在旁边的一串字母数字 git show 查看标签信息 git tag -a -m “&lt;说明&gt;” 创建带说明的标签。-a指定标签名，-m指定说明文字 git tag -d 删除标签 git push origin 推送某个标签到远程 git push origin –tags 一次性推送全部尚未推送到远程的本地标签 git push origin :refs/tags/ 删除远程标签 git config –global color.ui true 让Git显示颜色，会让命令输出看起来更醒目 git add -f 强制提交已忽略的的文件 git check-ignore -v 检查为什么Git会忽略该文件","tags":"git"},{"title":"排序算法 - 快速排序","url":"/posts/71d3e504.html","text":"基本思想 1）选择一个基准元素,通常选择第一个元素或者最后一个元素, 2）如果选择第一个元素作为基准元素，则先从右向左找比基准元素小的元素，再从左向右找比基准元素大的元素，交换这两个元素的位置。（如果选择最后一个元素做基准元素，则先从左向右找）直到找到同一位置，跟基准元素位置交换，第一趟排序就结束。 3）通过一趟排序将记录分割成独立的两部分，其中一部分记录的元素值均比基准元素值小。另一部分记录的元素值比基准值大。 4）此时基准元素在其排好序后的正确位置 5）然后分别对这两部分记录用同样的方法继续进行排序，直到整个序列有序。 算法流程图 快速排序之所比较快，因为相比冒泡排序，每次交换是跳跃式的。每次排序的时候设置一个基准点，将小于等于基准点的数全部放到基准点的左边，将大于等于基准点的数全部放到基准点的右边。这样在每次交换的时候就不会像冒泡排序一样每次只能在相邻的数之间进行交换，交换的距离就大的多了。因此总的比较和交换次数就少了，速度自然就提高了。当然在最坏的情况下，仍可能是相邻的两个数进行了交换。因此快速排序的最差时间复杂度和冒泡排序是一样的都是O(N2)，它的平均时间复杂度为O(NlogN)。 代码如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103package main.java.com.study.sortingAalgorithm;import main.java.com.study.utils.CommonUtils;/** * @author: whb * @description: 快速排序 */public class QuickSort &#123; /** * 快速排序的基本思想是，通过一趟排序将待排记录分割成独立的两部分，其中一部分记录的关键字均比另一部分记录的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。 * &lt;p&gt; * 一趟快速排序（或一次划分）的过程如下：首先任意选取一个记录（通常可选第一个记录）作为枢轴（或支点）（pivot），然后按下列原则重新排列其余记录：将所有关键字比它小的记录都安置在它的位置之前，将所有关键字比它大的记录都安置在它的位置之后。 * &lt;p&gt; * 经过一趟快速排序之后，以该枢轴记录最后所落的位置i作分界线，将序列分割成两个子序列，之后再分别对分割所得的两个子序列进行快速排序。 * &lt;p&gt; * 可以看出这个算法可以递归实现，可以用一个函数来实现划分，并返回分界位置。然后不断地这么分下去直到排序完成，可以看出函数的输入参数需要提供序列的首尾位置。 */ public static void quickSort(int[] numArr, int left, int right) &#123; //不管使用哪种分割方式，都可以通过递归形式进行排序 // 需要注意的是这个if语句不能少，不然没法停止，会导致堆栈溢出的异常。 if (left &lt; right) &#123; //分割数组，找到分割点 int point = partitionTwo(numArr, left, right); //递归调用，对左子数组进行快速排序 quickSort(numArr, left, point - 1); //递归调用，对右子数组进行快速排序 quickSort(numArr, point + 1, right); &#125; &#125; /** * 划分实现1 （枢轴跳来跳去法） * 一趟快速排序的实现：设两个指针left和right，设枢轴记录的关键字为first，则首先从right所指位置起向前搜索找到第一个关键字小于first的记录和枢轴记录互相交换， * 然后从left所指位置起向后搜索，找到第一个关键字大于first的记录和枢轴记录互相交换，重复这两步直至left==right为止。 */ public static int partitionOne(int[] numArr, int left, int right) &#123; //用数组的第一个元素做基准元素 int first = numArr[left]; while (left &lt; right) &#123; while (left &lt; right &amp;&amp; numArr[right] &gt;= first) &#123; right--; &#125; //交换 swap(numArr, left, right); while (left &lt; right &amp;&amp; numArr[left] &lt;= first) &#123; left++; &#125; //交换 swap(numArr, left, right); &#125; //返回分割点所在的位置 return left; &#125; /** * 划分实现2 （枢轴一次到位法） * partitionOne实现可以看出，枢轴元素（即最开始选的“中间”元素（其实往往是拿第一个元素作为“中间”元素））需要不断地和其他元素交换位置，而每交换一次位置实际上需要三次赋值操作。 * &lt;p&gt; * 实际上，只有最后left=right的位置才是枢轴元素的最终位置，所以可以先将枢轴元素保存起来，排序过程中只作元素的单向移动，直至一趟排序结束后再将枢轴元素移至正确的位置上。 * * @return */ public static int partitionTwo(int[] numArr, int left, int right) &#123; int first = numArr[left]; int temp = numArr[left]; while (left &lt; right) &#123; while (left &lt; right &amp;&amp; numArr[right] &gt;= first) &#123; right--; &#125; numArr[left] = numArr[right]; while (left &lt; right &amp;&amp; numArr[left] &lt;= first) &#123; left++; &#125; numArr[right] = numArr[left]; &#125; numArr[left] = temp; return left; &#125; /** * 交换数组中两个位置的元素 */ public static void swap(int[] numArr, int left, int right) &#123; int temp = 0; if (numArr != null &amp;&amp; numArr.length &gt; 0) &#123; temp = numArr[left]; numArr[left] = numArr[right]; numArr[right] = temp; &#125; &#125; public static void main(String[] args) &#123; int[] numArr = &#123;27, 11, 13, 45, 34, 22, 19, 8, 3, 99, 74, 55, 88, 66&#125;; System.out.println(\"**************快速排序******************\"); System.out.println(\"排序前：\"); CommonUtils.display(numArr); System.out.println(\"排序后：\"); quickSort(numArr, 0, numArr.length - 1); CommonUtils.display(numArr); &#125;&#125; CommonUtils工具类： 12345678910111213141516171819202122package main.java.com.study.utils;/** * @author: whb * @description: 工具类 */public class CommonUtils &#123; /** * 遍历打印 * * @param numArr */ public static void display(int[] numArr) &#123; if (numArr != null &amp;&amp; numArr.length &gt; 0) &#123; for (int num : numArr) &#123; System.out.print(num + \" \"); &#125; &#125; System.out.println(\"\"); &#125;&#125; 测试结果","tags":"java 算法"},{"title":"排序算法 - 冒泡排序","url":"/posts/9ab57c2f.html","text":"基本思想在要排序的一组数中，对当前还未排好序的范围内的全部数，自上而下对相邻的两个数依次进行比较和调整，让较大的数往下沉，较小的往上冒。即：每当两相邻的数比较后发现它们的排序与排序要求相反时，就将它们互换。 算法步骤 比较相邻的元素。如果第一个比第二个大，就交换他们两个。 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数。 针对所有的元素重复以上的步骤，除了最后一个。 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 算法流程图 算法改进对冒泡排序常见的改进方法是加入一标志性变量exchange，用于标志某一趟排序过程中是否有数据交换，如果进行某一趟排序时并没有进行数据交换，则说明数据已经按要求排列好，可立即结束排序，避免不必要的比较过程。 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package main.java.com.study.sortingAalgorithm;import main.java.com.study.utils.CommonUtils;/** * @author: whb * @description: 冒泡排序 */public class BubbleSort &#123; /** * 冒泡排序的过程很简单，就是不断比较相邻两个元素的大小关系，若逆序则交换，这样通过一轮比较，关子健最大的记录就沉底了。 * 一般地，第i趟冒泡排序从第一个元素起到第n-i+1个元素依次比较相邻两个记录的关键字，并在逆序时交换相邻记录，其结果就是这n-i+1个记录中关键字最大的记录被交换到n-i+1的位置上。 * 当然也可以反过来，从后往前进行，这样每经过一趟排序，就把未排序的序列中最小的元素放在它应当处于的位置上，然后下次比较就不再让前面的元素参与了。 * 整个排序过程需要进行k趟冒泡排序，其中k至少为1，至多为n-1次，如果一趟冒泡排序中没有出现交换元素的操作，则说明序列已经有序了，可以停止排序了。 * 时间复杂度：正序时O(n)， 逆序时O(n2)，平均时间复杂性O(n2)。使用temp 作为临时交换变量，空间复杂度为 O(1). * &lt;p&gt; * 一般情况下貌似效率不及直接插入排序（尽管它们的平均时间复杂度都是O(n2)）。 */ public static void bubbleSort(int[] numArr) &#123; int length = numArr.length; //最多length-1次排序 for (int i = 0; i &lt; length; i++) &#123; //每一轮多少元素参与排序 for (int j = 0; j &lt; length - 1 - i; j++) &#123; if (numArr[j] &gt; numArr[j + 1]) &#123; /** * 交换顺序，不使用临时变量，利用 * a = a + b; * b = a - b; * a = a - b; */ numArr[j] = numArr[j] + numArr[j + 1]; numArr[j + 1] = numArr[j] - numArr[j + 1]; numArr[j] = numArr[j] - numArr[j + 1]; &#125; &#125; &#125; &#125; /** * 改进版冒泡：当某趟排序没有元素交换的时候，证明整个序列有序，无需再循环比较 * * @param numArr */ public static void bubbleSortImprove(int[] numArr) &#123; int length = numArr.length; //设置标志变量，这样当序列有序时及时退出循环，避免冗余处理。 boolean sorted = false; //最多length-1次排序 for (int i = 0; i &lt; length; i++) &#123; sorted = true; //每一轮多少元素参与排序 for (int j = 0; j &lt; length - 1 - i; j++) &#123; if (numArr[j] &gt; numArr[j + 1]) &#123; /** * 交换顺序，不使用临时变量，利用 * a = a + b; * b = a - b; * a = a - b; */ numArr[j] = numArr[j] + numArr[j + 1]; numArr[j + 1] = numArr[j] - numArr[j + 1]; numArr[j] = numArr[j] - numArr[j + 1]; sorted = false; &#125; &#125; if (sorted) &#123; break; &#125; &#125; &#125; public static void main(String[] args) &#123; int[] numArr = &#123;27, 11, 13, 45, 34, 22, 19, 8, 3, 99, 74, 55, 88, 66&#125;; System.out.println(\"**************冒泡排序******************\"); System.out.println(\"排序前：\"); CommonUtils.display(numArr); System.out.println(\"排序后：\"); bubbleSortImprove(numArr); CommonUtils.display(numArr); &#125;&#125; CommonUtils工具类： 12345678910111213141516171819202122package main.java.com.study.utils;/** * @author: whb * @description: 工具类 */public class CommonUtils &#123; /** * 遍历打印 * * @param numArr */ public static void display(int[] numArr) &#123; if (numArr != null &amp;&amp; numArr.length &gt; 0) &#123; for (int num : numArr) &#123; System.out.print(num + \" \"); &#125; &#125; System.out.println(\"\"); &#125;&#125; 测试结果","tags":"java 算法"},{"title":"排序算法 - 堆排序","url":"/posts/1ca0adae.html","text":"堆排序是一种树形选择排序，是对直接选择排序的有效改进。 基本思想堆的定义如下：具有n个元素的序列（k1,k2,…,kn),当且仅当满足 时称之为堆。由堆的定义可以看出，堆顶元素（即第一个元素）必为最小项（小顶堆）。 若以一维数组存储一个堆，则堆对应一棵完全二叉树，且所有非叶结点的值均不大于(或不小于)其子女的值，根结点（堆顶元素）的值是最小(或最大)的。如：（a）大顶堆序列：（96, 83,27,38,11,09)（b）小顶堆序列：（12，36，24，85，47，30，53，91） 初始时把要排序的n个数的序列看作是一棵顺序存储的二叉树（一维数组存储二叉树），调整它们的存储顺序，使之成为一个堆，将堆顶元素输出，得到n 个元素中最小(或最大)的元素，这时堆的根节点的数最小（或者最大）。然后对前面(n-1)个元素重新调整使之成为堆，输出堆顶元素，得到n 个元素中次小(或次大)的元素。依此类推，直到只有两个节点的堆，并对它们作交换，最后得到有n个节点的有序序列。称这个过程为堆排序。因此，实现堆排序需解决两个问题： 如何将n 个待排序的数建成堆； 输出堆顶元素后，怎样调整剩余n-1 个元素，使其成为一个新堆。 首先讨论第二个问题：输出堆顶元素后，对剩余n-1元素重新建成堆的调整过程。 调整小顶堆的方法： 1）设有m 个元素的堆，输出堆顶元素后，剩下m-1 个元素。将堆底元素送入堆顶（（最后一个元素与堆顶进行交换），堆被破坏，其原因仅是根结点不满足堆的性质。 2）将根结点与左、右子树中较小元素的进行交换。 3）若与左子树交换：如果左子树堆被破坏，即左子树的根结点不满足堆的性质，则重复方法 （2）. 4）若与右子树交换，如果右子树堆被破坏，即右子树的根结点不满足堆的性质。则重复方法 （2）. 5）继续对不满足堆性质的子树进行上述交换操作，直到叶子结点，堆被建成。称这个自根结点到叶子结点的调整过程为筛选。如图： 再讨论对n 个元素初始建堆的过程。建堆方法：对初始序列建堆的过程，就是一个反复进行筛选的过程。1）n 个结点的完全二叉树，则最后一个结点是第个结点的子树。2）筛选从第 个结点为根的子树开始，该子树成为堆。3）之后向前依次对各结点为根的子树进行筛选，使之成为堆，直到根结点。如图建堆初始过程：无序序列：（49，38，65，97，76，13，27，49） 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package main.java.com.study.sortingAalgorithm;import main.java.com.study.utils.CommonUtils;/** * @author: whb * @description: 堆排序 */public class HeapSort &#123; /** * 堆排序的是集合了插入排序的单数组操作，又有归并排序的时间复杂度，完美的结合了2者的优点。 */ public static void heapSort(int[] numArr) &#123; //将无序堆构造成一个大根堆，大根堆有length/2个父节点 for (int i = numArr.length / 2 - 1; i &gt;= 0; i--) &#123; headAdjust(numArr, i, numArr.length); &#125; //逐步将每个最大值的根节点与末尾元素交换，并且再调整其为最大堆 for (int i = numArr.length - 1; i &gt; 0; i--) &#123; //将堆顶元素和当前未经排序的子序列的最后一个元素交换位置 swap(numArr, 0, i); headAdjust(numArr, 0, i); &#125; &#125; /** * 构造大根堆 */ public static void headAdjust(int[] numArr, int parent, int length) &#123; //保存当前父节点 int temp = numArr[parent]; //得到左孩子 int leftChild = 2 * parent + 1; while (leftChild &lt; length) &#123; //如果parent有左孩子，则要判断左孩子是否小于右孩子 if (leftChild + 1 &lt; length &amp;&amp; numArr[leftChild] &lt; numArr[leftChild + 1]) &#123; leftChild++; &#125; //如果父节点大于子节点，就不交换 if (temp &gt;= numArr[leftChild]) &#123; break; &#125; //将较大子节点的值赋给父节点 numArr[parent] = numArr[leftChild]; //然后将子节点作为父节点 parent = leftChild; //找到该父节点较小的左孩子 leftChild = 2 * parent + 1; &#125; //最后将temp的值赋给较大的子节点，以形成两值交换 numArr[parent] = temp; &#125; /** * 交换数组中两个位置的元素 */ public static void swap(int[] numArr, int top, int last) &#123; int temp = numArr[top]; numArr[top] = numArr[last]; numArr[last] = temp; &#125; public static void main(String[] args) &#123; int[] numArr = &#123;27, 11, 13, 45, 34, 22, 19, 8, 3, 99, 74, 55, 88, 66&#125;; System.out.println(\"**************堆排序******************\"); System.out.println(\"排序前：\"); CommonUtils.display(numArr); System.out.println(\"排序后：\"); heapSort(numArr); CommonUtils.display(numArr); &#125;&#125; CommonUtils工具类： 12345678910111213141516171819202122package main.java.com.study.utils;/** * @author: whb * @description: 工具类 */public class CommonUtils &#123; /** * 遍历打印 * * @param numArr */ public static void display(int[] numArr) &#123; if (numArr != null &amp;&amp; numArr.length &gt; 0) &#123; for (int num : numArr) &#123; System.out.print(num + \" \"); &#125; &#125; System.out.println(\"\"); &#125;&#125; 测试结果","tags":"java 算法"},{"title":"设计模式--单例模式","url":"/posts/6d67519e.html","text":"单例模式介绍** 意图 **：保证一个类仅有一个实例，并提供一个访问它的全局访问点。 ** 主要解决 **：一个全局使用的类频繁地创建与销毁。 ** 何时使用 **：当您想控制实例数目，节省系统资源的时候。 ** 如何解决 **：判断系统是否已经有这个单例，如果有则返回，如果没有则创建。 ** 关键代码 **：构造函数是私有的。 ** 优点 **： 在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如管理学院首页页面缓存）。 避免对资源的多重占用（比如写文件操作）。 ** 缺点 **：没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。 ** 使用场景 **： 要求生产唯一序列号。 WEB 中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来。 创建的一个对象需要消耗的资源过多，比如 I/O 与数据库的连接等。 注意事项：getInstance() 方法中需要使用同步锁 synchronized (Singleton.class) 防止多线程同时进入造成 instance 被多次实例化。 实现方式饿汉式（静态常量）【可用】** 代码实现 **： 12345678910111213141516171819202122package main.java.com.study.designPatterns.single;/** * @author: whb * @description: 饿汉式（静态常量）【可用】 * 优点：这种写法比较简单，就是在类装载的时候就完成实例化。避免了线程同步问题。 * 缺点：在类装载的时候就完成实例化，没有达到Lazy Loading的效果。如果从始至终从未使用过这个实例，则会造成内存的浪费。 */public class Hungry &#123; //自有永久的对象 private static final Hungry hungry = new Hungry(); //构造器私有化 private Hungry() &#123; System.out.println(\"饿汉式（静态常量）...\"); &#125; public static Hungry getInstance() &#123; return hungry; &#125;&#125; ** 测试类 **： 123456789101112131415161718192021package main.java.com.study.designPatterns.single;/** * @author: whb * @description: 单例模式测试 */public class singletonTest &#123; public static void main(String[] args) &#123; for (int i = 0; i &lt; 10; i++) &#123; int finalI = i; new Thread(() -&gt; &#123; /** * 饿汉式（静态常量）【可用】 */ Hungry hungry = Hungry.getInstance(); System.out.println(\"第\" + (finalI + 1) + \"次获得的hungry对象的hashCode：\" + hungry.hashCode()); &#125;).start(); &#125; &#125;&#125; ** 输出结果 **： 饿汉式（静态代码块）【可用】** 代码实现 **： 12345678910111213141516171819202122232425package main.java.com.study.designPatterns.single;/** * @author: whb * @description: 饿汉式（静态代码块）【可用】 * 将类实例化的过程放在了静态代码块中，也是在类装载的时候，就执行静态代码块中的代码，初始化类的实例。 * 优点：这种写法比较简单，就是在类装载的时候就完成实例化。避免了线程同步问题。 * 缺点：在类装载的时候就完成实例化，没有达到Lazy Loading的效果。如果从始至终从未使用过这个实例，则会造成内存的浪费。 */public class Hungry2 &#123; private static Hungry2 hungry2; static &#123; hungry2 = new Hungry2(); &#125; private Hungry2() &#123; System.out.println(\"饿汉式（静态代码块）...\"); &#125; public static Hungry2 getInstance() &#123; return hungry2; &#125;&#125; ** 测试类 **： 123456789101112131415161718192021package main.java.com.study.designPatterns.single;/** * @author: whb * @description: 单例模式测试 */public class singletonTest &#123; public static void main(String[] args) &#123; for (int i = 0; i &lt; 10; i++) &#123; int finalI = i; new Thread(() -&gt; &#123; /** * 饿汉式（静态代码块）【可用】 */ Hungry2 hungry2 = Hungry2.getInstance(); System.out.println(\"第\" + (finalI + 1) + \"次获得的hungry2对象的hashCode：\" + hungry2.hashCode()); &#125;).start(); &#125; &#125;&#125; ** 输出结果 **： 懒汉式（线程不安全）【不可用】** 代码实现 **： 123456789101112131415161718192021222324package main.java.com.study.designPatterns.single;/** * @author: whb * @description: 懒汉式（线程不安全）【不可用】 * 这种写法起到了Lazy Loading的效果，但是只能在单线程下使用。 * 如果在多线程下，一个线程进入了if (singleton == null)判断语句块，还未来得及往下执行，另一个线程也通过了这个判断语句， * 这时便会产生多个实例。所以在多线程环境下不可使用这种方式。 */public class Lazy &#123; private static Lazy lazy; private Lazy() &#123; System.out.println(\"懒汉式（线程不安全）...\"); &#125; public static Lazy getInstance() &#123; if (lazy == null) &#123; lazy = new Lazy(); &#125; return lazy; &#125;&#125; ** 测试类 **： 123456789101112131415161718192021package main.java.com.study.designPatterns.single;/** * @author: whb * @description: 单例模式测试 */public class singletonTest &#123; public static void main(String[] args) &#123; for (int i = 0; i &lt; 10; i++) &#123; int finalI = i; new Thread(() -&gt; &#123; /** * 懒汉式（线程不安全）【不可用】 */ Lazy lazy = Lazy.getInstance(); System.out.println(\"第\" + (finalI + 1) + \"次获得的lazy对象的hashCode：\" + lazy.hashCode()); &#125;).start(); &#125; &#125;&#125; ** 输出结果 **： 懒汉式(线程安全，同步方法)【不推荐用】** 代码实现 **： 123456789101112131415161718192021222324package main.java.com.study.designPatterns.single;/** * @author: whb * @description: 懒汉式(线程安全，同步方法)【不推荐用】 * 有点：解决了线程不安全问题，做个线程同步就可以了，于是就对getInstance()方法进行了线程同步。 * 缺点：效率太低了，每个线程在想获得类的实例时候，执行getInstance()方法都要进行同步。 * 而其实这个方法只执行一次实例化代码就够了，后面的想获得该类实例，直接return就行了。方法进行同步效率太低要改进。 */public class Lazy2 &#123; private static Lazy2 lazy; private Lazy2() &#123; System.out.println(\"懒汉式(线程安全，同步方法)...\"); &#125; public static synchronized Lazy2 getInstance() &#123; if (lazy == null) &#123; lazy = new Lazy2(); &#125; return lazy; &#125;&#125; ** 测试类 **： 123456789101112131415161718192021package main.java.com.study.designPatterns.single;/** * @author: whb * @description: 单例模式测试 */public class singletonTest &#123; public static void main(String[] args) &#123; for (int i = 0; i &lt; 10; i++) &#123; int finalI = i; new Thread(() -&gt; &#123; /** * 懒汉式(线程安全，同步方法)【不推荐用】 */ Lazy2 lazy2 = Lazy2.getInstance(); System.out.println(\"第\" + (finalI + 1) + \"次获得的lazy2对象的hashCode：\" + lazy2.hashCode()); &#125;).start(); &#125; &#125;&#125; ** 输出结果 **： 懒汉式(线程安全 ， 同步代码块)【不可用】** 代码实现 **： 12345678910111213141516171819202122232425package main.java.com.study.designPatterns.single;/** * @author: whb * @description: 懒汉式(线程安全 ， 同步代码块)【不可用】 * 由于同步方法的同步效率太低，所以摒弃同步方法，改为同步产生实例化的的代码块。 * 但是这种同步并不能起到线程同步的作用。假如一个线程进入了if (singleton == null)判断语句块，还未来得及往下执行，另一个线程也通过了这个判断语句，这时便会产生多个实例。 */public class Lazy3 &#123; private static volatile Lazy3 lazy; private Lazy3() &#123; System.out.println(\"懒汉式(线程安全，同步代码块)...\"); &#125; public static Lazy3 getInstance() &#123; if (lazy == null) &#123; synchronized (Lazy3.class) &#123; lazy = new Lazy3(); &#125; &#125; return lazy; &#125;&#125; ** 测试类 **： 123456789101112131415161718192021package main.java.com.study.designPatterns.single;/** * @author: whb * @description: 单例模式测试 */public class singletonTest &#123; public static void main(String[] args) &#123; for (int i = 0; i &lt; 10; i++) &#123; int finalI = i; new Thread(() -&gt; &#123; /** * 懒汉式(线程安全，同步代码块)【不可用】 */ Lazy3 lazy3 = Lazy3.getInstance(); System.out.println(\"第\" + (finalI + 1) + \"次获得的lazy3对象的hashCode：\" + lazy3.hashCode()); &#125;).start(); &#125; &#125;&#125; ** 输出结果 **： 静态内部类【推荐用】** 代码实现 **： 12345678910111213141516171819202122232425package main.java.com.study.designPatterns.single;/** * @author: whb * @description: 静态内部类【推荐用】 * 这种方式跟饿汉式方式采用的机制类似，但又有不同。两者都是采用了类装载的机制来保证初始化实例时只有一个线程。不同的地方在饿汉式方式是只要Singleton类被装载就会实例化，没有Lazy-Loading的作用，而静态内部类方式在Singleton类被装载时并不会立即实例化，而是在需要实例化时，调用getInstance方法，才会装载SingletonInstance类，从而完成Singleton的实例化。 * &lt;p&gt; * 类的静态属性只会在第一次加载类的时候初始化，所以在这里，JVM帮助我们保证了线程的安全性，在类进行初始化时，别的线程是无法进入的。 * &lt;p&gt; * 优点：避免了线程不安全，延迟加载，效率高。 */public class StaticInnerClass &#123; private StaticInnerClass() &#123; System.out.println(\"静态内部类...\"); &#125; private static class SingletonInstance &#123; private static StaticInnerClass instance = new StaticInnerClass(); &#125; public static StaticInnerClass getInstance() &#123; return SingletonInstance.instance; &#125;&#125; ** 测试类 **： 123456789101112131415161718192021package main.java.com.study.designPatterns.single;/** * @author: whb * @description: 单例模式测试 */public class singletonTest &#123; public static void main(String[] args) &#123; for (int i = 0; i &lt; 10; i++) &#123; int finalI = i; new Thread(() -&gt; &#123; /** * 静态内部类【推荐用】 */ StaticInnerClass staticInnerClass = StaticInnerClass.getInstance(); System.out.println(\"第\" + (finalI + 1) + \"次获得的staticInnerClass对象的hashCode：\" + staticInnerClass.hashCode()); &#125;).start(); &#125; &#125;&#125; ** 输出结果 **： 双重检查【推荐用】** 代码实现 **： 123456789101112131415161718192021222324252627package main.java.com.study.designPatterns.single;/** * @author: whb * @description: 双重检查【推荐用】 * 我们进行了两次if (doubleCheck == null)检查，这样就可以保证线程安全了。这样，实例化代码只用执行一次，后面再次访问时，判断if (doubleCheck == null)，直接return实例化对象。 * 优点：线程安全；延迟加载；效率较高。 */public class DoubleCheck &#123; private static volatile DoubleCheck doubleCheck; private DoubleCheck() &#123; System.out.println(\"双重检查...\"); &#125; public static DoubleCheck getInstance() &#123; if (doubleCheck == null) &#123; synchronized (DoubleCheck.class) &#123; if (doubleCheck == null) &#123; doubleCheck = new DoubleCheck(); &#125; &#125; &#125; return doubleCheck; &#125;&#125; ** 测试类 **： 123456789101112131415161718192021package main.java.com.study.designPatterns.single;/** * @author: whb * @description: 单例模式测试 */public class singletonTest &#123; public static void main(String[] args) &#123; for (int i = 0; i &lt; 10; i++) &#123; int finalI = i; new Thread(() -&gt; &#123; /** * 双重检查【推荐用】 */ DoubleCheck doubleCheck = DoubleCheck.getInstance(); System.out.println(\"第\" + (finalI + 1) + \"次获得的doubleCheck对象的hashCode：\" + doubleCheck.hashCode()); &#125;).start(); &#125; &#125;&#125; ** 输出结果 **： 枚举【推荐用】** 代码实现 **： 12345678910111213package main.java.com.study.designPatterns.single;/** * @author: whb * @description: 枚举【推荐用】 * 不仅能避免多线程同步问题，而且还能防止反序列化重新创建新的对象。 */public enum EnumSingleton &#123; Instance; public void whatEverMethod() &#123; &#125;&#125; ** 测试类 **： 123456789101112131415161718192021package main.java.com.study.designPatterns.single;/** * @author: whb * @description: 单例模式测试 */public class singletonTest &#123; public static void main(String[] args) &#123; for (int i = 0; i &lt; 10; i++) &#123; int finalI = i; new Thread(() -&gt; &#123; /** * 双重检查【推荐用】 */ DoubleCheck doubleCheck = DoubleCheck.getInstance(); System.out.println(\"第\" + (finalI + 1) + \"次获得的doubleCheck对象的hashCode：\" + doubleCheck.hashCode()); &#125;).start(); &#125; &#125;&#125; ** 输出结果 **：","tags":"java 设计模式"},{"title":"排序算法 - 希尔排序","url":"/posts/94971cbd.html","text":"基本思想先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录“基本有序”时，再对全体记录进行依次直接插入排序。希尔排序，也称递减增量排序算法，是插入排序的一种高速而稳定的改进版本。 操作方法 选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1； 按增量序列个数k，对序列进行k 趟排序； 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 算法流程图 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package main.java.com.study.sortingAalgorithm;import main.java.com.study.utils.CommonUtils;/** * @author: whb * @description: 希尔排序 */public class ShellSort &#123; /** * 希尔排序（Shell’s Sort）又称“缩小增量排序”(Diminishing Increment Sort)，它也是一种属于插入排序类的方法，但在时间效率上比直接插入排序方法有较大的改进。 * 从对直接插入排序的分析可知，其算法时间复杂度为O(n2)，但是，若待排记录序列为“正序”时，其时间复杂度可提高至O(n)。 * 由此设想，若待排记录序列按关键字“基本有序”，直接插入排序的效率就可以大大提高。 * 从另一方面来看，由于直接插入排序算法简单，所以在n值很小时效率比较高。希尔排序正是从这两点分析出发对直接插入排序进行改进而得到的一种插入排序方法。 * &lt;p&gt; * 希尔排序的基本思想是：先将整个待排序列分割成若干子序列分别进行直接插入排序，待整个序列中的记录“基本有序”时，再对全体记录进行一次直接插入排序。（这是《数据结构》这本书里的说法。） * &lt;p&gt; * 通俗点说就是：先取较大的步长对待排序列进行直接插入排序，每排一次就缩小一次步长，再进行插入排序，直到最后步长变为1。 */ public static void shellSort(int[] numArr) &#123; int length = numArr.length; //取增量 int gap = length / 2; while (gap &gt;= 1) &#123; //无序序列 for (int i = gap; i &lt; length; i++) &#123; int temp = numArr[i]; int j; //有序序列 for (j = i - gap; j &gt;= 0 &amp;&amp; numArr[j] &gt; temp; j = j - gap) &#123; numArr[j + gap] = numArr[j]; &#125; numArr[j + gap] = temp; &#125; //缩小增量 gap = gap / 2; &#125; &#125; public static void main(String[] args) &#123; int[] numArr = &#123;27, 11, 13, 45, 34, 22, 19, 8, 3, 99, 74, 55, 88, 66&#125;; System.out.println(\"**************希尔排序******************\"); System.out.println(\"排序前：\"); CommonUtils.display(numArr); System.out.println(\"排序后：\"); shellSort(numArr); CommonUtils.display(numArr); &#125;&#125; CommonUtils工具类： 12345678910111213141516171819202122package main.java.com.study.utils;/** * @author: whb * @description: 工具类 */public class CommonUtils &#123; /** * 遍历打印 * * @param numArr */ public static void display(int[] numArr) &#123; if (numArr != null &amp;&amp; numArr.length &gt; 0) &#123; for (int num : numArr) &#123; System.out.print(num + \" \"); &#125; &#125; System.out.println(\"\"); &#125;&#125; 测试结果","tags":"java 算法"},{"title":"排序算法 - 珠排序","url":"/posts/be6df974.html","text":"基本思想将每个数用珠子表示，例如：数字5就是5个珠子。用珠子表示好每一个数后，让所有的珠子自由下落。排序完成。 上图中的三个珠就表示数字3,两个珠表示数字2,这个OK了继续,这里的3和2都叫bead。 上图(a)中有两个数字,4和3,分别串在四条线上,于是数字4的最后一个珠子下落,因为它下边是空的,自由下落后变成上图(b) 上图(c)中随机给了四个数字,分别是3,2,4,2,这些珠子自由下落,就变成了(d)中,落完就有序了,2,2,3,4 以上就是珠排序的精华。 上图中的n表示待排序数组的长度,有多少数字就有多少层,横向表示一层;m表示有多少个珠子,就是多少个1,这取决于最大数是几。 举个例子：比如待排数组[6 2 4 1 5 9]。 让珠子全部做自由落体运动 9没有什么好落的,它在最底层 5也没有什么好落的,全部有支撑点 1同样不需要滑落 4除了第一个珠子不动外,其它三颗全部下落,落到1的位置变成下边这样 过程的细节不画了,原则就是你下边有支点,你就不用再滑落了,最后变成下边这样,排序完毕。 从上到下顺序输出即可得到结果:[ 1 2 4 5 6 9]。 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package main.java.com.study.sortingAalgorithm;import main.java.com.study.utils.CommonUtils;/** * @author: whb * @description: 珠排序:将每个数用珠子表示，例如：数字5就是5个珠子。用珠子表示好每一个数后，让所有的珠子自由下落。排序完成。 */public class BeadSort &#123; /** * 珠排序 * * @param unsorted 待排序列 * @return */ public static int[] beadSort(int[] unsorted) &#123; //待排序列中的最大值 int max = 0; //获取最大值 for (int i = 0; i &lt; unsorted.length; i++) &#123; if (unsorted[i] &gt; max) &#123; max = unsorted[i]; &#125; &#125; //每个数都用珠子表示，比如5就用5个珠子，所以用二维数组表示每个数 char[][] grid = new char[unsorted.length][max]; int[] levelCount = new int[max]; for (int i = 0; i &lt; max; i++) &#123; levelCount[i] = 0; for (int j = 0; j &lt; unsorted.length; j++) &#123; grid[j][i] = '_'; &#125; &#125; //删除珠子 for (int i = 0; i &lt; unsorted.length; i++) &#123; int num = unsorted[i]; for (int j = 0; num &gt; 0; j++) &#123; grid[levelCount[j]++][j] = '*'; num--; &#125; &#125; //数珠子，放到已排序列表 int[] sorted = new int[unsorted.length]; for (int i = 0; i &lt; unsorted.length; i++) &#123; int putt = 0; for (int j = 0; j &lt; max &amp;&amp; grid[unsorted.length - 1 - i][j] == '*'; j++) &#123; putt++; &#125; sorted[i] = putt; &#125; return sorted; &#125; public static void main(String[] args) &#123; //产生随机待排序列 int[] unsorted = new int[(int) (Math.random() * 11) + 5]; for (int i = 0; i &lt; unsorted.length; i++) &#123; unsorted[i] = (int) (Math.random() * 10); &#125; System.out.println(\"**************珠排序******************\"); System.out.println(\"排序前：\"); CommonUtils.display(unsorted); System.out.println(\"排序后：\"); int[] sorted = beadSort(unsorted); CommonUtils.display(sorted); &#125;&#125; 测试结果如下","tags":"java 算法"},{"title":"排序算法 - 简单选择排序","url":"/posts/8d8fd18d.html","text":"基本思想在要排序的一组数中，选出最小（或者最大）的一个数与第1个位置的数交换；然后在剩下的数当中再找最小（或者最大）的与第2个位置的数交换，依次类推，直到第n-1个元素（倒数第二个数）和第n个元素（最后一个数）比较为止。 操作方法第一趟，从n 个记录中找出关键码最小的记录与第一个记录交换；第二趟，从第二个记录开始的n-1 个记录中再选出关键码最小的记录与第二个记录交换；以此类推…..第i 趟，则从第i 个记录开始的n-i+1 个记录中选出关键码最小的记录与第i 个记录交换，直到整个序列按关键码有序。 算法流程图 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package main.java.com.study.sortingAalgorithm;import main.java.com.study.utils.CommonUtils;/** * @author: whb * @description: 选择排序 */public class SelectionSort &#123; /** * 选择排序：每一趟在剩余未排序的若干记录中选取关键字最小的（也可以是最大的）记录作为有序序列中下一个记录。 * 如第i趟选择排序就是在n-i+1个记录中选取关键字最小的记录作为有序序列中第i个记录。 * 这样，整个序列共需要n-1趟排序。 */ public static void selctionSort(int[] numArr) &#123; int length = numArr.length; //要遍历的次数（length-1） for (int i = 0; i &lt; length - 1; i++) &#123; //将当前下标定义为最小值下标 int min = i; //遍历min之后的数据 for (int j = i + 1; j &lt; length - 1; j++) &#123; //如果有小于当前最小值的元素，将它的下标赋值给min if (numArr[j] &lt; numArr[min]) &#123; min = j; &#125; &#125; //如果min不等于i，则说明找到了真正的最小值 if (min != i) &#123; swap(numArr, min, i); &#125; &#125; &#125; /** * 交换数组中两个元素的位置 * * @param numArr * @param min * @param i */ public static void swap(int[] numArr, int min, int i) &#123; int temp = numArr[min]; numArr[min] = numArr[i]; numArr[i] = temp; &#125; public static void main(String[] args) &#123; int[] numArr = &#123;27, 11, 13, 45, 34, 22, 19, 8, 3, 99, 74, 55, 88, 66&#125;; System.out.println(\"**************选择排序******************\"); System.out.println(\"排序前：\"); CommonUtils.display(numArr); System.out.println(\"排序后：\"); selctionSort(numArr); CommonUtils.display(numArr); &#125;&#125; CommonUtils工具类： 12345678910111213141516171819202122package main.java.com.study.utils;/** * @author: whb * @description: 工具类 */public class CommonUtils &#123; /** * 遍历打印 * * @param numArr */ public static void display(int[] numArr) &#123; if (numArr != null &amp;&amp; numArr.length &gt; 0) &#123; for (int num : numArr) &#123; System.out.print(num + \" \"); &#125; &#125; System.out.println(\"\"); &#125;&#125; 测试结果","tags":"java 算法"},{"title":"排序算法 - 直接插入排序","url":"/posts/da1a6844.html","text":"基本思想将一个记录插入到已排序好的有序表中，从而得到一个新，记录数增1的有序表。即：先将序列的第1个记录看成是一个有序的子序列，然后从第2个记录逐个进行插入，直至整个序列有序为止。 操作方法 从第一个元素开始，该元素可以认为已经被排序 取出下一个元素，在已经排序的元素序列中从后向前扫描 如果该元素（已排序）大于新元素，将该元素移到下一位置 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置 将新元素插入到该位置后 重复步骤2~5 算法流程图 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package main.java.com.study.sortingAalgorithm;import main.java.com.study.utils.CommonUtils;/** * @author: whb * @description: 插入排序 */public class InsertSort &#123; /** * 直接插入排序是一种最简单的排序方法，它的基本操作是将一个记录插入到已排好的有序的表中，从而得到一个新的、记录数增1的有序表。 * &lt;p&gt; * 当前元素的前面元素均为有序，要插入时，从当前元素的左边开始往前找（从后往前找），比当前元素大的元素均往右移一个位置，最后把当前元素放在它应该呆的位置就行了。 * 移动、比较的次数可作为衡量时间复杂性的标准。 * &lt;p&gt; * 最优情况：如果原始的输入序列为正序： * &lt;p&gt; * 比较次数：n-1 * &lt;p&gt; * 移动次数：0 * &lt;p&gt; * 最差情况：如果原始的输入序列为逆序： * &lt;p&gt; * 比较次数：(n+2)(n-1)/2 * &lt;p&gt; * 移动次数：(n+4)(n-1)/2 * &lt;p&gt; * 所以直接插入排序的时间复杂度为O(n2)。 */ public static void insertSort(int[] numArr) &#123; int length = numArr.length; for (int i = 1; i &lt; length; i++) &#123; int temp = numArr[i]; int j; //遍历有序序列，如果有序序列中的元素比临时元素大，则将有序序列中比临时元素大的元素依次向后移动 for (j = i - 1; j &gt;= 0 &amp;&amp; numArr[j] &gt; temp; j--) &#123; numArr[j + 1] = numArr[j]; &#125; //将临时元素插入到腾出的位置 numArr[j + 1] = temp; &#125; &#125; public static void main(String[] args) &#123; int[] numArr = &#123;27, 11, 13, 45, 34, 22, 19, 8, 3, 99, 74, 55, 88, 66&#125;; System.out.println(\"**************直接插入排序******************\"); System.out.println(\"排序前：\"); CommonUtils.display(numArr); System.out.println(\"排序后：\"); insertSort(numArr); CommonUtils.display(numArr); &#125;&#125;``` CommonUtils工具类：```Javapackage main.java.com.study.utils;/** * @author: whb * @description: 工具类 */public class CommonUtils &#123; /** * 遍历打印 * * @param numArr */ public static void display(int[] numArr) &#123; if (numArr != null &amp;&amp; numArr.length &gt; 0) &#123; for (int num : numArr) &#123; System.out.print(num + \" \"); &#125; &#125; System.out.println(\"\"); &#125;&#125; 测试结果","tags":"java 算法"},{"title":"设计模式-设计模式简介","url":"/posts/f7d67188.html","text":"设计模式简介设计模式（Design pattern）代表了最佳的实践，通常被有经验的面向对象的软件开发人员所采用。设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的。 设计模式是一套被反复使用的、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。 毫无疑问，设计模式于己于他人于系统都是多赢的，设计模式使代码编制真正工程化，设计模式是软件工程的基石，如同大厦的一块块砖石一样。项目中合理地运用设计模式可以完美地解决很多问题，每种模式在现实中都有相应的原理来与之对应，每种模式都描述了一个在我们周围不断重复发生的问题，以及该问题的核心解决方案，这也是设计模式能被广泛应用的原因。 设计模式的类型总共有 23 种设计模式，这些模式可以分为三大类：创建型模式（Creational Patterns）、结构型模式（Structural Patterns）、行为型模式（Behavioral Patterns）。当然，还有另一类设计模式：J2EE 设计模式。 .tg {border-collapse:collapse;border-spacing:0;border-color:#aaa;} .tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:2px;overflow:hidden;word-break:normal;border-color:#aaa;color:#333;background-color:#fff;} .tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:2px;overflow:hidden;word-break:normal;border-color:#aaa;color:#fff;background-color:#f38630;} .tg .tg-84q5{border-color:#00009b;text-align:left;vertical-align:top} .tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top} .tg .tg-hdkn{border-color:#cb0000;text-align:center;vertical-align:top} .tg .tg-tkru{border-color:#3531ff;text-align:left;vertical-align:top} 序 号 模式 &amp; 描述 包括 1 创建型模式这些设计模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new 运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活。 ★工厂模式（Factory Pattern）★抽象工厂模式（Abstract Factory Pattern）★单例模式（Singleton Pattern）★建造者模式（Builder Pattern）★原型模式（Prototype Pattern） 2 结构型模式这些设计模式关注类和对象的组合。继承的概念被用来组合接口和定义组合对象获得新功能的方式。 ★适配器模式（Adapter Pattern）★桥接模式（Bridge Pattern）★过滤器模式（Filter、Criteria Pattern）★组合模式（Composite Pattern）★装饰器模式（Decorator Pattern）★外观模式（Facade Pattern）★享元模式（Flyweight Pattern）★代理模式（Proxy Pattern） 3 行为型模式这些设计模式特别关注对象之间的通信。 ★责任链模式（Chain of Responsibility Pattern）★命令模式（Command Pattern）★解释器模式（Interpreter Pattern）★迭代器模式（Iterator Pattern）★中介者模式（Mediator Pattern）★备忘录模式（Memento Pattern）★观察者模式（Observer Pattern）★状态模式（State Pattern）★空对象模式（Null Object Pattern）★策略模式（Strategy Pattern）★模板模式（Template Pattern）★访问者模式（Visitor Pattern） 4 J2EE 模式这些设计模式特别关注表示层。这些模式是由 Sun Java Center 鉴定的。 ★MVC 模式（MVC Pattern）★业务代表模式（Business Delegate Pattern）★组合实体模式（Composite Entity Pattern）★数据访问对象模式（Data Access Object Pattern）★前端控制器模式（Front Controller Pattern）★拦截过滤器模式（Intercepting Filter Pattern）★服务定位器模式（Service Locator Pattern）★传输对象模式（Transfer Object Pattern） 下面用一个图片来整体描述一下设计模式之间的关系： 创建型模式创建型设计模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new 运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活。 结构型模式结构型模式设计，它关注类和对象的组合。继承这一概念被用来组合接口和定义组合对象获得新功能的方式。 行为型模式行为型模式设计，更关注对象与对象之间的通信。 设计模式的六大原则开闭原则（Open Close Principle）开闭原则的意思是：对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。简言之，是为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，需要使用接口和抽象类。 里氏代换原则（Liskov Substitution Principle）里氏代换原则是面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。LSP 是继承复用的基石，只有当派生类可以替换掉基类，且软件单位的功能不受到影响时，基类才能真正被复用，而派生类也能够在基类的基础上增加新的行为。里氏代换原则是对开闭原则的补充。实现开闭原则的关键步骤就是抽象化，而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。 依赖倒转原则（Dependence Inversion Principle）这个原则是开闭原则的基础，具体内容：针对接口编程，依赖于抽象而不依赖于具体。 接口隔离原则（Interface Segregation Principle）这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。它还有另外一个意思是：降低类之间的耦合度。由此可见，其实设计模式就是从大型软件架构出发、便于升级和维护的软件设计思想，它强调降低依赖，降低耦合。 迪米特法则，又称最少知道原则（Demeter Principle）最少知道原则是指：一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。 合成复用原则（Composite Reuse Principle）合成复用原则是指：尽量使用合成/聚合的方式，而不是使用继承。","tags":"java 设计模式"},{"title":"Java多线程-03之-Thread中start()和run()的区别","url":"/posts/22f6e11d.html","text":"start()和run()方法的区别start(): 它的作用是启动一个新线程，新线程会执行相应的run()方法。start()不能被重复调用。 run(): run()就和普通的成员方法一样，可以被重复调用。单独调用run()的话，会在当前线程中执行run()，而并不会启动新线程！ 下面以代码来进行说明。 123456class MyThread extends Thread&#123; public void run()&#123; ... &#125; &#125;;MyThread mythread = new MyThread(); mythread.start()会启动一个新线程，并在新线程中运行run()方法。而mythread.run()则会直接在当前线程中运行run()方法，并不会启动一个新线程来运行run()。 start()和run()方法示例下面，通过一个简单示例演示它们之间的区别。源码如下： 12345678910111213141516171819202122class TestThread extends Thread &#123; public TestThread(String name) &#123; super(name); &#125; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + \" is running\"); &#125;&#125;;public class ThreadMethodDemo &#123; public static void main(String[] args) &#123; Thread mythread = new TestThread(\"testThread\"); System.out.println(Thread.currentThread().getName() + \" call testThread.run()\"); mythread.run(); System.out.println(Thread.currentThread().getName() + \" call testThread.start()\"); mythread.start(); &#125;&#125; 运行结果： 1234main call testThread.run()main is runningmain call testThread.start()testThread is running 结果说明： 1) Thread.currentThread().getName()是用于获取“当前线程”的名字。当前线程是指正在cpu中调度执行的线程。2) testThread.run()是在“主线程main”中调用的，该run()方法直接运行在“主线程main”上。3) testThread.start()会启动“线程testThread”，“线程testThread”启动之后，会调用run()方法；此时的run()方法是运行在“线程testThread”上。 start()和run()源码说明（基于JDK1.8.0_171） Thread.java中start()方法源码如下： 12345678910111213141516171819202122232425262728public synchronized void start() &#123; /** * 如果线程不是\"新建状态\"，则抛出异常 * 状态值0 对应\"新建\" */ if (threadStatus != 0) throw new IllegalThreadStateException(); /** 将线程添加到ThreadGroup中 */ group.add(this); boolean started = false; try &#123; /** 通过start0()启动线程 */ start0(); /** 设置started标记 */ started = true; &#125; finally &#123; try &#123; if (!started) &#123; group.threadStartFailed(this); &#125; &#125; catch (Throwable ignore) &#123; /* do nothing. If start0 threw a Throwable then it will be passed up the call stack */ &#125; &#125;&#125; 说明： start()实际上是通过本地方法start0()启动线程的。而start0()会新运行一个线程，新线程会调用run()方法。 1private native void start0(); Thread.java中run()方法源码如下： 12345public void run() &#123; if (target != null) &#123; target.run(); &#125;&#125; 说明： target是一个Runnable对象。run()就是直接调用Thread线程的Runnable成员的run()方法，并不会新建一个线程。","tags":"java 多线程"},{"title":"Git学习之~cherry-pick、revert、reset介绍","url":"/posts/1c4d9168.html","text":"** gti checkout – filename **git checkout – filename 可以把工作区的某个文件的修改撤回到上一次add或者commit的状态，不过filename不能省略.可以使用 git checkout – 不加文件名来查看当前工作区修改了哪些文件，这个只是针对工作区的问题； ** git reset head filename **git reset HEAD filename 可以把add到缓存区的文件回退到工作区，也就是把add filename这个过程给回退了，这并不会修改文件的内容，只是把缓存区的某个文件变成和HEAD这个当前版本相同，也就是说如果你多次add，这会回退到第一次add的过程，和上面的操作一样，也可以不带上文件名来查看哪些文件被添加到了缓存区； ** git reset –hard head^ **git reset –hard HEAD~【1，2，3，4，5…】这个是大家熟悉的本地版本的回退 ** 某分支上的修改迁移到另一分支 **比如我们在分支a上开发新功能，此时有个紧急bug需要修改，然后切换到了分支b。bug修复完之后忘了切回之前的分支a，而是在分支b上面继续编写本应该是分支a的内容，这样b分支存在了一部分a分支的代码，这个时候需要把这段代码迁移到a分支上，两个思路： 1）如果还没有在b分支上commit的话(add的话没影响，在迁移后，就不会再当前分支的缓存中)。直接切到a分支，此时会提示有没有被commit的代码，切到a分支后，就可以commit这段没有被commit的代码，也就是在b分支上编写的代码正确的被迁移到了a分支。 2）如果已经commit了，可以这么来：git log找到你commit的分支号，然后直接切换到a分支，执行git cherry-pick commit-id，这个commit-id就是那个b分支错误commit的id，这个命令就是把这个commit的修改拿到当前分支来，很简单粗暴而有效。再切换到b分支，使用git revert commit-id把这个错误的分支号移除。 ** revert reset cherry-pick **git revert当我们的某个分支中有了很多版本之后，形成了一条版本链，如果想去除这个线路中的某一版本，但是保留版本链中的其他所有修改，生成一个新的版本链，版本链中的HEAD就是revert最新生成的版本。所以revert是会生成新版本的指令。可以这么想，链就像一个链条，是一环扣一环的，其中的一环就是一个版本，现在想去这个链条中的某一环（某个版本），执行git revert HEAD~2，这个HEAD2就是这个要删除的版本（链条中的一环），就会把这个环解开剔除，把和这个剔除的环（版本）相邻的环连在一起，形成了一个新的链条（少了一环），然后在链条的最后面添加一个新的没有任何修改的环（revert HEAD2 这个新的commit版本）整个过程就像剔除了中间某一个版本，最后加上了一个没有任何修改的新的版本。需要注意的是，不要随意删除中间的版本，因为可能会存在依赖，最好是revert最新的版本，风险会小很多。 git resetgit reset [--hard|soft|mixed|merge|keep] [&lt;commit&gt;或HEAD]是比较常用的指令，其中比较重要的是mode，也就是 –hard、–soft、–mixed。。。比较常见的是–hard和–soft； –hard是指完全重设，会把回退到某版本之后的修改全部删除， –soft这是个回退解体，让版本库回退到某个版本，这个版本之后的修改全部存在缓存区，这个时候在commit的话，又会把会退的部分重新加载到最新版本中； git cherry-pickgit cherry-pick &lt;commit id&gt;用于把另一个本地分支的commit修改应用到当前分支，也是解决之前遇到问题的关键，可以直接把其他的分支上的修改或者是某一个版本直接引过来，可能会存在冲突，这个时候就和正常的冲突一样的解决就好了。","tags":"git"},{"title":"Git学习之~合并指定文件或Commits到另一分支","url":"/posts/5040fe16.html","text":"刚使用git进行版本管理的时候，由于成员间的代码有的需要上线，有的不需要上线，如果直接merge，经常会把别人不需要上线的代码合并的master，导致问题从生。所以，最稳妥的是只合并你需要的那些commits，不需要的commits就不合并进去。那么如何从一个分支合并特定的文件或者Commits到另一个分支这个问题急待解。 合并某个分支上的单个commit首先，用git log或sourcetree工具查看你想选择哪些commits进行合并，例如： 比如dev-w 分支上的commit 2aeefdacad6ed1586a1e035fb8860f11533db23c 非常重要，它含有一个紧急bug的修复或是其他内容。无论什么原因，你现在只需要将 2aeefdacad6ed1586a1e035fb8860f11533db23c 合并到master，而不合并dev-w上的其他commits，所以我们用git cherry-pick命令来做： 123git checkout master git cherry-pick 2aeefdacad6ed1586a1e035fb8860f11533db23c 这样 2aeefdacad6ed1586a1e035fb8860f11533db23c 就被合并到master分支，并在master中添加了commit（作为一个新的commit）。cherry-pick 和merge比较类似，如果git不能合并代码改动（比如遇到合并冲突），git需要你自己来解决冲突并手动添加commit。 这里git cherry-pick每次合并过来会显示文件冲突(其实并没有代码冲突部分，只需手动解决既可) 合并某个分支上的一系列commits在一些特定情况下，合并单个commit并不够，你需要合并一系列相连的commits。这种情况下就不要使用cherry-pick了，rebase 更适合。假设你需要合并dev-w分支的commit 76cada ~62ecb3 到master分支。 首先需要基于dev-w创建一个新的分支，并指明新分支的最后一个commit： 12git checkout dev-w git checkout -b newbranch 62ecb3 然后，rebase这个新分支的commit到master（–ontomaster）。76cada^ 指明你想从哪个特定的commit开始。 1git rebase --ontomaster 76cada^ 得到的结果就是dev-w分支的commit 76cada ~ 62ecb3 都被合并到了master分支。 另外如果只想将dev-w分支的某个文件Test.java合并到master分支上。 12git checkout dev-wgit checkout --patch master Test.java 第一个命令： 切换到dev-w分支；第二个命令：合并master分支上Test.java文件到dev-w分支上，将master分支上 Test.java 文件追加补丁到dev-w分支上 Test.java文件。你可以接受或者拒绝补丁内容。 如果只是简单的将dev-w分支的文件Test.java copy到master分支上； 12git checkout mastergit checkout dev-w Test.java 分支test上有一个文件A，你在test1分支上， 此时如果想用test分支上的A文件替换test1分支上的文件的话，可以使用git checkout test1, 然后git checkout test – A 在feature分支commit 切换至release分支 从feature分支检出相应文件 12345678#branch featuregit commit -a -m &quot;msg&quot;git checkout release#branch releasegit checkout feature file-01git checkout feature file-x...git commit -a -m &quot;msg&quot;","tags":"git"},{"title":"Java多线程-02之 多线程实现方式","url":"/posts/3868ed28.html","text":"实现多线程的几种方式 继承Thread类 实现Runnable接口 通过Callable和Future 通过线程池 Thread和Runnable简介RunnableRunnable是一个接口库，该接口只包含了一个run()方法，定义如下： 123public interface Runnable &#123; public abstract void run();&#125; Runnable的作用，实现多线程。我们可以定义一个类A实现Runnable接口；然后，通过new Thread(new A())等方式新建线程。 ThreadThread 是一个类。Thread本身就实现了Runnable接口。它的声明如下： 1public class Thread implements Runnable &#123;&#125; Thread和Runnable的异同点Thread 和 Runnable 的相同点：都是“多线程的实现方式”。Thread 和 Runnable 的不同点：Thread 是类，而Runnable是接口；Thread本身是实现了Runnable接口的类。我们知道“一个类只能有一个父类，但是却能实现多个接口”，因此Runnable具有更好的扩展性。此外，Runnable还可以用于“资源的共享”。即，多个线程都是基于某一个Runnable对象建立的，它们会共享Runnable对象上的资源。通常，建议通过“Runnable”实现多线程！ Thread和Runnable的多线程示例Thread的多线程示例123456789101112131415161718192021222324public class ThreadTest &#123; public static void main(String[] args) &#123; // 启动3个线程t1,t2,t3；每个线程各卖10张票！ MyThread t1 = new MyThread(); MyThread t2 = new MyThread(); MyThread t3 = new MyThread(); t1.start(); t2.start(); t3.start(); &#125;&#125;class MyThread extends Thread &#123; private int ticket = 10; @Override public void run() &#123; for (int i = 0; i &lt; 20; i++) &#123; if (this.ticket &gt; 0) &#123; System.out.println(this.getName() + \" 卖票：ticket\" + this.ticket--); &#125; &#125; &#125;&#125;; 运行结果： 123456789101112131415161718192021222324252627282930Thread-2 卖票：ticket10Thread-1 卖票：ticket10Thread-0 卖票：ticket10Thread-1 卖票：ticket9Thread-2 卖票：ticket9Thread-1 卖票：ticket8Thread-0 卖票：ticket9Thread-1 卖票：ticket7Thread-2 卖票：ticket8Thread-1 卖票：ticket6Thread-0 卖票：ticket8Thread-1 卖票：ticket5Thread-2 卖票：ticket7Thread-1 卖票：ticket4Thread-0 卖票：ticket7Thread-1 卖票：ticket3Thread-2 卖票：ticket6Thread-1 卖票：ticket2Thread-0 卖票：ticket6Thread-1 卖票：ticket1Thread-2 卖票：ticket5Thread-0 卖票：ticket5Thread-2 卖票：ticket4Thread-0 卖票：ticket4Thread-2 卖票：ticket3Thread-0 卖票：ticket3Thread-2 卖票：ticket2Thread-0 卖票：ticket2Thread-2 卖票：ticket1Thread-0 卖票：ticket1 结果说明： (01) MyThread继承于Thread，它是自定义个线程。每个MyThread都会卖出10张票。(02) 主线程main创建并启动3个MyThread子线程。每个子线程都各自卖出了10张票。 Runnable的多线程示例1234567891011121314151617181920212223242526class MyThread2 implements Runnable &#123; private int ticket = 10; @Override public void run() &#123; for (int i = 0; i &lt; 20; i++) &#123; if (this.ticket &gt; 0) &#123; System.out.println(Thread.currentThread().getName() + \" 卖票：ticket\" + this.ticket--); &#125; &#125; &#125;&#125;;public class RunnableTest &#123; public static void main(String[] args) &#123; MyThread2 mt = new MyThread2(); // 启动3个线程t1,t2,t3(它们共用一个Runnable对象)，这3个线程一共卖10张票！ Thread t1 = new Thread(mt); Thread t2 = new Thread(mt); Thread t3 = new Thread(mt); t1.start(); t2.start(); t3.start(); &#125;&#125; 运行结果： 12345678910Thread-0 卖票：ticket10Thread-0 卖票：ticket7Thread-0 卖票：ticket6Thread-0 卖票：ticket5Thread-2 卖票：ticket8Thread-1 卖票：ticket9Thread-1 卖票：ticket2Thread-1 卖票：ticket1Thread-2 卖票：ticket3Thread-0 卖票：ticket4 结果说明： (01) 和上面“MyThread继承于Thread”不同；这里的MyThread实现了Thread接口。(02) 主线程main创建并启动3个子线程，而且这3个子线程都是基于“mt这个Runnable对象”而创建的。运行结果是这3个子线程一共卖出了10张票。这说明它们是共享了MyThread接口的。","tags":"java 多线程"},{"title":"Git学习之~重置","url":"/posts/b9f23f09.html","text":"分支游标master的探秘先来看看当有新的提交发生时，文件.git/refs/heads/master的内容如何改变。首先在工作区创建一个新文件，姑且叫做new-commit.txt，然后提交到版本库中。 123$ touch new-commit.txt $ git add new-commit.txt $ git commit -m &quot;does master follow this new commit?&quot; 此时工作目录下会有两个文件，其中文件new-commit.txt是新增的。 12$ lsnew-commit.txt welcome.txt 来看看master分支指向的提交ID是否改变了。 先看看在版本库引用空间(.git/refs/目录)下的master文件内容的确更改了，指向了新的提交。 12$ cat .git/refs/heads/master23995a2d61d0a2667ba0db8aa4a17b127c1977d1 再用git log查看一下提交日志，可以看到刚刚完成的提交。 1$ gilt log --graph --oneline 引用refs/heads/master就好像是一个游标，在有新的提交发生的时候指向了新的提交。可是如果只可上、不可下，就不能称为“游标”。Git提供了git reset命令，可以将“游标”指向任意一个存在的提交ID。下面就尝试人为更改游标。 1$ git reset --hard HEAD^ 注意，上面的命令中使用了--hard参数，会破坏工作区未提交的改动，要慎用。这条命令将master重置到了上一个老的提交上，来看下master文件内容是否更改了。 12$ cat .git/refs/heads/mastera67c6fdd0a0e809340944432a3bf7d78e7e10f31 果然master分支的引用文件的指向更改为前一次提交的ID了。而且通过下面的命令可以看到新添加的文件new-commit.txt也丢失了。 1$ ls 重置命令不仅可以重置到前一次提交，还可以直接使用提交ID重置到任何一次提交。 通过git log查询到最早的提交ID。 1$ git log --graph --oneline 然后重置到最早的一次提交。 1$ git reset --hard d3e0684 -重置后会发现welcome.txt也回退到了最原始版本库，曾经的修改都丢失了。 1$ cat welcome.txt 使用重置命令很危险，会彻底的丢弃历史。那么还能够通过浏览提交历史的办法找到丢弃的提交ID，再使用重置命令恢复历史吗？不可能！！！因为重置让提交历史也改变了。 1$ git log 使用reflog挽救错误的重置如果没有记下重置前master分支指向的提交ID，想要重置回原来的提交真的是一件麻烦的事情(去对象库中一个个地找)。幸好Git提供了一个挽救机制，通过.git/logs目录下日志文件记录了分支的变更。默认非裸版本库（带有工作区）都提供分支日志功能，这是因为带有工作区的八本库都有如下设置： 1$ git config core.logallrefupdates 查看一下master分支的日志文件.git/logs/refs/heads/master中的内容。下面命令显示了该文件的最后几行。 1$ tail -5 .git/logs/refs/heads/master 可以看出这个文件记录了master分支指向的变迁，最新的改变追加到文件的末尾因此最后出现。最后一行可以看出因执行git reset --hard命令，指向的提交ID由a67c6f改变为d3e0684。Git提供了一个git reflog命令，对这个文件进行操作。使用show子命令可以显示此文件的内容。 1$ git reflog show master | head -5 使用git reflog的输出和直接查看日志文件最大的不同在于显示顺序不同，即最新改变放在了最前面显示，而且只显示每次改变的最终的SHA1哈希值。还有个区别在于使用git reflog的输出中还提供了一个方便易记的表达式：&lt;refname&gt;@{&lt;n&gt;}。这个表达式的含义是引用&lt;refname&gt;之前第次改变时的SHA1哈希值。那么将引用master切换到两次变更之前的值，可以使用如下命令： 重置master为两次改变之前的值。 1$ git reset --hard master@&#123;2&#125; 重置后工作区中文件new-commit.txt又回来了。 12$ lsnew-commit.txt welcome.txt 提交的历史也回来了。 1$ git log --oneline 此时如果再用git reflog查看，会看到恢复master的操作也记录在了日志中。 1$ git reflog show master | head -5 深入了解git reset命令重置命令git reset是Git最常用的命令之一，也是最危险，最容易误用的命令。用法如下： 12用法一：git reset [-q] [&lt;commit&gt;] [--] &lt;paths&gt;…​用法二：git reset [--soft | --mixed [-N] | --hard | --merge | --keep] [-q] [&lt;commit&gt;] 上面列出的用法中，是可选项，可以使用引用或者提交ID，如果省略则相当于使用了HEAD的指向作为提交ID。上面列出的两种用法的区别在于，第一种用法在命令中包含路径&lt;paths&gt;。为了避免路径和引用（或者提交ID）同名而冲突，可以在&lt;paths&gt;前用两个连续的短线作为分隔。 第一种用法不会重置引用，更不会改变工作区，而是用指定提交状态（）下的文件（）替换掉暂存区的文件。例如命令git reset HEAD &lt;paths&gt;相当于取消之前执行的git add &lt;paths&gt;命令时改变的暂存区。 第二种用法（不使用路径&lt;paths&gt;的用法）则会重置引用。根据不同的选项，可以对暂存区或者工作区进行重置。参照下面的版本库模型图，来看一看不同的参数对第二种重置语法的影响。 命令格式：git reset [–soft | –mixed | –hard] [] 使用参数--hard，如：git reset --hard &lt;commit&gt; 会执行上图中的1、2、3全部的三个动作。即： 替换引用的指向。引用指向新的提交ID。 替换暂存区。替换后，暂存区的内容和引用指向的目录树一致。 替换工作区。替换后，工作区的内容变得和暂存区一致，也和HEAD指向的目录树内容相同。 使用参数--soft，如：git reset --soft &lt;commit&gt;，会执行上图中的操作1.即只更改引用的指向，不改变暂存区和工作区。 使用参数--mixed或者不使用参数（缺省为--mixed），如：git reset &lt;commit&gt;，会执行上图中的操作1和操作2。即更改引用的指向以及重置暂存区，但不改变工作区。 下面通过一些示例，看一下重置命令的不同用法。 命令：git reset仅用HEAD指向的目录树重置暂存区，工作区不受影响，相当于将之前用git add命令更新到暂存区的内容撤出暂存区。引用也未改变，因为引用重置到HEAD相当于没有重置。 命令：git reset HEAD 同上。 命令：git reset -- filename。仅将文件filename撤出暂存区，暂存区中其他文件不改变。相当于对命令git add filename的反向操作。 命令：git reset HEAD filename。同上。 命令：git reset --soft HEAD^。工作区和暂存区不改变，但是引用向前回退一次。当对最新提交的提交说明或者提交的更改不满意时，撤销下最新的提交以便重新提交。 之前曾经介绍过一个修改提交命令：git commit --amend，用于对最新的提交进行重新提交以修补错误的提交说明或者错误的提交文件。修补命令实际上相当于执行了下面两条命令。（文件.git/COMMIT_EDITMSG保存了上次的提交日志） 12$ git reset --soft HEAD^$ git commit -e -F .git/COMMIT_EDITMSG 命令：git reset HEAD^。工作区不改变，但是暂存区会回退到上一次提交之前，引用也会回退一次。 命令：git reset --mixed HEAD^。同上。 命令：git reset --hard HEAD^。彻底撤销最近的提交。引用会回退到前一次，而且工作区和暂存区都会回退到上一次提交的状态。自上一次以来的提交全部丢失。","tags":"git"},{"title":"Git学习之~对象","url":"/posts/779ee1e1.html","text":"Git对象库探秘通过查看日志的详尽输出，会看到非常多的SHA1哈希值。 1$ git log -l --pretty=raw 一个提交中居然包含了三个SHA1哈希值表示的对象ID。 commit a67c6fdd0a0e809340944432a3bf7d78e7e10f31这是本次提交的唯一标识。 tree b79fd13fac802739388af44a81d72b6e1d68da89这是本次提交所对应的的目录树。 parent d3617dadd10c274e6e2b6caf47635d5771b9034c这是本次提交的父提交（上一次提交）。 研究Git对象ID的一个重量级武器：git cat-file命令。用下面的命令可以查看这三个ID的类型。 123456$ git cat-file -t a67c6fcommit$ git cat-file -t b79ftree$ git cat-file d3617commit 在引用对象ID的时候，没有必要把整个40位的ID写全，只需要从头开始的几位不冲突即可。下面再使用git cat-file命令查看一下这几个对象的内容。 commit对象a67c6fdd0a0e809340944432a3bf7d78e7e10f31 1$ git cat-file -p a67c6f tree对象b79fd13fac802739388af44a81d72b6e1d68da89 1$ git cat-file -p b79fd commit对象d3617dadd10c274e6e2b6caf47635d5771b9034c 1$ git cat-file -p d3617 在上面目录树(tree)对象中看到了一个新的类型的对象：blob对象。这个对象保存着文件welcome.txt的内容。 该对象的类型为blob。 12$ git cat-file -t d7230d74c5f8d61ff3c1adbfd3b035c09cb62c16blob 该对象的内容就是welcome.txt文件的内容。 123$ git cat-file -p d7230d74c5f8d61ff3c1adbfd3b035c09cb62c16Hello Git.很高兴见到你。 这些对象保存在哪里？当然是Git库中的objects目录下（ID的前两位作为目录名，后38位作为文件名。） 用下面的命令可以看到这些对象在对象库中的实际位置。 1for id in a67c6f b79fd d3617 d7230d; do ls .git/objects/$&#123;id:0:2&#125;/$&#123;id:2&#125;*;done 通过下面的命令可以看到提交对象之间相互关联的跟踪连。 1$ git log --pretty=raw --graph a67c 上面的命令通过--graph参数可以看到提交链路，通过--pretty=raw参数以便显示每个提交对象的parent属性。最后一个提交没有parent属性，所以跟踪连到此终结，这实际上就是提交的起点。 HEAD和Master探秘现在先看下工作区的状态。 12$ git status -s -b## master 上面在显示工作区状态时，除了使用-s参数以显示精简输出外，还使用了-b参数以便能够同时显示出当前工作分支的名称。使用git branch也可以显示当前的工作分支。 12$ git branch * master 在master分支名称前面出现一个星号表明这个分支是当前工作分支。现在连续执行下面三个命令会看到相同的输出： 12345$ git log -1 HEAD $ git log -1 master $ git log -1 refs/heads/master 也就是说在当前版本库中，HEAD、master和refs/heads/master具有相同的指向。让我们去版本库.git目录中看一看。 12345$ find .git -name HEAD -o -name master.git/HEAD.git/logs/HEAD.git/logs/refs/heads/master.git/refs/heads/master 显示一下.git/HEAD的内容： 12$ cat .git/HEADref: refs/heads/master 把HEAD的内容翻译过来就是：“指向一个引用：refs/heads/master”。这个引用在文件.git/refs/heads/master。 12$ cat .git/refs/heads/mastera67c6fdd0a0e809340944432a3bf7d78e7e10f31 用git cat-file命令查看下a67c6fdd0a0e809340944432a3bf7d78e7e10f31的内容。 显示SHA1哈希值指代的数据类型。 12$ git cat-file -t a67c6commit 显示提交的内容。 1234567$ git cat-file -p a67c6tree b79fd13fac802739388af44a81d72b6e1d68da89parent d3617dadd10c274e6e2b6caf47635d5771b9034cauthor wanghongbo &lt;270028806@qq.com&gt; 1560174530 +0800committer wanghongbo &lt;270028806@qq.com&gt; 1560174530 +0800哪个版本的数据会被提交？ 原来分支master指向的是一个提交ID（最新提交）。这样的分支实现很巧妙：既然可以从任何提交开始建立一条历史跟踪连，那么用一个文件指向这个链条的最新提交，那么这个文件就可以用于追踪整个提交历史了。这个文件就是.git/refs/heads/master文件。下面看一个更接近于真实的版本库结构图： 目录.git/refs是保存引用的命名空间，其中.git/refs/heads目录下的引用又称为分支。对于分支既可以使用正规的长格式表示法，如refs/heads/master，也可以去掉前面的两级目录用master表示。Git有一个底层命令git rev-parse可以用于显示引用对应的提交ID。 12345678$ git rev-parse mastera67c6fdd0a0e809340944432a3bf7d78e7e10f31$ git rev-parse refs/heads/master a67c6fdd0a0e809340944432a3bf7d78e7e10f31$ git rev-parse HEAD a67c6fdd0a0e809340944432a3bf7d78e7e10f31 可以看出它们都指向同一个对象。下面来展示一下提交的SHA1哈希值生成方法。 看看HEAD对应的提交的内容。使用git cat-file命令。 1234567$ git cat-file commit HEADtree b79fd13fac802739388af44a81d72b6e1d68da89parent d3617dadd10c274e6e2b6caf47635d5771b9034cauthor wanghongbo &lt;270028806@qq.com&gt; 1560174530 +0800committer wanghongbo &lt;270028806@qq.com&gt; 1560174530 +0800哪个版本的数据会被提交？ 提交信息中总共包含243个字符。 1$ git cat-file commit HEAD | wc -c 在提交信息的前面加上内容commit 243&lt;null&gt;(为空字符)，然后执行SHA1哈希算法。 12$ (printf &quot;commit 243\\000&quot;; git cat-file commit HEAD) | sha1suma67c6fdd0a0e809340944432a3bf7d78e7e10f31 *- 上面命令得到的哈希值和用git rev-parse看到的是一样的。 1$ git rev-parse HEAD 下面看一看文件内容的SHA1哈希值生成方法。 看看版本库中welcome.txt的内容，使用git cat-file命令。 123$ git cat-file blob HEAD:welcome.txtHello Git.很高兴见到你。 文件总共包含33字节的内容。 12$ git cat-file blob HEAD:welcome.txt | wc -c 33 在文件内容的前面加上blob 33&lt;null&gt;的内容，然后执行SHA1哈希算法。 12$ (printf &quot;blob 33\\000&quot;; git cat-file blob HEAD:welcome.txt) | sha1sumd7230d74c5f8d61ff3c1adbfd3b035c09cb62c16 *- 上面命令得到的哈希值和用git rev-parse看到的是一样的。 12$ git rev-parse HEAD:welcome.txtd7230d74c5f8d61ff3c1adbfd3b035c09cb62c16 最后再来看看树的SHA1哈希值的形成方法。 HEAD对应的树的内容共包含39个字节。 12$ git cat-file tree HEAD^&#123;tree&#125; | wc -c39 在树的内容的前面加上tree 39&lt;null&gt;的内容，然后执行SHA1哈希算法。 12$ (printf &quot;tree 39\\000&quot;; git cat-file tree HEAD^&#123;tree&#125;) | sha1sumb79fd13fac802739388af44a81d72b6e1d68da89 *- 上面命令得到的哈希值和用git rev-parse看到的是一样的。 12$ git rev-parse HEAD^&#123;tree&#125;b79fd13fac802739388af44a81d72b6e1d68da89 Git提供了很多方法可以方便的访问Git库中的对象。 采用部分SHA1哈希值。不必写全40位的哈希值，只采用开头的部分，不和现有其他的冲突即可。 使用master代表分支master中最新的提交，使用全称refs/heads/master亦可。 使用HEAD代表版本库中最近的一次提交。 符号^可以用于指代父提交。例如： HEAD^代表版本库中上一次提交，即最近一次提交的父提交。 HEAD^^则代表HEAD^的父提交。 对于一个提交有多个父提交，可以在符号^后面用数字表示是第几个父提交。例如： a5731^2含义是提交a5731的多个父提交中的第二个父提交。 HEAD^1相当于HEAD^含义是HEAD多个父提交中的第一个。 HEAD^^2含义是HEAD^(HEAD父提交)的多个父提交中的第二个。 符号~&lt;n&gt;也可以用于指代祖先提交。下面两个表达式效果等同： 12a5731~5a5731^^^^^ 提交所对应的树对象，可以用类似如下的语法访问。 1a5731^&#123;tree&#125; 某一此提交对应的文件对象，可以用如下的语法访问。 1a5731:path/to/file 暂存区中的文件对象，可以用如下语法访问。 1:path/to/file 下面使用git rev-parse练习下。 12345678910111213141516$ git rev-parse HEAD a67c6fdd0a0e809340944432a3bf7d78e7e10f31$ git cat-file -p a67c6f tree b79fd13fac802739388af44a81d72b6e1d68da89parent d3617dadd10c274e6e2b6caf47635d5771b9034cauthor wanghongbo &lt;270028806@qq.com&gt; 1560174530 +0800committer wanghongbo &lt;270028806@qq.com&gt; 1560174530 +0800哪个版本的数据会被提交？$ git rev-parse a67c6f^&#123;tree&#125;b79fd13fac802739388af44a81d72b6e1d68da89$ git rev-parse a67c6f^^&#123;tree&#125;a070b35c2d55e057a2eead7b8ae1b06c3e4d8e3b","tags":"git"},{"title":"Git学习之~工作区、暂存区、HEAD","url":"/posts/2c9fc045.html","text":"首先看一下git-demo的提交日志，使用git log查看提交日志（附加--stat参数可以看到每次提交的文件变更统计）。 1$ git log --stat 通过日志可以看到第一次提交对文件welcome.txt有一行的变更，而第二次提交因为使用了--allow-empty参数进行的空提交，所以提交说明中看不到任何对实质内容的修改。 修改不能直接提交？首先更改welcome.txt文件的内容，在文件后面追加一行。 1$ echo &quot;很高兴见到你。&quot; &gt;&gt; welcome.txt 这时就可以通过git diff命令看到修改后的文件和版本库中文件的差异。实质和本地比较的不是版本库，而是一个中间状态的文件。 1$ git diff 接下来执行提交，看能否提交成功。 1$ git commit -m &quot;追加一行：很高兴见到你。&quot; 提交成功了吗？好像没有。提交没有成功的证据： 先看看提交日志，如果提交成功就会有新的提交记录。 1$ git log --pretty=oneline 使用了精简输出来显示日志，以便更简洁和清晰地看到提交历史。可以看到版本库中只有两个提交，针对刚才修改文件的提交没有成功！ 执行git diff可以看到和之前相同的差异输出，这也说明提交没有成功。 执行git status查看文件状态，可以看到文件处于未提交状态。 执行git status -s可以显示精简格式的状态输出。 提交为什么会失败呢？原因是没有对修改的welcome.txt文件执行git add命令，将修改的文件添加到“提交任务”，然后才能提交。现在就将修改的文件“添加”到提交任务。 1$ git add welcome.txt 现在再执行一些Git命令，看看当执行“添加”后会发生什么变化。 执行git diff没有输出。 执行git diff head或git diff master进行比较会发现有差异，这个差异是正常的，因为还没有提交。 1$ git diff head 执行git status，状态输出和之前不一样了。 1$ git status 对新的Git状态输出做下翻译： 12345位于分支master上下列的修改将被提交： （如果你后悔了，可以使用“git reset HEAD &lt;file&gt;...”命令将下列改动撤出提交任务（提交暂存区，stage）， 否则执行提交命令将会提交） 已修改： welcome.txt 不得不说，Git太人性化了，它把各种情况下可以使用到的命令都告诉了用户，虽然这显得有点啰嗦。如果不要这么啰嗦，可以使用简洁方式： 12$ git status -sM welcome.txt 上面精简状态输出与执行git add之前的精简状态的输出相比，有细微的差别。 虽然都是M(Modified)标识，但是位置不同。在执行git add之前，这个M位于第二列（第一列是个空格），执行完git add之后，字符M位于第一列（第二列是空白）。 位于第一列的字符M的含义：版本库中的文件和处于中间状态–提交任务（提交暂存区，stage）中的文件相比有改动； 位于第二列的字符M的含义：工作区当前的文件和处于中间状态–提交任务（提交暂存区，stage）中的文件相比有改动。这时如果直接提交git commit,加入提交任务的welcome.txt文件的更改就被提交入库了。但是先不忙着提交，再进行一些操作，看看能否被彻底搞糊涂。 继续修改welcome.txt文件（在文件后面追加一行）。 1$ echo &quot;Good-bye&quot; &gt;&gt; welcome.txt 然后执行git status查看一下状态： 1git status 状态输出中居然是之前出现的两种不同状态的输出。 使用简洁模式输出，也会看到两种精简输出的杂合。 1git status -s 上面Git状态的输出可以这么理解：不但版本库中最新提交的文件和处于中间状态（提交暂存区，stage）中文件相比有改动，而且工作区当前的文件和处于中间状态（提交暂存区，stage）中的文件相比也有改动。即现在welcome.txt中有三个不同的版本：一个在工作区，一个在暂存区，一个是版本库中最新版本。通过不同的参数调用git diff命令可以看到不同版本库之间的差异。 不带任何选项和参数调用git diff显示工作区最新改动，即工作区和提交暂存区中相比的差异。 将工作区和HEAD（当前工作分支）相比，会看到更多差异。 通过参数--cached或者--staged参数调用git diff命令，看到的是提交暂存区和版本库中文件的差异。 好了，现在提交下看看。 123$ git commit -m &quot;哪个版本的数据会被提交？&quot;[master a67c6fd] 哪个版本的数据会被提交？ 1 file changed, 1 insertion(+) 这次提交终于成功了，查看下日志： 1234$ git log --pretty=onelinea67c6fdd0a0e809340944432a3bf7d78e7e10f31 (HEAD -&gt; master) 哪个版本的数据会被提交？d3617dadd10c274e6e2b6caf47635d5771b9034c 这是谁提交的？d3e0684a1c510f4effd155b01591019e2c5d7812 初始化的第一次提交 查看精简状态输出： 12$ git status -s M welcome.txt 状态输出中文件名的前面出现了一个字母M，即只位于第二列的字母M。那么第一列的M去哪了？很明显被提交了。即提交任务（提交暂存区，stage）中的内容被提交到版本库，所以第一列因为提交暂存区和版本库中的状态一致，所以显示空白。那提交的welcome.txt是哪个版本呢？通过执行git diff或者git diff head命令查看差异。虽然命令git diff和git diff head的比较过程并不同，但是会看到下面相同的差异输出结果。 12$ git diff$ git diff head 理解Git暂存区（stage）Git暂存区（stage，或称为index）的设计是Git最成功的设计之一，也是最难理解的一个设计。在版本库.git目录下，有一个index文件，下面针对这个文件做个实验。首先执行git checkout命令，撤销工作区中welcome.txt文件尚未提交的修改。 12$ git checkout -- welcome.txt$ git status -s 通过状态输出可以看到工作区已经没有改动了，查看下.git/index文件的时间戳： 2019-06-10 22:00:43 1$ ls --full-time .git/index 再次执行git status命令，然后显示.git/index文件的时间戳：2019-06-10 22:00:43，和上面的一样。 12$ git status -s $ ls --full-time .git/index 现在更改一下welcome.txt文件的时间戳，但不改变它的内容。然后再执行git status命令，然后查看.git/index文件时间戳为：22:06:32 123$ touch welcome.txt$ git status -s $ ls --full-time .git/index 可以看到时间戳改变了。这个实验说明当执行git status或者git diff命令扫描工作区改动的时候，先依据.git/index文件中记录的（工作区跟踪文件）时间戳、长度等信息判断工作区文件是否改变。如果工作区的文件时间戳改变，说明文件的内容可能被改变了，需要打开文件，读取文件内容，和更改前的原始文件相比，判断文件内容是否被更改。如果文件内容没有改变，则将该文件新的时间戳记录到.git/index文件中。因为判断文件是否更改使用的是时间戳、文件长度等信息进行比较，要比通过文件内容比较快的多，所以GIt这样的实现方式可以让工作区状态扫描更快执行，这也是Git高效的因素之一。文件.git/index实际上就是一个包含文件索引的目录树，像是一个虚拟的工作区。在这个虚拟工作区的目录树中，记录了文件名、文件的状态信息（时间戳、文件长度等）。文件的内容并不存储其中，而是保存在Git对象库.git/objects目录中，文件索引建立了文件和对象库中对象实体之间的对应。下面这张图展示了工作区、版本库中的暂存区和版本库之间的关系。 图中左侧为工作区，右侧为版本库。在版本库中标记为index的区域是暂存区(stage，亦称index),标记为master的是master分支所代表的目录树。 图中可以看出此时HEAD实际上是指向master分支的一个“游标”，所以图示的命令中出现HEAD的地方可以用master替换。 图中的objects标识的区域为Git的对象库，实际位于.git/objects目录下。 当对工作区修改（或新增）的文件执行git add命令时，暂存区的目录树被更新，同时工作区修改（或新增）的文件内容被写入到对象库中的一个新的对象中，而对象的ID被记录在暂存区的文件索引中。 当执行提交操作时，暂存区的目录树写到版本库（对象库）中，master分支会做出相应的更新。即master最新指向的目录树就是提交时原暂存区的目录树。 当执行git reset HEAD命令时，暂存区的目录树会被重写，被master分支指向的目录树所替换，但是工作区不受影响。 当执行git rm --cached &lt;file&gt;命令时，会直接从暂存区删除文件，工作区则不做改变。 当执行git checkout . 或者git checkout -- &lt;file&gt;命令时，会用暂存区全部或指定的文件替换工作区的文件，。这个操作很危险，会清除工作区中未添加到暂存区的改动。 当执行git checkout HEAD .或者git checkout HEAD &lt;file&gt;命令时，会用HEAD指向的master分支中的全部或者部分文件替换暂存区和工作区中的文件。这个命令也极具危险性，因为不但会清除工作区中未提交的改动，也会清除暂存区中未提交的改动。 Git Diff 魔法暂存区目录树浏览 对于HEAD（版本库中当前提交）指向的目录树，可以使用git ls-tree来查看。 12$ git ls-tree -l HEAD 100644 blob d7230d74c5f8d61ff3c1adbfd3b035c09cb62c16 33 welcome.txt 使用-l参数，可以显示文件大小。上面welcome.txt大小33字节。 输出的条目从左至右，第一个字段是文件的属性（rw-r–r–）,第二个字段说明是Git对象库中的一个blob对象（文件），第三个字段则是该文件在对象库中对应的ID–一个40位的SHA1哈希值格式的ID，第四个字段是文件大小，第五个字段是文件名。 在浏览暂存区中的目录树之前，首先清除工作区当中的改动。通过 git clean -fd命令清除当前工作区中没有加入版本库的文件和目录（非跟踪文件和目录），然后执行git checkout .命令，用暂存区刷新工作区。 12$ git clean -fd$ git checkout . 然后在工作区中做出一些修改（修改welcome.txt，增加一个子目录和文件），然后添加到暂存区。最后再对工作区做出修改。 123456$ echo &quot;( ^_^ )/~~拜拜&quot; &gt;&gt; welcome.txt$ mkdir -p a/b/c$ echo &quot;Hello.&quot; &gt;&gt; a/b/c/hello.txt $ git add .$ echo &quot;ヾ(￣▽￣)Bye~Bye~&quot; &gt;&gt; a/b/c/hello.txt $ git status -s 上面的命令运行完毕后，通过精简的状态输出，可以看出工作区、暂存区、版本库当前分支的最新版本（HEAD）各不相同。先来看看工作区中文件的大小： 123$ find . -path ./.git -prune -o -type f -printf &quot;%-20p\\t%s\\n&quot;./a/b/c/hello.txt 30./welcome.txt 52 要显示暂存区的目录树，可以使用git ls-files命令。 123$ git ls-files -s100644 18832d35117ef2f013c4009f5b2128dfaeff354f 0 a/b/c/hello.txt100644 a2b90cc2992cf3ff4e0d6beb0c9461158124c2b6 0 welcome.txt 这个输出和之前使用git ls-tree命令的输出不一样，如果想要使用git ls-tree命令，需要先将暂存区的目录树写入Git对象库git write-tree命令，然后在针对git write-tree命令写入的tree执行git ls-tree。 12345$ git write-tree 1e9d611d50af21a2f0ec7bce6e270fd170a8f557$ git ls-tree -l 040000 tree 53583ee687fbb2e913d18d508aefd512465b2092 - a100644 blob a2b90cc2992cf3ff4e0d6beb0c9461158124c2b6 50 welcome.txt 从上面的命令可以看出： 到处都是40位的SHA1哈希值格式的ID，可以用于指代文件内容（blob），用于指代目录树(tree)，还可以用于指代提交。 git write-tree的输出就是写入Git对象库中的Tree ID，这个ID将作为下一条命令的输入。 git ls-tree命令中，没有把40位的ID写全，而是使用了前几位，实际上只要不和其他的对象ID冲突，可以随心所欲的使用缩写ID。 git ls-tree的输出显示的第一条是一个tree对象，即刚才创建的一级目录a。 如果想要递归显示目录内容，则使用-r参数调用。使用参数-t可以把递归过程中遇到的每棵树都显示出来，而不是只显示最终的文件。下面执行递归操作显示目录树的内容。 123456$ git write-tree | xargs git ls-tree -l -r -t040000 tree 53583ee687fbb2e913d18d508aefd512465b2092 - a040000 tree 514d729095b7bc203cf336723af710d41b84867b - a/b040000 tree deaec688e84302d4a0b98a1b78a434be1b22ca02 - a/b/c100644 blob 18832d35117ef2f013c4009f5b2128dfaeff354f 7 a/b/c/hello.txt100644 blob a2b90cc2992cf3ff4e0d6beb0c9461158124c2b6 50 welcome.txt 通过使用不同的参数调用git diff命令，可以对工作区、暂存区、HEAD中的内容两两比较。下面的图展示了git diff命令的作用范围。 通过上面的图就不难理解下面命令的输出。 工作区和暂存区比较。 1$ git diff 暂存区和HEAD比较。 1$ git diff --cached 工作区和HEAD比较。 1$ git diff HEAD 不要使用git commit -a实际上Git的提交命令git commit可以带上-a参数，对本地所有变更的文件执行提交操作，包括本地修改的文件，删除的文件，但不包括未被版本库跟踪的文件。这个命令的确可以简化一些操作，但同时会丢掉Git暂存区带给用户最大的好处：对提交内容进行控制的能力。","tags":"git"},{"title":"Git学习之~初始化","url":"/posts/7230a407.html","text":"创建版本库及第一次提交首先看一下当前Git的版本 1$ git --version 在开始Git之前，我们需要设置一下Git的环境变量，这个设置是一次性的工作。即这些设置会在全局文件（用户主目录的 .gitconfig）或系统文件（/etc/gitconfig）中做永久记录。 告诉Git当前用户的姓名和邮件地址，配置的用户名和邮件地址将在版本库提交时作为提交者的用户名和邮件地址。 12$ git config --global user.name &quot;wanghongbo&quot;$ git config --global user.email whb@163.com 设置一些Git别名，以便可以使用更为简洁的子命令。例如：输入 git ci 即相当于 git commit -s ，输入git st 即相当于 git -p status。 如果拥有系统管理员权限，希望注册的命令别名能被所有用户使用，可执行如下命令： 1234$ git config --system alias.br branch$ git config --system alias.ci &quot;commit -s&quot;$ git config --system alias.co checkout$ git config --system alias.st &quot;-p status&quot; - 如果只在本用户使用，执行下面的命令：1234$ git config --global alias.st status$ git config --global alias.ci &quot;commit -s&quot;$ git config --global alias.co checkout$ git config --global alias.br branch 创建Git版本库下面就从一个空目录开始初始化版本库，这个版本库命名为“git-demo”。首先建立一个新的工作目录，进入该目录后，执行git init创建版本库 12345$ cd /d/workspace$ mkdir git-demo$ cd git-demo$ git initInitialized empty Git repository in D:/workspace/git-demo/.git/ 从上面版本库初始化后的输出中，可以看到执行git init命令在工作区创建了隐藏目录.git。 12$ ls -aF./ ../ .git/ 这个隐藏的.git目录就是Git版本库（又叫仓库，repository）。.git版本库目录所在的目录，即/d/workspace/git-demo目录称为工作区，目前工作区除了包含一个隐藏的.git目录外空无一物。 下面在工作区中创建一个文件：welcome.txt，内容就是一行“Hello Git.”。 1$ echo &quot;Hello Git.&quot; &gt;&gt; welcome.txt 为了将这个新建立的文件添加到版本库，需要执行下面的命令： 1$ git add welcome.txt Git和大部分其他版本控制系统都需要再执行一个提交操作，对于Git执行git commit命令完成提交。在提交过程中需要输入提交说明，这个要求对Git是强制性的，不像CVS、SVN等允许空白的提交说明。在Git提交时，如果在命令行不提供提交说明（没有使用 -m 参数），Git会自动打开一个编辑器，要求您在其中输入提交说明，输入完毕保存退出。下面进行提交，为了说明方便，使用 -m 参数直接给出提交说明。 1$ git commit -m &quot;初始化的第一次提交&quot; 从上面的命令及输出可以看出： 通过-m参数设置提交说明为：“初始化的第一次提交”。该提交说明也显示在命令输出的第一行中。 命令输出的第一行还显示了当前处于名为master的分支上，提交ID为e55c54c，且该提交是该分支的第一个提交，即根提交（root-commit）。根提交和其他提交的区别在于没有关联的父提交。 命令输出的第二行开始显示本次提交所做修改的统计：修改了一个文件，包含一行的插入。 思考：Git工作区下为什么有个.git目录？Git及其他分布式版本控制系统的一个显著特点：版本库位于工作区的根目录下。对于Git，版本库位于工作区根目录下的.git目录中，且仅此一处，在工作区的子目录下则没有任何其他跟踪文件或目录。Git为什么要这样设计呢？对于CVS，工作区的根目录及每个子目录下都有一个CVS目录，该目录中包含几个配置文件，建立了对版本库的追踪。如CVS目录下的Entries文件记录了从版本库检出到工作区的文件的名称、版本和时间戳等，这样就可以通过对工作区文件时间戳的改变来判断文件是否更改。这样设计的好处是，可以将工作区移动到任何其他目录，工作区和版本控制服务器的映射关系保持不变，这样工作区依然能正常工作。甚至还将工作区的某个子目录移动到其他位置，形成新的工作区，在新的工作区仍然能完成版本控制相关的操作。但缺点也很多，例如工作区文件修改了，因为没有原始文件做比对，因此向服务器提交修改的时候只能对整个文件进行传输而不能仅传输文件的改动部分。还有一个风险就是信息泄露，通过扫描CVS/Entries文件就能得到目录下的文件列表，造成信息泄露。 对于SVN，工作区的根目录和每一个子目录下都有一个.svn目录，该目录不仅包含了类似CVS的跟踪目录下的配置文件，还包含了当前工作区下每一个文件的拷贝。多出文件的原始拷贝让某些svn命令可以脱离版本库执行，还可以在由客户端向服务器提交时，仅仅对文件改动的内容提交，因此改动的文件可以和原始拷贝进行差异比较。缺点除了像CVS跟踪目录造成信息泄露，还导致加倍占用工作区的空间。再有就是当在工作区目录下针对文件内容进行搜索时，会因为.svn目录下文件的原始拷贝，导致搜索的结果加倍，而出现混乱的搜索结果。 Git的设计，将版本库放在工作区根目录下，所有的版本控制操作（除了和远程版本库之间的相互操作）都是在本地即可完成，不向SVN只有寥寥几个命令才能脱离网络执行。而且Git也不存在安全泄露（只要保护好.git目录），也没有SVN本地文件搜索结果混乱的问题，Git甚至还提供了一条git grep命令来更好地搜索工作区的文件内容。 1$ git grep &quot;Hello&quot; 当工作区中包含子目录，在子目录中执行Git命令时，如何定位版本库？实际上，Git工作区目录下执行操作时，会对目录依次向上递归查找.git目录，找到.git目录就是工作区对应的版本库，.git所在的目录就是工作区的根目录，文件.git/index记录了工作区文件的状态（实际上是暂存区的状态）。 例如，在非Git工作区执行git命令，会因找不到.git目录而报错。 12$ cd /d/workspace/webstrom$ git status 怎样获取Git版本库的位置以及工作区根目录位置？ 先在工作区下建立目录a/b/c，进入该目录中。 12$ mkdir -p a/b/c`$ cd a/b/c 显示版本库.git目录所在的位置。 12$ git rev-parse --git-dirD:/workspace/git-demo/.git 显示工作区根目录 12$ git rev-parse --show-toplevelD:/workspace/git-demo 相对于工作区根目录的相对目录 12$ git rev-parse --show-prefixa/b/c 显示从当前目录（cd）后退（up）到工作区的根的深度。 12$ git rev-parse --show-cdup../../../ 思考：git config 命令参数的区别？在之前使用过的git config命令，有的使用了--global参数，有的使用了--system参数，这两个参数有什么区别？ 执行下面的命令，将打开D:/workspace/git-demo/.git/config文件进行编辑。 12$ cd /d/workspace/git-demo/$ git config -e 执行下面的命令，将打开C:/Users/ASUS/.gitconfig（用户主目录下的.gitconfig文件）全局配置文件进行编辑。 1$ git config -e --global 执行下面的命令，将打开E:/developerTools/git/mingw64/etc/gitconfig系统级配置文件进行编辑。 1$ git config -e --system Git的三个配置文件分别是版本库级别的配置、全局配置（用户主目录下）和系统级配置（Git安装目录下）。其中版本库级别配置文件的优先级最高，全局配置文件次之，系统级配置文件优先级最低。这样的优先级设置可以让版本库.git目录下的config文件中的配置可以覆盖用户主目录下的Git环境配置，而用户主目录下的配置也可以覆盖系统的Git配置文件。 执行之前的三个git config命令，会看到这三个级别配置文件的格式和内容，采用INI文件格式。如下： 12345678$ cat /d/workspace/git-demo/.git/config[core] repositoryformatversion = 0 filemode = false bare = false logallrefupdates = true symlinks = false ignorecase = true git config命令可以用来读取和更改INI配置文件的内容。使用git config &lt;section&gt;.&lt;key&gt;，来读取INI配置文件中某个配置的键值。例如读取[core]小节的bare的属性值，命令如下： 12$ git config core.barefalse 如果想要更改或配置INI文件中某个属性的值也很简单，命令格式：git config &lt;section&gt;.&lt;key&gt; &lt;value&gt;。 12$ git config a.b learningGit$ git config x.y.z something 打开.git/config文件会看到增加的内容： 1234[a] b = learningGit[x &quot;y&quot;] z = something 思考：是谁提交的？在一开始我们为Git设置了user.name和user.email全局环境变量，如果不设置会怎样？执行下面的命令，删除Git全局配置文件中关于user.name和user.email的设置： 12$ git config --unset --global user.name$ git config --unset --global user.email 这样关于用户名和邮件的设置都被清空了，执行下面的命令将看不到输出 12$ git config user.name$ git config user.email 下面再进行一次提交，看看提交过程有什么不同，以及提交之后显示的提交者是谁？ 1$ git commit --allow-empty -m &quot;这是谁提交的？&quot; 上面的命令使用了--allow-empty参数，这是因为没有对工作区的文件进行任何修改，Git默认是不会执行提交，使用了--allow-empty参数后，允许执行空白提交。 从提交结果看到，因为没有设置user.name和user.email，提交结果中Git提供了详细的帮助指引来告诉如何设置必须的变量，以及如何修改之前提交中出现的错误的提交者信息。为了保证提交时提交者和作者信息的正确性，重新恢复user.name和user.email的设置。 12$ git config --global user.name &quot;wanghongbo&quot;$ git config --global user.email youreamil@email.com 然后执行下面的命令，重新修改最新的提交，修正提交者的错误信息。 1$ git commit --amend --allow-empty --reset-author 说明： 参数--amend是对刚刚的提交进行修补，这样就可以改正之前错误的提交，而不会产生新的提交； 参数--allow-empty是因为要进行修改的提交实际上是一个空白提交，Git默认不允许空白提交； 参数--reset-author的含义是将提交者的ID重置，否则会影响最新的Commit的ID。这条命令也会重置AuthorDate的信息。 通过日志可以看到提交者的信息已经改正了。 1$ git log --pretty=fuller","tags":"git"},{"title":"Git学习之~检出","url":"/posts/b27802af.html","text":"HEAD的重置即检出HEAD可以理解为“头指针”，是当前工作区的“基础版本”，当执行提交时，HEAD指向的提交作为新提交的父提交。看看当前HEAD的指向。 1$ cat .git/HEAD 可以看出HEAD指向了分支master，此时执行git branch会看到当前处于master分支。 1$ git branch -v 现在使用git checkout命令检出该ID的父提交，看看会怎么样。 1$ git checkout 23995a2 翻译一下上面的输出结果： 12345678910$ git checkout 23995a2注意：正在检出 &apos;23995a2&apos;.您现在处于&apos;分离头指针&apos;状态，您可以检查、测试和提交，而不影响任何分支。通过执行另外的一个 checkout 检出指令会丢弃在此状态下的修改和提交。如果想保留在此状态下的修改和提交，使用 -b 参数调用 checkout 检出指令以创建新的跟踪分支。如： git checkout -b new_branch_name 头指针现在指向 23995a2... 提交说明为：does master follow this new commit? 什么叫做“分离头指针”状态？查看一下此时的HEAD的内容就明白了。 12$ cat .git/HEAD23995a2d61d0a2667ba0db8aa4a17b127c1977d1 原来“分离头指针”状态指的就是HEAD头指针指向了一个具体的提交ID，而不是一个引用（分支）。 查看最新提交的reflog也可以看到当针对提交执行git checkout命令时，HEAD头指针就被更改了：由指向master分支变成了指向一个提交ID。 12$ git reflog -l23995a2 (HEAD, master) HEAD@&#123;0&#125;: checkout: moving from master to 23995a2 注意上面的reflog是HEAD头指针的变迁记录，而非master分支。查看一下HEAD和master对应的提交ID，会发现现在它们指向的不一样。 1$ git rev-parse HEAD master 前一个是HEAD头指针的指向，后一个是master分支的指向。而且还可以看到执行git checkout命令与执行git reset命令不同，分支(master)的指向并没有改变，仍旧指向原有的提交ID。现在版本库的HEAD是指向23995a提交的，再做一次提交，HEAD会如何变化？ 先做一次修改：创建一个新文件detached-commit.txt，添加到暂存区中。 12$ touch detached-commit.txt $ git add detached-commit.txt 看一下状态，会发现其中有“当前不处于任何分支”的字样，显然这是因为HEAD处于“分离头指针”模式。 1$ git status 执行提交。在提交输出中也会出现[detached HEAD...]的标识，这也是对用户的警示。 1$ git commit -m &quot;commit in detached HEAD mode&quot; 此时头指针指向了新的提交。 12$ cat .git/HEAD1fe77f7b9993cd79b050826df1c73715cc1d1e45 再查看一下日志会发现新的提交是建立在之前的提交基础上的。 1$ git log --graph --oneline 记下新的提交ID(1fe77f7b9993cd79b050826df1c73715cc1d1e45)，然后以master分支名作为参数执行git checkout命令，会切换到master分支上。 切换到master分支上，再没有之前大段的文字警告。 1$ git checkout master 因为HEAD头指针重新指向了分支，而不是处于“分离头指针模式”。 1$ cat .git/HEAD 切换之后，之前本地建立的detached-commit.txt文件不见了。 12$ lsnew-commit.txt welcome.txt 切换之后，刚才的提交日志也不见了。 1$ git log --graph --oneline 刚才的提交还存在于版本库的对象库中吗？看看刚才记下的提交ID。 1$ git show 1fe77 可以看出这个提交现在仍在版本库中。由于这个提交没有被任何分支跟踪到，因此不能保证这个提交会永久存在。实际上当reflog中含有该提交的日志过期后，这个提交随时都会从版本库中彻底清除。 挽救分离头指针在“分离头指针”模式下进行的测试提交除了使用ID（1fe77）访问之外，不能通过master分支或其他引用访问到。如果这个提交是master分支所需的，那么该如何处理？如果使用git reset，的确可以将master分支重置到该测试提交的1fe77，但这就会丢掉master分支原先的提交23995a2。使用合并操作git merge可以实现两者的兼顾。下面的操作会将提交1fe77合并到master分支中来，具体操作如下： 确认当前处于master分支。 1$ git branch -v 执行合并操作，将1fe77提交合并到当前分支。 1$ git merge 1fe77 工作区中多了一个detached-commit.txt文件。 深入了解git checkout命令git checkout是Git常用的命令之一，同时也是很危险的命令，因为这条命令会重写工作区。检出命令的用法如下： 123用法一： git checkout [-q] [&lt;commit&gt;] [--] &lt;paths&gt;...用法二： git checkout [&lt;branch&gt;]用法三： git checkout [-m] [[-b|--orphan] &lt;new_branch&gt;] [&lt;start_point&gt;] 用法一和用法二的区别在于，用法一在命令中包含路径。为了避免路径和引用（或者提交ID）同名而发生冲突，可以在前用两个连续的短线作为分隔。 第一种用法的是可选项，如果省略相当于从暂存区(index)进行检出。这和重置命令大不相同：重置的默认值是HEAD，而检出的默认值是暂存区。因此重置一般用于重置暂存区(除非使用–hard参数，否则不重置工作区)，而检出命令主要是覆盖工作区(如果不省略，也会替换暂存区中相应的文件)。 用法一(包含了路径的用法)不会改变HEAD头指针，主要是用于指定版本的文件覆盖工作区中对应的文件。如果省略，则会用暂存区的文件覆盖工作区的文件，否则用指定提交中的文件覆盖暂存区和工作区中对应的文件。 用法二(不使用路径的用法)则会改变HEAD头指针。之所以后面的参数写作，是因为只有HEAD切换一个分支才可以对提交进行跟踪，否则仍然会进入“分离头指针”状态。在“分离头指针”状态下的提交不能被引用关联到，从而可能丢失。用法二的最主要作用就是切换到分支。如果省略则相当于对工作区进行状态检查。 用法三主要是创建和切换到新分支()，新的分支从指定的提交开始创建。新分支和我们熟悉的master分支没有什么实质的不同，都是在refs/heads命名空间下引用。","tags":"git"},{"title":"Git学习之~安装","url":"/posts/fe22a4f2.html","text":"最早Git是在Linux上开发的，很长一段时间内，Git也只能在Linux和Unix系统上跑。后来有人把它移植到了Windows上。现在，Git可以在Linux、Unix、Mac和Windows这几大平台上正常运行了。 要使用Git，第一步当然是安装Git了。根据你使用的操作系统如下： Linux上安装Git首先，你可以试着输入git，看看系统有没有安装Git： 123$ gitThe program &apos;git&apos; is currently not installed. You can install it by typing:sudo apt-get install git 像上面的命令，有很多Linux会友好地告诉你Git没有安装，还会告诉你如何安装Git。 如果你用的是Debian或Ubuntu Linux，通过 sudo apt-get install git 就可以直接完成Git的安装，非常简单。 老一点的Debian或Ubuntu Linux，要把命令改为sudo apt-get install git-core，因为以前有个软件也叫GIT（GNU Interactive Tools），结果Git就只能叫git-core了。由于Git名气实在太大，后来就把GNU Interactive Tools改成gnuit，git-core正式改为git。 如果是其他Linux版本，可以直接通过源码安装。先从Git官网下载源码，然后解压，依次输入：./config，make，sudo make install这几个命令安装就好了。 Mac OS X上安装Git 有两种安装Git的方法: 一是安装homebrew，然后通过homebrew安装Git，具体方法请参考homebrew的文档。 第二种方法更简单，直接从AppStore安装Xcode，Xcode集成了Git，不过默认没有安装，你需要运行Xcode，选择菜单“Xcode”-&gt;“Preferences”，在弹出窗口中找到“Downloads”，选择“Command Line Tools”，点“Install”就可以完成安装了。 Xcode是Apple官方IDE，功能非常强大，是开发Mac和iOS App的必选装备，而且是免费的！ Windows上安装Git在Windows上使用Git，可以从Git官网直接下载安装程序，然后按默认选项安装即可。 安装完成后，在开始菜单里找到“Git”-&gt;“Git Bash”，蹦出一个类似命令行窗口的东西，就说明Git安装成功！ 安装完成后，还需要最后一步设置，在命令行输入： 12$ git config --global user.name &quot;Your Name&quot;$ git config --global user.email &quot;email@example.com&quot; 注意git config命令的–global参数，用了这个参数，表示你这台机器上所有的Git仓库都会使用这个配置，当然也可以对某个仓库指定不同的用户名和Email地址。 Git可以安装在哪些操作系统上？ Linux macOS Solaris Windows Raspberry Pi Submit","tags":"git"},{"title":"Git学习之~爱上Git的理由","url":"/posts/d9014d70.html","text":"现场版本控制 现场版本库创建。直接在需要版本控制的目录下执行Git版本库初始化命令。 1git init 添加文件并提交 12git add -Agit commit -m &quot;本次提交的内容描述&quot; 为初始提交建立一个里程碑：”v1” 1git tag v1 然后开始在工作区中工作–修改文件，提交 1git commit -a 当对修改结果满意，想将工作成功保存带走时，可以通过下面的命令，将从v1开始的历次提交逐一导出为补丁文件。转换的补丁文件都包含一个数字前缀，并提取提交日志信息作为文件名，而且补丁文件还提供对二进制文件的支持。 1git format-patch v1..HEAD 通过邮件将补丁文件发出。当然也可以通过其他方式将补丁文件带走。 1git send-email *.patch Git创建的补丁文件使用了Git扩展格式，因此在导入时为了避免数据遗漏，要使用Git提供的命令而不能使用GNU patch命令。即时要导入的不是Git版本库，也可以使用Git命令。 修改提交说明1git commit --amend 这个命令如果不带”-m”参数，会进入提交提交说明编辑界面，修改原来的提交说明，直到满意为止。 如果要修改某个历史提交的提交说明，Git也可以实现，但要用到另一个命令：变基命令。例如要修改所标识提交的提交说明，执行下面的命令，并在弹出的变基索引文件中修改相应提交前面的动作的关键字。 1git rebase -i &lt;commit-id&gt;^ 删除不应提交的文件12git rm --cached 文件名git commit --amend 如果是历史版本，例如是在所标识的提交中引入的文件，则需要使用变基操作。 1git rebase -i &lt;commit-id&gt;^ 更好用的提交列表git add 命令将修改内容加入提交暂存区。git add -u 命令可以将所有修改过的文件加入暂存区。git add -A 命令可以将本地删除文件和新增文件都登记到暂存区。git add -p 命令甚至可以对一个文件内的修改进行有选择性的添加。 一个修改后的文件被登记到提交暂存区后，可以继续修改，继续修改的内容不会被提交，除非再对此文件再执行一次 git add 命令。即一个修改文件可以拥有两个版本，在提交暂存区中有一个版本，在工作区中有另外一个版本。 执行 git commit命令提交，无须设定什么变更列表，直接将登记在暂存区中的内容提交。Git支持对提交的撤销，而且可以撤销任意多次。 工作进度保存如果工作区的修改尚未完成时，忽然有一个紧急的任务，需要从一个干净的工作区开始新的工作，或者要切换到别的分支进行工作，那么如果保存当前尚未完成的工作进度呢？ 1git stash 在切换到新的工作分支之前，执行 git stash 保存工作进度，工作区会变的非常干净，然后就可以切换到新的分支。 12git stash git checkout &lt;new_branch&gt; 新的工作分支修改完毕后，再切换回当前分支，调用 git stash pop 命令则可恢复之前保存的工作进度。 12git checkout &lt;orignal_branch&gt;git stash pop 更好的差异比较Git对差异比较进行了扩展，支持对二进制文件的差异比较，这是对GNU的 diff 和 patch 命令的重要补充。还有Git的差异比较除了支持基于行的差异比较外，还支持在一行内逐字比较的方式，当向 git diff 命令传递 --word-diff 参数时，就会进行逐字比较。在上面介绍了工作区的文件修改可能会有两个不同的版本，一个是在提交暂存区，一个是在工作区。因此在执行 git diff 命令时会遇到令Git新手费解的现象。 修改后的文件在执行 git diff 命令时会看到修改造成的差异。 修改后的文件通过 git add 命令提交到暂存区，再执行 git diff 命令会看不到该文件的差异。 执行 git diff --cached 命令才可以看到添加到暂存区中的文件所做出的修改。 无处不在的分页器分页器默认使用 less命令（less -FRSX）进行分页。下面是在分页器中常用的热键： 字母q：退出分页器； 字母h：显示分页器帮助； 按空格下翻一页，按字母b上翻一页； 字母d和u：分别代表向下翻动半页和向上翻动半页； 字母j和k：分别代表向上翻一行和向下翻一行； 如果行太长被截断，可以用左箭头和右箭头使得窗口内容左右滚动； 输入/pattern：向下寻找和pattern匹配的内容； 输入?pattern：向上寻找和pattern匹配的内容； 字母n或N：代表向前或向后继续寻找； 字母g：跳到第一行； 字母G：跳到最后一行； 输入数字再加字母g：则跳转到对应的行； 输入!：可以执行Shell命令。 对于默认未提供分页器的Git命令，例如 git status 命令，可通过下面任一方法启用分页器： 在 git 和子命令(如：status)之间插入参数-p或--paginate，为命令启用内建分页器。如： 1git -p status -设置Git变量，设置完毕后运行相应的命令，将启用内建分页器。 1git config --global pager.status true Git 命令的分页器支持带颜色的字符输出，对于太长的行则采用截断方式处理（可用左右方向键滚动）。如果不习惯分页器的长行截断模式而希望采用自动折行模式，可通过下面任一方法进行设置： 通过设置LESS环境变量来实现。 1export LESS=FRX -或者通过定义Git配置变量来改变分页器的默认行为。 1git config --global core.pager &apos;less -+$LESS -FRX&apos;","tags":"git"},{"title":"Java多线程-01之-基本概念","url":"/posts/7335ce5b.html","text":"进程概述进程是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。 在早期面向进程设计的计算机结构中，进程是程序的基本执行实体；在当代面向线程设计的计算机结构中，进程是线程的容器。程序是指令、数据及其组织形式的描述，进程是程序的实体。 一个进程就是一个正在执行程序的实例，包括程序计数器，寄存器和变量的当前值。从概念上说，每个进程都拥有自己的虚拟CPU。实际上真正的CPU在各个进程间来回切换。 进程的层次结构进程只有一个父进程，但是可以有0个，一个，多个子进程。 进程的状态 运行态：该时刻进程实际占用CPU。 就绪态：可运行，但因为其他进程正在运行而暂时停止。 阻塞态：除非某种外部事件发生，否则进程不能运行。 线程线程是进程的一个实体，是CPU调度和分派的基本单位，他是比进程更小的能独立运行的基本单位，线程自己基本上不拥有系统资源。 进程和线程的区别进程用于把资源集中到一起，而线程则是在CPU上被调度执行的实体。 进程：指在系统中能独立运行并作为资源分配的基本单位，它是由一组机器指令、数据和堆栈等组成的，是一个能独立运行的活动实体。 线程：是进程的一个实体，是CPU调度和分派的基本单位，他是比进程更小的能独立运行的基本单位，线程自己基本上不拥有系统资源。 多个进程的内部数据和状态都是完全独立的,而多线程是共享一块内存空间和一组系统资源,有可能互相影响. 线程本身的数据通常只有寄存器数据，以及一个程序执行时使用的堆栈，所以线程的切换比进程切换的负担要小。 在同一进程中的不同线程之间的独立性要比不同进程之间的独立性低得多。这是因为为防止进程之间彼此干扰和破坏，每个进程都拥有一个独立的地址空间和其它资源，除了共享全局变量外，不允许其它进程的访问。但是同一进程中的不同线程往往是为了提高并发性以及进行相互之间的合作而创建的，它们共享进程的内存地址空间和资源，如每个线程都可以访问它们所属进程地址空间中的所有地址，如一个线程的堆栈可以被其它线程读、写，甚至完全清除。 线程状态图 线程状态解析 1. 新建状态(New): 线程对象被创建后，就进入了新建状态。例如，Thread thread = new Thread()。 2. 就绪状态(Runnable): 也被称为“可执行状态”，处于就绪状态的线程，随时可能被CPU调度执行。 调用线程的start()方法，此线程进入就绪状态。 当前线程sleep()方法结束，其他线程join()结束，等待用户输入完毕，某个线程拿到对象锁，这些线程也将进入就绪状态。 当前线程时间片用完了，调用当前线程的yield()方法，当前线程进入就绪状态。 锁池里的线程拿到对象锁后，进入就绪状态。 3. 运行状态(Running):线程获取CPU权限进行执行。需要注意的是，线程只能从就绪状态进入到运行状态。 4. 阻塞状态(Blocked): 阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况分三种： 等待阻塞 – 通过调用线程的wait()方法，让线程等待某工作的完成。 同步阻塞 – 线程在获取synchronized同步锁失败(因为锁被其它线程所占用)，它会进入同步阻塞状态。 其他阻塞 – 通过调用线程的sleep()或join()或发出了I/O请求时，线程会进入到阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。 5. 死亡状态(Dead): 线程执行完了或者因异常退出了run()方法，该线程结束生命周期。线程一旦终止了，就不能复生。在一个终止的线程上调用start()方法，会抛出java.lang.IllegalThreadStateException异常。 说明这5种状态涉及到的内容包括Object类, Thread和synchronized关键字。Object类，定义了wait(), notify(), notifyAll()等休眠/唤醒函数。Thread类，定义了一些列的线程操作函数。例如，sleep()休眠函数, interrupt()中断函数, getName()获取线程名称等。synchronized，是关键字；它区分为synchronized代码块和synchronized方法。synchronized的作用是让线程获取对象的同步锁。 几个方法的比较 1. Thread.sleep(long millis)，一定是当前线程调用此方法，当前线程进入TIMED_WAITING状态，但不释放对象锁，millis后线程自动苏醒进入就绪状态。作用：给其它线程执行机会的最佳方式。 2. Thread.yield()，一定是当前线程调用此方法，当前线程放弃获取的CPU时间片，但不释放锁资源，由运行状态变为就绪状态，让OS再次选择线程。作用：让相同优先级的线程轮流执行，但并不保证一定会轮流执行。实际中无法保证yield()达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。Thread.yield()不会导致阻塞。该方法与sleep()类似，只是不能由用户指定暂停多长时间。 3. t.join()/t.join(long millis)，当前线程里调用其它线程t的join方法，当前线程进入WAITING/TIMED_WAITING状态，当前线程不会释放已经持有的对象锁。线程t执行完毕或者millis时间到，当前线程进入就绪状态。 4. obj.wait()，当前线程调用对象的wait()方法，当前线程释放对象锁，进入等待队列。依靠notify()/notifyAll()唤醒或者wait(long timeout) timeout时间到自动唤醒。 5. obj.notify()唤醒在此对象监视器上等待的单个线程，选择是任意性的。notifyAll()唤醒在此对象监视器上等待的所有线程。","tags":"java 多线程"},{"title":"有趣的SpringBoot启动banner（持续更新）","url":"/posts/74450131.html","text":"千里马123456789101112131415161718192021 _(\\_/) ,((((^`\\ (((( (6 \\ ,((((( , \\ ,,,_ ,((((( /\"._ ,`, ((((\\\\ ,... ,(((( / `-.-' ))) ;' `\"'\"'\"\"(((( ( ((( / ((( \\ )) | |(( | . ' |)) \\ _ ' `t ,.')( | y;- -,-\"\"'\"-.\\ \\/ ) / ./ ) / `\\ \\ |./ ( ( / /' || \\\\ //'| || \\\\ _//'|| || )) |_/ || \\_\\ |_/ || `'\" \\_\\ `'\" 文字兔12345678910111213141516171819202122232425262728293031323334353637/*** * 瓦瓦 十 * 十齱龠己 亅瓦車己 * 乙龍龠毋日丶 丶乙己毋毋丶 * 十龠馬鬼車瓦 己十瓦毋毋 * 鬼馬龠馬龠十 己己毋車毋瓦 * 毋龠龠龍龠鬼乙丶丶乙車乙毋鬼車己 * 乙龠龍龍鬼龍瓦 十瓦毋乙瓦龠瓦亅 * 馬齱龍馬鬼十丶日己己己毋車乙丶 * 己齱馬鬼車十十毋日乙己己乙乙 * 車馬齱齱日乙毋瓦己乙瓦日亅 * 亅車齺龖瓦乙車龖龍乙乙十 * 日龠龠十亅車龍毋十十 * 日毋己亅 己己十亅亅 * 丶己十十乙 丶丶丶丶丶 * 亅己十龍龖瓦 丶 丶 乙十 * 亅己十龠龖毋 丶丶 丶己鬼鬼瓦亅 * 十日十十日亅丶亅丶 丶十日毋鬼馬馬車乙 * 十日乙十亅亅亅丶 十乙己毋鬼鬼鬼龍齺馬乙 * 丶瓦己乙十十亅丶亅乙乙乙己毋鬼鬼鬼龍齱齺齺鬼十 * 乙乙十十十亅乙瓦瓦己日瓦毋鬼鬼龠齱齱龍龍齱齱毋丶 * 亅十十十十乙瓦車毋瓦瓦日車馬龠龍龍龍龍龍龠龠龠馬亅 * 十十十十己毋車瓦瓦瓦瓦鬼馬龠龍龠龠龍龠龠龠馬龠車 * 亅十十日毋瓦日日瓦鬼鬼鬼龠龠馬馬龠龍龍龠馬馬車 * 亅亅亅乙瓦瓦毋車車車馬龍龠鬼鬼馬龠龍龍龠馬馬鬼 * 丶丶乙亅亅乙車鬼鬼鬼毋車龍龍龠鬼馬馬龠龍齱齱龍馬鬼 * 亅己十十己十日鬼鬼車瓦毋龠龍龠馬馬龠龠龠齱齺齺齱龠鬼 * 亅乙乙乙十車馬車毋馬齱齱龍龠龠龠馬龠龍齱龍龠龠鬼瓦 * 丶毋龠鬼車瓦車馬龠龍龠龠龍齱齱龠馬馬鬼毋日 * 十乙己日十 丶己鬼龍齱齺齱龍馬馬馬車毋己 * 丶十己乙亅丶 亅瓦馬龠龍龠龠馬毋瓦乙 * 丶十十乙亅十 亅己瓦車馬龠鬼車瓦乙 * 丶十乙十十丶 丶丶亅十瓦鬼車瓦己 * 丶亅亅丶 亅日瓦日 * 丶 */ 狗头1123456789101112131415161718192021222324252627282930313233343536373839/*** * .,:,,, .::,,,::. * .::::,,;;, .,;;:,,....:i: * :i,.::::,;i:. ....,,:::::::::,.... .;i:,. ......;i. * :;..:::;::::i;,,:::;:,,,,,,,,,,..,.,,:::iri:. .,:irsr:,.;i. * ;;..,::::;;;;ri,,,. ..,,:;s1s1ssrr;,.;r, * :;. ,::;ii;:, . ................... .;iirri;;;,,;i, * ,i. .;ri:. ... ............................ .,,:;:,,,;i: * :s,.;r:... ....................................... .::;::s; * ,1r::. .............,,,.,,:,,........................,;iir; * ,s;........... ..::.,;:,,. ...............,;1s * :i,..,. .,:,,::,. .......... .......;1, * ir,....:rrssr;:, ,,.,::. .r5S9989398G95hr;. ....,.:s, * ;r,..,s9855513XHAG3i .,,,,,,,. ,S931,.,,.;s;s&amp;BHHA8s.,..,..:r: * :r;..rGGh, :SAG;;G@BS:.,,,,,,,,,.r83: hHH1sXMBHHHM3..,,,,.ir. * ,si,.1GS, sBMAAX&amp;MBMB5,,,,,,:,,.:&amp;8 3@HXHBMBHBBH#X,.,,,,,,rr * ;1:,,SH: .A@&amp;&amp;B#&amp;8H#BS,,,,,,,,,.,5XS, 3@MHABM&amp;59M#As..,,,,:,is, * .rr,,,;9&amp;1 hBHHBB&amp;8AMGr,,,,,,,,,,,:h&amp;&amp;9s; r9&amp;BMHBHMB9: . .,,,,;ri. * :1:....:5&amp;XSi;r8BMBHHA9r:,......,,,,:ii19GG88899XHHH&amp;GSr. ...,:rs. * ;s. .:sS8G8GG889hi. ....,,:;:,.:irssrriii:,. ...,,i1, * ;1, ..,....,,isssi;, .,,. ....,.i1, * ;h: i9HHBMBBHAX9: . ...,,,rs, * ,1i.. :A#MBBBBMHB#s ....,,,;si. * .r1,.. ,..;3BMBBBHBB#Bh. .. ....,,,,,i1; * :h;.. .,..;,1XBMMMMBXs,.,, .. :: ,. ....,,,,,,ss. * ih: .. .;;;, ;;:s58A3i,.. ,. ,.:,,. ...,,,,,:,s1, * .s1,.... .,;sh, ,iSAXs;. ,. ,,.i85 ...,,,,,,:i1; * .rh: ... rXG9XBBM#M#MHAX3hss13&amp;&amp;HHXr .....,,,,,,,ih; * .s5: ..... i598X&amp;&amp;A&amp;AAAAAA&amp;XG851r: ........,,,,:,,sh; * . ihr, ... . .. ........,,,,,;11:. * ,s1i. ... ..,,,..,,,.,,.,,.,.. ........,,.,,.;s5i. * .:s1r,...................... ..............;shs, * . .:shr:. .... ..............,ishs. * .,issr;,... ...........................,is1s;. * .,is1si;:,....................,:;ir1sr;, * ..:isssssrrii;::::::;;iirsssssr;:.. * .,::iiirsssssssssrri;;:. */ 狗头212345678910111213141516171819202122232425262728293031323334353637383940/*** * ii. ;9ABH, * SA391, .r9GG35&amp;G * &amp;#ii13Gh; i3X31i;:,rB1 * iMs,:,i5895, .5G91:,:;:s1:8A * 33::::,,;5G5, ,58Si,,:::,sHX;iH1 * Sr.,:;rs13BBX35hh11511h5Shhh5S3GAXS:.,,::,,1AG3i,GG * .G51S511sr;;iiiishS8G89Shsrrsh59S;.,,,,,..5A85Si,h8 * :SB9s:,............................,,,.,,,SASh53h,1G. * .r18S;..,,,,,,,,,,,,,,,,,,,,,,,,,,,,,....,,.1H315199,rX, * ;S89s,..,,,,,,,,,,,,,,,,,,,,,,,....,,.......,,,;r1ShS8,;Xi * i55s:.........,,,,,,,,,,,,,,,,.,,,......,.....,,....r9&amp;5.:X1 * 59;.....,. .,,,,,,,,,,,... .............,..:1;.:&amp;s * s8,..;53S5S3s. .,,,,,,,.,.. i15S5h1:.........,,,..,,:99 * 93.:39s:rSGB@A; ..,,,,..... .SG3hhh9G&amp;BGi..,,,,,,,,,,,,.,83 * G5.G8 9#@@@@@X. .,,,,,,..... iA9,.S&amp;B##@@Mr...,,,,,,,,..,.;Xh * Gs.X8 S@@@@@@@B:..,,,,,,,,,,. rA1 ,A@@@@@@@@@H:........,,,,,,.iX: * ;9. ,8A#@@@@@@#5,.,,,,,,,,,... 9A. 8@@@@@@@@@@M; ....,,,,,,,,S8 * X3 iS8XAHH8s.,,,,,,,,,,...,..58hH@@@@@@@@@Hs ...,,,,,,,:Gs * r8, ,,,...,,,,,,,,,,..... ,h8XABMMHX3r. .,,,,,,,.rX: * :9, . .:,..,:;;;::,.,,,,,.. .,,. ..,,,,,,.59 * .Si ,:.i8HBMMMMMB&amp;5,.... . .,,,,,.sMr * SS :: h@@@@@@@@@@#; . ... . ..,,,,iM5 * 91 . ;:.,1&amp;@@@@@@MXs. . .,,:,:&amp;S * hS .... .:;,,,i3MMS1;..,..... . . ... ..,:,.99 * ,8; ..... .,:,..,8Ms:;,,,... .,::.83 * s&amp;: .... .sS553B@@HX3s;,. .,;13h. .:::&amp;1 * SXr . ...;s3G99XA&amp;X88Shss11155hi. ,;:h&amp;, * iH8: . .. ,;iiii;,::,,,,,. .;irHA * ,8X5; . ....... ,;iihS8Gi * 1831, .,;irrrrrs&amp;@ * ;5A8r. .:;iiiiirrss1H * :X@H3s....... .,:;iii;iiiiirsrh * r#h:;,...,,.. .,,:;;;;;:::,... .:;;;;;;iiiirrss1 * ,M8 ..,....,.....,,::::::,,... . .,;;;iiiiiirss11h * 8B;.,,,,,,,.,..... . .. .:;;;;iirrsss111h * i@5,:::,,,,,,,,.... . . .:::;;;;;irrrss111111 * 9Bi,:,,,,...... ..r91;;;;;iirrsss1ss1111 */ 滑稽笑脸12345678910111213141516171819202122232425262728293031323334/*** * .,, .,:;;iiiiiiiii;;:,,. .,, * rGB#HS,.;iirrrrriiiiiiiiiirrrrri;,s&amp;#MAS, * r5s;:r3AH5iiiii;;;;;;;;;;;;;;;;iiirXHGSsiih1, * .;i;;s91;;;;;;::::::::::::;;;;iS5;;;ii: * :rsriii;;r::::::::::::::::::::::;;,;;iiirsi, * .,iri;;::::;;;;;;::,,,,,,,,,,,,,..,,;;;;;;;;iiri,,. * ,9BM&amp;, .,:;;:,,,,,,,,,,,hXA8: ..,,,. * ,;&amp;@@#r:;;;;;::::,,. ,r,,,,,,,,,,iA@@@s,,:::;;;::,,. .;. * :ih1iii;;;;;::::;;;;;;;:,,,,,,,,,,;i55r;;;;;;;;;iiirrrr,.. * .ir;;iiiiiiiiii;;;;::::::,,,,,,,:::::,,:;;;iiiiiiiiiiiiri * iriiiiiiiiiiiiiiii;;;::::::::::::::::;;;iiiiiiiiiiiiiiiir; * ,riii;;;;;;;;;;;;;:::::::::::::::::::::::;;;;;;;;;;;;;;iiir. * iri;;;::::,,,,,,,,,,:::::::::::::::::::::::::,::,,::::;;iir: * .rii;;::::,,,,,,,,,,,,:::::::::::::::::,,,,,,,,,,,,,::::;;iri * ,rii;;;::,,,,,,,,,,,,,:::::::::::,:::::,,,,,,,,,,,,,:::;;;iir. * ,rii;;i::,,,,,,,,,,,,,:::::::::::::::::,,,,,,,,,,,,,,::i;;iir. * ,rii;;r::,,,,,,,,,,,,,:,:::::,:,:::::::,,,,,,,,,,,,,::;r;;iir. * .rii;;rr,:,,,,,,,,,,,,,,:::::::::::::::,,,,,,,,,,,,,:,si;;iri * ;rii;:1i,,,,,,,,,,,,,,,,,,:::::::::,,,,,,,,,,,,,,,:,ss:;iir: * .rii;;;5r,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sh:;;iri * ;rii;:;51,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.:hh:;;iir, * irii;::hSr,.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.,sSs:;;iir: * irii;;:iSSs:.,,,,,,,,,,,,,,,,,,,,,,,,,,,..:135;:;;iir: * ;rii;;:,r535r:...,,,,,,,,,,,,,,,,,,..,;sS35i,;;iirr: * :rrii;;:,;1S3Shs;:,............,:is533Ss:,;;;iiri, * .;rrii;;;:,;rhS393S55hh11hh5S3393Shr:,:;;;iirr: * .;rriii;;;::,:;is1h555555h1si;:,::;;;iirri:. * .:irrrii;;;;;:::,,,,,,,,:::;;;;iiirrr;, * .:irrrriiiiii;;;;;;;;iiiiiirrrr;,. * .,:;iirrrrrrrrrrrrrrrrri;:. * ..,:::;;;;:::,,. */ 键盘1234567891011121314151617/*** * ┌───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┐ * │Esc│ │ F1│ F2│ F3│ F4│ │ F5│ F6│ F7│ F8│ │ F9│F10│F11│F12│ │P/S│S L│P/B│ ┌┐ ┌┐ ┌┐ * └───┘ └───┴───┴───┴───┘ └───┴───┴───┴───┘ └───┴───┴───┴───┘ └───┴───┴───┘ └┘ └┘ └┘ * ┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───────┐ ┌───┬───┬───┐ ┌───┬───┬───┬───┐ * │~ `│! 1│@ 2│# 3│$ 4│% 5│^ 6│&amp; 7│* 8│( 9│) 0│_ -│+ =│ BacSp │ │Ins│Hom│PUp│ │N L│ / │ * │ - │ * ├───┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─────┤ ├───┼───┼───┤ ├───┼───┼───┼───┤ * │ Tab │ Q │ W │ E │ R │ T │ Y │ U │ I │ O │ P │&#123; [│&#125; ]│ | \\ │ │Del│End│PDn│ │ 7 │ 8 │ 9 │ │ * ├─────┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴─────┤ └───┴───┴───┘ ├───┼───┼───┤ + │ * │ Caps │ A │ S │ D │ F │ G │ H │ J │ K │ L │: ;│\" '│ Enter │ │ 4 │ 5 │ 6 │ │ * ├──────┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴────────┤ ┌───┐ ├───┼───┼───┼───┤ * │ Shift │ Z │ X │ C │ V │ B │ N │ M │&lt; ,│&gt; .│? /│ Shift │ │ ↑ │ │ 1 │ 2 │ 3 │ │ * ├─────┬──┴─┬─┴──┬┴───┴───┴───┴───┴───┴──┬┴───┼───┴┬────┬────┤ ┌───┼───┼───┐ ├───┴───┼───┤ E││ * │ Ctrl│ │Alt │ Space │ Alt│ │ │Ctrl│ │ ← │ ↓ │ → │ │ 0 │ . │←─┘│ * └─────┴────┴────┴───────────────────────┴────┴────┴────┴────┘ └───┴───┴───┘ └───────┴───┴───┘ */ 佛祖保佑123456789101112131415161718192021222324/*** * _ooOoo_ * o8888888o * 88\" . \"88 * (| -_- |) * O\\ = /O * ____/`---'\\____ * . ' \\\\| |// `. * / \\\\||| : |||// \\ * / _||||| -:- |||||- \\ * | | \\\\\\ - /// | | * | \\_| ''\\---/'' | | * \\ .-\\__ `-` ___/-. / * ___`. .' /--.--\\ `. . __ * .\"\" '&lt; `.___\\_&lt;|&gt;_/___.' &gt;'\"\". * | | : `- \\`.;`\\ _ /`;.`/ - ` : | | * \\ \\ `-. \\_ __\\ /__ _/ .-` / / * ======`-.____`-.___\\_____/___.-`____.-'====== * `=---=' * * ............................................. * 佛祖保佑 永无BUG */ 佛曰123456789101112/*** * 佛曰: * 写字楼里写字间，写字间里程序员； * 程序人员写程序，又拿程序换酒钱。 * 酒醒只在网上坐，酒醉还来网下眠； * 酒醉酒醒日复日，网上网下年复年。 * 但愿老死电脑间，不愿鞠躬老板前； * 奔驰宝马贵者趣，公交自行程序员。 * 别人笑我忒疯癫，我笑自己命太贱； * 不见满街漂亮妹，哪个归得程序员？ */ 佛祖瘫痪1234567891011121314151617181920212223/*** * _ooOoo_ * o8888888o * 88\" . \"88 * (| -_- |) * O\\ = /O * ___/`---'\\____ * . ' \\\\| |// `. * / \\\\||| : |||// \\ * / _||||| -:- |||||- \\ * | | \\\\\\ - /// | | * | \\_| ''\\---/'' | | * \\ .-\\__ `-` ___/-. / * ___`. .' /--.--\\ `. . __ * .\"\" '&lt; `.___\\_&lt;|&gt;_/___.' &gt;'\"\". * | | : `- \\`.;`\\ _ /`;.`/ - ` : | | * \\ \\ `-. \\_ __\\ /__ _/ .-` / / * ======`-.____`-.___\\_____/___.-`____.-'====== * `=---=' * ............................................. * 佛曰：bug泛滥，我已瘫痪！ */ Fuck Bug12345678910111213/*** * * █████▒█ ██ ▄████▄ ██ ▄█▀ ██████╗ ██╗ ██╗ ██████╗ * ▓██ ▒ ██ ▓██▒▒██▀ ▀█ ██▄█▒ ██╔══██╗██║ ██║██╔════╝ * ▒████ ░▓██ ▒██░▒▓█ ▄ ▓███▄░ ██████╔╝██║ ██║██║ ███╗ * ░▓█▒ ░▓▓█ ░██░▒▓▓▄ ▄██▒▓██ █▄ ██╔══██╗██║ ██║██║ ██║ * ░▒█░ ▒▒█████▓ ▒ ▓███▀ ░▒██▒ █▄ ██████╔╝╚██████╔╝╚██████╔╝ * ▒ ░ ░▒▓▒ ▒ ▒ ░ ░▒ ▒ ░▒ ▒▒ ▓▒ ╚═════╝ ╚═════╝ ╚═════╝ * ░ ░░▒░ ░ ░ ░ ▒ ░ ░▒ ▒░ * ░ ░ ░░░ ░ ░ ░ ░ ░░ ░ * ░ ░ ░ ░ ░ */ 哭脸神兽12345678910111213141516171819202122232425/*** * ┌─┐ ┌─┐ * ┌──┘ ┴───────┘ ┴──┐ * │ │ * │ ─── │ * │ ─┬┘ └┬─ │ * │ │ * │ ─┴─ │ * │ │ * └───┐ ┌───┘ * │ │ * │ │ * │ │ * │ └──────────────┐ * │ │ * │ ├─┐ * │ ┌─┘ * │ │ * └─┐ ┐ ┌───────┬──┐ ┌──┘ * │ ─┤ ─┤ │ ─┤ ─┤ * └──┴──┘ └──┴──┘ * 神兽保佑 * 代码无BUG! */ 害羞神兽12345678910111213141516171819202122232425/*** * ┌─┐ ┌─┐ * ┌──┘ ┴───────┘ ┴──┐ * │ │ * │ ─── │ * │ &gt; &lt; │ * │ │ * │ ... ⌒ ... │ * │ │ * └───┐ ┌───┘ * │ │ * │ │ * │ │ * │ └──────────────┐ * │ │ * │ ├─┐ * │ ┌─┘ * │ │ * └─┐ ┐ ┌───────┬──┐ ┌──┘ * │ ─┤ ─┤ │ ─┤ ─┤ * └──┴──┘ └──┴──┘ * 神兽保佑 * 代码无BUG! */ 墨镜神兽12345678910111213141516171819202122232425/*** * ┌─┐ ┌─┐ + + * ┌──┘ ┴───────┘ ┴──┐++ * │ │ * │ ─── │++ + + + * ███████───███████ │+ * │ │+ * │ ─┴─ │ * │ │ * └───┐ ┌───┘ * │ │ * │ │ + + * │ │ * │ └──────────────┐ * │ │ * │ ├─┐ * │ ┌─┘ * │ │ * └─┐ ┐ ┌───────┬──┐ ┌──┘ + + + + * │ ─┤ ─┤ │ ─┤ ─┤ * └──┴──┘ └──┴──┘ + + + + * 神兽保佑 * 代码无BUG! */ 蝙蝠123456789101112131415161718192021/*** * ___====-_ _-====___ * _--^^^###// \\\\###^^^--_ * _-^#####// ( ) \\\\#####^-_ * -######// |\\^^/| \\\\######- * _/######// (@::@) \\\\######\\_ * /#######(( \\\\// ))#######\\ * -########\\\\ (oo) //########- * -#########\\\\ / VV \\ //#########- * -##########\\\\/ \\//##########- * _#/|#####/\\###( /\\ )###/\\#####|\\#_ * |/ |#/\\#/\\#/\\/ \\#/\\#\\ | | /#/\\#/ \\/\\#/\\#/\\#| \\| * ` |/ V V ` V \\#\\| | | |/#/ V ' V V \\| ' * ` ` ` ` / | | | | \\ ' ' ' ' * ( | | | | ) * __\\ | | | | /__ * (vvv(VVV)(VVV)vvv) * 神兽保佑 * 代码无BUG! */ 飞天龙123456789101112131415161718192021222324/*** * * * __----~~~~~~~~~~~------___ * . . ~~//====...... __--~ ~~ * -. \\_|// |||\\\\ ~~~~~~::::... /~ * ___-==_ _-~o~ \\/ ||| \\\\ _/~~- * __---~~~.==~||\\=_ -_--~/_-~|- |\\\\ \\\\ _/~ * _-~~ .=~ | \\\\-_ '-~7 /- / || \\ / * .~ .~ | \\\\ -_ / /- / || \\ / * / ____ / | \\\\ ~-_/ /|- _/ .|| \\ / * |~~ ~~|--~~~~--_ \\ ~==-/ | \\~--===~~ .\\ * ' ~-| /| |-~\\~~ __--~~ * |-~~-_/ | | ~\\_ _-~ /\\ * / \\ \\__ \\/~ \\__ * _--~ _/ | .-~~____--~-/ ~~==. * ((-&gt;/~ '.|||' -_| ~~-/ , . _|| * -_ ~\\ ~~---l__i__i__i--~~_/ * _-~-__ ~) \\--______________--~~ * //.-~~~-~_--~- |-------~~~~~~~~ * //.-~~~--\\ * 神兽保佑 * 代码无BUG! */ 猪123456789101112131415/*** _ * _._ _..._ .-', _.._(`)) * '-. ` ' /-._.-' ',/ * ) \\ '. * / _ _ | \\ * | a a / | * \\ .-. ; * '-('' ).-' ,' ; * '-; | .' * \\ \\ / * | 7 .__ _.-\\ \\ * | | | ``/ /` / * /,_| | /,_/ / * /,_/ '`-' */ 骷髅头123456789101112131415161718192021222324/*** ************************************************************** * * * .=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-. * * | ______ | * * | .-\" \"-. | * * | / \\ | * * | _ | | _ | * * | ( \\ |, .-. .-. ,| / ) | * * | &gt; \"=._ | )(__/ \\__)( | _.=\" &lt; | * * | (_/\"=._\"=._ |/ /\\ \\| _.=\"_.=\"\\_) | * * | \"=._\"(_ ^^ _)\"_.=\" | * * | \"=\\__|IIIIII|__/=\" | * * | _.=\"| \\IIIIII/ |\"=._ | * * | _ _.=\"_.=\"\\ /\"=._\"=._ _ | * * | ( \\_.=\"_.=\" `--------` \"=._\"=._/ ) | * * | &gt; _.=\" \"=._ &lt; | * * | (_/ \\_) | * * | | * * '-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=' * * * * LASCIATE OGNI SPERANZA, VOI CH'ENTRATE * ************************************************************** */ 妈妈再爱我一次123456789101112131415161718192021222324252627282930313233/*** * ,s555SB@@&amp; * :9H##@@@@@Xi * 1@@@@@@@@@@@@@@8 * ,8@@@@@@@@@B@@@@@@8 * :B@@@@X3hi8Bs;B@@@@@Ah, * ,8i r@@@B: 1S ,M@@@@@@#8; * 1AB35.i: X@@8 . SGhr ,A@@@@@@@@S * 1@h31MX8 18Hhh3i .i3r ,A@@@@@@@@@5 * ;@&amp;i,58r5 rGSS: :B@@@@@@@@@@A * 1#i . 9i hX. .: .5@@@@@@@@@@@1 * sG1, ,G53s. 9#Xi;hS5 3B@@@@@@@B1 * .h8h.,A@@@MXSs, #@H1: 3ssSSX@1 * s ,@@@@@@@@@@@@Xhi, r#@@X1s9M8 .GA981 * ,. rS8H#@@@@@@@@@@#HG51;. .h31i;9@r .8@@@@BS;i; * .19AXXXAB@@@@@@@@@@@@@@#MHXG893hrX#XGGXM@@@@@@@@@@MS * s@@MM@@@hsX#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@&amp;, * :GB@#3G@@Brs ,1GM@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@B, * .hM@@@#@@#MX 51 r;iSGAM@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@8 * :3B@@@@@@@@@@@&amp;9@h :Gs .;sSXH@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@: * s&amp;HA#@@@@@@@@@@@@@@M89A;.8S. ,r3@@@@@@@@@@@@@@@@@@@@@@@@@@@r * ,13B@@@@@@@@@@@@@@@@@@@5 5B3 ;. ;@@@@@@@@@@@@@@@@@@@@@@@@@@@i * 5#@@#&amp;@@@@@@@@@@@@@@@@@@9 .39: ;@@@@@@@@@@@@@@@@@@@@@@@@@@@; * 9@@@X:MM@@@@@@@@@@@@@@@#; ;31. H@@@@@@@@@@@@@@@@@@@@@@@@@@: * SH#@B9.rM@@@@@@@@@@@@@B :. 3@@@@@@@@@@@@@@@@@@@@@@@@@@5 * ,:. 9@@@@@@@@@@@#HB5 .M@@@@@@@@@@@@@@@@@@@@@@@@@B * ,ssirhSM@&amp;1;i19911i,. s@@@@@@@@@@@@@@@@@@@@@@@@@@S * ,,,rHAri1h1rh&amp;@#353Sh: 8@@@@@@@@@@@@@@@@@@@@@@@@@#: * .A3hH@#5S553&amp;@@#h i:i9S #@@@@@@@@@@@@@@@@@@@@@@@@@A. * * * 又看源码，看你妹妹呀！ */ 初音12345678910111213141516171819202122232425/*** *_______________#####_______________________ *______________######_____________________ *______________#######____________________ *_____________#__######___________________ *____________##__###_###__________________ *____________##_####___##_________________ *___________##__#####_##________________ *__________##__######_##_______________ *________###___######__###_____________ *_______###___##_####___###___________ *_______###___##___####___###_________ *______###___##__######___###_______ *_____###___##_#######__###______ *____####__###########_####_____ *____####__###############____ *___####__###_#########_####___ *___####__###_###_#####___###___ *___####____#__###___###_____###___ *___####________###____###_____###____ *____###________###_____###_____##_____ *_____###________##______###_____##______ *______###______;##________##______#________ *________#_______##________##______________ */ 攻城湿123456789101112131415161718192021/*** * ,%%%%%%%%, * ,%%/\\%%%%/\\%% * ,%%%\\c \"\" J/%%% * %. %%%%/ o o \\%%% * `%%. %%%% _ |%%% * `%% `%%%%(__Y__)%%' * // ;%%%%`\\-/%%%' * (( / `%%%%%%%' * \\\\ .' | * \\\\ / \\ | | * \\\\/ ) | | * \\ /_ | |__ * (___________))))))) 攻城湿 * * _ _ * __ _(_)_ _(_) __ _ _ __ * \\ \\ / / \\ \\ / / |/ _` |'_ \\ * \\ V /| |\\ V /| | (_| | | | | * \\_/ |_| \\_/ |_|\\__,_|_| |_| */ 掘金1234567891011121314151617181920212223/*** * https://gold.xitu.io/ * １１１ １ * １１１ １１１１１１１１１１１１ １１１ * １１ １１１１１１１１１１１１ １１１１１ * １１ １１１ １１ １１１１１１１ * １１１１ １ １１１１１１１１１１１ １１１ １１１１ * １１１１１１ １１１１１１１１１１１ １１１１ １１１１１ * １１１１１１ １１ １１１１ １１１１１１ * １１ １１１１１１１１ １１ １１１１１１１１１１１１１１１１１１ * １１ １１１１１１１１１１１ １１１１１１１１１１１１１１１１１１１ * １１１１１１１１１ １１ １１ １１ １１ * １１１１１１１１１１１１１１１１１１ １１ * １１１１ １１１１１１１１１１１１ １１１１１１１１１１１１１１ * １１１１ １１ １１ １１１１１１１１１１１１１１ * １１ １１ １１ １１ １１１ １１ １１ １１１ * １１ １１ １１ １１ １１ １１１ １１ １１１ * １１ １１１ １１ １１ １１ １１１ １１ １１１ * １１１１ １１１ １１１１１１１１１ １１ １１１ １１ １１１１１１１ * １１１１１１ １１１１１１１１１１ １１１１１１１１１１１１１１１１１ * １１ １１１ １１１ １１１１１１１１１１１１１１１１１ */ 知乎123456789101112131415161718192021222324/*** * https://www.zhihu.com/ * _____ _____ _____ _____ * /\\ \\ /\\ \\ /\\ \\ /\\ \\ * /::\\____\\ /::\\ \\ /::\\ \\ /::\\ \\ * /:::/ / \\:::\\ \\ /::::\\ \\ /::::\\ \\ * /:::/ / \\:::\\ \\ /::::::\\ \\ /::::::\\ \\ * /:::/ / \\:::\\ \\ /:::/\\:::\\ \\ /:::/\\:::\\ \\ * /:::/____/ \\:::\\ \\ /:::/__\\:::\\ \\ /:::/__\\:::\\ \\ * /::::\\ \\ /::::\\ \\ /::::\\ \\:::\\ \\ /::::\\ \\:::\\ \\ * /::::::\\ \\ _____ ____ /::::::\\ \\ /::::::\\ \\:::\\ \\ /::::::\\ \\:::\\ \\ * /:::/\\:::\\ \\ /\\ \\ /\\ \\ /:::/\\:::\\ \\ /:::/\\:::\\ \\:::\\____\\ /:::/\\:::\\ \\:::\\ \\ * /:::/ \\:::\\ /::\\____\\/::\\ \\/:::/ \\:::\\____\\/:::/ \\:::\\ \\:::| |/:::/__\\:::\\ \\:::\\____\\ * \\::/ \\:::\\ /:::/ /\\:::\\ /:::/ \\::/ /\\::/ |::::\\ /:::|____|\\:::\\ \\:::\\ \\::/ / * \\/____/ \\:::\\/:::/ / \\:::\\/:::/ / \\/____/ \\/____|:::::\\/:::/ / \\:::\\ \\:::\\ \\/____/ * \\::::::/ / \\::::::/ / |:::::::::/ / \\:::\\ \\:::\\ \\ * \\::::/ / \\::::/____/ |::|\\::::/ / \\:::\\ \\:::\\____\\ * /:::/ / \\:::\\ \\ |::| \\::/____/ \\:::\\ \\::/ / * /:::/ / \\:::\\ \\ |::| ~| \\:::\\ \\/____/ * /:::/ / \\:::\\ \\ |::| | \\:::\\ \\ * /:::/ / \\:::\\____\\ \\::| | \\:::\\____\\ * \\::/ / \\::/ / \\:| | \\::/ / * \\/____/ \\/____/ \\|___| \\/____/ */ freebuf1234567891011121314151617181920212223242526272829/*** * http://www.freebuf.com/ * _.._ ,------------. * ,' `. ( We want you! ) * / __) __` \\ `-,----------' * ( (`-`(-') ) _.-' * /) \\ = / ( * /' |--' . \\ * ( ,---| `-.)__` * )( `-.,--' _`-. * '/,' ( Uu\", * (_ , `/,-' ) * `.__, : `-'/ /`--' * | `--' | * ` `-._ / * \\ ( * /\\ . \\. freebuf * / |` \\ ,-\\ * / \\| .) / \\ * ( ,'|\\ ,' : * | \\,`.`--\"/ &#125; * `,' \\ |,' / * / \"-._ `-/ | * \"-. \"-.,'| ; * / _/[\"---'\"\"] * : / |\"- ' * ' | / * ` | */ Alibaba12345678910111213141516171819202122232425262728293031323334353637/*** * https://campus.alibaba.com/ * `:::::::::::, * `::;:::::::;:::::::, ` * `::;;:::::::@@@@;:::::::` * ,:::::::::::::@ #@':::::` * :::::::::::::::'@@ @;:::: * ::::::::::::'@@@@'``` .+:::` * ::::::::::;@@@#. ,:::, * .::::::::+@#@` :::: * :::::::+@@' :::: * `:::::'@@: `:::. * ,::::@@: ` :::: * ;::::::@ .:::; * :;:::::;@` ` :::; * :::::::::@` @ ;:::: * :::::::::#` @` ,:::: * :::::::::@` +@ @ .::::` * .::::::'@@` `@@' @ ::::, * :::::::++@@@@@@@@@@. ::::; * ;:::::::+, `..` ::::: * ,::::::::', ::::: * :::::::::+, :::::` * :::::::::+@. ,::::.` `, * ::::::;;@+ .::;:: `; * :::::::@@ `:::;: `::`` * ::::::#@ ;:::: .::` * :::::;@ :::::` .;::` * :::::@ `:;::: `::::; * :::::# :::::. `,;::::: * :::::: ` ::::::,.,::::::::::. * ,::::::` .:: ::::::::::::::::;` * ;::::::::,````.,:::::, ::::::::::::::. * :::::::::::::::::: ` `::::::::::` * `::::::::::::, .:::. * `..` */ 小老鼠123456789101112131415/*** * http://www.flvcd.com/ * .--, .--, * ( ( \\.---./ ) ) * '.__/o o\\__.' * &#123;= ^ =&#125; * &gt; - &lt; * / \\ * // \\\\ * //| . |\\\\ * \"'\\ /'\"_.-~^`'-. * \\ _ /--' ` * ___)( )(___ * (((__) (__))) 高山仰止,景行行止.虽不能至,心向往之。 */ 顶12345678910111213141516/*** * 頂頂頂頂頂頂頂頂頂 頂頂頂頂頂頂頂頂頂 * 頂頂頂頂頂頂頂 頂頂 * 頂頂 頂頂頂頂頂頂頂頂頂頂頂 * 頂頂 頂頂頂頂頂頂頂頂頂頂頂 * 頂頂 頂頂 頂頂 * 頂頂 頂頂 頂頂頂 頂頂 * 頂頂 頂頂 頂頂頂 頂頂 * 頂頂 頂頂 頂頂頂 頂頂 * 頂頂 頂頂 頂頂頂 頂頂 * 頂頂 頂頂頂 * 頂頂 頂頂 頂頂 頂頂 * 頂頂頂頂 頂頂頂頂頂 頂頂頂頂頂 * 頂頂頂頂 頂頂頂頂 頂頂頂頂 */ 单身狗的凝视123456789101112131415/*** * ░░░░░░░░░░░░░░░░░░░░░░░░▄░░ * ░░░░░░░░░▐█░░░░░░░░░░░▄▀▒▌░ * ░░░░░░░░▐▀▒█░░░░░░░░▄▀▒▒▒▐ * ░░░░░░░▐▄▀▒▒▀▀▀▀▄▄▄▀▒▒▒▒▒▐ * ░░░░░▄▄▀▒░▒▒▒▒▒▒▒▒▒█▒▒▄█▒▐ * ░░░▄▀▒▒▒░░░▒▒▒░░░▒▒▒▀██▀▒▌ * ░░▐▒▒▒▄▄▒▒▒▒░░░▒▒▒▒▒▒▒▀▄▒▒ * ░░▌░░▌█▀▒▒▒▒▒▄▀█▄▒▒▒▒▒▒▒█▒▐ * ░▐░░░▒▒▒▒▒▒▒▒▌██▀▒▒░░░▒▒▒▀▄ * ░▌░▒▄██▄▒▒▒▒▒▒▒▒▒░░░░░░▒▒▒▒ * ▀▒▀▐▄█▄█▌▄░▀▒▒░░░░░░░░░░▒▒▒ * 单身狗就这样默默地看着你，一句话也不说。 */ 埃及法老1234567891011121314151617181920212223242526272829303132333435/*** * /88888888888888888888888888\\ * |88888888888888888888888888/ * |~~____~~~~~~~~~\"\"\"\"\"\"\"\"\"| * / \\_________/\"\"\"\"\"\"\"\"\"\"\"\"\"\\ * / | \\ \\ * / | 88 88 \\ \\ * / | 88 88 \\ \\ * / / \\ | * / | ________ \\ | * \\ | \\______/ / | * /\"\\ \\ \\____________ / | * | |__________\\_ | | / / * /\"\"\"\"\\ \\_------' '-------/ -- * \\____/,___________\\ -------/ * ------* | \\ * || | \\ * || | ^ \\ * || | | \\ \\ * || | | \\ \\ * || | | \\ \\ * \\| / /\"\"\"\\/ / * ------------- | | / * |\\--_ \\____/___/ * | |\\-_ | * | | \\_ | * | | \\ | * | | \\_ | * | | ----___ | * | | \\----------| * / | | ----------\"\"\\ * /\"\\--\"--_| | | \\ * |_______/ \\______________/ ) * \\___/ */ 耶123456789101112131415161718192021222324252627282930313233343536/*** * d*#$. * zP\"\"\"\"\"$e. $\" $o * 4$ '$ $\" $ * '$ '$ J$ $F * 'b $k $&gt; $ * $k $r J$ d$ * '$ $ $\" $~ * '$ \"$ '$E $ * $ $L $\" $F ... * $. 4B $ $$$*\"\"\"*b * '$ $. $$ $$ $F * \"$ R$ $F $\" $ * $k ?$ u* dF .$ * ^$. $$\" z$ u$$$$e * #$b $E.dW@e$\" ?$ * #$ .o$$# d$$$$c ?F * $ .d$$#\" . zo$&gt; #$r .uF * $L .u$*\" $&amp;$$$k .$$d$$F * $$\" \"\"^\"$$$P\"$P9$ * JP .o$$$$u:$P $$ * $ ..ue$\" \"\" $\" * d$ $F $ * $$ ....udE 4B * #$ \"\"\"\"` $r @$ * ^$L '$ $F * RN 4N $ * *$b d$ * $$k $F * $$b $F * $\"\" $F * '$ $ * $L $ * '$ $ * $ $ */ 台式电脑1234567891011121314151617181920/*** * ,----------------, ,---------, * ,-----------------------, ,\" ,\"| * ,\" ,\"| ,\" ,\" | * +-----------------------+ | ,\" ,\" | * | .-----------------. | | +---------+ | * | | | | | | -==----'| | * | | I LOVE DOS! | | | | | | * | | Bad command or | | |/----|`---= | | * | | C:\\&gt;_ | | | ,/|==== ooo | ; * | | | | | // |(((( [33]| ,\" * | `-----------------' |,\" .;'| |(((( | ,\" * +-----------------------+ ;; | | |,\" * /_)______________(_/ //' | +---------+ * ___________________________/___ `, * / oooooooooooooooo .o. oooo /, \\,\"----------- * / ==ooooooooooooooo==.o. ooo= // ,`\\--&#123;)B ,\" * /_==__==========__==_ooo__ooo=_/' /___________,\" * */ 书本123456789101112/*** * .-~~~~~~~~~-._ _.-~~~~~~~~~-. * __.' ~. .~ `.__ * .'// \\./ \\\\`. * .'// | \\\\`. * .'// .-~\"\"\"\"\"\"\"~~~~-._ | _,-~~~~\"\"\"\"\"\"\"~-. \\\\`. * .'//.-\" `-. | .-' \"-.\\\\`. * .'//______.============-.. \\ | / ..-============.______\\\\`. * .'______________________________\\|/______________________________`. * */ 人生12345678910111213141516171819202122/** * 出生 * || * || * \\ / * \\/ * 青年 * （年龄 = rand(20,25))） 《============== * || || * || || * || 祝福所有开发工作者 || * || 永远年轻 || * || || * \\ / || * \\/ || *（ 20 &lt;= 年龄 &lt;= 25） =============== * || * || * \\ / * \\/ * 等死状态 */ 比克大魔王12345678910111213141516171819202122232425/* _.---..._ ./^ ^-._ ./^C===. ^\\. /\\ .|' \\\\ _ ^|.^.| ___.--'_ ( ) . ./ /|| /.---^T\\ , | / /||| C' ._`| ._ / __,-/ / /-,|| \\ \\/ ; /O / _ |) )|, i \\./^O\\./_,-^/^ ,;-^,' \\ |`--/ ..-^^ |_-^ `| \\^- /|: i. .-- / '|. i ==' /' |\\._ _./`._ // |. ^-ooo.._ _.oo../' | ^-.__./X/ . `| |####b d## |' ^^^^ / | _\\#### ###b ^^^^^^^^--. ...--^--^^^^^^^_.d### ###b._ Y _.d##### #####b._ | _.d####### \"Piccolo\" no. 2 (from Dragonball Z) --- Steven J. Simmons */ Fuck you123456789101112131415161718192021/* * .::::. * .::::::::. * ::::::::::: FUCK YOU * ..:::::::::::' * '::::::::::::' * .:::::::::: * '::::::::::::::.. * ..::::::::::::. * ``:::::::::::::::: * ::::``:::::::::' .:::. * ::::' ':::::' .::::::::. * .::::' :::: .:::::::'::::. * .:::' ::::: .:::::::::' ':::::. * .::' :::::.:::::::::' ':::::. * .::' ::::::::::::::' ``::::. * ...::: ::::::::::::' ``::. * ```` ':. ':::::::::' ::::.. * '.:::::' ':'````.. */ 围棋12345678910111213141516171819202122232425262728293031323334 // _______________________________________ // / ___________________________________ \\// _--\"\"\"\"--_ / /_/_/_/_/_|_|_|_|_|_|_|_|_|_\\_\\_\\_\\_\\ \\// / \\ / /_/_/_/_J__L_L_L_|_|_|_J_J_J__L_\\_\\_\\_\\ \\// /\\ /\\ / /_/_/_J__L_J__L_L_|_|_|_J_J__L_J__L_\\_\\_\\ \\// L \"\"-____-\"\" J / /_/_J__L_J__L_J_J__L_|_J__L_L_J__L_J__L_\\_\\ \\// \\ / / /_/__L_/__L_J__L_J__L_|_J__L_J__L_J__\\_J__\\_\\ \\// \\_ _/ / /_J__/_J__/__L_J__|__L_|_J__|__L_J__\\__L_\\__L_\\ \\// _--\"\"\"\"\"--_\" / / F / F J J | F J | F J | F F J \\ J \\ \\// / \\ / /--/-J--/--L--|--L-J--J--|--L--L-J--|--J--\\--L-\\--\\ \\///\\ /\\ / /__/__L_J__J___L_J__J__|__|__|__L__L_J___L__L_J__\\__\\ \\//L \"\"-_____-\"\" J / / / / F F J J | | | | | F F J J \\ \\ \\ \\//\\ / / /--/--/--/--J---L--|--|--|--o--|--|--|--J---L--\\--\\--\\--\\ \\// \\_ _/ / /__/__J__J___L__J___L__L__L__|__J__J__J___L__J___L__L__\\__\\ \\// \"--___--\" / / / F F J F J J F | J F F J F J J \\ \\ \\// / /--/---/--J---L--J---L--|--J---|---L--|--J---L--J---L--\\---\\--\\ \\// / /__J___/___L__/___L__J___L__J___|___L__J___L__J___\\__J___\\___L__\\ \\// / / F J / J J | J J | F F | F F \\ F J \\ \\// / /---/---L--J---L---L---L--|---|---|---|---|--J---J---J---L--J---\\---\\ \\// / /___/___/___L__J___J___J___|___|___|___|___|___L___L___L__J___\\___\\___\\ \\// / / / / / F F F F F | J J J J J \\ \\ \\ \\ \\// / /___/___J___J___J___J___J____L___L___|___J___J____L___L___L___L___L___\\___\\ \\// / / / F F F | | J F | J F | | J J J \\ \\ \\// / /___J____/___/___J____L___L___|___J____|____L___|___J___J____L___\\___\\____L___\\ \\// / / F / J F J J | J | F | F F J F \\ J \\ \\// / /____/___J____L___/____L___|____L___|____|____|___J____|___J____\\___J____L___\\____\\ \\// / / / F / J J F J F | J F J F F \\ J \\ \\ \\// / /____/____/___J____L____|____L___J____L____|____J____L___J____|____J____L___\\____\\____\\ \\// / \\///_______________________________________________________________________________________________\\//| |//| hs |//|_______________________________________________________________________________________________| 居中的佛祖1234567891011121314151617181920212223/* _ooOoo_ o8888888o 88\" . \"88 (| -_- |) O\\ = /O ____/`---'\\____ .' \\\\| |// `. / \\\\||| : |||// \\ / _||||| -:- |||||- \\ | | \\\\\\ - /// | | | \\_| ''\\---/'' | | \\ .-\\__ `-` ___/-. / ___`. .' /--.--\\ `. . __ .\"\" '&lt; `.___\\_&lt;|&gt;_/___.' &gt;'\"\". | | : `- \\`.;`\\ _ /`;.`/ - ` : | | \\ \\ `-. \\_ __\\ /__ _/ .-` / /======`-.____`-.___\\_____/___.-`____.-'====== `=---='^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 佛祖保佑 永无BUG*/ windows图标123456789101112131415161718/* __ ,-~¨^ ^¨-, _, / / ;^-._...,¨/ / / / / / / / / / / / / /,.-:''-,_ / / / _,.-:--._ ^ ^:-._ __../ /^ / /¨:.._¨__.; / / / ^ / / / / / / / / / /_,.--:^-._/ / /^ ^¨¨-.___.:^ (R) - G33K */ 七龙珠比克1234567891011121314151617181920212223242526/* /^_.-^ _ --^=_ ./'-^__ _&gt;=\\^^==^-. |'/^^_/ /^ \\ \\.^\\\\\\/\\ ,|/| ' /' _____\\ `\\|.^.| |'/ /_--^^ . ^^-./ /|| |/,--^ , | / /||' ._|/ \\ / __,-/ / /-,|| \\ '/ ; /O / _ |) )|, i \\./^O\\./_,-^/^ ,;-^,' \\ |`--/ ..-^^ |_-^ `| \\^-_,/^Y\\ | ^^\\ _i. \\\".--V_/ /| \\. ^\\._____...--.&gt;^^^^^^-------...._ / i ^--^^ /'|' |\\. |./' | ;___...----/^^^^---|. `._\\ /^ /' |'_/' \\ `| |' ,/' |' \\ _|^-.__./'__.^^\\ .| ,| _.-^ `\\ ,|`_./^^-----^^._ ` ./ / /^ _.-^^/ |' ^ /-^ ./^ /\\ `\\_ __.-&lt; _,/ ./' |' `\\. `i ^^--/._____...--^ . ./ |. `| | / / `| \"Piccolo\" (from Dragonball Z) --- Steven J. Simmons */ 七龙珠悟空123456789101112131415161718192021222324252627282930313233/* _ \\\"-._ _.--\"~~\"--._ \\ \" ^. ___ / \\.-~_.-~ .-----' /\\/\"\\ /~-._ / / __ _/\\-.__\\L_.-/\\ \"-. /.-\" \\ ( ` \\_o&gt;\"&lt;o_/ \\ .--._\\ /' \\ \\: \" :/_/ \"` / /\\ \"\\ ~ /~\" \\ I \\/]\"-._ _.-\"[ ___ \\|___/ ./ l \\___ ___ .--v~ \"v` ( `-.__ __.-' ) ~v\" ~v--. .-&#123; | : \\_ \"~\" _/ : | &#125;-. / \\ | ~-.,___,.-~ | / \\ ] \\ | | / [ /\\ \\| : : |/ /\\ / ^._ _K.___,^ ^.___,K_ _.^ \\ / / \"~/ \"\\ /\" \\~\" \\ \\ / / / \\ _ : _ / \\ \\ \\ .^--./ / Y___________l___________Y \\ \\.--^. [ \\ / | [/ ] | \\ / ] | \"v\" l________[____/]________j -Row &#125;r\" / &#125;------t / \\ /`-. / | | Y Y / \"-._/ &#125;-----v' | : | 7-. / | |_| | l | / . \"-._/ l .[_] : \\ : r[]/_. / \\_____] \"--. \"-.____/ \"Dragonball Z\" ---Row */ 超级赛亚人123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134/* MMMMM MMMMMM MMMMMMM MMMMMMMM . MMMMMMMMM HMMMMMMMMMM MMMMMMMMMMMM M MMMMMMMMMMMMM M MMMMMMMMMMMMM M MMMMMMMMMMMMM: oMMMMMMMMMMMMMM .MMMMMMMMMMMMMMo MMMMMMMMMMMMMMM MMMMMMMMMMMMMMMMMMMMMMMMMMMM MMMMMMMMMMMMMMMM MMMMMMMMMMMMMMMMMMMMMMMMMMMM. oMMMMMMMMMMMMMMM.M MMMMMMMMMMMMMMMMMMMMMMMMMMMM MMMMMMMMMMMMMMMM MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM oMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM: H MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM . MMM MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM M MMMMMM .MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM M MMMMMMMMMM MM. MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM M MMMMMMMMMMMM MM MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM .MMMMMMMMMMMMMM MM MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM MM MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM .MMMMMMMMM MMMMMMMMMMMMMMMMMMMMMMMM.MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM HMMMMMMMMMMMMMMMMMMMMM.MMMMMMMMM.MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM MMMMMMMMMMMMMMM MMM.oMMMMMMM..MMMMMMMMM:MMMMMMMMMMMMMMMMMMMMMMM MMMMMMMMMMMMMM MM..MMMMMMM...MMMMMMM. MMMMMMMMMMMMMMMMMMMMM MMMMMMMMMMMMMMM ..MMMMMM...MMMMMM ..MMMMMMMMMMMMMMMMMMM MMMMMMM:M.MMM.M.. MMMMM M..MMMMM...MMMMMMMMMMMMMMMMMM MMM MMMM. .M..MM.M...MMMMMM..MMMMM.. MMMMMMMMMMMMMMMMMMMMMMMMMMMMMM . MMMM..M....M.....:MMM .MMMMMM..MMMMMMM...MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM MMM.M.. ...M......MM.MMMMM.......MHM.M .MMMMMMMMMMMMMMMMMMMMMMMMM MMMMMMMM..MM. . MMM.....MMMMMM.M.....M ..MM..M MMMMMMMMMMMMMMMMMMM .MMMMMHMM. ..MMMM. MMM............o..... . .MMMMMMMMMMMMMMM MMM. M... .........................M..:.MMMMMMMMMMMM oMMM............ .................M.M.MMMMMMMMM .....MM........................ . MMMMMM M.....M.....................o.MM.MMMMMMMM. M........................M.. ...MMMMMMMMMMMMMo :....MMM..............MMM..oMMMMMMM M...MMM.............MMMMMMM .............:MMMMMMMM M..... MMM.....M M M............. ................M ooM.................MM MoMMMMMoooM MMoooM......................MoooooooH..oMM MHooooMoM.....................MMooooooM........M oooooooMoooM......... o........MoooooooM............ Mooooooooooo.......M.........Moooooooo:..............M MooMoooooooooM...M........:Mooooooooooo:..............M M..oooooooooooo .........Mooooooooooooooo..............M M...Mooo:oooooooo.M....ooooooooooooooooooo..M...........M ...oooooMoooooooM..Mooooooooooooo:oooooooM.M...........M. M...ooooooMoo:ooooMoooooooooooooHoooooooooH:M. ...........: M..MoooooooMoooooooooooooooooo:ooooooMooooMoM..............M M..ooooooooooMooooooooooooooHoooooooMooHooooM...............M ...ooooooooooooooooooo:MooooooooooooooMoMoooM................ M...oooooooooooooooooooooooooooooooooooooMooMM................M ...MooooooooooooooooooooooooooooooooooooooooMo ................ ...MooooooooooooooooooooooooooooooooooooooooM M................M M...ooooooooooooooooooooooooooooooooooooooooM ................M ...MoooooooooooooooooooooooooooooooooooooooMM .:............... .....MooooooooooooooooooooooooooooooooooooMoo .............M M...... ooooooooooooooooooooooooooooooooooooM M..............M M........MooooMMM MM MM MMMMMMMMMooooooooM M...............M .........HM M: MM :MMMMMM M M............... M..........M M MoM M M................M M.........:M MoH M M M MooooHoooMM. M M...............M M..........Moooo MMooM oooooMooooooooM M..............H M.........MooooM Mooo : ooooooMooooMoooM M........ . .o.M H.. .....ooooo oooo M MooooooooooooooM M... MMMMMMMMMMM MMMMMMMMMMooooM M oooo . ooooooMooooooooM .MMMMMMMMMMMMMMM MMMMMMMMMMooooH : ooooH oooooooooooooooo MMMMMMMMMMMMMMM MMMMMMMMMMoooo ooooM Moooooooooooooooo .MMMMMMMMMMMMMMM MMMMMMMMMMoooo ooooM MooooooooooooooooM MMMMMMMMMMMMMMM MMMMMMMMMMoooM ooooM ooooooooooooooooo MMMMMMMMMMM:M MMMMMMMMMMoooM MooooM oooooooooooMoooooo MH........... . ......Mooo. MooooM oooooooooooooooooo M............M M.M......oooo MooooM Moooooooooooooooooo: .........M..... M.M.....Moooo MooooM ooooooooooooooooooM .M............ .......MooooH MooooM oooooooooMoooooooooo M..o...M..o....M .o....HMooooM MooooH MooooooooMooooooooooM .:M...M.......M M..M.....MoooM :oooo: .MooooooooHooMoooooooooM M M... ..oM.M M...M.:.Mooo. MMMMooooo oooooooooooMoooooooooooooM ....M. M M:M..o.Moooooooooooooo MooooooooooooooMooooooooooooM .Mo MooooooooooooooMooooooooooooMoMoooooooooooooo Mooooooooooooooo:ooooooooooooooooooooooooooooo ooooooooooooooooMooooooooooMoooooooooooooooooo ooooooooooooooooMoooooooooooMooooooooooooooooHo ooMooooooooooooooMoooooooooooooooooooooooooooMoM MooMoooooooooooooo.ooooooooooooooooooooooooooo:oM MoooooooooooooooooooooooooooooooooooooooooooooooM MoooMooooooooooooooMooooooooooooooooooooooooooooo. MoooMooooooooooooooMoooooooooooooooooooooooooMooooM MooooooooooooooooooMoooooooooooooooooooooooooMoooooM MooooMoooooooooooooMoooooooooooooooooooooooooMoHooooM ooooooMooooooooooooooooooooooooooooooooooooooooMoMoooM MooooooooooooooooooooMooooooooooooooooooooooooooMoooooH: MoooooooMooooooooooooMoooooooooooooooooooooooooooooHoooM MooooooooMoooooooooooMoooooooooooooooooooooooooMoooMooooM Moooooooooooooooooooooooooooooooooooooooooooooo.oooMooooo MoooooooooooooooooooooooooooooooooooooooooooooMoooooooooM MooooooooooooooooooooMoooooooooooooooooooooooooooooooooM MooooooooooooooooooooMHooooooooooooooooooooMoooo:ooooo MMooooooooooooooooooMoMHoooooooooooooooooooooooMooooo MMoooooooooooooooMMooo MMooooooooooooooooooooooooooM MMMoooooooooooooMooooo oooooooooooooooooooooMooooo MooMMoooooooooMoooMMoM ooooHooooooooooooooooMooooM MooooMooooooMooooMoooM MoooooMoooooooooooooMooooo ooooooMMooooooooMooooM MoooooooooMooooooooooooooM HooooooMoooooooMooooM HoooooooHooMooooooooooooo oooMoooooooooHoooM MoooooooooMoooooooooM HooooooooooooHM MooooooooMMoooooooM MMMMMMMMMMMMMM Moooooo:MooooHMM MMMMMMM: ... MMMMMMMMMMMMMM M............M MMMMMMMMM .... M.MM.......... M.............M M ..............MM M.............. MMMMM............MMMM ..MMMMMMMM ....M MMMMMMMMMMMMMMMMMMMMMMMM MMMMMMMMMMMMM...M .MMMMMMMMMMMMMMMMMMMMMMMMMM MMMMMMMMMMMMMMMMMM MMMMMMMMMMMMMMMMMMMMMMMMM MMMMMMMMMMMMMMMMMMM :MMMMMMMMMMMMMMMMMMH MMMMMMMMMMMMMMMMMMM By EBEN Jérôme MMMMMMMMMMMMMMMMMM MMMMMMMMMMMMMMM HMMMMMM */ 皮卡丘123456789101112131415161718192021222324252627282930313233343536373839404142/*quu..__ $$$b `---.__ \"$$b `--. ___.---uuudP `$$b `.__.------.__ __.---' $$$$\" . \"$b -' `-.-' $$$\" .'| \". d$\" _.' | `. / ...\" .' | `./ ..::-' _.' | / .:::-' .-' .' : ::''\\ _.' | .' .-. .-. `. .' | : /'$$| .@\"$\\ `. .' _.-' .'|$u$$| |$$,$$| | &lt; _.-' | `:$$:' :$$$$$: `. `. .-' : `\"--' | `-. \\ :#. == .##. `. `. `\\ |#: :##: | &gt; &gt; |#' `..'`..' `##' x: / / \\ xXX| / ./ \\ xXXX'| / ./ /`-. `. / / : `- ..........., | / .' | ``:::::::' . |&lt; `. | ``` | x| \\ `.:``. | .' /' xXX| `:`M`M':. | | ; /:' xXXX'| -'MMMMM:' `. .' : /:' |-'MMMM.-' | | .' /' .'MMM.-' `'`' : ,' |MMM&lt; | `' |tbap\\ \\ :MM.-' \\ | .'' \\. `. / / .:::::::.. : / | .:::::::::::`. / | .:::------------\\ / / .'' &gt;::' / `',: : .' `:.:' */","tags":"springboot"},{"title":"Nginx应用场景","url":"/posts/cd76424b.html","text":"反向代理反向代理：简单来说就是真实的服务器不能直接被外部网络访问，所以需要一台代理服务器，而代理服务器能被外部网络访问的同时又跟真实服务器在同一个网络环境，当然也可能是同一台服务器，端口不同而已。 下面贴上一段简单的实现反向代理的代码： 123456789server &#123; listen 80; server_name localhost; client_max_body_size 1024M; location / &#123; proxy_pass http://localhost:8080; proxy_set_header Host $host:$server_port; &#125;&#125; 保存配置文件后启动Nginx，这样当我们访问localhost的时候，就相当于访问 localhost:8080 了。 负载均衡负载均衡其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其他关键任务服务器等，从而共同完成工作任务。 简单而言就是当有2台或以上服务器时，根据规则随机的将请求分发到指定的服务器上处理，负载均衡配置一般都需要同时配置反向代理，通过反向代理跳转到负载均衡。而Nginx目前支持自带3种负载均衡策略，还有2种常用的第三方策略。 RR(默认)每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 12345678910111213upstream test &#123; server localhost:8080; server localhost:8081; &#125; server &#123; listen 81; server_name localhost; client_max_body_size 1024M; location / &#123; proxy_pass http://test; proxy_set_header Host $host:$server_port; &#125; &#125; 负载均衡的核心代码: 1234upstream test &#123; server localhost:8080; server localhost:8081; &#125; 权重指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 例如 1234upstream test &#123; server localhost:8080 weight=9; server localhost:8081 weight=1; &#125; 那么10次一般只会有1次会访问到8081，而有9次会访问到8080。 ip_hash（session保持）上面的2种方式都有一个问题，那就是下一个请求来的时候请求可能分发到另外一个服务器，当我们的程序不是无状态的时候(采用了session保存数据)，这时候就有一个很大的很问题了，比如把登录信息保存到了session中，那么跳转到另外一台服务器的时候就需要重新登录了，所以很多时候我们需要一个客户只访问一个服务器，那么就需要用iphash了，iphash的每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 12345upstream test &#123; ip_hash; server localhost:8080; server localhost:8081; &#125; fair(第三方)按后端服务器的响应时间来分配请求，响应时间短的优先分配。 12345upstream backend &#123; fair; server localhost:8080; server localhost:8081;&#125; url_hash(第三方)按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法 123456upstream backend &#123; hash $request_uri; hash_method crc32; server localhost:8080; server localhost:8081; &#125; HTTP服务器Nginx本身也是一个静态资源的服务器，当只有静态资源的时候，就可以使用Nginx来做服务器，同时现在也很流行动静分离，就可以通过Nginx来实现，首先看看Nginx做静态资源服务器。 123456789server &#123; listen 80; server_name localhost; client_max_body_size 1024M; location / &#123; root E:/wwwroot; index index.html; &#125; &#125; 这样如果访问就会默认访问到E盘wwwroot目录下面的index.html，如果一个网站只是静态页面的话，那么就可以通过这种方式来实现部署。 动静分离动静分离是让动态网站里的动态网页根据一定规则把不变的资源和经常变的资源区分开来，动静资源做好了拆分以后，我们就可以根据静态资源的特点将其做缓存操作，这就是网站静态化处理的核心思路。 123456789101112131415161718192021222324upstream test&#123; server localhost:8080; server localhost:8081; &#125; server &#123; listen 80; server_name localhost; location / &#123; root e:/wwwroot; index index.html; &#125; # 所有静态请求都由nginx处理，存放目录为html location ~ .(gif|jpg|jpeg|png|bmp|swf|css|js)$ &#123; root e:/wwwroot; &#125; # 所有动态请求都转发给tomcat处理 location ~ .(jsp|do)$ &#123; proxy_pass http://test; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root e:/wwwroot; &#125; &#125; 这样就可以将HTML以及图片和css以及js放到wwwroot目录下，而tomcat只负责处理jsp和请求，例如当后缀为gif的时候，Nginx默认会从wwwroot获取到当前请求的动态图文件返回，当然这里的静态文件跟Nginx是同一台服务器，也可以在另外一台服务器，然后通过反向代理和负载均衡配置过去就好了 Nginx 配置文件结构12345678910111213141516171819202122232425... #全局块events &#123; #events块 ...&#125;http #http块&#123; ... #http全局块 server #server块 &#123; ... #server全局块 location [PATTERN] #location块 &#123; ... &#125; location [PATTERN] &#123; ... &#125; &#125; server &#123; ... &#125; ... #http全局块&#125; 全局块：配置影响nginx全局的指令。一般有运行nginx服务器的用户组，nginx进程pid存放路径，日志存放路径，配置文件引入，允许生成worker process数等。events块：配置影响nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网路连接，开启多个网络连接序列化等。http块：可以嵌套多个server，配置代理，缓存，日志定义等绝大多数功能和第三方模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，连接超时时间，单连接请求数等。server块：配置虚拟主机的相关参数，一个http中可以有多个server。location块：配置请求的路由，以及各种页面的处理情况。 附上一个配置文件，作为参考理解 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556########### 每个指令必须有分号结束。##################user administrator administrators; #配置用户或者组，默认为nobody nobody。#worker_processes 2; #允许生成的进程数，默认为1#pid /nginx/pid/nginx.pid; #指定nginx进程运行文件存放地址error_log log/error.log debug; #制定日志路径，级别。这个设置可以放入全局块，http块，server块，级别以此为：debug|info|notice|warn|error|crit|alert|emergevents &#123; accept_mutex on; #设置网路连接序列化，防止惊群现象发生，默认为on multi_accept on; #设置一个进程是否同时接受多个网络连接，默认为off #use epoll; #事件驱动模型，select|poll|kqueue|epoll|resig|/dev/poll|eventport worker_connections 1024; #最大连接数，默认为512&#125;http &#123; include mime.types; #文件扩展名与文件类型映射表 default_type application/octet-stream; #默认文件类型，默认为text/plain #access_log off; #取消服务日志 log_format myFormat &apos;$remote_addr–$remote_user [$time_local] $request $status $body_bytes_sent $http_referer $http_user_agent $http_x_forwarded_for&apos;; #自定义格式 access_log log/access.log myFormat; #combined为日志格式的默认值 sendfile on; #允许sendfile方式传输文件，默认为off，可以在http块，server块，location块。 sendfile_max_chunk 100k; #每个进程每次调用传输数量不能大于设定的值，默认为0，即不设上限。 keepalive_timeout 65; #连接超时时间，默认为75s，可以在http，server，location块。 upstream mysvr &#123; server 127.0.0.1:7878; server 192.168.10.121:3333 backup; #热备 &#125; error_page 404 https://www.baidu.com; #错误页 server &#123; keepalive_requests 120; #单连接请求上限次数。 listen 4545; #监听端口 server_name 127.0.0.1; #监听地址 location ~*^.+$ &#123; #请求的url过滤，正则匹配，~为区分大小写，~*为不区分大小写。 #root path; #根目录 #index vv.txt; #设置默认页 proxy_pass http://mysvr; #请求转向mysvr 定义的服务器列表 deny 127.0.0.1; #拒绝的ip allow 172.18.5.54; #允许的ip &#125; &#125;&#125; 上面是nginx的基本配置，需要注意的有以下几点： $remote_addr 与$http_x_forwarded_for 用以记录客户端的ip地址； $remote_user ：用来记录客户端用户名称； $time_local ： 用来记录访问时间与时区；$request ： 用来记录请求的url与http协议；$status ： 用来记录请求状态；成功是200； $body_bytes_s ent ：记录发送给客户端文件主体内容大小；$http_referer ：用来记录从那个页面链接访问过来的； $http_user_agent ：记录客户端浏览器的相关信息；惊群现象：一个网路连接到来，多个睡眠的进程被同时叫醒，但只有一个进程能获得链接，这样会影响系统性能。每个指令必须有分号结束。","tags":"nginx"},{"title":"Java多态","url":"/posts/7b7480f6.html","text":"定义对于同一个类型的不同实例对象，同一个行为具备不同的表现形式。 作用 消除同一类型之间的耦合关系； 使得不同对象对于同一行为具备多种表现形式； 原理变量的静态类型 &amp; 动态类型 变量的静态类型 = 引用类型 = 编译时变量 ：不会被改变、在编译器可知变量的动态类型 = 实例对象类型 = 运行时变量 ：会变化、在运行期才可知 如下示例： 1234567891011121314151617181920public class Test &#123; // Human是 Man与Human的父类 static abstract class Human &#123; &#125; static class Man extends Human &#123; &#125; static class Woman extends Human &#123; &#125; // 执行代码public static void main(String[] args) &#123; Human man = new Man(); // 变量man的静态类型 = 引用类型 = 编译时变量 = Human：不会被改变、在编译器可知 // 变量man的动态类型 = 实例对象类型 = 运行时变量 = Man ：会变化、在运行期才可知 &#125; &#125; 实现原理通过将 子类对象实例 赋值给 父类引用变量，使得编译时的静态变量 与 运行时的动态变量不一样，在调用方法 / 变量时，多态就发生了。 应用示例： 123456// 设 B类是A类的子类A b = new B(); //编译时变量 = A b 、运行时变量 = new B()b.name; // 调用了父类A的成员变量name b.move(); // 调用的是子类B重写后的2个方法move（）、content（）b.content(); 结论：因将 子类对象引用 赋值给 父类对象变量，即A a = new B()，即 编译时变量和运行时变量不一样，所以多态发生 实现过程（直接指针访问） JVM 通过 引用类型（reference，即A的引用）查询Java栈中的本地变量表，得到堆中的对象类型的数据地址； 根据地址，从而找到方法区中的对象类型数据（B的对象类型数据）； 查询对象类型数据中的方发表定位到实际类(B类)的方法，从而运行。 对于A a = new B() 数据存储方式 对于 A a：作为引用类型数据，存储在JVM栈的本地变量表中； 对于 new B()： 作为示例对象数据存储在堆中； B的对象实例数据（接口、方法、对象类型等）的地址存储在堆中； B的对象类型数据（对象实例数据的地址所执行的数据）存储在方法区中，在方法区中，对象类型数据中有1个指向该类方法的方发表； 引用类型访问实现方式 Java程序通过 栈上的引用类型数据（reference） 来访问Java堆上的对象。 由于引用类型数据（reference）在 Java虚拟机中只规定了一个指向对象的引用，但没定义该引用应该通过何种方式去定位、访问堆中的对象的具体位置所以对象访问方式 取决于 虚拟机实现。目前主流的对象访问方式有两种： 句柄访问 直接指针访问 多态实现方式方法重载(Overload)定义同一个类中具备多个重名的方法。 特点 方法名字必须相同； 参数列表必须不同：个数不同；个数不同但对应参数类型不同； 返回类型/访问修饰符可同可不同； 可声明新的或更广的检查异常； 能够在同一个类或子类中被重载； 应用场景针对同一类的对象，对于不同条件同一行为的不同表现； 原理静态分派，发生在编译阶段。 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package main.java.com.study.polymorphic;/** * @author: whb * @description: 方法重载测试 */public class OverloadTest &#123; /** * 类定义 */ static abstract class Human &#123; &#125; /** * 继承自抽象类Human */ static class Man extends Human &#123; &#125; static class Woman extends Man &#123; &#125; /** * 定义的重载方法（方法名相同，但参数列表不同（此处是类型不同）） * * @param guy */ public void sayHello(Human guy) &#123; System.out.println(\"hello,guy!\"); &#125; public void sayHello(Man guy) &#123; System.out.println(\"hello gentleman!\"); &#125; public void sayHello(Woman guy) &#123; System.out.println(\"hello lady!\"); &#125; public static void main(String[] args) &#123; Human man = new Man(); Man woman = new Woman(); OverloadTest test = new OverloadTest(); test.sayHello(man); test.sayHello(woman); &#125;&#125; 执行结果： 12hello,guy!hello gentleman! 结果解析： 方法重载（OverLoad）的原理 = 静态分派 = 根据 变量的静态类型 确定执行（重载）哪个方法; 所以上述的方法执行时，是根据变量（man、woman）的静态类型（Human、Man）确定重载sayHello()中参数为Human guy、Man guy的方法,即sayHello(Human guy)、sayHello(Man guy) ; 方法重写(Override)定义子类重写父类方法的实现。 特点 返回值、函数名、形参都不能改变，即外壳不变，重写内在实现； 不能被重写的方法：构造方法；不能继承/不具备访问权限的方法(如private)；声明为final、static的方法； 子类方法不能缩小父类方法的访问权限； 子类方法不能比父类方法抛出更广的异常； 原理动态分派，发生在运行阶段。 示例1234567891011121314151617181920212223242526272829303132333435363738394041424344package main.java.com.study.polymorphic;/** * @author: whb * @description: 方法重写测试类 */public class OverrideTest &#123; // 测试代码 public static void main(String[] args) &#123; // 情况1 Human man = new Man(); man.sayHello(); // 情况2 man = new Woman(); man.sayHello(); &#125; /** * 定义父类 */ static class Human &#123; public void sayHello() &#123; System.out.println(\"Human say hello\"); &#125; &#125; /** * 继承类Human 并 重写sayHello() */ static class Man extends Human &#123; @Override public void sayHello() &#123; System.out.println(\"man say hello\"); &#125; &#125; static class Woman extends Human &#123; @Override public void sayHello() &#123; System.out.println(\"woman say hello\"); &#125; &#125;&#125; 执行结果 12man say hellowoman say hello 结果分析 方法重写（Override） = 动态分派 = 根据 变量的动态类型 确定执行（重写）哪个方法; 对于情况1：根据变量（Man）的动态类型（man）确定调用man中的重写方法sayHello(); 对于情况2：根据变量（Man）的动态类型（woman）确定调用woman中的重写方法sayHello(); 方法重载、方法重写对比","tags":"java"},{"title":"Windows-常见问题及实用技巧（持续更新）","url":"/posts/e5866ae9.html","text":"快速提取某一文件夹下所有文件名称 在需要获取文件名的文件夹中新建一个txt格式的记事本文件。在记事本文件中输入：DIR . /B &gt;LIST.TXT将此记事本文件后辍名，由txt改为bat。会弹出重命名对话框，单击“是”。双击文件“新建文本文档.bat”即可生成list.txt文件。打开txt文件就可以看到当前文件夹内的所有文件名列表。 一键获取新电脑硬件信息bat脚本内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110@echo offcolor 0atitle 硬件检测 mode con cols=90sc config winmgmt start= auto &gt;nul 2&lt;&amp;1net start winmgmt 2&gt;1nulsetlocal ENABLEDELAYEDEXPANSIONecho 主版:for /f &quot;tokens=1,* delims==&quot; %%a in (&apos;wmic BASEBOARD get Manufacturer^,Product^,Version^,SerialNumber /value&apos;) do ( set /a tee+=1 if &quot;!tee!&quot; == &quot;3&quot; echo 制造商 = %%b if &quot;!tee!&quot; == &quot;4&quot; echo 型 号 = %%b if &quot;!tee!&quot; == &quot;5&quot; echo 序列号 = %%b if &quot;!tee!&quot; == &quot;6&quot; echo 版 本 = %%b)set tee=0echo BIOS:for /f &quot;tokens=1,* delims==&quot; %%a in (&apos;wmic bios get CurrentLanguage^,Manufacturer^,SMBIOSBIOSVersion^,SMBIOSMajorVersion^,SMBIOSMinorVersion^,ReleaseDate /value&apos;) do ( set /a tee+=1 if &quot;!tee!&quot; == &quot;3&quot; echo 当前语言 = %%b if &quot;!tee!&quot; == &quot;4&quot; echo 制造商 = %%b if &quot;!tee!&quot; == &quot;5&quot; echo 发行日期 = %%b if &quot;!tee!&quot; == &quot;6&quot; echo 版 本 = %%b if &quot;!tee!&quot; == &quot;7&quot; echo SMBIOSMajorVersion = %%b if &quot;!tee!&quot; == &quot;8&quot; echo SMBIOSMinorVersion = %%b )set tee=0echo.echo CPU:for /f &quot;tokens=1,* delims==&quot; %%a in (&apos;wmic cpu get name^,ExtClock^,CpuStatus^,Description /value&apos;) do ( set /a tee+=1 if &quot;!tee!&quot; == &quot;3&quot; echo CPU个数 = %%b if &quot;!tee!&quot; == &quot;4&quot; echo 处理器版本 = %%b if &quot;!tee!&quot; == &quot;5&quot; echo 外 频 = %%b if &quot;!tee!&quot; == &quot;6&quot; echo 名称及主频率 = %%b)set tee=0echo.echo 显示器:for /f &quot;tokens=1,* delims==&quot; %%a in (&apos;wmic DESKTOPMONITOR get name^,ScreenWidth^,ScreenHeight^,PNPDeviceID /value&apos;) do ( set /a tee+=1 if &quot;!tee!&quot; == &quot;3&quot; echo 类 型 = %%b if &quot;!tee!&quot; == &quot;4&quot; echo 其他信息 = %%b if &quot;!tee!&quot; == &quot;5&quot; echo 屏幕高 = %%b if &quot;!tee!&quot; == &quot;6&quot; echo 屏幕宽 = %%b)set tee=0echo.echo 硬 盘:for /f &quot;tokens=1,* delims==&quot; %%a in (&apos;wmic DISKDRIVE get model^,interfacetype^,size^,totalsectors^,partitions /value&apos;) do ( set /a tee+=1 if &quot;!tee!&quot; == &quot;3&quot; echo 接口类型 = %%b if &quot;!tee!&quot; == &quot;4&quot; echo 硬盘型号 = %%b if &quot;!tee!&quot; == &quot;5&quot; echo 分区数 = %%b if &quot;!tee!&quot; == &quot;6&quot; echo 容 量 = %%b if &quot;!tee!&quot; == &quot;7&quot; echo 总扇区 = %%b)echo 分区信息:wmic LOGICALDISK where mediatype=&apos;12&apos; get description,deviceid,filesystem,size,freespaceset tee=0echo.echo 网 卡:for /f &quot;tokens=1,* delims==&quot; %%a in (&apos;wmic NICCONFIG where &quot;index=&apos;1&apos;&quot; get ipaddress^,macaddress^,description /value&apos;) do ( set /a tee+=1 if &quot;!tee!&quot; == &quot;3&quot; echo 网卡类型 = %%b if &quot;!tee!&quot; == &quot;4&quot; echo 网卡IP = %%b if &quot;!tee!&quot; == &quot;5&quot; echo 网卡MAC = %%b)set tee=0echo.echo 打印机:for /f &quot;tokens=1,* delims==&quot; %%a in (&apos;wmic PRINTER get caption /value&apos;) do ( set /a tee+=1 if &quot;!tee!&quot; == &quot;3&quot; echo 打印机名字 = %%b)set tee=0echo.echo 声 卡:for /f &quot;tokens=1,* delims==&quot; %%a in (&apos;wmic SOUNDDEV get name^,deviceid /value&apos;) do ( set /a tee+=1 if &quot;!tee!&quot; == &quot;3&quot; echo 其他信息 = %%b if &quot;!tee!&quot; == &quot;4&quot; echo 型 号 = %%b)set tee=0echo.echo 内 存: for /f &quot;tokens=1,* delims==&quot; %%a in (&apos;systeminfo^|find &quot;内存&quot;&apos;) do ( echo %%a 4534 %%b )echo.echo 显 卡:del /f &quot;%TEMP%\\temp.txt&quot; 2&gt;nuldxdiag /t %TEMP%\\temp.txt:显卡rem 这里需要30秒左右!if EXIST &quot;%TEMP%\\temp.txt&quot; ( for /f &quot;tokens=1,2,* delims=:&quot; %%a in (&apos;findstr /c:&quot; Card name:&quot; /c:&quot;Display Memory:&quot; /c:&quot;Current Mode:&quot; &quot;%TEMP%\\temp.txt&quot;&apos;) do ( set /a tee+=1 if !tee! == 1 echo 显卡型号: %%b if !tee! == 2 echo 显存大小: %%b if !tee! == 3 echo 当前设置: %%b) ) else ( ping /n 2 127.1&gt;nul goto 显卡)set /p var=需要额外信息吗(y/n): if /i %var% == y notepad &quot;%TEMP%\\temp.txt&quot;del /f &quot;%TEMP%\\temp.txt&quot; 2&gt;nulpause 只需要新建一个txt，复制上面代码后修改后缀名为bat(本来为txt),然后右键以管理员身份运行就可以了。 查看进程使用的端口1netstat -nbaov","tags":"windows"},{"title":"MySQL中的函数总结","url":"/posts/578ec873.html","text":"CONCAT()函数CONCAT（）函数用于将多个字符串连接成一个字符串。使用数据表sys_user作为示例，sql如下： SELECT user_id as id,zwxm as name FROM sys_user LIMIT 1; 返回结果如下： 12345+----+--------+| id | name |+----+--------+| 1 | 张三 |+----+--------+ 1、语法及使用特点： CONCAT(str1,str2,…)返回结果为连接参数产生的字符串。如有任何一个参数为NULL ，则返回值为 NULL。可以有一个或多个参数。 2、使用示例： SELECT CONCAT(user_id, ‘，’, zwxm) AS con FROM sys_user LIMIT 1;返回结果如下： 12345+----------+| con |+----------+| 1,张三 |+----------+ SELECT CONCAT(‘My’, NULL, ‘QL’); 返回结果如下： 12345+--------------------------+| CONCAT(&apos;My&apos;, NULL, &apos;QL&apos;) |+--------------------------+| NULL |+--------------------------+ CONCAT_WS()函数使用语法为：· CONCAT_WS(separator,str1,str2,…) ·CONCAT_WS() 代表 CONCAT With Separator ，是CONCAT()的特殊形式。第一个参数是其它参数的分隔符。分隔符的位置放在要连接的两个字符串之间。分隔符可以是一个字符串，也可以是其它参数。如果分隔符为 NULL，则结果为 NULL。函数会忽略任何分隔符参数后的 NULL 值。但是CONCAT_WS()不会忽略任何空字符串。 (然而会忽略所有的 NULL）。 示例1： SELECT CONCAT_WS(&#39;_&#39;,user_id,zwxm) AS con_ws FROM sys_user LIMIT 1; 返回结果： 12345+----------+| con_ws |+----------+| 1_张三 |+----------+ 示例2： SELECT CONCAT_WS(&#39;,&#39;,&#39;First name&#39;,NULL,&#39;Last Name&#39;); 返回结果： 12345+----------------------------------------------+| CONCAT_WS(&apos;,&apos;,&apos;First name&apos;,NULL,&apos;Last Name&apos;) |+----------------------------------------------+| First name,Last Name |+----------------------------------------------+ GROUP_CONCAT()函数语法如下： group_concat([DISTINCT] 要连接的字段 [Order BY ASC/DESC 排序字段] [Separator ‘分隔符’]) 基本查询： 123456789101112mysql&gt; select * from test; +------+------+ | id| name | +------+------+ |1 | 10 | |1 | 20 | |1 | 20 | |2 | 20 | |3 | 200 | |3 | 500 | +------+------+ 6 rows in set (0.00 sec) 以id分组，把name字段的值打印在一行，逗号分隔(默认) 123456789mysql&gt; select id,group_concat(name) from test group by id; +------+--------------------+ | id | group_concat(name) | +------+--------------------+ |1 | 10,20,20 | |2 | 20 | |3 | 200,500 | +------+--------------------+ 3 rows in set (0.00 sec) 以id分组，把name字段的值打印在一行，分号分隔 123456789mysql&gt; select id,group_concat(name separator &apos;;&apos;) from test group by id; +------+----------------------------------+ | id | group_concat(name separator &apos;;&apos;) | +------+----------------------------------+ |1 | 10;20;20 | |2 | 20 | |3 | 200;500 | +------+----------------------------------+ 3 rows in set (0.00 sec) 以id分组，把去冗余的name字段的值打印在一行，逗号分隔 123456789mysql&gt; select id,group_concat(distinct name) from test group by id; +------+-----------------------------+ | id | group_concat(distinct name) | +------+-----------------------------+ |1 | 10,20 | |2 | 20 | |3 | 200,500 | +------+-----------------------------+ 3 rows in set (0.00 sec) 以id分组，把name字段的值打印在一行，逗号分隔，以name排倒序 123456789mysql&gt; select id,group_concat(name order by name desc) from test group by id; +------+---------------------------------------+ | id | group_concat(name order by name desc) | +------+---------------------------------------+ |1 | 20,20,10 | |2 | 20 | |3 | 500,200 | +------+---------------------------------------+ 3 rows in set (0.00 sec) 使用group_concat_max_len系统变量，你可以设置允许的最大长度。 程序中进行这项操作的语法如下，其中 val 是一个无符号整数：SET [SESSION | GLOBAL] group_concat_max_len = val;若已经设置了最大长度， 则结果被截至这个最大长度。将环境变量group_concat_max_len 增大。默认是1024.我就设置了session级的环境变量将其变为2048（不够用再加大）","tags":"数据库 mysql"},{"title":"Linux-常见问题及实用技巧（持续更新）","url":"/posts/22401d2a.html","text":"虚拟机安装linux提示intel VT-x处于禁用状态问题描述我们在第一次使用虚拟机启动linux的时候经常会碰到下面这个报错，如下： 已将该虚拟机配置为使用 64 位客户机操作系统。但是，无法执行 64 位操作。此主机支持 Intel VT-x，但 Intel VT-x 处于禁用状态。 如果已在 BIOS/固件设置中禁用 Intel VT-x，或主机自更改此设置后从未重新启动，则 Intel VT-x 可能被禁用。 确认 BIOS/固件设置中启用了 Intel VT-x 并禁用了“可信执行”。如果这两项 BIOS/固件设置有一项已更改，请重新启动主机。如果您在安装 VMware Workstation 之后从未重新启动主机，请重新启动。将主机的 BIOS/固件更新至最新版本。 解决办法 重启电脑，进入bios（一般是F10），选择Configuration选项，选择Intel Virtual Technology并回车 ，选择enable. 保存退出OK。 nginx日志文件删除后空间不释放问题描述因nginx日志过大，占满存储空间，想删除日志减少空间，但是删除日志后发现空间还是没有减少。 未释放磁盘空间原因在Linux或者Unix系统中，通过rm或者文件管理器删除文件将会从文件系统的目录结构上解除链接(unlink)。然而如果文件是被打开的（有一个进程正在使用），那么进程将仍然可以读取该文件，磁盘空间也一直被占用。而我删除的是nginx的log文件，删除的时候文件应该正在被使用。 解决办法重启nginx服务，或者用&gt;/opt/nginx/logs/nginx.log清空日志文件，而不是直接删除。 给指定用户或全部用户（已登录）发送消息给指定用户发送消息首先，可使用w或who命令查看当前登录的用户信息； 然后，使用write命令将信息发送到用户的终端上，用法步骤如下： write + shh登陆用户名+ttyname(例如pts/1)ENTER输入信息（所要发送的消息，中文可能会乱码）。EOFCTRL+D结束 实例： 123root# write root pts/1I&apos;ll come by at 12:00 to look at your problem.root# 然后使用root账号登录，且tty号为pts/1的登录用户终端会收到如下消息： 123Message from root@cs2c.com.cn on pts/3 at 10:20 ...I&apos;ll come by at 12:00 to look at you problem.EOF 给当前登录的所有用户发送消息给当前登录所有用户发送消息，使用wall（write all的缩写） 实例如下： 首先，你可以通过who命令查看登录到该机器的所有用户。比如： 12345# whoroot pts/0 Sep 13 04:28 (10.56.226.25)root pts/1 Sep 13 22:32 (10.140.1.37)root pts/2 Sep 13 23:31 (10.140.2.70)root pts/3 Sep 13 23:56 (10.140.2.70) 执行who命令，就会返回上面的结果。表示有三个用户登录到该机器，有个用户有两个登录Console。 其次，广播消息 123#wall &apos;I will use this host. If somebody is using it, pls let me know. Thanks a lot.&apos;Broadcast message from root (pts/3) (Fri Jun 13 23:57:13 2008):I will use this host. If somebody is using it, pls let me know. Thanks a lot 执行wall命令，所有登录到该机器的控制台(console)界面上都会收到如上所示的消息。 LINUX系统软件安装和卸载的常见方法 rpm包卸载：rpm -e XXX.rpm (如果想忽略依赖，可加上–nodeps)。yum remove xxx.rpm 这种方法非常不建议使用，卸载过程会将待卸载的软件包所依赖的软件包一并卸载掉，很容易造成系统缺少某些包而崩溃等问题。源码包卸载：cd命令进入编译后的软件目录，即安装时的目录，执行make uninstall命令即可；或者直接删除安装目录。 如何修改LINUX的IP地址、网关和主机名 1、修改IP地址、网关：编辑/etc/sysconfig/network-scripts/ifcfg-eth0，修改里面IPADDR和GATEWAY内容，没有这两行，则添加即可，添加时确保BOOTPROTO=static，静态地址，如IPADDR=192.168.1.100 GATEWAY=192.168.1.1。2、修改主机名称：编辑/etc/sysconfig/network，修改里面的HOSTNAME内容，如设置主机名称为mysql，则：HOSTNAME=mysql即可； 如何查看当前的Linux服务器的运行级别使用 who -r 或者 runlevel 命令。 如何查看Linux的默认网关用 route -n 或者 netstat -nr 命令。 如何在/usr目录下找出大小超过10MB的文件find /usr -size +10M 如何在/home目录下找出120天之前被修改过的文件find /home -mtime +120 如何在/var目录下找出90天之内未被访问过的文件find /var \\! -atime -90 查看各系统用户的进程（LWP）数1ps h -Led -o user | sort | uniq -c | sort -n 默认情况下采用 ps 命令并不能显示出所有的进程。因为 Linux 环境下执行多线程，每个线程都将以一个轻量级进程（light-weight process 『LWP』）的形式执行，而 ps 命令如果不带 -L 选项将无法查看 LWP。 确定某用户的进程（LWP）数的分布情况1ps -o nlwp,pid,lwp,args -u username | sort -n 其中 username 为系统用户名。 常用日志查询命令查看实时日志1tail -f info.log 分页查看所有日志1cat info.log | more 分页查看前N行日志1tail -n 1000 info.log | more 检索日志，并显示该日志的前后N行记录1cat info.log | grep -n -B10 -A10 &quot;关键字&quot; 查看日志，从第1000行开始，显示500行1cat info.log |tail -n+1000|head -n 500 查看日志，显示1350行到1400行1cat info.log | head -n 1400 | tail -n +1350 删除包括关键词的行1sed -i &apos;/关键词/d&apos; info.log grep查看打印匹配的下几行或前后几行前言平时工作中总会碰到排查错误想要看XX日志里面的某个关键词，但是这个关键词前后又有很多其他信息也是需要关注的，这时候怎么办呢？ 实现一般是通过grep来实现。假设要看A.log里面“ABC”关键词上下100行，一般执行命令： 1grep -C 100 &apos;ABC&apos; A.log 将信息输出到指定文件： 1grep -C 100 &apos;ABC&apos; A.log &gt; /opt/error.log 想匹配模式的上下几行，grep也可以实现 1234567grep -5 &apos;parttern&apos; inputfile //打印匹配行的前后5行grep -C 5 &apos;parttern&apos; inputfile //打印匹配行的前后5行grep -A 5 &apos;parttern&apos; inputfile //打印匹配行的后5行grep -B 5 &apos;parttern&apos; inputfile //打印匹配行的前5行 查找最后创建时间是3天前，后缀是*.log的文件并删除1find / -name “*.log” -ctime +3 -exec rm -f &#123;&#125; \\ 将某目录下大于100k的文件移动至/tmp下1for i in `find /test -type f -size +100k`;do cd /test &amp;&amp; mv $i /tmp;done 将数据库备份并打包至远程服务器192.168.1.1 /backup目录下123456789mount 192.168.1.1:/backup /mntcd /mnt/usr/local/mysql/bin/mysqldump -hlocalhost -uroot test &gt;test.sqltar czf test.sql.tar.gz test.sqlrm -f test.sql 防火墙配置脚本，只允许远程主机访问本机的80端口12345678910111213iptables -P INPUT ACCEPTiptables -P OUTPUT ACCEPTiptables -P FORWARD ACCEPTiptables -Fiptables -Xiptables -A INPUT -i eth0 -p tcp –dport 80 -j ACCEPTiptables -P INPUT DROP 脚本统计nginx日志，得到访问ip最多的前10个(nginx日志路径：/home/logs/nginx/default/access.log1awk ‘&#123;a[$1]++&#125;END&#123;for (j in a) print a[j],j&#125;’ /home/logs/nginx/default/access.log|sort -nr|head -10 查看最消耗CPU、内存的进程CPU占用最多的前10个进程1ps auxw|head -1;ps auxw|sort -rn -k3|head -10 内存消耗最多的前10个进程1ps auxw|head -1;ps auxw|sort -rn -k4|head -10 虚拟内存使用最多的前10个进程1ps auxw|head -1;ps auxw|sort -rn -k5|head -10 参数说明ps auxw u：以用户为主的格式来显示程序状况x：显示所有程序，不以终端机来区分w：采用宽阔的格式来显示程序状况 ps auxw|head -1 输出表头 sort -rn -k5 -n是按照数字大小排序，-r是以相反顺序，-k是指定需要排序的栏位 linux磁盘空间满了后怎么去判定哪个地方占了多大的空间并回收 使用df -h查看磁盘空间占用情况。使用du -s /* | sort -nr命令查看那个目录占用空间大。然后那个目录占用多再通过du -s /root/* | sort -nr 一层层排查，找到占用文件多的地方。使用du -h –max-depth=1查看当前目录下文件夹大小情况。查看文件是否被进程占用。如果通过以上方法没有找到问题所在，那么可以使用 lsof | grep deleted 命令，看看是否删除掉的文件仍然被进程占用而没有进行实际删除。 Linux服务器忘记root密码怎么办 重启或者开机时，在倒数3秒的界面按下任意键。 该界面有如下提示(e 编辑 a 更改内核选项 c 命令行 b 启动)，所以我们按下”e”编辑。 上下键选中第二行再按下”e”编辑 行末加上”singal,s,S,1”其中一项，然后回车。 按”b”,启动。 启动之后就可以用passwd命令重置root命令。 用shell脚本输出带颜色字体语法 shell脚本中echo显示内容带颜色显示,echo显示带颜色，需要使用参数-e，如下： 1echo -e &quot;\\033[41;36m something here \\033[0m&quot; 其中41的位置代表底色， 36的位置是代表字的颜色 色值对应 1、字背景颜色和文字颜色之间是英文的&quot;&quot;;2、文字颜色后面有个m;3、字符串前后可以没有空格，如果有的话，输出也是同样有空格; 下面是相应的字和背景颜色，可以自己来尝试找出不同颜色搭配 1234567echo -e “\\033[31m 红色字 \\033[0m”echo -e “\\033[34m 黄色字 \\033[0m”echo -e “\\033[41;33m 红底黄字 \\033[0m”echo -e “\\033[41;37m 红底白字 \\033[0m” 字颜色：30—–3712345678echo -e “\\033[30m 黑色字 \\033[0m” echo -e “\\033[31m 红色字 \\033[0m” echo -e “\\033[32m 绿色字 \\033[0m” echo -e “\\033[33m 黄色字 \\033[0m” echo -e “\\033[34m 蓝色字 \\033[0m” echo -e “\\033[35m 紫色字 \\033[0m” echo -e “\\033[36m 天蓝字 \\033[0m” echo -e “\\033[37m 白色字 \\033[0m” 字背景颜色范围：40—–4712345678echo -e “\\033[40;37m 黑底白字 \\033[0m” echo -e “\\033[41;37m 红底白字 \\033[0m” echo -e “\\033[42;37m 绿底白字 \\033[0m” echo -e “\\033[43;37m 黄底白字 \\033[0m” echo -e “\\033[44;37m 蓝底白字 \\033[0m” echo -e “\\033[45;37m 紫底白字 \\033[0m” echo -e “\\033[46;37m 天蓝底白字 \\033[0m” echo -e “\\033[47;30m 白底黑字 \\033[0m” 控制选项说明12345678910111213141516171819\\33[0m 关闭所有属性 \\33[1m 设置高亮度 \\33[4m 下划线 \\33[5m 闪烁 \\33[7m 反显 \\33[8m 消隐 \\33[30m — \\33[37m 设置前景色 \\33[40m — \\33[47m 设置背景色 \\33[nA 光标上移n行 \\33[nB 光标下移n行 \\33[nC 光标右移n行 \\33[nD 光标左移n行 \\33[y;xH设置光标位置 \\33[2J 清屏 \\33[K 清除从光标到行尾的内容 \\33[s 保存光标位置 \\33[u 恢复光标位置 \\33[?25l 隐藏光标 \\33[?25h 显示光标 实例：五颜六色的shell脚本123456789101112131415161718192021222324252627282930#!/bin/bash clearecho -e &quot;\\033[1m Hello World&quot; # bold effectecho -e &quot;\\033[5m Blink&quot; # blink effectecho -e &quot;\\033[0m Hello World&quot; # back to noraml echo -e &quot;\\033[31m Hello World&quot; # Red colorecho -e &quot;\\033[32m Hello World&quot; # Green colorecho -e &quot;\\033[33m Hello World&quot; # See remaing on screenecho -e &quot;\\033[34m Hello World&quot;echo -e &quot;\\033[35m Hello World&quot;echo -e &quot;\\033[36m Hello World&quot; echo -e -n &quot;\\033[0m&quot; # back to noramlecho -e &quot;\\033[41m Hello World&quot;echo -e &quot;\\033[42m Hello World&quot;echo -e &quot;\\033[43m Hello World&quot;echo -e &quot;\\033[44m Hello World&quot;echo -e &quot;\\033[45m Hello World&quot;echo -e &quot;\\033[46m Hello World&quot; echo -e &quot;\\033[0m Hello World&quot; 重启命令 rebootshutdown -r now 立刻重启(root用户使用)shutdown -r 10 过10分钟自动重启(root用户使用)shutdown -r 20:35 在时间为20:35时候重启(root用户使用)如果是通过shutdown命令设置重启的话，可以用shutdown -c命令取消重启 关机命令 halt 立刻关机poweroff 立刻关机shutdown -h now 立刻关机(root用户使用)shutdown -h 10 10分钟后自动关机如果是通过shutdown命令设置关机的话，可以用shutdown -c命令取消重启 查看当前使用的网卡1watch cat /proc/net/dev 重启网卡方法全部网卡重启重启网卡使设定生效： 1sudo /etc/init.d/networking restart 单个网卡重启关闭网卡 ifdown eth0 开启网卡 ifup eth0 禁用网卡123vi /etc/sysconfig/network-scripts/ifcfg-eth1onboot=NO 修改IP动态设定一个网卡IP： 1ifconfig eth1 192.168.1.10 netmask 255.255.255.0 重启网卡使设定生效： 1sudo /etc/init.d/networking restart 静态编辑文件 /etc/network/interfaces 1sudo vi /etc/network/interfaces 并用下面的行来替换有关eth0的行： 12345678# The primary network interfaceauto eth0iface eth0 inet staticaddress 192.168.2.1gateway 192.168.2.254netmask 255.255.255.0#network 192.168.2.0#broadcast 192.168.2.255 将eth0的IP分配方式修改为静态分配(static)后，为其制定IP、网关、子网掩码等信息。 将上面的Ubuntu IP地址等信息换成你自己就可以了。 用下面的命令使网络设置生效： 1sudo /etc/init.d/networking restart 操作防火墙(service方式)查看防火墙状态1service iptables status 开启防火墙1service iptables start 关闭防火墙1service iptables stop 查找大文件搜索当前目录下，超过100M大小的文件1find . -type f -size +100M 查看超过100M大小的文件及其相关信息1find . -type f -size +800M -print0 | xargs -0 ls -l 查找超过100M大小文件，并显示查找出来文件的具体大小1find . -type f -size +100M -print0 | xargs -0 du -h 查找超过100M大小文件并对查找结果按照文件大小做一个排序1find . -type f -size +800M -print0 | xargs -0 du -h | sort -nr 查找Linux下的大目录1du -h --max-depth=1","tags":"linux"},{"title":"Java String常见问题","url":"/posts/d0a49d51.html","text":"首先看一段代码块： 123456789public String gets1() &#123; return \"\" + System.currentTimeMillis();&#125;public String gets2() &#123; return String.valueOf(System.currentTimeMillis());&#125;public String gets3() &#123; return new String(\"\") + System.currentTimeMillis();&#125; 这三个方法都是输出当前时间戳string类型的数据，但他们有什么不同呢？反编译看下三个方法的细节： 12345678910111213141516171819202122232425262728293031public java.lang.String gets1();Code: 0: new #2 // class java/lang/StringBuilder 3: dup 4: invokespecial #3 // Method java/lang/StringBuilder.\"&lt;init&gt;\":()V 7: ldc #4 // String 9: invokevirtual #5 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 12: invokestatic #6 // Method java/lang/System.currentTimeMillis:()J 15: invokevirtual #7 // Method java/lang/StringBuilder.append:(J)Ljava/lang/StringBuilder; 18: invokevirtual #8 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 21: areturn' public java.lang.String gets2();Code: 0: invokestatic #6 // Method java/lang/System.currentTimeMillis:()J 3: invokestatic #9 // Method java/lang/String.valueOf:(J)Ljava/lang/String; 6: areturnpublic java.lang.String gets3();Code: 0: new #2 // class java/lang/StringBuilder 3: dup 4: invokespecial #3 // Method java/lang/StringBuilder.\"&lt;init&gt;\":()V 7: new #10 // class java/lang/String 10: dup 11: ldc #4 // String 13: invokespecial #11 // Method java/lang/String.\"&lt;init&gt;\":(Ljava/lang/String;)V 16: invokevirtual #5 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 19: invokestatic #6 // Method java/lang/System.currentTimeMillis:()J 22: invokevirtual #7 // Method java/lang/StringBuilder.append:(J)Ljava/lang/StringBuilder; 25: invokevirtual #8 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 28: areturn 方法1：””+System.currentTimeMillis()是通过StringBuilder的append方法添加了一个空字符串及当前时间戳，然后通过toString方法生成一个全新的String对象。 该方法中使用了一个StringBuilder和一个String对象。 方法2：String.valueOf(System.currentTimeMillis())直接获取当前时间戳，然后创建了一个String对象。 该方法中使用了一个String对象。 方法3：new String(“”) + System.currentTimeMillis()则最麻烦，先创建了StringBuilder对象，然后新建了一个空字符串的String对象，通过append方法添加进去，最后toString创建了一个新的String对象。 该方法中使用了一个StringBuilder对象和两个String对象。 从上面的分析中就可以看出，很明显方法2是最优的，为什么呢？在深入String之前，先了解下JVM的组成。 堆：JVM运行中申请的对象存放的位置。也就是所说的新生代+老年代。 虚拟机栈：每个方法在被调用执行时都会创建一个虚拟机栈，用于存储临时的遍历、方法等信息。调用相当于进栈，返回结果则相当于出栈，异常输出的栈信息就是从这里来的。 本地方法栈：也是方法调用，只是调用的方法是本地native方法。 方法区：存储的类的结构信息，静态变量等信息。也就是永生代，发生FULL GC的地方（Java8中以元空间代替了永生代这个概念）。 常量池：方法区的一部分，用来存放各种生成的字面量，例如定义的一个String类型的数据（Java7中把常量池移到了堆中） 0. String的特性 1、String类是final的，不可被继承。 2、String类是的本质是字符数组char[], 并且其值不可改变。 3、Java运行时会维护一个String Pool（String池），JavaDoc翻译很模糊“字符串缓冲区”。String池用来存放运行时中产生的各种字符串，并且池中的字符串的内容不重复。而一般对象不存在这个缓冲池，并且创建的对象仅仅存在于方法的堆栈区。 1. 创建字符串创建字符串一般就两种方法： 123String s1=\"hello\";String s2=new String(\"hello\"); 第一种方法是在栈中创建一个String类型的引用s1，然后在常量池中寻找，如果常量池中存在hello的字符串数据，则直接把s1指向常量池中hello的地址；否则就会在常量池中创建hello这个字符串数据，然后把s1指向新创建的hello地址。 第二种方法是在栈中创建一个String类型的引用s2，然后在常量池中寻找，如果常量池中存在该数据，则在堆中复制拷贝该数据，然后把s2指向堆中新建的地址；否则会创建一个字符串存放在常量池中，然后进行拷贝一份到堆中，s2指向堆中的地址。 通过new创建的string一定会在堆中创建一份数据，同时常量池肯定有一个值的备份操作；而单独的字符串则是直接指向常量池，所以一般还是使用字符串更好些，具体可看如下的图解： 2. 字符串 + 操作 1234567891011String s1=\"helloworld\";String s2=\"hello\" + \"world\";String s3=new String(\"hello\") + \"world\";System.out.println(s1 == s2); // trueSystem.out.println(s2 == s3); // falseSystem.out.println(s1 == s3); // false 代码中”hello” + “world”在编译期已经知道了数据情况（使用javac编译查看class文件会发现s1和s2是一致的），JVM会自动优化使得s1和s2是一样的，s3由于有new操作，所以需要StringBuilder的append完成，具体可看如下图解: 3. 字符串变量 + 操作 123456789String s1=\"hello\";String s2=\"world\";String s3=\"helloworld\";String s4=s1 + s2;System.out.println(s3 == s4); // false 这里的样例和上一个样例存在一些差别，这里的s4是由s1 + s2获得的，在编译期无法感知到其实际值，在运行期时会利用StringBuilder的append剩下一个新的String对象，所以s3指向的是常量池，而s4指向的堆，两者自然是不一样的。 1s4 = new StringBuilder()).append(s1).append(s2).toString(); 5. 带final的字符串变量 + 操作 12345678910111213final String s1=\"hello\";String s2=\"world\";String s3=\"helloworld\";String s4=s1 + \"world\";String s5=s1 + s2;System.out.println(s3 == s4); // trueSystem.out.println(s3 == s5); // false 使用javac反编译之后的class文件如下： 1234567891011String var1 = \"world\";String var2 = \"helloworld\";String var3 = \"helloworld\";String var4 = \"hello\" + var1;System.out.println(var2 == var3);System.out.println(var2 == var4); 添加了final关键字修饰的变量在编译期会被对应的字符串直接替换掉，相当于字符串数据，而包含了字符串变量的+操作则依旧是使用了StringBuilder。 5. intern()方法String.intern方法是一个native方法，获取的是当前字符串在常量池的数据，如果常量池存在该数据则直接返回，如果不存在则把该数据添加到常量池中后返回，所以有String s1 = “abc” 和 String s2 = s1.intern() 中的s1 == s2和String s1=”world” 和 String s2=new String(“world”) 中 s1.intern() == s2.intern()1 6. 总结 String 本身是final类型的类，在日常使用中需要频繁的做字符串合并操作时，尽可能的使用StringBuilder（如需要考虑线程安全则使用StringBuffer），降低无谓的字符串创建操作，在保证安全的情况下，提高效率！","tags":"java 面试题"},{"title":"Java异常学习","url":"/posts/e60072fb.html","text":"什么是异常异常本质上是程序上的错误，这个错误包括程序逻辑错误和系统错误。错误在程序中又有运行时异常和编译时异常。 编译异常在编译期间出错有编译器帮助错，然而运行期间的错误编译器则鞭长莫及了，并且运行期间的错误往往是难以预料的，但是如果不处理这些异常则会直接导致程序崩溃。因此在运行期间出现错误应该如何来补救昵？Java提供了异常机制来处理这些错误。 异常分类在Java中的异常被当做对象来处理，根类为java.lang.Throwable类，在Java中定义了很多异常类（如OutOfMemoryError、NullPointerException、IndexOutOfBoundsException等），这些异常类分为两大类：Error和Exception。 ErrorError是无法处理的异常，比如OutOfMemoryError，一般发生这种异常，JVM会自动终止程序，因此编写程序时不需要关心这类异常。 ExceptionException，是经常见到的一些异常情况，比如NullPointerException，这些异常是可以处理的。 Exception类的异常包括checked exception和unchecked exception（unchecked exception也称运行时异常RuntimeException，当然这里的运行时异常并不是前面所说的运行期间的异常，只是Java中用运行时异常这个术语来表示，Exception类的异常都是在运行期间发生的）。 unchecked exception（非检查异常），也称运行时异常（RuntimeException），比如常见的NullPointerException、IndexOutOfBoundsException。对于运行时异常，java编译器不要求必须进行异常捕获处理或者抛出声明，由程序员自行决定。 checked exception（检查异常），也称非运行时异常（运行时异常以外的异常就是非运行时异常），java编译器强制程序员必须进行捕获处理，比如常见的IOExeption和SQLException。对于非运行时异常如果不进行捕获或者抛出声明处理，编译都不会通过。 在Java中，所有异常类的父类是Throwable类，Error类是error类型异常的父类，Exception类是exception类型异常的父类，RuntimeException类是所有运行时异常的父类，RuntimeException以外的并且继承Exception的类是非运行时异常。 典型的RuntimeException包括NullPointerException、IndexOutOfBoundsException、IllegalArgumentException等。 典型的非RuntimeException包括IOException、SQLException等。 Java中如何处理异常在Java中如果需要处理异常，必须先对异常进行捕获，然后再对异常情况进行处理。 如何对可能发生异常的代码进行异常捕获和处理呢？使用try和catch关键字即可。 捕获异常12345678910111213try &#123; File file = new File(\"d:/a.txt\"); if(!file.exists()) file.createNewFile();&#125; catch (IOException e) &#123;// TODO: handle exception&#125; 在try中发生的异常，将交由catch进行处理。 抛出异常123456789101112131415161718192021222324252627public class Main &#123; public static void main(String[] args) &#123; try &#123; createFile(); &#125; catch (Exception e) &#123; // TODO: handle exception &#125; &#125; public static void createFile() throws IOException&#123; File file = new File(\"d:/a.txt\"); if(!file.exists()) file.createNewFile(); &#125;&#125; 在createFile()中并没有对异常进行处理，而是用throws关键字声明抛出异常，即告知这个方法的调用者此方法可能会抛出IOException。那么在main方法中调用createFile方法的时候，采用try...catch块进行了异常捕获处理。 throw关键字手动来抛出异常1234567891011121314151617181920212223242526272829public class Main &#123; public static void main(String[] args) &#123; try &#123; int[] data = new int[]&#123;1,2,3&#125;; System.out.println(getDataByIndex(-1,data)); &#125; catch (Exception e) &#123; System.out.println(e.getMessage()); &#125; &#125; public static int getDataByIndex(int index,int[] data) &#123; if(index&lt;0||index&gt;=data.length) throw new ArrayIndexOutOfBoundsException(\"数组下标越界\"); return data[index]; &#125;&#125; 然后在catch块中进行捕获。 在Java中进行异常处理的话，对于可能会发生异常的代码，可以选择三种方法来进行异常处理：1）对代码块用try..catch进行异常捕获处理；2）在该代码的方法体外用throws进行抛出声明，告知此方法的调用者这段代码可能会出现这些异常，需要谨慎处理。此时有两种情况：如果声明抛出的异常是非运行时异常，此方法的调用者必须显示地用try..catch块进行捕获或者继续向上层抛出异常。如果声明抛出的异常是运行时异常，此方法的调用者可以选择地进行异常捕获处理。3）在代码块用throw手动抛出一个异常对象，此时也有两种情况，跟2）中的类似：如果抛出的异常对象是非运行时异常，此方法的调用者必须显示地用try..catch块进行捕获或者继续向上层抛出异常。如果抛出的异常对象是运行时异常，此方法的调用者可以选择地进行异常捕获处理。（如果最终将异常抛给main方法，则相当于交给jvm自动处理，此时jvm会简单地打印异常信息） 一个方法所能捕捉的异常，一定是Java代码在某处所抛出的异常。简单地说，异常总是先被抛出，后被捕捉的。 理解try,catch,finally,throws,throw五个关键字try,catch,finallytry关键字用来包围可能会出现异常的逻辑代码，它单独无法使用，必须配合catch或者finally使用。Java编译器允许的组合使用形式只有以下三种形式： try...catch...; try....finally......; try....catch...finally... 当然catch块可以有多个，注意try块只能有一个,finally块是可选的（但是最多只能有一个finally块）。 三个块执行的顺序为try—&gt;catch—&gt;finally。 当然如果没有发生异常，则catch块不会执行。但是finally块无论在什么情况下都是会执行的（这点要非常注意，因此部分情况下，都会将释放资源的操作放在finally块中进行）。 在有多个catch块的时候，是按照catch块的先后顺序进行匹配的，一旦异常类型被一个catch块匹配，则不会与后面的catch块进行匹配。 在使用try..catch..finally块的时候，注意千万不要在finally块中使用return，因为finally中的return会覆盖已有的返回值。 1234567891011121314151617181920212223242526272829303132public String openFile() &#123; try &#123; FileInputStream inputStream = new FileInputStream(\"d:/a.txt\"); int ch = inputStream.read(); System.out.println(\"aaa\"); return \"step1\"; &#125; catch (FileNotFoundException e) &#123; System.out.println(\"file not found\"); return \"step2\"; &#125;catch (IOException e) &#123; System.out.println(\"io exception\"); return \"step3\"; &#125;finally&#123; System.out.println(\"finally block\"); return \"finally\"; &#125;&#125; 这里finally中的返回值回吧catch里面的返回值给覆盖，也会把try中的return覆盖掉。从调试中可以看出来，try中就算有return，也会执行finally中。 总结： try 块：用于捕获异常。其后可接零个或多个catch块，如果没有catch块，则必须跟一个finally块。catch 块：用于处理try捕获到的异常。finally 块：无论是否捕获或处理异常，finally块里的语句都会被执行。当在try块或catch块中遇到return语句时，finally语句块将在方法返回之前被执行。在以下4种特殊情况下，finally块不会被执行：1）在finally语句块中发生了异常。2）在前面的代码中用了System.exit()退出程序。3）程序所在的线程死亡。4）关闭CPU。 throws和thow关键字 throws出现在方法的声明中，表示该方法可能会抛出的异常，然后交给上层调用它的方法程序处理，允许throws后面跟着多个异常类型； throw一般会用于程序出现某种逻辑时程序员主动抛出某种特定类型的异常。throw只会出现在方法体中，当方法在执行过程中遇到异常情况时，将异常信息封装为异常对象，然后throw出去。throw关键字的一个非常重要的作用就是异常类型的转换。 throws表示出现异常的一种可能性，并不一定会发生这些异常；throw则是抛出了异常，执行throw则一定抛出了某种异常对象。两者都是消极处理异常的方式（这里的消极并不是说这种方式不好），只是抛出或者可能抛出异常，但是不会由方法去处理异常，真正的处理异常由此方法的上层调用处理。 异常处理建议 只在必要使用异常的地方才使用异常，不要用异常去控制程序的流程。谨慎地使用异常：异常捕获的代价非常高昂，异常使用过多会严重影响程序的性能。如果在程序中能够用if语句和Boolean变量来进行逻辑判断，那么尽量减少异常的使用，从而避免不必要的异常捕获和处理。切忌使用空catch块在捕获了异常之后什么都不做，相当于忽略了这个异常。千万不要使用空的catch块，空的catch块意味着你在程序中隐藏了错误和异常，并且很可能导致程序出现不可控的执行结果。如果你非常肯定捕获到的异常不会以任何方式对程序造成影响，最好用Log日志将该异常进行记录，以便日后方便更新和维护。检查异常和非检查异常的选择一旦决定抛出异常，就要决定抛出什么异常。这里面的主要问题就是抛出检查异常还是非检查异常。检查异常导致了太多的try…catch代码，可能有很多检查异常对开发人员来说是无法合理地进行处理的，比如SQLException，而开发人员却不得不去进行try…catch，这样就会导致经常出现这样一种情况：逻辑代码只有很少的几行，而进行异常捕获和处理的代码却有很多行。这样不仅导致逻辑代码阅读起来晦涩难懂，而且降低了程序的性能。建议尽量避免检查异常的使用，如果确实该异常情况的出现很普遍，需要提醒调用者注意处理的话，就使用检查异常；否则使用非检查异常。一般情况下，尽量将检查异常转变为非检查异常交给上层处理。注意catch块的顺序，不要把上层类的异常放在最前面的catch块。 不要将提供给用户看的信息放在异常信息里。避免多次在日志信息中记录同一个异常只在异常最开始发生的地方进行日志信息记录。很多情况下异常都是层层向上跑出的，如果在每次向上抛出的时候，都Log到日志系统中，则会导致无从查找异常发生的根源。异常处理尽量放在高层进行尽量将异常统一抛给上层调用者，由上层调用者统一之时如何进行处理。如果在每个出现异常的地方都直接进行处理，会导致程序异常处理流程混乱，不利于后期维护和异常错误排查。由上层统一进行处理会使得整个程序的流程清晰易懂。在finally中释放资源如果有使用文件读取、网络操作以及数据库操作等，记得在finally中释放资源。这样不仅会使得程序占用更少的资源，也会避免不必要的由于资源未释放而发生的异常情况。避免过大的try块，不要把不会出现异常的代码放到try块里面，尽量保持一个try块对应一个或多个异常。细化异常的类型，不要不管什么类型的异常都写成Excetpion。catch块尽量保持一个块捕获一类异常，不要忽略捕获的异常，捕获到后要么处理，要么转译，要么重新抛出新类型的异常。不要把自己能处理的异常抛给别人。不要用try…catch参与控制程序流程，异常控制的根本目的是处理程序的非正常情况。 Throwable类中的常用方法catch关键字后面括号中的Exception类型的参数e。Exception就是try代码块传递给catch代码块的变量类型，e就是变量名。catch代码块中语句”e.getMessage();”用于输出错误性质。通常异常处理常用3个函数来获取异常的有关信息: getCause()：返回抛出异常的原因。如果 cause 不存在或未知，则返回 null。 getMeage()：返回异常的消息信息。 printStackTrace()：对象的堆栈跟踪输出至错误输出流，作为字段 System.err 的值。 有时为了简单会忽略掉catch语句后的代码，这样try-catch语句就成了一种摆设，一旦程序在运行过程中出现了异常，就会忽略处理异常，而错误发生的原因很难查找。 Java常见异常runtimeException子类 java.lang.ArrayIndexOutOfBoundsException数组索引越界异常。当对数组的索引值为负数或大于等于数组大小时抛出。 java.lang.ArithmeticException算术条件异常。譬如：整数除零等。 java.lang.NullPointerException空指针异常。当应用试图在要求使用对象的地方使用了null时，抛出该异常。譬如：调用null对象的实例方法、访问null对象的属性、计算null对象的长度、使用throw语句抛出null等等 java.lang.ClassNotFoundException找不到类异常。当应用试图根据字符串形式的类名构造类，而在遍历CLASSPAH之后找不到对应名称的class文件时，抛出该异常。 java.lang.NegativeArraySizeException 数组长度为负异常 java.lang.ArrayStoreException 数组中包含不兼容的值抛出的异常 java.lang.SecurityException 安全性异常 java.lang.IllegalArgumentException 非法参数异常 IOException IOException：操作输入流和输出流时可能出现的异常。 EOFException：文件已结束异常 FileNotFoundException：文件未找到异常 其他异常 ClassCastException：类型转换异常类 ArrayStoreException：数组中包含不兼容的值抛出的异常 SQLException：操作数据库异常类 NoSuchFieldException：字段未找到异常 NoSuchMethodException：方法未找到抛出的异常 NumberFormatException：字符串转换为数字抛出的异常 StringIndexOutOfBoundsException：字符串索引超出范围抛出的异常 IllegalAccessException：不允许访问某类异常 InstantiationException：当应用程序试图使用Class类中的newInstance()方法创建一个类的实例，而指定的类对象无法被实例化时，抛出该异常 自定义异常使用Java内置的异常类可以描述在编程时出现的大部分异常情况。除此之外，用户还可以自定义异常。用户自定义异常类，只需继承Exception类即可。 在程序中使用自定义异常类，大体可分为以下几个步骤。（1）创建自定义异常类。（2）在方法中通过throw关键字抛出异常对象。（3）如果在当前抛出异常的方法中处理异常，可以使用try-catch语句捕获并处理；否则在方法的声明处通过throws关键字指明要抛出给方法调用者的异常，继续进行下一步操作。（4）在出现异常方法的调用者中捕获并处理异常。","tags":"java"},{"title":"Markdown 语法画流程图","url":"/posts/711ce00.html","text":"添加支持Hexo 默认是不支持流程图的 Markdown 语法的，需要添加支持： 1npm install --save hexo-filter-flowchart 演示一个简单的流程图语法如下： 12345678910···flow #由于渲染问题，请自行将 · 替换为 `st=&gt;start: 开始e=&gt;end: 结束op=&gt;operation: 我的操作cond=&gt;condition: 确认？st-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op··· 效果如下： 一个稍复杂的流程图语法如下： 12345678910111213···flow #由于渲染问题，请自行将 · 替换为 `st=&gt;start: Start:&gt;http://www.google.com[blank]e=&gt;end:&gt;http://www.google.comop1=&gt;operation: My Operationsub1=&gt;subroutine: My Subroutinecond=&gt;condition: Yesor No?:&gt;http://www.google.comio=&gt;inputoutput: catch something...st-&gt;op1-&gt;condcond(yes)-&gt;io-&gt;econd(no)-&gt;sub1(right)-&gt;op1··· 效果如下： 语法详解Hexo中的流程图是依赖于flowchart.js 实现的。以上面那个稍复杂的流程图为例： 1234567891011121314···flow #由于渲染问题，请自行将 · 替换为 `//定义部分st=&gt;start: Start:&gt;http://www.google.com[blank]e=&gt;end:&gt;http://www.google.comop1=&gt;operation: My Operationsub1=&gt;subroutine: My Subroutinecond=&gt;condition: Yes or No?:&gt;http://www.google.comio=&gt;inputoutput: catch something...//判断和位置控制st-&gt;op1-&gt;condcond(yes)-&gt;io-&gt;econd(no)-&gt;sub1(right)-&gt;op1··· 例如这一句： st=&gt;start: Start|past:&gt;http://www.google.com[blank] 其中，st是变量名，start是指操作模块名，冒号后面就是内容了。需要注意的是，** 冒号后要加空格才能识别 ** 操作模块语法 操作模块 说明 start 开始 end 结束 operation 普通操作块 condition 判断块 subroutine 子任务块 inputoutput 输入输出块 判断和位置控制```markdown流程控制st-&gt;op1-&gt;e -&gt; 作为控制流程的操作符，就是指向下一步要操作的。 每一条都算是一条流程 你也可以断开写，怎么方便怎么来，如：下面两个是一样的。 分着写st-&gt;op1op1-&gt;e 合着写st-&gt;op1-&gt;e 判断cond(yes)-&gt;io-&gt;e #yes的时候到io，再到e 位置指定cond(no)-&gt;sub1(right)-&gt;op1 #no的时候到到 sub1，再从sub1的右侧到op1还可以这样 cond1(no,right)```st=>start: 开始 e=>end: 结束 op=>operation: 我的操作 cond=>condition: 确认？ st->op->cond cond(yes)->e cond(no)->op{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-0-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-0\", options);st=>start: Start:>http://www.google.com[blank] e=>end:>http://www.google.com op1=>operation: My Operation sub1=>subroutine: My Subroutine cond=>condition: Yes or No?:>http://www.google.com io=>inputoutput: catch something... st->op1->cond cond(yes)->io->e cond(no)->sub1(right)->op1{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-1-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-1-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-1\", options);","tags":"markdown"},{"title":"Markdown语法糖","url":"/posts/43883629.html","text":"前言Markdown 是一种轻量级的标记语言，其用简单的标记语法便可达到排版的目的，可以使我们更加专注于内容的编写，而不需过多关注排版。本文主要整理了 Markdown 中的常用的标记语法，以便自己与他人以后查用。 优点 纯文本，所以兼容性极强，可以用所有文本编辑器打开。 让你专注于文字而不是排版。 格式转换方便，Markdown 的文本你可以轻松转换为 html、电子书等。 Markdown 的标记语法有极好的可读性。 缺点 需要记一些语法（当然，是很简单。五分钟学会）。 有些平台不支持Markdown编辑模式。 基本语法标题在想要设置为标题的文字前面加#来表示，一个#是一级标题，二个#是二级标题，以此类推。支持六级标题。 注：#与文字之间要有一个空格。 示例： 123456# 这是一级标题## 这是二级标题### 这是三级标题#### 这是四级标题##### 这是五级标题###### 这是六级标题 效果如下： 字体星号或者下划线都可以，单是斜体，双是粗体，符号可以跨行，符号可加空格。 加粗要加粗的文字左右分别用两个*号包起来 斜体要倾斜的文字左右分别用一个*号包起来 斜体加粗要倾斜和加粗的文字左右分别用三个*号包起来 删除线要加删除线的文字左右分别用两个~~号包起来 示例： 1234**这是加粗的文字***这是倾斜的文字*`***这是斜体加粗的文字***~~这是加删除线的文字~~ 效果如下： 引用在引用的文字前加&gt;即可。引用也可以嵌套，如加两个&gt;&gt;三个&gt;&gt;&gt;n个…貌似可以一直加下去，但没神马卵用。 示例： 123&gt;这是引用的内容&gt;&gt;这是引用的内容&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;这是引用的内容 效果如下： 分割线三个或者三个以上的 - 或者 * 都可以。 示例： 1234-------******** 效果如下：可以看到，显示效果是一样的。 图片语法： 1234![图片alt](图片地址 ''图片title'')图片alt就是显示在图片下面的文字，相当于对图片内容的解释。图片title是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加 示例： 1![一脸懵逼](https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1558179968948&amp;di=1c8a7432843fdaafb91e9cbffacd1557&amp;imgtype=0&amp;src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201608%2F02%2F20160802213915_x23St.thumb.700_0.jpeg \"一脸懵逼\") 效果如下： 超链接语法： 12[超链接名](超链接地址 \"超链接title\")title可加可不加 示例： 12[简书](http://jianshu.com)[百度](http://baidu.com) 效果如下：简书百度注：Markdown本身语法不支持链接在新页面中打开，如果想要在新页面中打开的话可以用html语言的a标签代替。 1234&lt;a href=\"超链接地址\" target=\"_blank\"&gt;超链接名&lt;/a&gt;示例&lt;a href=\"https://www.jianshu.com/u/1f5ac0cf6a8b\" target=\"_blank\"&gt;简书&lt;/a&gt; 索引超链接示例： 12[百度][1][1]:http://www.baidu.com 效果如下：[百度][1][1]:http://www.baidu.com 自动链接语法：使用尖括号。 示例： 12&lt;http://www.baidu.com&gt;&lt;1111111@qq.com&gt; 效果如下：http://www.baidu.com&#x31;&#49;&#x31;&#49;&#x31;&#x31;&#49;&#x40;&#x71;&#113;&#46;&#99;&#x6f;&#x6d; 列表无序列表语法：无序列表用 - + * 任何一种都可以。 12345- 列表内容+ 列表内容* 列表内容注意：- + * 跟内容之间都要有一个空格 效果如下： 列表内容 列表内容 列表内容 有序列表语法：数字加点。 123451. 列表内容2. 列表内容3. 列表内容注意：序号跟内容之间要有空格 效果如下： 列表内容 列表内容 列表内容 嵌套列表语法：上一级和下一级之间敲三个空格即可 一级无序列表内容 二级无序列表内容 二级无序列表内容 二级无序列表内容 一级无序列表内容 二级有序列表内容 二级有序列表内容 二级有序列表内容 一级有序列表内容 二级无序列表内容 二级无序列表内容 二级无序列表内容 一级有序列表内容 二级有序列表内容 二级有序列表内容 二级有序列表内容 注意：在使用列表时，只要是数字后面加上英文的点，就会无意间产生列表，比如2019.5.18 这时候想表达的是日期，有些软件把它被误认为是列表。解决方式：在每个点前面加上\\就可以了。如所示：示例： 12019\\.5\\.18 效果如下：2019.5.18 表格Markdown表格语法： 1234567891011|表头|表头|表头||---|:---:|---:||内容|内容|内容||内容|内容|内容|第二行分割表头和内容。- 有一个就行，为了对齐，多加了几个文字默认居左-两边加：表示文字居中-右边加：表示文字居右注：原生的语法两边都要用 | 包起来。此处省略 示例1： 12345| 法号 | 本领 | 排行 || :--------: | :-----: | :----: || 悟空 | 72变 | 大师兄|| 悟能 | 36变 | 二师哥|| 悟净 | 18变 | 三师弟| 效果如下： 法号 本领 排行 悟空 72变 大师兄 悟能 36变 二师哥 悟净 18变 三师弟 示例2： 1234567891011121314151617181920212223242526272829表头1 | 表头2------------- | -------------Content Cell | Content CellContent Cell | Content Cell| 表头1 | 表头2|| ------------- | ------------- || Content Cell | Content Cell || Content Cell | Content Cell || 名字 | 描述 || ------------- | ----------- || Help | Display the help window.|| Close | Closes a window |表格中也可以使用普通文本的删除线，斜体等效果| 名字 | 描述 || ------------- | ----------- || Help | ~~Display the~~ help window.|| Close | _Closes_ a window |表格可以指定对齐方式| 左对齐 | 居中 | 右对齐 || :------------ |:---------------:| -----:|| col 3 is | some wordy text | $1600 || col 2 is | centered | $12 || zebra stripes | are neat | $1 | 效果如下： 表头1 表头2 Content Cell Content Cell Content Cell Content Cell 表头1 表头2 Content Cell Content Cell Content Cell Content Cell 名字 描述 Help Display the help window. Close Closes a window 名字 描述 Help Display the help window. Close Closes a window 左对齐 居中 右对齐 col 3 is some wordy text $1600 col 2 is centered $12 zebra stripes are neat $1 HTML表格语法： 1234567891011121314151617181920&lt;table&gt; &lt;tr&gt; &lt;th&gt;项目1&lt;/th&gt; &lt;th&gt;项目2&lt;/th&gt; &lt;th&gt;项目3&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;a1&lt;/td&gt; &lt;td colspan=\"2\"&gt;a2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td rowspan=\"2\"&gt;b1&lt;/td&gt; &lt;td&gt;b2&lt;/td&gt; &lt;td&gt;b3&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;c2&lt;/td&gt; &lt;td&gt;c3&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt; 效果： 项目1 项目2 项目3 a1 a2 b1 b2 b3 c2 c3 需要注意的一点是，在markdown中使用html代码来实现表格的效果，需要在表格的外面套上： 1&lt;escape&gt;&lt;/escape&gt; （转义），防止markdown直接将代码中的行进行转义成回车，不然会出现表格前空了一大块空白。 但同时，引入html会使得markdown的易读易写的特性降低。除非必要，还是推荐使用markdown本身的表格语法。那么，我们如何在使用html表格的时候，偷懒不用打这段表格呢？ http://www.tablesgenerator.com/ 安利这个网站，它可以实现你的需求，包括合并单元格等。 代码单行代码语法：代码之间分别用一个反引号包起来。 1`代码内容` 示例： 1`create database hero;` 效果如下： create database hero; 代码块语法：代码之间分别用三个反引号包起来，且两边的反引号单独占一行。 12345(```) 代码... 代码... 代码...(```) 注：为了防止转译，前后三个反引号处加了小括号，实际是没有的。这里只是用来演示，实际中去掉两边小括号即可。 示例： 123456(```) function fun()&#123; echo \"这是一句非常牛逼的代码\"; &#125; fun();(```) 效果如下： 1234function fun()&#123; echo \"这是一句非常牛逼的代码\";&#125;fun(); 注释语法：用html的注释 1&lt;!-- 用html的注释 --&gt; 转义字符Markdown中的转义字符为\\，转义的有： 123456789101112\\\\ 反斜杠\\` 反引号\\* 星号\\_ 下划线\\&#123;\\&#125; 大括号\\[\\] 中括号\\(\\) 小括号\\# 井号\\+ 加号\\- 减号\\. 英文句号\\! 感叹号 效果如下：\\ 反斜杠` 反引号* 星号_ 下划线{} 大括号[] 中括号() 小括号# 井号+ 加号- 减号. 英文句号! 感叹号 其他特殊字符示例： 1234567891011&amp;#10084&amp;#10003&amp;#9728&amp;#9733&amp;#9730&amp;#9775&amp;#9762&amp;#9742&amp;#8734&amp;#10052&amp;#9835 效果如下： &amp;#10084&amp;#10003&amp;#9728&amp;#9733&amp;#9730&amp;#9775&amp;#9762&amp;#9742&amp;#8734&amp;#10052&amp;#9835 想知道字符对应的Unicode码，可以看这个网站：https://unicode-table.com/cn/ 流程图效果如下： 段落与换行Markdown中段落指连续的一段文字，编写时段落之间至少一个空行隔开，段落内多个空格被视为一个空格，段首不支持缩进。如何想要在显示时显示多个空行，可以插入实现，注意的是，插入的应与前后的段落中间至少空一行。 段落缩进（空格）示例： 1234半方大的空白&amp;ensp;或&amp;#8194;看，飞碟全方大的空白&amp;emsp;或&amp;#8195;看，飞碟不断行的空白格&amp;nbsp;或&amp;#160;看，飞碟&amp;emsp;&amp;emsp;段落从此开始。 效果如下：半方大的空白&ensp;或&#8194;看，飞碟全方大的空白&emsp;或&#8195;看，飞碟不断行的空白格&nbsp;或&#160;看，飞碟&emsp;&emsp;段落从此开始。 字体、字号、颜色、背景色示例： 1234567&lt;font face=&quot;黑体&quot;&gt;我是黑体字&lt;/font&gt;&lt;font face=&quot;微软雅黑&quot;&gt;我是微软雅黑&lt;/font&gt;&lt;font face=&quot;STCAIYUN&quot;&gt;我是华文彩云&lt;/font&gt;&lt;font color=#0099ff size=12 face=&quot;黑体&quot;&gt;黑体&lt;/font&gt;&lt;font color=#00ffff size=3&gt;null&lt;/font&gt;&lt;font color=gray size=5&gt;gray&lt;/font&gt;&lt;table&gt;&lt;tr&gt;&lt;td bgcolor=#FF4500&gt;这里的背景色是：OrangeRed， 十六进制颜色值：#FF4500， rgb(255, 69, 0)&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; 效果如下：我是黑体字我是微软雅黑我是华文彩云黑体nullgray 这里的背景色是：OrangeRed， 十六进制颜色值：#FF4500， rgb(255, 69, 0) 快捷键 功能 快捷键 加粗 Ctrl + B 斜体 Ctrl + I 引用 Ctrl + Q 插入链接 Ctrl + L 插入代码 Ctrl + K 插入图片 Ctrl + G 提升标题 Ctrl + H 有序列表 Ctrl + O 无序列表 Ctrl + U 横线 Ctrl + R 撤销 Ctrl + Z 重做 Ctrl + Y GitHub特有特性复选框列表在列表符号后面加上[]或者[x]代表选中或者未选中情况。示例： 1234567+ [x] C+ [x] C+++ [x] Java+ [x] Qt+ [x] Android+ [ ] C#+ [ ] .NET 效果如下： C C++ Java Qt Android C# .NET emoji表情符号emoji表情使用:EMOJICODE:的格式，详细列表可见：https://www.webpagefx.com/tools/emoji-cheat-sheet/当然现在很多markdown工具或者网站都不支持。 下面列出几个平台的对比： 工具/网站 emoji 简书 否 github 是 有道云笔记 否 st=>start: 开始 op=>operation: My Operation cond=>condition: Yes or No? e=>end st->op->cond cond(yes)->e cond(no)->op{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12} var code = document.getElementById(\"flowchart-0-code\").value; var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-0-options\").value)); var diagram = flowchart.parse(code); diagram.drawSVG(\"flowchart-0\", options);","tags":"markdown"},{"title":"MarkdownPad发生HTML渲染组件出错","url":"/posts/e13690e.html","text":"在安装破解MarkdownPad之后，新建一个文档准备练习下MarkdownPad的使用，结果，很不幸地出现了下面的错误： 根据它的提示跳转到官网上查看了一番，表示很懵逼…. 最终还是借助强大的百度搜到其他小伙伴也遇到过这个问题，现将解决方案总结如下。 下载这个东东： Awesomium 1.6.6 SDK 下载完成后双击exe安装文件开始安装，点击Next： 勾选“I accept the terms in the License Agreement”，点击Next 勾选“Yes,remove the older version.”，点击Next 安装路径可以使用默认的安装路径，也可以更改安装路径，然后选择Typical标准套餐 点击Install开始安装 安装完成Finsh 然后重启MarkdownPad，问题解决。","tags":"markdown"},{"title":"MarkdownPad正版破解与汉化","url":"/posts/19a65e9.html","text":"下载先去官网：http://markdownpad.com/ 下载MarkdownPad，如下图： 安装安装过程很简单，一路NexT下去，可使用默认的安装目录，也可以自定义安装目录，这里不做截图展示。 汉化安装完成后，启动MarkdownPad，在工具栏上面点击Tools-Options，如下图： 在打开的页面下方有个languages的选项，点击English的选项卡弹出选择窗，选中文，点击save and close按钮后就可以看到中文效果，并弹窗“需要重新启动 MarkdownPad”的提示。如下图： 破解注册码1GBPduHjWfJU1mZqcPM3BikjYKF6xKhlKIys3i1MU2eJHqWGImDHzWdD6xhMNLGVpbP2M5SN6bnxn2kSE8qHqNY5QaaRxmO3YSMHxlv2EYpjdwLcPwfeTG7kUdnhKE0vVy4RidP6Y2wZ0q74f47fzsZo45JE2hfQBFi2O9Jldjp1mW8HUpTtLA2a5/sQytXJUQl/QKO0jUQY4pa5CCx20sV1ClOTZtAGngSOJtIOFXK599sBr5aIEFyH0K7H4BoNMiiDMnxt1rD8Vb/ikJdhGMMQr0R4B+L3nWU97eaVPTRKfWGDE8/eAgKzpGwrQQoDh+nzX1xoVQ8NAuH+s4UcSeQ== 邮箱地址Soar360@live.com 使用方式点击帮助-专业版激活在弹出的小窗口输入邮箱Soar360@live.com 授权密钥粘贴上面的注册码.点击确定就激活。现在是2019年5月18日，目前依然有效。","tags":"markdown"},{"title":"","url":"/404/index.html","text":"404 L2Dwidget.init({\"model\":{\"jsonPath\":\"/live2dw/assets/z16.model.json\"},\"display\":{\"position\":\"right\",\"width\":140,\"height\":260},\"mobile\":{\"show\":false},\"log\":false,\"pluginJsPath\":\"lib/\",\"pluginModelPath\":\"assets/\",\"pluginRootPath\":\"live2dw/\",\"tagMode\":false});","tags":""},{"title":"archives","url":"/archives/index.html","text":"","tags":""},{"title":"categories","url":"/categories/index.html","text":"","tags":""},{"title":"tags","url":"/tags/index.html","text":"","tags":""},{"title":"关于我","url":"/about/index.html","text":"个人简介： 王洪博，男，29岁，山东菏泽人，于2013年9月正式成为一名菜鸟级Java攻城狮，至今已有6年。期间有过对编码的兴奋，也有过迷茫，但仍在坚持，不断充实自己。 开博目的： 记录日常阅读的各种技术文档、博客等，对个人认为有意义的知识点做个收集及总结。有些内容并非原创，如有雷同，还请海涵。 座右铭： 雄心不惧泥泞路，展翅翱翔九重天！","tags":""}]}